{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4faf3c9",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7f334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e39782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe9dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_model_cifar10 as create_model\n",
    "from neumeta.utils import (\n",
    "    parse_args, print_omegaconf,\n",
    "    load_checkpoint, save_checkpoint,\n",
    "    set_seed,\n",
    "    get_cifar10, \n",
    "    sample_coordinates, sample_subset, shuffle_coordinates_all,\n",
    "    get_hypernetwork, get_optimizer, \n",
    "    sample_weights,\n",
    "    weighted_regression_loss, validate_single, AverageMeter, EMA,\n",
    "    sample_single_model, sample_merge_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cea0a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad05e8",
   "metadata": {},
   "source": [
    "### 1 Find maximum dimension of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504abeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dim(model_cls):\n",
    "    \"\"\"Find maximum dimension of the model\"\"\"\n",
    "    # Get the learnable parameters of the model\n",
    "    checkpoint = model_cls.learnable_parameter \n",
    "\n",
    "    # Set the maximum value to the length of the checkpoint\n",
    "    max_value = len(checkpoint)\n",
    "\n",
    "    # Iterate over the new model's weight\n",
    "    for i, (k, tensor) in enumerate(checkpoint.items()):\n",
    "        # Handle 2D tensors (e.g., weight matrices) \n",
    "        if len(tensor.shape) == 4:\n",
    "            coords = [tensor.shape[0], tensor.shape[1]]\n",
    "            max_value = max(max_value, max(coords))\n",
    "        # Handle 1D tensors (e.g., biases)\n",
    "        elif len(tensor.shape) == 1:\n",
    "            max_value = max(max_value, tensor.shape[0])\n",
    "    \n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413443e",
   "metadata": {},
   "source": [
    "### 2 Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f49acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(config):\n",
    "    import time\n",
    "    \"\"\"\n",
    "    Initializes Weights and Biases (wandb) with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        configuration (dict): Configuration parameters for the run.\n",
    "    \"\"\"\n",
    "    # Name the run using current time and configuration name\n",
    "    run_name = f\"{time.strftime('%Y%m%d%H%M%S')}-{config.experiment.name}\"\n",
    "    \n",
    "    wandb.init(project=\"ninr-trial\", name=run_name, config=dict(config), group='cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cc73b",
   "metadata": {},
   "source": [
    "### 3 Initialize model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed520bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(args, device):\n",
    "    \"\"\"\n",
    "    Initializes a dictionary of models for each dimension in the given range, along with ground truth models for the starting dimension.\n",
    "\n",
    "    Args:\n",
    "        args: An object containing the arguments for initializing the models.\n",
    "\n",
    "    Returns:\n",
    "        dim_dict: A dictionary containing the models for each dimension, along with their corresponding coordinates, keys, indices, size, and ground truth models.\n",
    "        gt_model_dict: A dictionary containing the ground truth models for the starting dimension.\n",
    "    \"\"\"\n",
    "    dim_dict = {}\n",
    "    gt_model_dict = {}\n",
    "    \n",
    "    # Create a model for each dimension in dimensions range\n",
    "    for dim in args.dimensions.range:\n",
    "        model_cls = create_model(args.model.type,\n",
    "                                 hidden_dim=dim,\n",
    "                                 path=args.model.pretrained_path,\n",
    "                                 smooth=args.model.smooth).to(device)\n",
    "        # Sample the coordinates, keys, indices, and the size for the model\n",
    "        coords_tensor, keys_list, indices_list, size_list = sample_coordinates(model_cls)\n",
    "        # Add the model, coordinates, keys, indices, size, and key mask to the dictionary\n",
    "        dim_dict[f\"{dim}\"] = (model_cls, coords_tensor, keys_list, indices_list, size_list, None)\n",
    "\n",
    "        # Print to makes line better\n",
    "        print('\\n')\n",
    "        \n",
    "        # If the dimension is the starting dimension (the dimension of pretrained_model), add the ground truth model to the dictionary\n",
    "        if dim == args.dimensions.start:\n",
    "            print(f\"Loading model for dim {dim}\")\n",
    "            model_trained = create_model(args.model.type, \n",
    "                                         hidden_dim=dim, \n",
    "                                         path=args.model.pretrained_path, \n",
    "                                         smooth=args.model.smooth).to(device)\n",
    "            model_trained.eval()\n",
    "            gt_model_dict[f'{dim}'] = model_trained\n",
    "\n",
    "    \n",
    "    return dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b8aa0",
   "metadata": {},
   "source": [
    "### 4 Training function for target model of a random dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab93eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, dim_dict, gt_model_dict, epoch_idx, ema=None, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    reconstruct_losses = AverageMeter()\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Preprocess input\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Move the data to the device\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # Choose a random hidden dimension\n",
    "        hidden_dim = random.choice(args.dimensions.range)\n",
    "        # Get the model class, coordinates, keys, indices, size, and key mask for the chosen dimension\n",
    "        model_cls, coords_tensor, keys_list, indices_list, size_list, key_mask = dim_dict[f\"{hidden_dim}\"]\n",
    "        # Sample a subset the input tensor of the coordinates, keys, indices, size, and selected keys\n",
    "        coords_tensor, keys_list, indices_list, size_list, selected_keys = sample_subset(coords_tensor,\n",
    "                                                                                         keys_list,\n",
    "                                                                                         indices_list,\n",
    "                                                                                         size_list,\n",
    "                                                                                         key_mask,\n",
    "                                                                                         ratio=args.ratio)\n",
    "        # Add noise to the coordinates if specified\n",
    "        if args.training.coordinate_noise > 0.0:\n",
    "            coords_tensor = coords_tensor + (torch.rand_like(coords_tensor) - 0.5) * args.training.coordinate_noise\n",
    "\n",
    "\n",
    "        # Main task of hypernetwork and target network\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Sample the weights for the target model using hypernetwork\n",
    "        model_cls, reconstructed_weights = sample_weights(model, model_cls,\n",
    "                                                          coords_tensor, keys_list, indices_list, size_list, key_mask, selected_keys,\n",
    "                                                          device=device, NORM=args.dimensions.norm)\n",
    "        # Forward pass\n",
    "        predict = model_cls(x)\n",
    "\n",
    "\n",
    "        # Compute losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Compute classification loss\n",
    "        cls_loss = criterion(predict, target) \n",
    "        # Compute regularization loss\n",
    "        reg_loss = sum([torch.norm(w, p=2) for w in reconstructed_weights])\n",
    "        # Compute reconstruction loss if ground truth model is available\n",
    "        if f\"{hidden_dim}\" in gt_model_dict:\n",
    "            gt_model = gt_model_dict[f\"{hidden_dim}\"]\n",
    "            gt_selected_weights = [\n",
    "                w for k, w in gt_model.learnable_parameter.items() if k in selected_keys]\n",
    "\n",
    "            reconstruct_loss = weighted_regression_loss(\n",
    "                reconstructed_weights, gt_selected_weights)\n",
    "        else:\n",
    "            reconstruct_loss = torch.tensor(0.0)\n",
    "        # Compute the total loss\n",
    "        loss = args.hyper_model.loss_weight.ce_weight * cls_loss + args.hyper_model.loss_weight.reg_weight * \\\n",
    "            reg_loss + args.hyper_model.loss_weight.recon_weight * reconstruct_loss\n",
    "\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Zero the gradients of the updated weights\n",
    "        for updated_weight in model_cls.parameters():\n",
    "            updated_weight.grad = None\n",
    "\n",
    "        # Compute the gradients of the reconstructed weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.autograd.backward(reconstructed_weights, [\n",
    "                                w.grad for k, w in model_cls.named_parameters() if k in selected_keys])\n",
    "        \n",
    "        # Clip the gradients if specified\n",
    "        if args.training.get('clip_grad', 0.0) > 0:\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), args.training.clip_grad)\n",
    "            \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA if specified\n",
    "        if ema:\n",
    "            ema.update()  # Update the EMA after each training step\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update the AverageMeter objects\n",
    "        losses.update(loss.item())\n",
    "        cls_losses.update(cls_loss.item())\n",
    "        reg_losses.update(reg_loss.item())\n",
    "        reconstruct_losses.update(reconstruct_loss.item())\n",
    "\n",
    "\n",
    "        # Log (or plot) losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Log the losses and learning rate to wandb\n",
    "        if batch_idx % args.experiment.log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"Loss\": losses.avg,\n",
    "                \"Cls Loss\": cls_losses.avg,\n",
    "                \"Reg Loss\": reg_losses.avg,\n",
    "                \"Reconstruct Loss\": reconstruct_losses.avg,\n",
    "                \"Learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }, step=batch_idx + epoch_idx * len(train_loader))\n",
    "            # Print the losses and learning rate\n",
    "            print(\n",
    "                f\"Iteration {batch_idx}: Loss = {losses.avg:.4f}, Reg Loss = {reg_losses.avg:.4f}, Reconstruct Loss = {reconstruct_losses.avg:.4f}, Cls Loss = {cls_losses.avg:.4f}, Learning rate = {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "    \n",
    "    # Returns the training loss, structure of network in each dimension, and the original structure of pretrained network\n",
    "    return losses.avg, dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d8965",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e292aae",
   "metadata": {},
   "source": [
    "### 0 Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670c10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd9af3",
   "metadata": {},
   "source": [
    "### 1 Parsing arguments for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21d5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = 'neumeta/config/cifar10/resnet20_cifar10_32-64v3_200e-coordnoise-resmlpv2_smooth_5_256_16.yaml'\n",
    "RATIO = '1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6fd9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv_train = ['--config', CONFIG_PATH, '--ratio', RATIO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebf601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base config from toy/experiments/base_config.yaml\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                 Key                  |                                                                Value                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|           experiment.name            |                             ninr_resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16                              |\n",
      "|         experiment.recononly         |                                                                  0                                                                   |\n",
      "|        experiment.num_epochs         |                                                                 200                                                                  |\n",
      "|       experiment.log_interval        |                                                                 100                                                                  |\n",
      "|       experiment.eval_interval       |                                                                  1                                                                   |\n",
      "|           experiment.seed            |                                                                  42                                                                  |\n",
      "|              model.type              |                                                               ResNet20                                                               |\n",
      "|        model.pretrained_path         |                                           toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth                                            |\n",
      "|             model.smooth             |                                                                False                                                                 |\n",
      "|        training.learning_rate        |                                                                0.001                                                                 |\n",
      "|         training.batch_size          |                                                                  64                                                                  |\n",
      "|      training.coordinate_noise       |                                                                 1.0                                                                  |\n",
      "|          training.lr_steps           |                                                              [100, 150]                                                              |\n",
      "|        training.weight_decay         |                                                                 0.01                                                                 |\n",
      "|          training.clip_grad          |                                                                 10.0                                                                 |\n",
      "|       training.save_model_path       |                        toy/experiments/resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16                        |\n",
      "|        hyper_model.input_dim         |                                                                  6                                                                   |\n",
      "|        hyper_model.hidden_dim        |                                                                 256                                                                  |\n",
      "|        hyper_model.num_layers        |                                                                  5                                                                   |\n",
      "|        hyper_model.num_freqs         |                                                                  16                                                                  |\n",
      "|        hyper_model.output_dim        |                                                                  9                                                                   |\n",
      "|        hyper_model.ema_decay         |                                                                0.995                                                                 |\n",
      "|  hyper_model.loss_weight.ce_weight   |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.reg_weight  |                                                                0.0001                                                                |\n",
      "| hyper_model.loss_weight.recon_weight |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.kd_weight   |                                                                 0.1                                                                  |\n",
      "|           hyper_model.type           |                                                                resmlp                                                                |\n",
      "|           dimensions.range           | [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64] |\n",
      "|           dimensions.test            |                                                                  32                                                                  |\n",
      "|           dimensions.norm            |                                                                  64                                                                  |\n",
      "|           dimensions.start           |                                                                  64                                                                  |\n",
      "|             base_config              |                                                   toy/experiments/base_config.yaml                                                   |\n",
      "|                config                |                    neumeta/config/cifar10/resnet20_cifar10_32-64v3_200e-coordnoise-resmlpv2_smooth_5_256_16.yaml                     |\n",
      "|                ratio                 |                                                                 1.0                                                                  |\n",
      "|             resume_from              |                                                                 None                                                                 |\n",
      "|              load_from               |                                                                 None                                                                 |\n",
      "|           test_result_path           |                                                                 None                                                                 |\n",
      "|                 test                 |                                                                False                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(argv_train)  # Parse arguments\n",
    "print_omegaconf(args)  # Print arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84954fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed... 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.experiment.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2086b8",
   "metadata": {},
   "source": [
    "### 2 Get training and validation data (in dataloader format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633b90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10(args.training.batch_size, strong_transform=args.training.get('strong_aug', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685e32a",
   "metadata": {},
   "source": [
    "### 3 Create target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d8f75",
   "metadata": {},
   "source": [
    "#### 3.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47436d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args.model.type,\n",
    "                     hidden_dim=args.dimensions.start,\n",
    "                     path=args.model.pretrained_path,\n",
    "                     smooth=args.model.smooth).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb133f",
   "metadata": {},
   "source": [
    "#### 3.1 Print the structure and shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09f9614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): Identity()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock_Resize(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b86d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3.2.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv1.bias torch.Size([64])\n",
      "layer3.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, (k, tensor) in enumerate(model.learnable_parameter.items()):\n",
    "    print(k, tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f7b45",
   "metadata": {},
   "source": [
    "#### 3.2 The maximum dimension of the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad8c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum DIM: 64\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum dimension of the model\n",
    "print(f'Maximum DIM: {find_max_dim(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195929e",
   "metadata": {},
   "source": [
    "#### 3.3 Validate the accuracy of pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d75f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 39.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.2825, Validation Accuracy: 92.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(model, val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb61dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learnable parameters of the model\n",
    "checkpoint = model.learnable_parameter\n",
    "# Get the number of parameters\n",
    "number_param = len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2fe99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters keys: ['layer3.2.conv1.weight', 'layer3.2.conv1.bias', 'layer3.2.conv2.weight', 'layer3.2.conv2.bias']\n",
      "Number of parameters to be learned: 4\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the parameters and the number of parameters\n",
    "print(f\"Parameters keys: {model.keys}\")\n",
    "print(f\"Number of parameters to be learned: {number_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5fa6f",
   "metadata": {},
   "source": [
    "### 4 Create the hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa4a2f",
   "metadata": {},
   "source": [
    "#### 4.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82e9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Get the hypermodel\n",
    "hyper_model = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297bd73",
   "metadata": {},
   "source": [
    "#### 4.1 Print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903829b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_ResMLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-3): 4 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d592e",
   "metadata": {},
   "source": [
    "#### 4.2 Initialize EMA to track only a smooth version of the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a4812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA\n",
    "ema = EMA(hyper_model, decay=args.hyper_model.ema_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffae0",
   "metadata": {},
   "source": [
    "### 5 Get Loss function, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079aa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, val_criterion, optimizer, scheduler = get_optimizer(args, hyper_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7561c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Val_criterion: CrossEntropyLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x00000199546B5BD0>\n"
     ]
    }
   ],
   "source": [
    "print(f'Criterion: {criterion}\\nVal_criterion: {val_criterion}\\nOptimizer: {optimizer}\\nScheduler: {scheduler}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906454",
   "metadata": {},
   "source": [
    "### 6 Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d1d4f",
   "metadata": {},
   "source": [
    "#### 6.1 Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2cdca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting epoch and best accuracy\n",
    "start_epoch = 0\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373217",
   "metadata": {},
   "source": [
    "#### 6.2 Directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35a2746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the model\n",
    "os.makedirs(args.training.save_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504af23",
   "metadata": {},
   "source": [
    "#### 6.3 Resume training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "714db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_from:\n",
    "        print(f\"Resuming from checkpoint: {args.resume_from}\")\n",
    "        checkpoint_info = load_checkpoint(args.resume_from, hyper_model, optimizer, ema)\n",
    "        start_epoch = checkpoint_info['epoch']\n",
    "        best_acc = checkpoint_info['best_acc']\n",
    "        print(f\"Resuming from epoch: {start_epoch}, best accuracy: {best_acc*100:.2f}%\")\n",
    "        # Note: If there are more elements to retrieve, do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a3248",
   "metadata": {},
   "source": [
    "#### 6.4 Initialize wandb for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9fd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mefradosuryadi\u001b[0m (\u001b[33mefradosuryadi-universitas-indonesia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\wandb\\run-20250520_015347-quvsqrph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/quvsqrph' target=\"_blank\">20250520015346-ninr_resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16</a></strong> to <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/quvsqrph' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/quvsqrph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "initialize_wandb(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46056e65",
   "metadata": {},
   "source": [
    "#### 6.5 Initialize model dictionary for each dimension and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641149b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Loading model for dim 64\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n"
     ]
    }
   ],
   "source": [
    "# Initialize model dictionary\n",
    "dim_dict, gt_model_dict = init_model_dict(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d01d9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'64': CifarResNet(\n",
       "   (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn1): Identity()\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock_Resize(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26d9c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7476d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict = shuffle_coordinates_all(dim_dict)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d6ad4",
   "metadata": {},
   "source": [
    "#### 6.6 Hypernetwork training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332580b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.experiment.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f486f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 1.9313, Reg Loss = 3.5250, Reconstruct Loss = 0.0000, Cls Loss = 1.9310, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9304, Reg Loss = 6.4627, Reconstruct Loss = 0.0008, Cls Loss = 1.9290, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8972, Reg Loss = 5.9850, Reconstruct Loss = 0.0012, Cls Loss = 1.8954, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8830, Reg Loss = 6.1283, Reconstruct Loss = 0.0013, Cls Loss = 1.8811, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8735, Reg Loss = 6.5342, Reconstruct Loss = 0.0013, Cls Loss = 1.8716, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8686, Reg Loss = 6.7784, Reconstruct Loss = 0.0012, Cls Loss = 1.8667, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8639, Reg Loss = 6.8017, Reconstruct Loss = 0.0011, Cls Loss = 1.8621, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8618, Reg Loss = 7.2133, Reconstruct Loss = 0.0009, Cls Loss = 1.8602, Learning rate = 1.0000e-03\n",
      "Epoch [1/200], Training Loss: 1.8600, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Validation Loss: 1.8112, Validation Accuracy: 72.10%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 0 with accuracy: 72.10%\n",
      "Iteration 0: Loss = 1.7838, Reg Loss = 9.1052, Reconstruct Loss = 0.0000, Cls Loss = 1.7829, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8466, Reg Loss = 7.3239, Reconstruct Loss = 0.0013, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8465, Reg Loss = 6.4827, Reconstruct Loss = 0.0009, Cls Loss = 1.8450, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8455, Reg Loss = 6.0528, Reconstruct Loss = 0.0008, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8456, Reg Loss = 6.2221, Reconstruct Loss = 0.0009, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8442, Reg Loss = 6.6371, Reconstruct Loss = 0.0010, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8431, Reg Loss = 7.2685, Reconstruct Loss = 0.0013, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8408, Reg Loss = 8.0363, Reconstruct Loss = 0.0014, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Epoch [2/200], Training Loss: 1.8411, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Validation Loss: 1.8076, Validation Accuracy: 73.30%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 1 with accuracy: 73.30%\n",
      "Iteration 0: Loss = 1.8247, Reg Loss = 22.2345, Reconstruct Loss = 0.0000, Cls Loss = 1.8225, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8435, Reg Loss = 21.4041, Reconstruct Loss = 0.0014, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8460, Reg Loss = 19.0769, Reconstruct Loss = 0.0019, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8448, Reg Loss = 15.7357, Reconstruct Loss = 0.0016, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8446, Reg Loss = 15.3516, Reconstruct Loss = 0.0016, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8448, Reg Loss = 14.9491, Reconstruct Loss = 0.0014, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8419, Reg Loss = 14.8255, Reconstruct Loss = 0.0014, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8393, Reg Loss = 15.2683, Reconstruct Loss = 0.0013, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Epoch [3/200], Training Loss: 1.8375, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Validation Loss: 1.8069, Validation Accuracy: 76.17%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 2 with accuracy: 76.17%\n",
      "Iteration 0: Loss = 1.7906, Reg Loss = 24.8349, Reconstruct Loss = 0.0000, Cls Loss = 1.7881, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8172, Reg Loss = 23.2011, Reconstruct Loss = 0.0017, Cls Loss = 1.8132, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8206, Reg Loss = 25.0363, Reconstruct Loss = 0.0019, Cls Loss = 1.8162, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8073, Reg Loss = 24.6850, Reconstruct Loss = 0.0017, Cls Loss = 1.8031, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7878, Reg Loss = 23.8576, Reconstruct Loss = 0.0016, Cls Loss = 1.7838, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7729, Reg Loss = 23.1655, Reconstruct Loss = 0.0015, Cls Loss = 1.7691, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7534, Reg Loss = 22.8983, Reconstruct Loss = 0.0013, Cls Loss = 1.7498, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7311, Reg Loss = 22.9125, Reconstruct Loss = 0.0012, Cls Loss = 1.7276, Learning rate = 1.0000e-03\n",
      "Epoch [4/200], Training Loss: 1.7173, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Validation Loss: 1.6370, Validation Accuracy: 56.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5563, Reg Loss = 21.9539, Reconstruct Loss = 0.0000, Cls Loss = 1.5541, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5353, Reg Loss = 24.4398, Reconstruct Loss = 0.0004, Cls Loss = 1.5324, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.5375, Reg Loss = 24.5858, Reconstruct Loss = 0.0013, Cls Loss = 1.5338, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.5256, Reg Loss = 24.9221, Reconstruct Loss = 0.0013, Cls Loss = 1.5218, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.5163, Reg Loss = 25.1194, Reconstruct Loss = 0.0013, Cls Loss = 1.5124, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.5118, Reg Loss = 25.3531, Reconstruct Loss = 0.0013, Cls Loss = 1.5079, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.5116, Reg Loss = 25.4439, Reconstruct Loss = 0.0016, Cls Loss = 1.5075, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.5074, Reg Loss = 25.4582, Reconstruct Loss = 0.0017, Cls Loss = 1.5031, Learning rate = 1.0000e-03\n",
      "Epoch [5/200], Training Loss: 1.5013, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Validation Loss: 1.4108, Validation Accuracy: 63.67%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.4245, Reg Loss = 27.0944, Reconstruct Loss = 0.0000, Cls Loss = 1.4218, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.4532, Reg Loss = 27.3626, Reconstruct Loss = 0.0028, Cls Loss = 1.4477, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.4439, Reg Loss = 27.6877, Reconstruct Loss = 0.0025, Cls Loss = 1.4386, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.4396, Reg Loss = 28.0465, Reconstruct Loss = 0.0024, Cls Loss = 1.4344, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.4395, Reg Loss = 28.4425, Reconstruct Loss = 0.0020, Cls Loss = 1.4346, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.4394, Reg Loss = 28.9759, Reconstruct Loss = 0.0017, Cls Loss = 1.4348, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4375, Reg Loss = 29.5487, Reconstruct Loss = 0.0014, Cls Loss = 1.4331, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4333, Reg Loss = 30.0735, Reconstruct Loss = 0.0013, Cls Loss = 1.4290, Learning rate = 1.0000e-03\n",
      "Epoch [6/200], Training Loss: 1.4321, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Validation Loss: 1.3664, Validation Accuracy: 59.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.4885, Reg Loss = 33.4882, Reconstruct Loss = 0.0000, Cls Loss = 1.4852, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.3979, Reg Loss = 35.9634, Reconstruct Loss = 0.0024, Cls Loss = 1.3919, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.3926, Reg Loss = 36.1341, Reconstruct Loss = 0.0019, Cls Loss = 1.3871, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.3827, Reg Loss = 37.1761, Reconstruct Loss = 0.0016, Cls Loss = 1.3774, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.3760, Reg Loss = 38.1074, Reconstruct Loss = 0.0014, Cls Loss = 1.3709, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.3711, Reg Loss = 38.7197, Reconstruct Loss = 0.0015, Cls Loss = 1.3658, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.3661, Reg Loss = 39.0132, Reconstruct Loss = 0.0014, Cls Loss = 1.3608, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.3597, Reg Loss = 39.3659, Reconstruct Loss = 0.0014, Cls Loss = 1.3544, Learning rate = 1.0000e-03\n",
      "Epoch [7/200], Training Loss: 1.3534, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Validation Loss: 1.2873, Validation Accuracy: 53.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.3570, Reg Loss = 43.1656, Reconstruct Loss = 0.0000, Cls Loss = 1.3527, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.3127, Reg Loss = 43.8934, Reconstruct Loss = 0.0000, Cls Loss = 1.3083, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.3087, Reg Loss = 44.4728, Reconstruct Loss = 0.0004, Cls Loss = 1.3039, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.3051, Reg Loss = 44.3598, Reconstruct Loss = 0.0006, Cls Loss = 1.3001, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.3021, Reg Loss = 44.9020, Reconstruct Loss = 0.0006, Cls Loss = 1.2970, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.2925, Reg Loss = 45.7507, Reconstruct Loss = 0.0008, Cls Loss = 1.2871, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.2879, Reg Loss = 46.1325, Reconstruct Loss = 0.0010, Cls Loss = 1.2822, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.2881, Reg Loss = 46.4115, Reconstruct Loss = 0.0012, Cls Loss = 1.2823, Learning rate = 1.0000e-03\n",
      "Epoch [8/200], Training Loss: 1.2861, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Validation Loss: 1.2727, Validation Accuracy: 53.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.2882, Reg Loss = 47.7447, Reconstruct Loss = 0.0000, Cls Loss = 1.2834, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.2598, Reg Loss = 49.3179, Reconstruct Loss = 0.0014, Cls Loss = 1.2535, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.2523, Reg Loss = 49.2663, Reconstruct Loss = 0.0022, Cls Loss = 1.2452, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.2509, Reg Loss = 49.6246, Reconstruct Loss = 0.0017, Cls Loss = 1.2443, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.2433, Reg Loss = 50.1058, Reconstruct Loss = 0.0014, Cls Loss = 1.2369, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.2376, Reg Loss = 50.0606, Reconstruct Loss = 0.0014, Cls Loss = 1.2311, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.2330, Reg Loss = 50.3788, Reconstruct Loss = 0.0015, Cls Loss = 1.2265, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.2299, Reg Loss = 50.8538, Reconstruct Loss = 0.0017, Cls Loss = 1.2231, Learning rate = 1.0000e-03\n",
      "Epoch [9/200], Training Loss: 1.2248, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Validation Loss: 1.1853, Validation Accuracy: 54.92%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.0543, Reg Loss = 60.0026, Reconstruct Loss = 0.0000, Cls Loss = 1.0483, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.1875, Reg Loss = 54.7306, Reconstruct Loss = 0.0029, Cls Loss = 1.1791, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.1721, Reg Loss = 56.6491, Reconstruct Loss = 0.0024, Cls Loss = 1.1641, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.1614, Reg Loss = 57.9571, Reconstruct Loss = 0.0024, Cls Loss = 1.1532, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.1541, Reg Loss = 58.2189, Reconstruct Loss = 0.0023, Cls Loss = 1.1460, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.1481, Reg Loss = 58.1669, Reconstruct Loss = 0.0020, Cls Loss = 1.1403, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.1374, Reg Loss = 58.5898, Reconstruct Loss = 0.0019, Cls Loss = 1.1297, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.1311, Reg Loss = 59.5238, Reconstruct Loss = 0.0022, Cls Loss = 1.1229, Learning rate = 1.0000e-03\n",
      "Epoch [10/200], Training Loss: 1.1243, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Validation Loss: 1.0778, Validation Accuracy: 61.71%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.0498, Reg Loss = 62.5384, Reconstruct Loss = 0.0000, Cls Loss = 1.0435, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.0579, Reg Loss = 68.7886, Reconstruct Loss = 0.0020, Cls Loss = 1.0490, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.0421, Reg Loss = 68.6723, Reconstruct Loss = 0.0017, Cls Loss = 1.0336, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0325, Reg Loss = 67.8888, Reconstruct Loss = 0.0018, Cls Loss = 1.0238, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0271, Reg Loss = 67.3799, Reconstruct Loss = 0.0020, Cls Loss = 1.0184, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0194, Reg Loss = 67.5528, Reconstruct Loss = 0.0019, Cls Loss = 1.0108, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0087, Reg Loss = 67.6434, Reconstruct Loss = 0.0017, Cls Loss = 1.0002, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0011, Reg Loss = 68.3675, Reconstruct Loss = 0.0018, Cls Loss = 0.9925, Learning rate = 1.0000e-03\n",
      "Epoch [11/200], Training Loss: 0.9899, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Validation Loss: 0.9035, Validation Accuracy: 70.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8686, Reg Loss = 65.2133, Reconstruct Loss = 0.0000, Cls Loss = 0.8621, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8923, Reg Loss = 70.0278, Reconstruct Loss = 0.0040, Cls Loss = 0.8813, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8996, Reg Loss = 70.1911, Reconstruct Loss = 0.0033, Cls Loss = 0.8893, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8925, Reg Loss = 70.2188, Reconstruct Loss = 0.0030, Cls Loss = 0.8825, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8830, Reg Loss = 70.7468, Reconstruct Loss = 0.0026, Cls Loss = 0.8734, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8707, Reg Loss = 71.0554, Reconstruct Loss = 0.0022, Cls Loss = 0.8614, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8637, Reg Loss = 71.8898, Reconstruct Loss = 0.0020, Cls Loss = 0.8545, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8612, Reg Loss = 71.6871, Reconstruct Loss = 0.0020, Cls Loss = 0.8520, Learning rate = 1.0000e-03\n",
      "Epoch [12/200], Training Loss: 0.8553, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Validation Loss: 0.8150, Validation Accuracy: 72.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8906, Reg Loss = 78.0828, Reconstruct Loss = 0.0000, Cls Loss = 0.8828, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7866, Reg Loss = 71.3928, Reconstruct Loss = 0.0017, Cls Loss = 0.7778, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7822, Reg Loss = 71.9564, Reconstruct Loss = 0.0011, Cls Loss = 0.7739, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7707, Reg Loss = 73.1748, Reconstruct Loss = 0.0012, Cls Loss = 0.7622, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7682, Reg Loss = 72.7592, Reconstruct Loss = 0.0009, Cls Loss = 0.7600, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7596, Reg Loss = 72.7179, Reconstruct Loss = 0.0012, Cls Loss = 0.7511, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7502, Reg Loss = 72.6391, Reconstruct Loss = 0.0012, Cls Loss = 0.7418, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7414, Reg Loss = 72.8744, Reconstruct Loss = 0.0012, Cls Loss = 0.7329, Learning rate = 1.0000e-03\n",
      "Epoch [13/200], Training Loss: 0.7383, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Validation Loss: 0.6946, Validation Accuracy: 76.21%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 12 with accuracy: 76.21%\n",
      "Iteration 0: Loss = 0.6381, Reg Loss = 76.9092, Reconstruct Loss = 0.0000, Cls Loss = 0.6304, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7118, Reg Loss = 72.5321, Reconstruct Loss = 0.0024, Cls Loss = 0.7022, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.6936, Reg Loss = 72.5761, Reconstruct Loss = 0.0016, Cls Loss = 0.6847, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.6799, Reg Loss = 73.0760, Reconstruct Loss = 0.0012, Cls Loss = 0.6714, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.6714, Reg Loss = 73.5276, Reconstruct Loss = 0.0017, Cls Loss = 0.6624, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.6682, Reg Loss = 74.1688, Reconstruct Loss = 0.0019, Cls Loss = 0.6589, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.6663, Reg Loss = 74.0653, Reconstruct Loss = 0.0018, Cls Loss = 0.6571, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.6624, Reg Loss = 73.9378, Reconstruct Loss = 0.0017, Cls Loss = 0.6534, Learning rate = 1.0000e-03\n",
      "Epoch [14/200], Training Loss: 0.6586, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Validation Loss: 0.6371, Validation Accuracy: 78.06%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 13 with accuracy: 78.06%\n",
      "Iteration 0: Loss = 0.4901, Reg Loss = 79.0048, Reconstruct Loss = 0.0000, Cls Loss = 0.4822, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.6406, Reg Loss = 73.9503, Reconstruct Loss = 0.0004, Cls Loss = 0.6328, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.6373, Reg Loss = 74.7787, Reconstruct Loss = 0.0009, Cls Loss = 0.6289, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.6308, Reg Loss = 75.0554, Reconstruct Loss = 0.0012, Cls Loss = 0.6221, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.6262, Reg Loss = 75.9007, Reconstruct Loss = 0.0011, Cls Loss = 0.6175, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.6188, Reg Loss = 75.7900, Reconstruct Loss = 0.0013, Cls Loss = 0.6100, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.6151, Reg Loss = 76.2214, Reconstruct Loss = 0.0013, Cls Loss = 0.6061, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.6094, Reg Loss = 76.5186, Reconstruct Loss = 0.0014, Cls Loss = 0.6003, Learning rate = 1.0000e-03\n",
      "Epoch [15/200], Training Loss: 0.6005, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Validation Loss: 0.5954, Validation Accuracy: 79.80%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 14 with accuracy: 79.80%\n",
      "Iteration 0: Loss = 0.5261, Reg Loss = 76.8553, Reconstruct Loss = 0.0000, Cls Loss = 0.5185, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.5558, Reg Loss = 76.3616, Reconstruct Loss = 0.0024, Cls Loss = 0.5457, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.5527, Reg Loss = 77.0053, Reconstruct Loss = 0.0019, Cls Loss = 0.5430, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.5599, Reg Loss = 77.1637, Reconstruct Loss = 0.0018, Cls Loss = 0.5504, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.5566, Reg Loss = 77.6193, Reconstruct Loss = 0.0017, Cls Loss = 0.5471, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.5499, Reg Loss = 77.6346, Reconstruct Loss = 0.0016, Cls Loss = 0.5406, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.5457, Reg Loss = 78.1508, Reconstruct Loss = 0.0015, Cls Loss = 0.5364, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.5449, Reg Loss = 78.3990, Reconstruct Loss = 0.0013, Cls Loss = 0.5357, Learning rate = 1.0000e-03\n",
      "Epoch [16/200], Training Loss: 0.5421, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Validation Loss: 0.6019, Validation Accuracy: 79.92%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 15 with accuracy: 79.92%\n",
      "Iteration 0: Loss = 0.5308, Reg Loss = 75.4683, Reconstruct Loss = 0.0000, Cls Loss = 0.5232, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.5163, Reg Loss = 80.4691, Reconstruct Loss = 0.0005, Cls Loss = 0.5078, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.5225, Reg Loss = 81.3879, Reconstruct Loss = 0.0010, Cls Loss = 0.5134, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.5184, Reg Loss = 81.8619, Reconstruct Loss = 0.0010, Cls Loss = 0.5092, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.5117, Reg Loss = 82.9929, Reconstruct Loss = 0.0008, Cls Loss = 0.5026, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.5072, Reg Loss = 82.7028, Reconstruct Loss = 0.0007, Cls Loss = 0.4983, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.4996, Reg Loss = 82.9915, Reconstruct Loss = 0.0009, Cls Loss = 0.4904, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.4915, Reg Loss = 83.1384, Reconstruct Loss = 0.0008, Cls Loss = 0.4823, Learning rate = 1.0000e-03\n",
      "Epoch [17/200], Training Loss: 0.4881, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200], Validation Loss: 0.5337, Validation Accuracy: 82.26%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 16 with accuracy: 82.26%\n",
      "Iteration 0: Loss = 0.4016, Reg Loss = 80.9576, Reconstruct Loss = 0.0000, Cls Loss = 0.3935, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.4628, Reg Loss = 86.8295, Reconstruct Loss = 0.0015, Cls Loss = 0.4526, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.4574, Reg Loss = 86.1904, Reconstruct Loss = 0.0022, Cls Loss = 0.4466, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.4453, Reg Loss = 86.4825, Reconstruct Loss = 0.0016, Cls Loss = 0.4350, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.4472, Reg Loss = 86.7567, Reconstruct Loss = 0.0017, Cls Loss = 0.4369, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.4505, Reg Loss = 86.7000, Reconstruct Loss = 0.0017, Cls Loss = 0.4401, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.4492, Reg Loss = 87.0534, Reconstruct Loss = 0.0019, Cls Loss = 0.4386, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.4501, Reg Loss = 86.9726, Reconstruct Loss = 0.0017, Cls Loss = 0.4397, Learning rate = 1.0000e-03\n",
      "Epoch [18/200], Training Loss: 0.4478, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200], Validation Loss: 0.5136, Validation Accuracy: 83.55%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 17 with accuracy: 83.55%\n",
      "Iteration 0: Loss = 0.6153, Reg Loss = 88.1504, Reconstruct Loss = 0.0000, Cls Loss = 0.6065, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.4588, Reg Loss = 88.5597, Reconstruct Loss = 0.0022, Cls Loss = 0.4477, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.4385, Reg Loss = 88.1929, Reconstruct Loss = 0.0024, Cls Loss = 0.4272, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.4336, Reg Loss = 87.7210, Reconstruct Loss = 0.0020, Cls Loss = 0.4228, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.4254, Reg Loss = 87.6312, Reconstruct Loss = 0.0019, Cls Loss = 0.4147, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.4221, Reg Loss = 87.9788, Reconstruct Loss = 0.0019, Cls Loss = 0.4114, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.4166, Reg Loss = 88.1813, Reconstruct Loss = 0.0018, Cls Loss = 0.4060, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.4107, Reg Loss = 88.3241, Reconstruct Loss = 0.0017, Cls Loss = 0.4002, Learning rate = 1.0000e-03\n",
      "Epoch [19/200], Training Loss: 0.4058, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Validation Loss: 0.5011, Validation Accuracy: 83.53%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6390, Reg Loss = 80.1930, Reconstruct Loss = 0.0000, Cls Loss = 0.6310, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.3955, Reg Loss = 89.6672, Reconstruct Loss = 0.0007, Cls Loss = 0.3859, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.3962, Reg Loss = 89.4074, Reconstruct Loss = 0.0007, Cls Loss = 0.3865, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.3892, Reg Loss = 89.3701, Reconstruct Loss = 0.0013, Cls Loss = 0.3790, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.3870, Reg Loss = 89.1254, Reconstruct Loss = 0.0014, Cls Loss = 0.3766, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.3831, Reg Loss = 89.3421, Reconstruct Loss = 0.0015, Cls Loss = 0.3727, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.3807, Reg Loss = 89.7085, Reconstruct Loss = 0.0015, Cls Loss = 0.3702, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.3774, Reg Loss = 89.9087, Reconstruct Loss = 0.0016, Cls Loss = 0.3669, Learning rate = 1.0000e-03\n",
      "Epoch [20/200], Training Loss: 0.3763, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Validation Loss: 0.5382, Validation Accuracy: 83.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3612, Reg Loss = 93.3406, Reconstruct Loss = 0.0598, Cls Loss = 0.2921, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.3668, Reg Loss = 87.1547, Reconstruct Loss = 0.0018, Cls Loss = 0.3563, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.3659, Reg Loss = 88.1636, Reconstruct Loss = 0.0021, Cls Loss = 0.3550, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.3653, Reg Loss = 88.5644, Reconstruct Loss = 0.0022, Cls Loss = 0.3542, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.3636, Reg Loss = 88.9402, Reconstruct Loss = 0.0021, Cls Loss = 0.3526, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.3603, Reg Loss = 89.1731, Reconstruct Loss = 0.0018, Cls Loss = 0.3496, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.3576, Reg Loss = 89.1110, Reconstruct Loss = 0.0019, Cls Loss = 0.3468, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.3540, Reg Loss = 89.1506, Reconstruct Loss = 0.0016, Cls Loss = 0.3434, Learning rate = 1.0000e-03\n",
      "Epoch [21/200], Training Loss: 0.3528, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Validation Loss: 0.5032, Validation Accuracy: 84.64%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 20 with accuracy: 84.64%\n",
      "Iteration 0: Loss = 0.2494, Reg Loss = 92.7343, Reconstruct Loss = 0.0000, Cls Loss = 0.2401, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.3374, Reg Loss = 88.7966, Reconstruct Loss = 0.0011, Cls Loss = 0.3275, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.3323, Reg Loss = 88.3409, Reconstruct Loss = 0.0031, Cls Loss = 0.3204, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.3275, Reg Loss = 88.3680, Reconstruct Loss = 0.0028, Cls Loss = 0.3159, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.3288, Reg Loss = 88.9431, Reconstruct Loss = 0.0024, Cls Loss = 0.3175, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.3263, Reg Loss = 89.3560, Reconstruct Loss = 0.0023, Cls Loss = 0.3151, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.3257, Reg Loss = 89.5250, Reconstruct Loss = 0.0024, Cls Loss = 0.3144, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.3294, Reg Loss = 89.0742, Reconstruct Loss = 0.0025, Cls Loss = 0.3180, Learning rate = 1.0000e-03\n",
      "Epoch [22/200], Training Loss: 0.3302, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200], Validation Loss: 0.5011, Validation Accuracy: 84.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1288, Reg Loss = 85.7899, Reconstruct Loss = 0.0000, Cls Loss = 0.1202, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.3131, Reg Loss = 87.0813, Reconstruct Loss = 0.0024, Cls Loss = 0.3020, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.3123, Reg Loss = 86.8124, Reconstruct Loss = 0.0020, Cls Loss = 0.3016, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.3152, Reg Loss = 87.0748, Reconstruct Loss = 0.0016, Cls Loss = 0.3049, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.3137, Reg Loss = 87.2029, Reconstruct Loss = 0.0016, Cls Loss = 0.3034, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.3130, Reg Loss = 87.5640, Reconstruct Loss = 0.0018, Cls Loss = 0.3025, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.3157, Reg Loss = 87.3617, Reconstruct Loss = 0.0017, Cls Loss = 0.3053, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.3169, Reg Loss = 87.4149, Reconstruct Loss = 0.0017, Cls Loss = 0.3064, Learning rate = 1.0000e-03\n",
      "Epoch [23/200], Training Loss: 0.3136, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200], Validation Loss: 0.4223, Validation Accuracy: 86.81%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 22 with accuracy: 86.81%\n",
      "Iteration 0: Loss = 0.3170, Reg Loss = 86.4193, Reconstruct Loss = 0.0000, Cls Loss = 0.3084, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.3072, Reg Loss = 86.3684, Reconstruct Loss = 0.0006, Cls Loss = 0.2980, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.3056, Reg Loss = 85.9448, Reconstruct Loss = 0.0016, Cls Loss = 0.2954, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.3032, Reg Loss = 86.2001, Reconstruct Loss = 0.0013, Cls Loss = 0.2933, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2996, Reg Loss = 86.7224, Reconstruct Loss = 0.0010, Cls Loss = 0.2899, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.3012, Reg Loss = 86.8259, Reconstruct Loss = 0.0009, Cls Loss = 0.2916, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2987, Reg Loss = 86.7916, Reconstruct Loss = 0.0008, Cls Loss = 0.2892, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2971, Reg Loss = 86.5091, Reconstruct Loss = 0.0010, Cls Loss = 0.2875, Learning rate = 1.0000e-03\n",
      "Epoch [24/200], Training Loss: 0.2956, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Validation Loss: 0.4374, Validation Accuracy: 86.51%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1047, Reg Loss = 88.1506, Reconstruct Loss = 0.0000, Cls Loss = 0.0958, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2784, Reg Loss = 83.7702, Reconstruct Loss = 0.0021, Cls Loss = 0.2680, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2776, Reg Loss = 84.9277, Reconstruct Loss = 0.0023, Cls Loss = 0.2668, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2741, Reg Loss = 84.5100, Reconstruct Loss = 0.0024, Cls Loss = 0.2632, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2778, Reg Loss = 84.5169, Reconstruct Loss = 0.0019, Cls Loss = 0.2674, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2789, Reg Loss = 84.6954, Reconstruct Loss = 0.0017, Cls Loss = 0.2687, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2765, Reg Loss = 84.5239, Reconstruct Loss = 0.0018, Cls Loss = 0.2662, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2760, Reg Loss = 84.6445, Reconstruct Loss = 0.0018, Cls Loss = 0.2657, Learning rate = 1.0000e-03\n",
      "Epoch [25/200], Training Loss: 0.2737, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200], Validation Loss: 0.4046, Validation Accuracy: 87.59%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 24 with accuracy: 87.59%\n",
      "Iteration 0: Loss = 0.3554, Reg Loss = 78.4504, Reconstruct Loss = 0.0000, Cls Loss = 0.3475, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2620, Reg Loss = 82.1153, Reconstruct Loss = 0.0035, Cls Loss = 0.2503, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2766, Reg Loss = 81.7319, Reconstruct Loss = 0.0018, Cls Loss = 0.2667, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2732, Reg Loss = 82.2368, Reconstruct Loss = 0.0013, Cls Loss = 0.2637, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2762, Reg Loss = 82.6520, Reconstruct Loss = 0.0017, Cls Loss = 0.2663, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2745, Reg Loss = 82.8604, Reconstruct Loss = 0.0019, Cls Loss = 0.2644, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2701, Reg Loss = 83.2036, Reconstruct Loss = 0.0016, Cls Loss = 0.2601, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2704, Reg Loss = 83.4308, Reconstruct Loss = 0.0017, Cls Loss = 0.2603, Learning rate = 1.0000e-03\n",
      "Epoch [26/200], Training Loss: 0.2672, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200], Validation Loss: 0.5401, Validation Accuracy: 85.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1741, Reg Loss = 79.5055, Reconstruct Loss = 0.0000, Cls Loss = 0.1662, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2487, Reg Loss = 81.2577, Reconstruct Loss = 0.0009, Cls Loss = 0.2396, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2582, Reg Loss = 81.5721, Reconstruct Loss = 0.0015, Cls Loss = 0.2486, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2552, Reg Loss = 81.3240, Reconstruct Loss = 0.0013, Cls Loss = 0.2457, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2564, Reg Loss = 81.2365, Reconstruct Loss = 0.0010, Cls Loss = 0.2473, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2543, Reg Loss = 81.1819, Reconstruct Loss = 0.0010, Cls Loss = 0.2452, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2529, Reg Loss = 81.2368, Reconstruct Loss = 0.0010, Cls Loss = 0.2438, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2491, Reg Loss = 81.0194, Reconstruct Loss = 0.0010, Cls Loss = 0.2400, Learning rate = 1.0000e-03\n",
      "Epoch [27/200], Training Loss: 0.2477, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200], Validation Loss: 0.4188, Validation Accuracy: 87.73%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 26 with accuracy: 87.73%\n",
      "Iteration 0: Loss = 0.1634, Reg Loss = 87.2959, Reconstruct Loss = 0.0000, Cls Loss = 0.1547, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2516, Reg Loss = 83.1771, Reconstruct Loss = 0.0014, Cls Loss = 0.2419, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2591, Reg Loss = 81.8360, Reconstruct Loss = 0.0026, Cls Loss = 0.2483, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2606, Reg Loss = 81.1554, Reconstruct Loss = 0.0025, Cls Loss = 0.2500, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2542, Reg Loss = 81.1840, Reconstruct Loss = 0.0021, Cls Loss = 0.2440, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2518, Reg Loss = 81.2136, Reconstruct Loss = 0.0018, Cls Loss = 0.2419, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2519, Reg Loss = 80.9837, Reconstruct Loss = 0.0015, Cls Loss = 0.2423, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2488, Reg Loss = 80.7293, Reconstruct Loss = 0.0016, Cls Loss = 0.2391, Learning rate = 1.0000e-03\n",
      "Epoch [28/200], Training Loss: 0.2468, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200], Validation Loss: 0.4014, Validation Accuracy: 87.79%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 27 with accuracy: 87.79%\n",
      "Iteration 0: Loss = 0.1387, Reg Loss = 84.0667, Reconstruct Loss = 0.0000, Cls Loss = 0.1303, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2381, Reg Loss = 79.5073, Reconstruct Loss = 0.0005, Cls Loss = 0.2297, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2399, Reg Loss = 79.8752, Reconstruct Loss = 0.0005, Cls Loss = 0.2314, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2414, Reg Loss = 80.2188, Reconstruct Loss = 0.0007, Cls Loss = 0.2327, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2422, Reg Loss = 80.2758, Reconstruct Loss = 0.0013, Cls Loss = 0.2329, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2385, Reg Loss = 80.1948, Reconstruct Loss = 0.0014, Cls Loss = 0.2291, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2369, Reg Loss = 79.8667, Reconstruct Loss = 0.0014, Cls Loss = 0.2275, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2373, Reg Loss = 79.9607, Reconstruct Loss = 0.0017, Cls Loss = 0.2276, Learning rate = 1.0000e-03\n",
      "Epoch [29/200], Training Loss: 0.2352, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200], Validation Loss: 0.3985, Validation Accuracy: 87.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1144, Reg Loss = 78.0345, Reconstruct Loss = 0.0000, Cls Loss = 0.1066, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2326, Reg Loss = 80.4040, Reconstruct Loss = 0.0018, Cls Loss = 0.2227, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2260, Reg Loss = 80.0645, Reconstruct Loss = 0.0011, Cls Loss = 0.2168, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2287, Reg Loss = 80.1139, Reconstruct Loss = 0.0011, Cls Loss = 0.2196, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2292, Reg Loss = 80.2118, Reconstruct Loss = 0.0009, Cls Loss = 0.2202, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2266, Reg Loss = 80.3512, Reconstruct Loss = 0.0010, Cls Loss = 0.2175, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2274, Reg Loss = 80.4685, Reconstruct Loss = 0.0012, Cls Loss = 0.2182, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2265, Reg Loss = 80.7310, Reconstruct Loss = 0.0011, Cls Loss = 0.2173, Learning rate = 1.0000e-03\n",
      "Epoch [30/200], Training Loss: 0.2266, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Validation Loss: 0.4002, Validation Accuracy: 88.01%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 29 with accuracy: 88.01%\n",
      "Iteration 0: Loss = 0.1927, Reg Loss = 87.3292, Reconstruct Loss = 0.0000, Cls Loss = 0.1840, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2172, Reg Loss = 81.7535, Reconstruct Loss = 0.0018, Cls Loss = 0.2072, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2176, Reg Loss = 81.4654, Reconstruct Loss = 0.0013, Cls Loss = 0.2081, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2241, Reg Loss = 81.5759, Reconstruct Loss = 0.0012, Cls Loss = 0.2148, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2231, Reg Loss = 81.6512, Reconstruct Loss = 0.0011, Cls Loss = 0.2138, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2216, Reg Loss = 81.8695, Reconstruct Loss = 0.0011, Cls Loss = 0.2123, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2196, Reg Loss = 81.9720, Reconstruct Loss = 0.0010, Cls Loss = 0.2104, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2186, Reg Loss = 81.9601, Reconstruct Loss = 0.0012, Cls Loss = 0.2091, Learning rate = 1.0000e-03\n",
      "Epoch [31/200], Training Loss: 0.2181, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 83.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200], Validation Loss: 0.4084, Validation Accuracy: 88.23%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 30 with accuracy: 88.23%\n",
      "Iteration 0: Loss = 0.2058, Reg Loss = 79.7772, Reconstruct Loss = 0.0000, Cls Loss = 0.1978, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2129, Reg Loss = 79.9465, Reconstruct Loss = 0.0008, Cls Loss = 0.2041, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2077, Reg Loss = 80.7190, Reconstruct Loss = 0.0013, Cls Loss = 0.1983, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2017, Reg Loss = 81.2155, Reconstruct Loss = 0.0013, Cls Loss = 0.1922, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2066, Reg Loss = 80.9439, Reconstruct Loss = 0.0013, Cls Loss = 0.1972, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2070, Reg Loss = 81.0792, Reconstruct Loss = 0.0013, Cls Loss = 0.1976, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2050, Reg Loss = 81.4519, Reconstruct Loss = 0.0011, Cls Loss = 0.1958, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2057, Reg Loss = 81.3747, Reconstruct Loss = 0.0011, Cls Loss = 0.1964, Learning rate = 1.0000e-03\n",
      "Epoch [32/200], Training Loss: 0.2038, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200], Validation Loss: 0.3939, Validation Accuracy: 88.62%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 31 with accuracy: 88.62%\n",
      "Iteration 0: Loss = 0.1525, Reg Loss = 85.8972, Reconstruct Loss = 0.0000, Cls Loss = 0.1440, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2081, Reg Loss = 82.2931, Reconstruct Loss = 0.0009, Cls Loss = 0.1990, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2151, Reg Loss = 81.8158, Reconstruct Loss = 0.0013, Cls Loss = 0.2056, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2124, Reg Loss = 81.1962, Reconstruct Loss = 0.0012, Cls Loss = 0.2030, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2078, Reg Loss = 81.1691, Reconstruct Loss = 0.0011, Cls Loss = 0.1985, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2070, Reg Loss = 80.7955, Reconstruct Loss = 0.0011, Cls Loss = 0.1978, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2068, Reg Loss = 80.5912, Reconstruct Loss = 0.0011, Cls Loss = 0.1976, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2039, Reg Loss = 80.7407, Reconstruct Loss = 0.0012, Cls Loss = 0.1947, Learning rate = 1.0000e-03\n",
      "Epoch [33/200], Training Loss: 0.2022, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200], Validation Loss: 0.3871, Validation Accuracy: 88.72%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 32 with accuracy: 88.72%\n",
      "Iteration 0: Loss = 0.2381, Reg Loss = 79.1002, Reconstruct Loss = 0.0000, Cls Loss = 0.2302, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2175, Reg Loss = 84.1236, Reconstruct Loss = 0.0021, Cls Loss = 0.2070, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2081, Reg Loss = 83.9424, Reconstruct Loss = 0.0019, Cls Loss = 0.1978, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2049, Reg Loss = 83.1331, Reconstruct Loss = 0.0016, Cls Loss = 0.1950, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2037, Reg Loss = 82.7084, Reconstruct Loss = 0.0018, Cls Loss = 0.1936, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2030, Reg Loss = 82.2150, Reconstruct Loss = 0.0019, Cls Loss = 0.1929, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1993, Reg Loss = 82.0727, Reconstruct Loss = 0.0018, Cls Loss = 0.1894, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1988, Reg Loss = 81.8825, Reconstruct Loss = 0.0017, Cls Loss = 0.1889, Learning rate = 1.0000e-03\n",
      "Epoch [34/200], Training Loss: 0.1969, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/200], Validation Loss: 0.3820, Validation Accuracy: 88.82%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 33 with accuracy: 88.82%\n",
      "Iteration 0: Loss = 0.0868, Reg Loss = 80.2862, Reconstruct Loss = 0.0000, Cls Loss = 0.0788, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2021, Reg Loss = 78.6717, Reconstruct Loss = 0.0004, Cls Loss = 0.1938, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1918, Reg Loss = 79.5027, Reconstruct Loss = 0.0011, Cls Loss = 0.1828, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1915, Reg Loss = 79.9002, Reconstruct Loss = 0.0013, Cls Loss = 0.1822, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1910, Reg Loss = 80.1505, Reconstruct Loss = 0.0012, Cls Loss = 0.1818, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1921, Reg Loss = 80.3775, Reconstruct Loss = 0.0012, Cls Loss = 0.1828, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1915, Reg Loss = 80.1803, Reconstruct Loss = 0.0011, Cls Loss = 0.1823, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1911, Reg Loss = 79.7995, Reconstruct Loss = 0.0011, Cls Loss = 0.1820, Learning rate = 1.0000e-03\n",
      "Epoch [35/200], Training Loss: 0.1885, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/200], Validation Loss: 0.3785, Validation Accuracy: 89.03%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 34 with accuracy: 89.03%\n",
      "Iteration 0: Loss = 0.1656, Reg Loss = 82.5212, Reconstruct Loss = 0.0000, Cls Loss = 0.1574, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1948, Reg Loss = 80.4306, Reconstruct Loss = 0.0005, Cls Loss = 0.1863, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1887, Reg Loss = 80.7751, Reconstruct Loss = 0.0009, Cls Loss = 0.1797, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1846, Reg Loss = 80.4154, Reconstruct Loss = 0.0014, Cls Loss = 0.1751, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1835, Reg Loss = 80.3813, Reconstruct Loss = 0.0013, Cls Loss = 0.1742, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1821, Reg Loss = 80.2596, Reconstruct Loss = 0.0014, Cls Loss = 0.1727, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1818, Reg Loss = 79.9557, Reconstruct Loss = 0.0014, Cls Loss = 0.1724, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1824, Reg Loss = 79.8099, Reconstruct Loss = 0.0012, Cls Loss = 0.1732, Learning rate = 1.0000e-03\n",
      "Epoch [36/200], Training Loss: 0.1810, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200], Validation Loss: 0.4053, Validation Accuracy: 88.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1897, Reg Loss = 87.3074, Reconstruct Loss = 0.0000, Cls Loss = 0.1810, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1671, Reg Loss = 79.1291, Reconstruct Loss = 0.0009, Cls Loss = 0.1583, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1683, Reg Loss = 79.8029, Reconstruct Loss = 0.0009, Cls Loss = 0.1594, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1741, Reg Loss = 79.9762, Reconstruct Loss = 0.0011, Cls Loss = 0.1651, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1759, Reg Loss = 79.6677, Reconstruct Loss = 0.0009, Cls Loss = 0.1671, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1756, Reg Loss = 80.0841, Reconstruct Loss = 0.0010, Cls Loss = 0.1666, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1750, Reg Loss = 80.2283, Reconstruct Loss = 0.0015, Cls Loss = 0.1655, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1743, Reg Loss = 80.1600, Reconstruct Loss = 0.0014, Cls Loss = 0.1649, Learning rate = 1.0000e-03\n",
      "Epoch [37/200], Training Loss: 0.1744, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/200], Validation Loss: 0.4109, Validation Accuracy: 88.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1442, Reg Loss = 75.6150, Reconstruct Loss = 0.0000, Cls Loss = 0.1366, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1581, Reg Loss = 82.0629, Reconstruct Loss = 0.0021, Cls Loss = 0.1479, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1638, Reg Loss = 80.6691, Reconstruct Loss = 0.0014, Cls Loss = 0.1543, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1677, Reg Loss = 80.3592, Reconstruct Loss = 0.0015, Cls Loss = 0.1582, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1690, Reg Loss = 80.5710, Reconstruct Loss = 0.0015, Cls Loss = 0.1595, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1715, Reg Loss = 80.5501, Reconstruct Loss = 0.0014, Cls Loss = 0.1620, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1724, Reg Loss = 80.6654, Reconstruct Loss = 0.0013, Cls Loss = 0.1631, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1701, Reg Loss = 80.6910, Reconstruct Loss = 0.0014, Cls Loss = 0.1607, Learning rate = 1.0000e-03\n",
      "Epoch [38/200], Training Loss: 0.1681, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200], Validation Loss: 0.3861, Validation Accuracy: 89.43%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 37 with accuracy: 89.43%\n",
      "Iteration 0: Loss = 0.1145, Reg Loss = 80.4520, Reconstruct Loss = 0.0000, Cls Loss = 0.1065, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1691, Reg Loss = 78.5042, Reconstruct Loss = 0.0015, Cls Loss = 0.1597, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1695, Reg Loss = 79.7617, Reconstruct Loss = 0.0009, Cls Loss = 0.1606, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1781, Reg Loss = 80.0245, Reconstruct Loss = 0.0012, Cls Loss = 0.1689, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1733, Reg Loss = 80.1491, Reconstruct Loss = 0.0011, Cls Loss = 0.1642, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1737, Reg Loss = 80.2021, Reconstruct Loss = 0.0010, Cls Loss = 0.1648, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1717, Reg Loss = 80.5979, Reconstruct Loss = 0.0011, Cls Loss = 0.1625, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1725, Reg Loss = 80.5194, Reconstruct Loss = 0.0011, Cls Loss = 0.1634, Learning rate = 1.0000e-03\n",
      "Epoch [39/200], Training Loss: 0.1704, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200], Validation Loss: 0.3756, Validation Accuracy: 89.59%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 38 with accuracy: 89.59%\n",
      "Iteration 0: Loss = 0.2471, Reg Loss = 82.4251, Reconstruct Loss = 0.0000, Cls Loss = 0.2389, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1693, Reg Loss = 78.5129, Reconstruct Loss = 0.0016, Cls Loss = 0.1598, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1736, Reg Loss = 78.2733, Reconstruct Loss = 0.0023, Cls Loss = 0.1635, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1662, Reg Loss = 78.2924, Reconstruct Loss = 0.0016, Cls Loss = 0.1568, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1637, Reg Loss = 78.4549, Reconstruct Loss = 0.0015, Cls Loss = 0.1544, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1610, Reg Loss = 78.3537, Reconstruct Loss = 0.0013, Cls Loss = 0.1519, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1609, Reg Loss = 78.6691, Reconstruct Loss = 0.0015, Cls Loss = 0.1515, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1593, Reg Loss = 79.0410, Reconstruct Loss = 0.0015, Cls Loss = 0.1499, Learning rate = 1.0000e-03\n",
      "Epoch [40/200], Training Loss: 0.1593, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/200], Validation Loss: 0.3718, Validation Accuracy: 89.87%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 39 with accuracy: 89.87%\n",
      "Iteration 0: Loss = 0.2686, Reg Loss = 76.5113, Reconstruct Loss = 0.0000, Cls Loss = 0.2609, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1656, Reg Loss = 81.0969, Reconstruct Loss = 0.0000, Cls Loss = 0.1575, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1647, Reg Loss = 80.4019, Reconstruct Loss = 0.0009, Cls Loss = 0.1558, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1611, Reg Loss = 80.2247, Reconstruct Loss = 0.0006, Cls Loss = 0.1524, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1639, Reg Loss = 80.1290, Reconstruct Loss = 0.0011, Cls Loss = 0.1548, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1621, Reg Loss = 79.7966, Reconstruct Loss = 0.0010, Cls Loss = 0.1531, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1606, Reg Loss = 79.7822, Reconstruct Loss = 0.0014, Cls Loss = 0.1512, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1594, Reg Loss = 79.6285, Reconstruct Loss = 0.0014, Cls Loss = 0.1501, Learning rate = 1.0000e-03\n",
      "Epoch [41/200], Training Loss: 0.1578, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/200], Validation Loss: 0.3817, Validation Accuracy: 89.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1035, Reg Loss = 82.6299, Reconstruct Loss = 0.0000, Cls Loss = 0.0953, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1519, Reg Loss = 79.5244, Reconstruct Loss = 0.0016, Cls Loss = 0.1423, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1555, Reg Loss = 78.5304, Reconstruct Loss = 0.0014, Cls Loss = 0.1463, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1575, Reg Loss = 78.3014, Reconstruct Loss = 0.0012, Cls Loss = 0.1485, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1544, Reg Loss = 78.1647, Reconstruct Loss = 0.0009, Cls Loss = 0.1457, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1539, Reg Loss = 77.9005, Reconstruct Loss = 0.0010, Cls Loss = 0.1452, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1534, Reg Loss = 78.0725, Reconstruct Loss = 0.0012, Cls Loss = 0.1444, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1530, Reg Loss = 78.4564, Reconstruct Loss = 0.0012, Cls Loss = 0.1440, Learning rate = 1.0000e-03\n",
      "Epoch [42/200], Training Loss: 0.1531, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/200], Validation Loss: 0.3934, Validation Accuracy: 89.62%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0925, Reg Loss = 78.1546, Reconstruct Loss = 0.0000, Cls Loss = 0.0847, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1573, Reg Loss = 78.9877, Reconstruct Loss = 0.0012, Cls Loss = 0.1482, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1550, Reg Loss = 79.2055, Reconstruct Loss = 0.0010, Cls Loss = 0.1461, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1592, Reg Loss = 78.8232, Reconstruct Loss = 0.0011, Cls Loss = 0.1502, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1543, Reg Loss = 79.0339, Reconstruct Loss = 0.0012, Cls Loss = 0.1451, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1516, Reg Loss = 78.9295, Reconstruct Loss = 0.0011, Cls Loss = 0.1426, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1515, Reg Loss = 78.8206, Reconstruct Loss = 0.0012, Cls Loss = 0.1423, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1527, Reg Loss = 78.8633, Reconstruct Loss = 0.0012, Cls Loss = 0.1436, Learning rate = 1.0000e-03\n",
      "Epoch [43/200], Training Loss: 0.1519, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/200], Validation Loss: 0.3859, Validation Accuracy: 89.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1045, Reg Loss = 77.1564, Reconstruct Loss = 0.0000, Cls Loss = 0.0968, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1511, Reg Loss = 78.4820, Reconstruct Loss = 0.0007, Cls Loss = 0.1426, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1479, Reg Loss = 77.8520, Reconstruct Loss = 0.0006, Cls Loss = 0.1395, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1491, Reg Loss = 77.5857, Reconstruct Loss = 0.0009, Cls Loss = 0.1404, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1528, Reg Loss = 77.7054, Reconstruct Loss = 0.0011, Cls Loss = 0.1439, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1509, Reg Loss = 77.7488, Reconstruct Loss = 0.0013, Cls Loss = 0.1418, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1498, Reg Loss = 77.7272, Reconstruct Loss = 0.0013, Cls Loss = 0.1407, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1471, Reg Loss = 77.8393, Reconstruct Loss = 0.0012, Cls Loss = 0.1381, Learning rate = 1.0000e-03\n",
      "Epoch [44/200], Training Loss: 0.1464, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/200], Validation Loss: 0.3691, Validation Accuracy: 90.03%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 43 with accuracy: 90.03%\n",
      "Iteration 0: Loss = 0.0473, Reg Loss = 76.3328, Reconstruct Loss = 0.0000, Cls Loss = 0.0396, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1410, Reg Loss = 81.3238, Reconstruct Loss = 0.0020, Cls Loss = 0.1308, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1474, Reg Loss = 79.6337, Reconstruct Loss = 0.0012, Cls Loss = 0.1383, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1478, Reg Loss = 79.7160, Reconstruct Loss = 0.0013, Cls Loss = 0.1385, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1469, Reg Loss = 79.3382, Reconstruct Loss = 0.0011, Cls Loss = 0.1379, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1460, Reg Loss = 78.9486, Reconstruct Loss = 0.0013, Cls Loss = 0.1369, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1461, Reg Loss = 78.4390, Reconstruct Loss = 0.0012, Cls Loss = 0.1371, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1452, Reg Loss = 78.5291, Reconstruct Loss = 0.0011, Cls Loss = 0.1363, Learning rate = 1.0000e-03\n",
      "Epoch [45/200], Training Loss: 0.1450, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/200], Validation Loss: 0.3658, Validation Accuracy: 90.11%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 44 with accuracy: 90.11%\n",
      "Iteration 0: Loss = 0.0893, Reg Loss = 71.3815, Reconstruct Loss = 0.0000, Cls Loss = 0.0821, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1403, Reg Loss = 78.0375, Reconstruct Loss = 0.0011, Cls Loss = 0.1315, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1403, Reg Loss = 78.1407, Reconstruct Loss = 0.0009, Cls Loss = 0.1316, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1368, Reg Loss = 78.3712, Reconstruct Loss = 0.0010, Cls Loss = 0.1280, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1387, Reg Loss = 78.7177, Reconstruct Loss = 0.0009, Cls Loss = 0.1300, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1411, Reg Loss = 78.6117, Reconstruct Loss = 0.0011, Cls Loss = 0.1322, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1412, Reg Loss = 78.3732, Reconstruct Loss = 0.0012, Cls Loss = 0.1322, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1426, Reg Loss = 78.1887, Reconstruct Loss = 0.0013, Cls Loss = 0.1335, Learning rate = 1.0000e-03\n",
      "Epoch [46/200], Training Loss: 0.1430, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/200], Validation Loss: 0.3600, Validation Accuracy: 90.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2127, Reg Loss = 81.3885, Reconstruct Loss = 0.0000, Cls Loss = 0.2045, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1308, Reg Loss = 78.6196, Reconstruct Loss = 0.0011, Cls Loss = 0.1218, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1307, Reg Loss = 78.3437, Reconstruct Loss = 0.0010, Cls Loss = 0.1219, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1354, Reg Loss = 78.7471, Reconstruct Loss = 0.0012, Cls Loss = 0.1264, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1362, Reg Loss = 78.5616, Reconstruct Loss = 0.0012, Cls Loss = 0.1271, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1365, Reg Loss = 78.1240, Reconstruct Loss = 0.0013, Cls Loss = 0.1274, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1385, Reg Loss = 77.8859, Reconstruct Loss = 0.0012, Cls Loss = 0.1295, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1384, Reg Loss = 77.8356, Reconstruct Loss = 0.0013, Cls Loss = 0.1293, Learning rate = 1.0000e-03\n",
      "Epoch [47/200], Training Loss: 0.1387, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/200], Validation Loss: 0.3844, Validation Accuracy: 89.37%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1542, Reg Loss = 82.4978, Reconstruct Loss = 0.0000, Cls Loss = 0.1460, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1285, Reg Loss = 78.3268, Reconstruct Loss = 0.0013, Cls Loss = 0.1194, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1277, Reg Loss = 78.1703, Reconstruct Loss = 0.0012, Cls Loss = 0.1187, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1277, Reg Loss = 78.0864, Reconstruct Loss = 0.0011, Cls Loss = 0.1188, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1314, Reg Loss = 78.0036, Reconstruct Loss = 0.0009, Cls Loss = 0.1227, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1297, Reg Loss = 77.7113, Reconstruct Loss = 0.0010, Cls Loss = 0.1209, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1328, Reg Loss = 77.8343, Reconstruct Loss = 0.0013, Cls Loss = 0.1237, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1325, Reg Loss = 78.0700, Reconstruct Loss = 0.0012, Cls Loss = 0.1234, Learning rate = 1.0000e-03\n",
      "Epoch [48/200], Training Loss: 0.1317, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/200], Validation Loss: 0.3596, Validation Accuracy: 90.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1000, Reg Loss = 80.9959, Reconstruct Loss = 0.0000, Cls Loss = 0.0919, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1343, Reg Loss = 77.4209, Reconstruct Loss = 0.0016, Cls Loss = 0.1250, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1301, Reg Loss = 78.4831, Reconstruct Loss = 0.0015, Cls Loss = 0.1207, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1360, Reg Loss = 78.2261, Reconstruct Loss = 0.0011, Cls Loss = 0.1271, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1328, Reg Loss = 78.2085, Reconstruct Loss = 0.0009, Cls Loss = 0.1240, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1314, Reg Loss = 78.1267, Reconstruct Loss = 0.0009, Cls Loss = 0.1226, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1296, Reg Loss = 78.2294, Reconstruct Loss = 0.0011, Cls Loss = 0.1206, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1297, Reg Loss = 78.2561, Reconstruct Loss = 0.0011, Cls Loss = 0.1207, Learning rate = 1.0000e-03\n",
      "Epoch [49/200], Training Loss: 0.1296, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/200], Validation Loss: 0.3714, Validation Accuracy: 90.24%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 48 with accuracy: 90.24%\n",
      "Iteration 0: Loss = 0.0708, Reg Loss = 82.4159, Reconstruct Loss = 0.0000, Cls Loss = 0.0626, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1387, Reg Loss = 78.6374, Reconstruct Loss = 0.0018, Cls Loss = 0.1290, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1273, Reg Loss = 78.9022, Reconstruct Loss = 0.0014, Cls Loss = 0.1179, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1335, Reg Loss = 79.1160, Reconstruct Loss = 0.0018, Cls Loss = 0.1239, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1343, Reg Loss = 79.0273, Reconstruct Loss = 0.0014, Cls Loss = 0.1250, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1336, Reg Loss = 78.8307, Reconstruct Loss = 0.0013, Cls Loss = 0.1244, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1312, Reg Loss = 78.8667, Reconstruct Loss = 0.0011, Cls Loss = 0.1222, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1314, Reg Loss = 78.8160, Reconstruct Loss = 0.0010, Cls Loss = 0.1225, Learning rate = 1.0000e-03\n",
      "Epoch [50/200], Training Loss: 0.1318, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Validation Loss: 0.3658, Validation Accuracy: 90.62%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 49 with accuracy: 90.62%\n",
      "Iteration 0: Loss = 0.0530, Reg Loss = 72.5348, Reconstruct Loss = 0.0000, Cls Loss = 0.0458, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1193, Reg Loss = 77.6872, Reconstruct Loss = 0.0020, Cls Loss = 0.1095, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1226, Reg Loss = 77.5187, Reconstruct Loss = 0.0010, Cls Loss = 0.1139, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1231, Reg Loss = 77.2284, Reconstruct Loss = 0.0010, Cls Loss = 0.1143, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1225, Reg Loss = 77.2457, Reconstruct Loss = 0.0008, Cls Loss = 0.1140, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1250, Reg Loss = 77.3563, Reconstruct Loss = 0.0009, Cls Loss = 0.1164, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1253, Reg Loss = 77.5278, Reconstruct Loss = 0.0008, Cls Loss = 0.1167, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1259, Reg Loss = 77.5571, Reconstruct Loss = 0.0008, Cls Loss = 0.1173, Learning rate = 1.0000e-03\n",
      "Epoch [51/200], Training Loss: 0.1267, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 59.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/200], Validation Loss: 0.3659, Validation Accuracy: 90.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2044, Reg Loss = 78.0138, Reconstruct Loss = 0.0000, Cls Loss = 0.1966, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1397, Reg Loss = 76.9049, Reconstruct Loss = 0.0018, Cls Loss = 0.1302, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1334, Reg Loss = 76.8104, Reconstruct Loss = 0.0012, Cls Loss = 0.1245, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1307, Reg Loss = 77.7017, Reconstruct Loss = 0.0012, Cls Loss = 0.1217, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1321, Reg Loss = 77.8335, Reconstruct Loss = 0.0010, Cls Loss = 0.1233, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1327, Reg Loss = 77.6206, Reconstruct Loss = 0.0012, Cls Loss = 0.1238, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1321, Reg Loss = 77.5700, Reconstruct Loss = 0.0012, Cls Loss = 0.1232, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1299, Reg Loss = 77.6341, Reconstruct Loss = 0.0013, Cls Loss = 0.1209, Learning rate = 1.0000e-03\n",
      "Epoch [52/200], Training Loss: 0.1280, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/200], Validation Loss: 0.3699, Validation Accuracy: 90.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0805, Reg Loss = 75.1664, Reconstruct Loss = 0.0000, Cls Loss = 0.0730, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1334, Reg Loss = 76.4477, Reconstruct Loss = 0.0007, Cls Loss = 0.1251, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1241, Reg Loss = 75.9187, Reconstruct Loss = 0.0005, Cls Loss = 0.1160, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1238, Reg Loss = 75.6799, Reconstruct Loss = 0.0010, Cls Loss = 0.1153, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1232, Reg Loss = 75.3698, Reconstruct Loss = 0.0012, Cls Loss = 0.1145, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1221, Reg Loss = 75.3025, Reconstruct Loss = 0.0011, Cls Loss = 0.1135, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1230, Reg Loss = 75.3194, Reconstruct Loss = 0.0009, Cls Loss = 0.1146, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1226, Reg Loss = 75.3499, Reconstruct Loss = 0.0010, Cls Loss = 0.1140, Learning rate = 1.0000e-03\n",
      "Epoch [53/200], Training Loss: 0.1240, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/200], Validation Loss: 0.3729, Validation Accuracy: 90.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1025, Reg Loss = 74.1739, Reconstruct Loss = 0.0000, Cls Loss = 0.0951, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1201, Reg Loss = 74.9338, Reconstruct Loss = 0.0010, Cls Loss = 0.1116, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1247, Reg Loss = 75.7655, Reconstruct Loss = 0.0010, Cls Loss = 0.1161, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1224, Reg Loss = 75.6207, Reconstruct Loss = 0.0012, Cls Loss = 0.1136, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1214, Reg Loss = 75.5364, Reconstruct Loss = 0.0011, Cls Loss = 0.1127, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1216, Reg Loss = 75.4019, Reconstruct Loss = 0.0010, Cls Loss = 0.1131, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1203, Reg Loss = 75.5348, Reconstruct Loss = 0.0010, Cls Loss = 0.1118, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1204, Reg Loss = 75.5844, Reconstruct Loss = 0.0009, Cls Loss = 0.1120, Learning rate = 1.0000e-03\n",
      "Epoch [54/200], Training Loss: 0.1193, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/200], Validation Loss: 0.3725, Validation Accuracy: 90.53%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1124, Reg Loss = 73.6884, Reconstruct Loss = 0.0000, Cls Loss = 0.1050, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1082, Reg Loss = 75.7933, Reconstruct Loss = 0.0007, Cls Loss = 0.0999, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1138, Reg Loss = 75.7213, Reconstruct Loss = 0.0012, Cls Loss = 0.1050, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1129, Reg Loss = 75.9205, Reconstruct Loss = 0.0013, Cls Loss = 0.1041, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1140, Reg Loss = 76.0099, Reconstruct Loss = 0.0015, Cls Loss = 0.1050, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1171, Reg Loss = 75.8480, Reconstruct Loss = 0.0013, Cls Loss = 0.1082, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1169, Reg Loss = 75.6204, Reconstruct Loss = 0.0011, Cls Loss = 0.1082, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1175, Reg Loss = 75.4944, Reconstruct Loss = 0.0010, Cls Loss = 0.1090, Learning rate = 1.0000e-03\n",
      "Epoch [55/200], Training Loss: 0.1178, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/200], Validation Loss: 0.3779, Validation Accuracy: 90.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1631, Reg Loss = 71.0634, Reconstruct Loss = 0.0000, Cls Loss = 0.1560, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1272, Reg Loss = 74.3557, Reconstruct Loss = 0.0015, Cls Loss = 0.1183, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1266, Reg Loss = 75.3541, Reconstruct Loss = 0.0016, Cls Loss = 0.1174, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1249, Reg Loss = 75.4282, Reconstruct Loss = 0.0011, Cls Loss = 0.1163, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1255, Reg Loss = 75.1743, Reconstruct Loss = 0.0011, Cls Loss = 0.1169, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1228, Reg Loss = 75.3215, Reconstruct Loss = 0.0009, Cls Loss = 0.1144, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1207, Reg Loss = 75.4653, Reconstruct Loss = 0.0009, Cls Loss = 0.1123, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1204, Reg Loss = 75.5876, Reconstruct Loss = 0.0009, Cls Loss = 0.1120, Learning rate = 1.0000e-03\n",
      "Epoch [56/200], Training Loss: 0.1219, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/200], Validation Loss: 0.3708, Validation Accuracy: 90.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1331, Reg Loss = 71.1715, Reconstruct Loss = 0.0000, Cls Loss = 0.1259, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1187, Reg Loss = 74.4549, Reconstruct Loss = 0.0014, Cls Loss = 0.1099, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1163, Reg Loss = 75.6552, Reconstruct Loss = 0.0016, Cls Loss = 0.1071, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1156, Reg Loss = 75.7195, Reconstruct Loss = 0.0015, Cls Loss = 0.1065, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1150, Reg Loss = 75.6723, Reconstruct Loss = 0.0012, Cls Loss = 0.1062, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1151, Reg Loss = 75.2840, Reconstruct Loss = 0.0012, Cls Loss = 0.1064, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1148, Reg Loss = 75.0724, Reconstruct Loss = 0.0010, Cls Loss = 0.1063, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1159, Reg Loss = 75.0521, Reconstruct Loss = 0.0010, Cls Loss = 0.1074, Learning rate = 1.0000e-03\n",
      "Epoch [57/200], Training Loss: 0.1158, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/200], Validation Loss: 0.3683, Validation Accuracy: 90.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0497, Reg Loss = 80.0492, Reconstruct Loss = 0.0000, Cls Loss = 0.0417, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1126, Reg Loss = 75.3602, Reconstruct Loss = 0.0007, Cls Loss = 0.1043, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1166, Reg Loss = 74.6697, Reconstruct Loss = 0.0005, Cls Loss = 0.1086, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1186, Reg Loss = 74.7388, Reconstruct Loss = 0.0009, Cls Loss = 0.1103, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1184, Reg Loss = 74.9770, Reconstruct Loss = 0.0008, Cls Loss = 0.1100, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1195, Reg Loss = 74.6499, Reconstruct Loss = 0.0008, Cls Loss = 0.1112, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1187, Reg Loss = 74.5565, Reconstruct Loss = 0.0009, Cls Loss = 0.1104, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1177, Reg Loss = 74.6055, Reconstruct Loss = 0.0009, Cls Loss = 0.1093, Learning rate = 1.0000e-03\n",
      "Epoch [58/200], Training Loss: 0.1173, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/200], Validation Loss: 0.3553, Validation Accuracy: 90.77%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 57 with accuracy: 90.77%\n",
      "Iteration 0: Loss = 0.1883, Reg Loss = 74.5128, Reconstruct Loss = 0.0000, Cls Loss = 0.1808, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1165, Reg Loss = 75.0693, Reconstruct Loss = 0.0014, Cls Loss = 0.1077, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1100, Reg Loss = 75.7435, Reconstruct Loss = 0.0009, Cls Loss = 0.1016, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1129, Reg Loss = 75.7608, Reconstruct Loss = 0.0015, Cls Loss = 0.1038, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1143, Reg Loss = 75.5694, Reconstruct Loss = 0.0011, Cls Loss = 0.1056, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1140, Reg Loss = 75.6762, Reconstruct Loss = 0.0014, Cls Loss = 0.1050, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1160, Reg Loss = 75.7242, Reconstruct Loss = 0.0015, Cls Loss = 0.1070, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1159, Reg Loss = 75.6424, Reconstruct Loss = 0.0013, Cls Loss = 0.1071, Learning rate = 1.0000e-03\n",
      "Epoch [59/200], Training Loss: 0.1158, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/200], Validation Loss: 0.3652, Validation Accuracy: 90.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0791, Reg Loss = 74.1406, Reconstruct Loss = 0.0000, Cls Loss = 0.0717, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1150, Reg Loss = 75.5980, Reconstruct Loss = 0.0004, Cls Loss = 0.1070, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1072, Reg Loss = 75.0440, Reconstruct Loss = 0.0006, Cls Loss = 0.0992, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1122, Reg Loss = 74.8688, Reconstruct Loss = 0.0006, Cls Loss = 0.1041, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1156, Reg Loss = 74.8211, Reconstruct Loss = 0.0006, Cls Loss = 0.1075, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1123, Reg Loss = 75.0276, Reconstruct Loss = 0.0010, Cls Loss = 0.1038, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1134, Reg Loss = 75.0875, Reconstruct Loss = 0.0009, Cls Loss = 0.1049, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1149, Reg Loss = 74.9719, Reconstruct Loss = 0.0011, Cls Loss = 0.1063, Learning rate = 1.0000e-03\n",
      "Epoch [60/200], Training Loss: 0.1138, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/200], Validation Loss: 0.3691, Validation Accuracy: 90.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1894, Reg Loss = 72.8846, Reconstruct Loss = 0.0000, Cls Loss = 0.1822, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1135, Reg Loss = 76.0660, Reconstruct Loss = 0.0022, Cls Loss = 0.1036, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1112, Reg Loss = 76.5900, Reconstruct Loss = 0.0014, Cls Loss = 0.1021, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1147, Reg Loss = 76.1594, Reconstruct Loss = 0.0011, Cls Loss = 0.1060, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1149, Reg Loss = 76.0731, Reconstruct Loss = 0.0009, Cls Loss = 0.1064, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1129, Reg Loss = 76.3562, Reconstruct Loss = 0.0010, Cls Loss = 0.1043, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1118, Reg Loss = 76.2033, Reconstruct Loss = 0.0010, Cls Loss = 0.1032, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1109, Reg Loss = 76.0398, Reconstruct Loss = 0.0010, Cls Loss = 0.1024, Learning rate = 1.0000e-03\n",
      "Epoch [61/200], Training Loss: 0.1104, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/200], Validation Loss: 0.3758, Validation Accuracy: 90.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0912, Reg Loss = 75.7388, Reconstruct Loss = 0.0000, Cls Loss = 0.0836, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1068, Reg Loss = 75.4118, Reconstruct Loss = 0.0012, Cls Loss = 0.0981, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1026, Reg Loss = 75.1900, Reconstruct Loss = 0.0009, Cls Loss = 0.0942, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1038, Reg Loss = 74.8833, Reconstruct Loss = 0.0009, Cls Loss = 0.0954, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1050, Reg Loss = 74.9767, Reconstruct Loss = 0.0008, Cls Loss = 0.0967, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1055, Reg Loss = 75.2839, Reconstruct Loss = 0.0009, Cls Loss = 0.0971, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1088, Reg Loss = 75.4305, Reconstruct Loss = 0.0008, Cls Loss = 0.1005, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1088, Reg Loss = 75.3380, Reconstruct Loss = 0.0008, Cls Loss = 0.1005, Learning rate = 1.0000e-03\n",
      "Epoch [62/200], Training Loss: 0.1088, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/200], Validation Loss: 0.3770, Validation Accuracy: 90.61%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0350, Reg Loss = 73.0420, Reconstruct Loss = 0.0000, Cls Loss = 0.0277, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1188, Reg Loss = 74.4742, Reconstruct Loss = 0.0007, Cls Loss = 0.1107, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1206, Reg Loss = 74.1895, Reconstruct Loss = 0.0010, Cls Loss = 0.1122, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1170, Reg Loss = 74.0622, Reconstruct Loss = 0.0008, Cls Loss = 0.1087, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1138, Reg Loss = 73.7804, Reconstruct Loss = 0.0008, Cls Loss = 0.1055, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1129, Reg Loss = 74.3362, Reconstruct Loss = 0.0011, Cls Loss = 0.1043, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1093, Reg Loss = 74.8193, Reconstruct Loss = 0.0011, Cls Loss = 0.1007, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1094, Reg Loss = 75.0325, Reconstruct Loss = 0.0013, Cls Loss = 0.1006, Learning rate = 1.0000e-03\n",
      "Epoch [63/200], Training Loss: 0.1088, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/200], Validation Loss: 0.3895, Validation Accuracy: 90.58%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0763, Reg Loss = 73.7770, Reconstruct Loss = 0.0000, Cls Loss = 0.0690, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1133, Reg Loss = 75.1276, Reconstruct Loss = 0.0013, Cls Loss = 0.1045, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1146, Reg Loss = 75.1333, Reconstruct Loss = 0.0014, Cls Loss = 0.1056, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1154, Reg Loss = 75.3921, Reconstruct Loss = 0.0015, Cls Loss = 0.1063, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1136, Reg Loss = 76.0370, Reconstruct Loss = 0.0014, Cls Loss = 0.1045, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1105, Reg Loss = 76.3184, Reconstruct Loss = 0.0013, Cls Loss = 0.1016, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1092, Reg Loss = 76.4151, Reconstruct Loss = 0.0012, Cls Loss = 0.1003, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1094, Reg Loss = 76.2170, Reconstruct Loss = 0.0011, Cls Loss = 0.1007, Learning rate = 1.0000e-03\n",
      "Epoch [64/200], Training Loss: 0.1089, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/200], Validation Loss: 0.3788, Validation Accuracy: 90.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1055, Reg Loss = 75.6611, Reconstruct Loss = 0.0000, Cls Loss = 0.0979, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1180, Reg Loss = 75.6620, Reconstruct Loss = 0.0013, Cls Loss = 0.1092, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1146, Reg Loss = 75.8358, Reconstruct Loss = 0.0010, Cls Loss = 0.1060, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1095, Reg Loss = 75.7323, Reconstruct Loss = 0.0010, Cls Loss = 0.1010, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1084, Reg Loss = 75.2166, Reconstruct Loss = 0.0010, Cls Loss = 0.0999, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1082, Reg Loss = 74.8568, Reconstruct Loss = 0.0010, Cls Loss = 0.0997, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1074, Reg Loss = 74.4920, Reconstruct Loss = 0.0009, Cls Loss = 0.0991, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1070, Reg Loss = 74.3197, Reconstruct Loss = 0.0009, Cls Loss = 0.0987, Learning rate = 1.0000e-03\n",
      "Epoch [65/200], Training Loss: 0.1059, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/200], Validation Loss: 0.3659, Validation Accuracy: 90.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0791, Reg Loss = 72.9156, Reconstruct Loss = 0.0000, Cls Loss = 0.0719, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1059, Reg Loss = 74.4804, Reconstruct Loss = 0.0016, Cls Loss = 0.0969, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1053, Reg Loss = 73.6654, Reconstruct Loss = 0.0013, Cls Loss = 0.0967, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1045, Reg Loss = 73.8722, Reconstruct Loss = 0.0013, Cls Loss = 0.0959, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1050, Reg Loss = 73.8109, Reconstruct Loss = 0.0012, Cls Loss = 0.0965, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1033, Reg Loss = 74.0314, Reconstruct Loss = 0.0010, Cls Loss = 0.0949, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1054, Reg Loss = 73.9739, Reconstruct Loss = 0.0009, Cls Loss = 0.0970, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1070, Reg Loss = 73.8117, Reconstruct Loss = 0.0010, Cls Loss = 0.0987, Learning rate = 1.0000e-03\n",
      "Epoch [66/200], Training Loss: 0.1078, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/200], Validation Loss: 0.3794, Validation Accuracy: 90.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0473, Reg Loss = 77.2146, Reconstruct Loss = 0.0000, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1141, Reg Loss = 74.1651, Reconstruct Loss = 0.0010, Cls Loss = 0.1057, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1156, Reg Loss = 74.3345, Reconstruct Loss = 0.0010, Cls Loss = 0.1072, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1147, Reg Loss = 74.3018, Reconstruct Loss = 0.0011, Cls Loss = 0.1062, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1161, Reg Loss = 74.2060, Reconstruct Loss = 0.0011, Cls Loss = 0.1076, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1144, Reg Loss = 74.4734, Reconstruct Loss = 0.0011, Cls Loss = 0.1059, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1106, Reg Loss = 74.7748, Reconstruct Loss = 0.0012, Cls Loss = 0.1019, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1083, Reg Loss = 75.3025, Reconstruct Loss = 0.0012, Cls Loss = 0.0995, Learning rate = 1.0000e-03\n",
      "Epoch [67/200], Training Loss: 0.1084, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/200], Validation Loss: 0.3929, Validation Accuracy: 90.50%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0926, Reg Loss = 69.5348, Reconstruct Loss = 0.0000, Cls Loss = 0.0857, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0982, Reg Loss = 75.5779, Reconstruct Loss = 0.0015, Cls Loss = 0.0892, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1037, Reg Loss = 74.6146, Reconstruct Loss = 0.0015, Cls Loss = 0.0947, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1019, Reg Loss = 74.3442, Reconstruct Loss = 0.0013, Cls Loss = 0.0932, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1024, Reg Loss = 74.3425, Reconstruct Loss = 0.0011, Cls Loss = 0.0938, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1026, Reg Loss = 74.1722, Reconstruct Loss = 0.0009, Cls Loss = 0.0943, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1045, Reg Loss = 73.8744, Reconstruct Loss = 0.0011, Cls Loss = 0.0960, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1033, Reg Loss = 73.7761, Reconstruct Loss = 0.0011, Cls Loss = 0.0949, Learning rate = 1.0000e-03\n",
      "Epoch [68/200], Training Loss: 0.1033, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/200], Validation Loss: 0.3659, Validation Accuracy: 90.82%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 67 with accuracy: 90.82%\n",
      "Iteration 0: Loss = 0.2076, Reg Loss = 69.9220, Reconstruct Loss = 0.0000, Cls Loss = 0.2006, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1014, Reg Loss = 74.4351, Reconstruct Loss = 0.0009, Cls Loss = 0.0931, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0983, Reg Loss = 74.5725, Reconstruct Loss = 0.0008, Cls Loss = 0.0901, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1018, Reg Loss = 74.2694, Reconstruct Loss = 0.0009, Cls Loss = 0.0934, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1056, Reg Loss = 74.1888, Reconstruct Loss = 0.0007, Cls Loss = 0.0975, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1035, Reg Loss = 74.1574, Reconstruct Loss = 0.0006, Cls Loss = 0.0955, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1041, Reg Loss = 74.1680, Reconstruct Loss = 0.0008, Cls Loss = 0.0959, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1052, Reg Loss = 74.2210, Reconstruct Loss = 0.0008, Cls Loss = 0.0969, Learning rate = 1.0000e-03\n",
      "Epoch [69/200], Training Loss: 0.1055, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/200], Validation Loss: 0.3515, Validation Accuracy: 90.87%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 68 with accuracy: 90.87%\n",
      "Iteration 0: Loss = 0.0482, Reg Loss = 73.1891, Reconstruct Loss = 0.0000, Cls Loss = 0.0408, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1079, Reg Loss = 74.0126, Reconstruct Loss = 0.0009, Cls Loss = 0.0996, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1018, Reg Loss = 73.7088, Reconstruct Loss = 0.0009, Cls Loss = 0.0935, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0991, Reg Loss = 73.8895, Reconstruct Loss = 0.0011, Cls Loss = 0.0906, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0976, Reg Loss = 74.2083, Reconstruct Loss = 0.0012, Cls Loss = 0.0890, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0969, Reg Loss = 74.4636, Reconstruct Loss = 0.0012, Cls Loss = 0.0883, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0968, Reg Loss = 74.6236, Reconstruct Loss = 0.0011, Cls Loss = 0.0882, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0975, Reg Loss = 74.4660, Reconstruct Loss = 0.0012, Cls Loss = 0.0889, Learning rate = 1.0000e-03\n",
      "Epoch [70/200], Training Loss: 0.0983, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/200], Validation Loss: 0.3738, Validation Accuracy: 91.01%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 69 with accuracy: 91.01%\n",
      "Iteration 0: Loss = 0.1872, Reg Loss = 73.3270, Reconstruct Loss = 0.0000, Cls Loss = 0.1799, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1052, Reg Loss = 74.8370, Reconstruct Loss = 0.0011, Cls Loss = 0.0966, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1022, Reg Loss = 74.6654, Reconstruct Loss = 0.0014, Cls Loss = 0.0934, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1063, Reg Loss = 74.3419, Reconstruct Loss = 0.0011, Cls Loss = 0.0977, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1055, Reg Loss = 74.1127, Reconstruct Loss = 0.0009, Cls Loss = 0.0972, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1023, Reg Loss = 74.1684, Reconstruct Loss = 0.0007, Cls Loss = 0.0942, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1004, Reg Loss = 74.1614, Reconstruct Loss = 0.0008, Cls Loss = 0.0923, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1008, Reg Loss = 74.0580, Reconstruct Loss = 0.0008, Cls Loss = 0.0925, Learning rate = 1.0000e-03\n",
      "Epoch [71/200], Training Loss: 0.1016, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/200], Validation Loss: 0.3661, Validation Accuracy: 90.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0218, Reg Loss = 73.6640, Reconstruct Loss = 0.0000, Cls Loss = 0.0145, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1004, Reg Loss = 71.4404, Reconstruct Loss = 0.0003, Cls Loss = 0.0930, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1023, Reg Loss = 71.8897, Reconstruct Loss = 0.0009, Cls Loss = 0.0942, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1008, Reg Loss = 72.3307, Reconstruct Loss = 0.0010, Cls Loss = 0.0925, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1014, Reg Loss = 72.7839, Reconstruct Loss = 0.0011, Cls Loss = 0.0931, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0995, Reg Loss = 73.2802, Reconstruct Loss = 0.0010, Cls Loss = 0.0911, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1005, Reg Loss = 73.1985, Reconstruct Loss = 0.0010, Cls Loss = 0.0922, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1015, Reg Loss = 72.9880, Reconstruct Loss = 0.0010, Cls Loss = 0.0932, Learning rate = 1.0000e-03\n",
      "Epoch [72/200], Training Loss: 0.1025, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/200], Validation Loss: 0.3587, Validation Accuracy: 90.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1896, Reg Loss = 69.1888, Reconstruct Loss = 0.0000, Cls Loss = 0.1827, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1041, Reg Loss = 72.4985, Reconstruct Loss = 0.0013, Cls Loss = 0.0956, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0981, Reg Loss = 72.7200, Reconstruct Loss = 0.0009, Cls Loss = 0.0899, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0966, Reg Loss = 73.2237, Reconstruct Loss = 0.0011, Cls Loss = 0.0881, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0979, Reg Loss = 73.2569, Reconstruct Loss = 0.0009, Cls Loss = 0.0896, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0986, Reg Loss = 73.4075, Reconstruct Loss = 0.0008, Cls Loss = 0.0905, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0993, Reg Loss = 73.5374, Reconstruct Loss = 0.0009, Cls Loss = 0.0911, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0992, Reg Loss = 73.5477, Reconstruct Loss = 0.0008, Cls Loss = 0.0910, Learning rate = 1.0000e-03\n",
      "Epoch [73/200], Training Loss: 0.0994, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/200], Validation Loss: 0.3835, Validation Accuracy: 90.60%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1099, Reg Loss = 79.0117, Reconstruct Loss = 0.0000, Cls Loss = 0.1020, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0918, Reg Loss = 74.2923, Reconstruct Loss = 0.0009, Cls Loss = 0.0834, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0944, Reg Loss = 74.7849, Reconstruct Loss = 0.0011, Cls Loss = 0.0859, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0969, Reg Loss = 74.8737, Reconstruct Loss = 0.0012, Cls Loss = 0.0882, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0950, Reg Loss = 75.0809, Reconstruct Loss = 0.0011, Cls Loss = 0.0864, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0970, Reg Loss = 74.7156, Reconstruct Loss = 0.0010, Cls Loss = 0.0885, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0978, Reg Loss = 74.3911, Reconstruct Loss = 0.0012, Cls Loss = 0.0892, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0974, Reg Loss = 74.0387, Reconstruct Loss = 0.0012, Cls Loss = 0.0888, Learning rate = 1.0000e-03\n",
      "Epoch [74/200], Training Loss: 0.0977, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/200], Validation Loss: 0.3581, Validation Accuracy: 90.98%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1419, Reg Loss = 74.5928, Reconstruct Loss = 0.0000, Cls Loss = 0.1345, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0884, Reg Loss = 73.5919, Reconstruct Loss = 0.0007, Cls Loss = 0.0804, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0961, Reg Loss = 72.8137, Reconstruct Loss = 0.0008, Cls Loss = 0.0880, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0968, Reg Loss = 72.2342, Reconstruct Loss = 0.0009, Cls Loss = 0.0887, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0966, Reg Loss = 72.0944, Reconstruct Loss = 0.0008, Cls Loss = 0.0886, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0973, Reg Loss = 71.7403, Reconstruct Loss = 0.0008, Cls Loss = 0.0892, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0968, Reg Loss = 71.8516, Reconstruct Loss = 0.0008, Cls Loss = 0.0888, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0974, Reg Loss = 72.2366, Reconstruct Loss = 0.0008, Cls Loss = 0.0894, Learning rate = 1.0000e-03\n",
      "Epoch [75/200], Training Loss: 0.0985, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/200], Validation Loss: 0.3516, Validation Accuracy: 91.03%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 74 with accuracy: 91.03%\n",
      "Iteration 0: Loss = 0.1316, Reg Loss = 72.6425, Reconstruct Loss = 0.0000, Cls Loss = 0.1244, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1001, Reg Loss = 73.3234, Reconstruct Loss = 0.0008, Cls Loss = 0.0920, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0977, Reg Loss = 74.0092, Reconstruct Loss = 0.0010, Cls Loss = 0.0893, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0993, Reg Loss = 73.7563, Reconstruct Loss = 0.0008, Cls Loss = 0.0911, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0982, Reg Loss = 74.0151, Reconstruct Loss = 0.0009, Cls Loss = 0.0899, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0984, Reg Loss = 74.0559, Reconstruct Loss = 0.0009, Cls Loss = 0.0901, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0978, Reg Loss = 74.3061, Reconstruct Loss = 0.0009, Cls Loss = 0.0895, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0980, Reg Loss = 74.3081, Reconstruct Loss = 0.0009, Cls Loss = 0.0897, Learning rate = 1.0000e-03\n",
      "Epoch [76/200], Training Loss: 0.0971, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/200], Validation Loss: 0.3735, Validation Accuracy: 90.90%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0296, Reg Loss = 71.7726, Reconstruct Loss = 0.0000, Cls Loss = 0.0224, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0926, Reg Loss = 75.0919, Reconstruct Loss = 0.0003, Cls Loss = 0.0848, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0980, Reg Loss = 74.8910, Reconstruct Loss = 0.0006, Cls Loss = 0.0899, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0967, Reg Loss = 74.2198, Reconstruct Loss = 0.0004, Cls Loss = 0.0888, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0973, Reg Loss = 73.6232, Reconstruct Loss = 0.0007, Cls Loss = 0.0892, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0978, Reg Loss = 73.2984, Reconstruct Loss = 0.0006, Cls Loss = 0.0899, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0982, Reg Loss = 73.2134, Reconstruct Loss = 0.0006, Cls Loss = 0.0902, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0978, Reg Loss = 73.2790, Reconstruct Loss = 0.0007, Cls Loss = 0.0897, Learning rate = 1.0000e-03\n",
      "Epoch [77/200], Training Loss: 0.0976, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/200], Validation Loss: 0.3959, Validation Accuracy: 90.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1226, Reg Loss = 71.0219, Reconstruct Loss = 0.0000, Cls Loss = 0.1155, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0924, Reg Loss = 73.5254, Reconstruct Loss = 0.0016, Cls Loss = 0.0835, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0934, Reg Loss = 73.6481, Reconstruct Loss = 0.0016, Cls Loss = 0.0844, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0949, Reg Loss = 73.3451, Reconstruct Loss = 0.0014, Cls Loss = 0.0862, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0943, Reg Loss = 72.8200, Reconstruct Loss = 0.0014, Cls Loss = 0.0857, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0928, Reg Loss = 72.3781, Reconstruct Loss = 0.0013, Cls Loss = 0.0843, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0926, Reg Loss = 72.4871, Reconstruct Loss = 0.0013, Cls Loss = 0.0841, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0950, Reg Loss = 72.5362, Reconstruct Loss = 0.0012, Cls Loss = 0.0866, Learning rate = 1.0000e-03\n",
      "Epoch [78/200], Training Loss: 0.0948, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/200], Validation Loss: 0.3710, Validation Accuracy: 90.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0659, Reg Loss = 71.9924, Reconstruct Loss = 0.0000, Cls Loss = 0.0587, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0907, Reg Loss = 72.7730, Reconstruct Loss = 0.0023, Cls Loss = 0.0811, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0892, Reg Loss = 73.3735, Reconstruct Loss = 0.0018, Cls Loss = 0.0800, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0900, Reg Loss = 73.7731, Reconstruct Loss = 0.0018, Cls Loss = 0.0809, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0893, Reg Loss = 74.1294, Reconstruct Loss = 0.0016, Cls Loss = 0.0802, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0909, Reg Loss = 74.0521, Reconstruct Loss = 0.0015, Cls Loss = 0.0820, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0914, Reg Loss = 74.0186, Reconstruct Loss = 0.0015, Cls Loss = 0.0826, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0928, Reg Loss = 73.9211, Reconstruct Loss = 0.0013, Cls Loss = 0.0841, Learning rate = 1.0000e-03\n",
      "Epoch [79/200], Training Loss: 0.0932, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/200], Validation Loss: 0.3922, Validation Accuracy: 90.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0832, Reg Loss = 70.9494, Reconstruct Loss = 0.0000, Cls Loss = 0.0761, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0922, Reg Loss = 74.0577, Reconstruct Loss = 0.0016, Cls Loss = 0.0833, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0935, Reg Loss = 74.2732, Reconstruct Loss = 0.0012, Cls Loss = 0.0849, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0930, Reg Loss = 73.9522, Reconstruct Loss = 0.0009, Cls Loss = 0.0847, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0937, Reg Loss = 74.1489, Reconstruct Loss = 0.0009, Cls Loss = 0.0854, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0992, Reg Loss = 73.8182, Reconstruct Loss = 0.0009, Cls Loss = 0.0909, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0994, Reg Loss = 73.6610, Reconstruct Loss = 0.0011, Cls Loss = 0.0909, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0987, Reg Loss = 73.3906, Reconstruct Loss = 0.0011, Cls Loss = 0.0902, Learning rate = 1.0000e-03\n",
      "Epoch [80/200], Training Loss: 0.0986, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/200], Validation Loss: 0.3738, Validation Accuracy: 90.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2054, Reg Loss = 71.9453, Reconstruct Loss = 0.0000, Cls Loss = 0.1982, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0909, Reg Loss = 73.7473, Reconstruct Loss = 0.0008, Cls Loss = 0.0828, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0905, Reg Loss = 73.6856, Reconstruct Loss = 0.0010, Cls Loss = 0.0821, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0916, Reg Loss = 74.0332, Reconstruct Loss = 0.0011, Cls Loss = 0.0830, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0937, Reg Loss = 73.9636, Reconstruct Loss = 0.0011, Cls Loss = 0.0852, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0923, Reg Loss = 74.0605, Reconstruct Loss = 0.0010, Cls Loss = 0.0839, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0910, Reg Loss = 73.8933, Reconstruct Loss = 0.0010, Cls Loss = 0.0826, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0919, Reg Loss = 73.6507, Reconstruct Loss = 0.0010, Cls Loss = 0.0836, Learning rate = 1.0000e-03\n",
      "Epoch [81/200], Training Loss: 0.0926, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/200], Validation Loss: 0.3700, Validation Accuracy: 91.09%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 80 with accuracy: 91.09%\n",
      "Iteration 0: Loss = 0.0950, Reg Loss = 71.5158, Reconstruct Loss = 0.0000, Cls Loss = 0.0879, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0907, Reg Loss = 73.3165, Reconstruct Loss = 0.0013, Cls Loss = 0.0821, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0891, Reg Loss = 73.2229, Reconstruct Loss = 0.0015, Cls Loss = 0.0803, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0897, Reg Loss = 73.1806, Reconstruct Loss = 0.0011, Cls Loss = 0.0813, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0898, Reg Loss = 73.1512, Reconstruct Loss = 0.0010, Cls Loss = 0.0815, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0918, Reg Loss = 73.2778, Reconstruct Loss = 0.0010, Cls Loss = 0.0834, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0924, Reg Loss = 73.2678, Reconstruct Loss = 0.0011, Cls Loss = 0.0840, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0952, Reg Loss = 73.1427, Reconstruct Loss = 0.0010, Cls Loss = 0.0868, Learning rate = 1.0000e-03\n",
      "Epoch [82/200], Training Loss: 0.0946, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/200], Validation Loss: 0.3722, Validation Accuracy: 91.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1082, Reg Loss = 69.7833, Reconstruct Loss = 0.0000, Cls Loss = 0.1012, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0893, Reg Loss = 72.2572, Reconstruct Loss = 0.0008, Cls Loss = 0.0812, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0934, Reg Loss = 72.2119, Reconstruct Loss = 0.0007, Cls Loss = 0.0855, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0941, Reg Loss = 72.1900, Reconstruct Loss = 0.0006, Cls Loss = 0.0863, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0944, Reg Loss = 72.4548, Reconstruct Loss = 0.0005, Cls Loss = 0.0866, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0929, Reg Loss = 72.4683, Reconstruct Loss = 0.0006, Cls Loss = 0.0851, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0932, Reg Loss = 72.4140, Reconstruct Loss = 0.0009, Cls Loss = 0.0851, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0941, Reg Loss = 72.3802, Reconstruct Loss = 0.0009, Cls Loss = 0.0860, Learning rate = 1.0000e-03\n",
      "Epoch [83/200], Training Loss: 0.0937, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/200], Validation Loss: 0.3905, Validation Accuracy: 90.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1896, Reg Loss = 69.8782, Reconstruct Loss = 0.0000, Cls Loss = 0.1826, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0837, Reg Loss = 71.8092, Reconstruct Loss = 0.0000, Cls Loss = 0.0765, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0908, Reg Loss = 72.1760, Reconstruct Loss = 0.0007, Cls Loss = 0.0829, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0907, Reg Loss = 72.2831, Reconstruct Loss = 0.0007, Cls Loss = 0.0828, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0922, Reg Loss = 72.1772, Reconstruct Loss = 0.0009, Cls Loss = 0.0841, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0928, Reg Loss = 72.0661, Reconstruct Loss = 0.0007, Cls Loss = 0.0849, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0919, Reg Loss = 72.0241, Reconstruct Loss = 0.0007, Cls Loss = 0.0840, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0915, Reg Loss = 72.0011, Reconstruct Loss = 0.0008, Cls Loss = 0.0835, Learning rate = 1.0000e-03\n",
      "Epoch [84/200], Training Loss: 0.0917, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/200], Validation Loss: 0.3800, Validation Accuracy: 90.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0702, Reg Loss = 73.3820, Reconstruct Loss = 0.0000, Cls Loss = 0.0629, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0845, Reg Loss = 73.7514, Reconstruct Loss = 0.0009, Cls Loss = 0.0762, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0904, Reg Loss = 73.2397, Reconstruct Loss = 0.0006, Cls Loss = 0.0824, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0881, Reg Loss = 73.2150, Reconstruct Loss = 0.0007, Cls Loss = 0.0800, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0870, Reg Loss = 73.3082, Reconstruct Loss = 0.0008, Cls Loss = 0.0789, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0902, Reg Loss = 73.4305, Reconstruct Loss = 0.0010, Cls Loss = 0.0819, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0909, Reg Loss = 73.2967, Reconstruct Loss = 0.0011, Cls Loss = 0.0825, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0914, Reg Loss = 73.1184, Reconstruct Loss = 0.0011, Cls Loss = 0.0830, Learning rate = 1.0000e-03\n",
      "Epoch [85/200], Training Loss: 0.0924, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/200], Validation Loss: 0.3717, Validation Accuracy: 90.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0474, Reg Loss = 71.1008, Reconstruct Loss = 0.0000, Cls Loss = 0.0403, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0910, Reg Loss = 72.7924, Reconstruct Loss = 0.0011, Cls Loss = 0.0826, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0878, Reg Loss = 72.9997, Reconstruct Loss = 0.0009, Cls Loss = 0.0797, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0898, Reg Loss = 73.1872, Reconstruct Loss = 0.0007, Cls Loss = 0.0818, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0926, Reg Loss = 72.6179, Reconstruct Loss = 0.0007, Cls Loss = 0.0847, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0928, Reg Loss = 72.7468, Reconstruct Loss = 0.0009, Cls Loss = 0.0846, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0939, Reg Loss = 72.5840, Reconstruct Loss = 0.0008, Cls Loss = 0.0858, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0939, Reg Loss = 72.3758, Reconstruct Loss = 0.0008, Cls Loss = 0.0859, Learning rate = 1.0000e-03\n",
      "Epoch [86/200], Training Loss: 0.0943, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/200], Validation Loss: 0.3896, Validation Accuracy: 90.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0680, Reg Loss = 69.9672, Reconstruct Loss = 0.0000, Cls Loss = 0.0610, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0836, Reg Loss = 71.0862, Reconstruct Loss = 0.0007, Cls Loss = 0.0758, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0884, Reg Loss = 72.0511, Reconstruct Loss = 0.0005, Cls Loss = 0.0807, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0906, Reg Loss = 71.8805, Reconstruct Loss = 0.0004, Cls Loss = 0.0830, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0920, Reg Loss = 71.8635, Reconstruct Loss = 0.0004, Cls Loss = 0.0844, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0926, Reg Loss = 71.9217, Reconstruct Loss = 0.0004, Cls Loss = 0.0850, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0914, Reg Loss = 72.1110, Reconstruct Loss = 0.0005, Cls Loss = 0.0837, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0917, Reg Loss = 71.9331, Reconstruct Loss = 0.0004, Cls Loss = 0.0840, Learning rate = 1.0000e-03\n",
      "Epoch [87/200], Training Loss: 0.0924, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/200], Validation Loss: 0.3879, Validation Accuracy: 90.62%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0520, Reg Loss = 67.7167, Reconstruct Loss = 0.0000, Cls Loss = 0.0452, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0852, Reg Loss = 70.5808, Reconstruct Loss = 0.0010, Cls Loss = 0.0772, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0887, Reg Loss = 70.3433, Reconstruct Loss = 0.0010, Cls Loss = 0.0807, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0846, Reg Loss = 70.8416, Reconstruct Loss = 0.0009, Cls Loss = 0.0766, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0846, Reg Loss = 71.6040, Reconstruct Loss = 0.0008, Cls Loss = 0.0766, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0843, Reg Loss = 72.0713, Reconstruct Loss = 0.0009, Cls Loss = 0.0762, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0845, Reg Loss = 72.2446, Reconstruct Loss = 0.0010, Cls Loss = 0.0763, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0840, Reg Loss = 72.1140, Reconstruct Loss = 0.0009, Cls Loss = 0.0760, Learning rate = 1.0000e-03\n",
      "Epoch [88/200], Training Loss: 0.0857, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/200], Validation Loss: 0.3680, Validation Accuracy: 91.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0311, Reg Loss = 69.5280, Reconstruct Loss = 0.0000, Cls Loss = 0.0242, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0815, Reg Loss = 72.2970, Reconstruct Loss = 0.0009, Cls Loss = 0.0734, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0829, Reg Loss = 72.5211, Reconstruct Loss = 0.0004, Cls Loss = 0.0752, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0844, Reg Loss = 72.5042, Reconstruct Loss = 0.0005, Cls Loss = 0.0767, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0849, Reg Loss = 72.5674, Reconstruct Loss = 0.0006, Cls Loss = 0.0770, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0846, Reg Loss = 72.4244, Reconstruct Loss = 0.0006, Cls Loss = 0.0767, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0866, Reg Loss = 72.2334, Reconstruct Loss = 0.0007, Cls Loss = 0.0787, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0878, Reg Loss = 72.1955, Reconstruct Loss = 0.0008, Cls Loss = 0.0798, Learning rate = 1.0000e-03\n",
      "Epoch [89/200], Training Loss: 0.0884, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/200], Validation Loss: 0.3690, Validation Accuracy: 90.76%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0698, Reg Loss = 70.9745, Reconstruct Loss = 0.0000, Cls Loss = 0.0627, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0938, Reg Loss = 73.0596, Reconstruct Loss = 0.0000, Cls Loss = 0.0865, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0878, Reg Loss = 73.2015, Reconstruct Loss = 0.0005, Cls Loss = 0.0799, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0887, Reg Loss = 73.7534, Reconstruct Loss = 0.0011, Cls Loss = 0.0802, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0886, Reg Loss = 73.6586, Reconstruct Loss = 0.0012, Cls Loss = 0.0800, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0895, Reg Loss = 73.5728, Reconstruct Loss = 0.0012, Cls Loss = 0.0810, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0893, Reg Loss = 73.6014, Reconstruct Loss = 0.0011, Cls Loss = 0.0809, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0895, Reg Loss = 73.2896, Reconstruct Loss = 0.0011, Cls Loss = 0.0810, Learning rate = 1.0000e-03\n",
      "Epoch [90/200], Training Loss: 0.0896, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/200], Validation Loss: 0.4050, Validation Accuracy: 90.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0468, Reg Loss = 75.3725, Reconstruct Loss = 0.0000, Cls Loss = 0.0393, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0806, Reg Loss = 71.6353, Reconstruct Loss = 0.0012, Cls Loss = 0.0722, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0791, Reg Loss = 72.6805, Reconstruct Loss = 0.0013, Cls Loss = 0.0705, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0859, Reg Loss = 72.9412, Reconstruct Loss = 0.0011, Cls Loss = 0.0775, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0857, Reg Loss = 73.2893, Reconstruct Loss = 0.0013, Cls Loss = 0.0771, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0864, Reg Loss = 73.6502, Reconstruct Loss = 0.0012, Cls Loss = 0.0779, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0895, Reg Loss = 73.7791, Reconstruct Loss = 0.0012, Cls Loss = 0.0810, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0884, Reg Loss = 73.7850, Reconstruct Loss = 0.0011, Cls Loss = 0.0799, Learning rate = 1.0000e-03\n",
      "Epoch [91/200], Training Loss: 0.0880, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200], Validation Loss: 0.3835, Validation Accuracy: 90.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0359, Reg Loss = 76.2940, Reconstruct Loss = 0.0000, Cls Loss = 0.0283, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0901, Reg Loss = 72.2810, Reconstruct Loss = 0.0006, Cls Loss = 0.0822, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0875, Reg Loss = 73.0288, Reconstruct Loss = 0.0006, Cls Loss = 0.0796, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0891, Reg Loss = 73.4606, Reconstruct Loss = 0.0006, Cls Loss = 0.0811, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0893, Reg Loss = 73.1869, Reconstruct Loss = 0.0008, Cls Loss = 0.0813, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0892, Reg Loss = 73.1222, Reconstruct Loss = 0.0008, Cls Loss = 0.0811, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0883, Reg Loss = 72.8175, Reconstruct Loss = 0.0008, Cls Loss = 0.0803, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0883, Reg Loss = 72.6853, Reconstruct Loss = 0.0007, Cls Loss = 0.0803, Learning rate = 1.0000e-03\n",
      "Epoch [92/200], Training Loss: 0.0891, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/200], Validation Loss: 0.3898, Validation Accuracy: 90.82%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0833, Reg Loss = 67.9749, Reconstruct Loss = 0.0000, Cls Loss = 0.0765, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0872, Reg Loss = 70.2791, Reconstruct Loss = 0.0018, Cls Loss = 0.0783, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0825, Reg Loss = 70.9095, Reconstruct Loss = 0.0014, Cls Loss = 0.0741, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0842, Reg Loss = 71.8466, Reconstruct Loss = 0.0010, Cls Loss = 0.0760, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0852, Reg Loss = 72.4395, Reconstruct Loss = 0.0008, Cls Loss = 0.0772, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0867, Reg Loss = 72.0909, Reconstruct Loss = 0.0008, Cls Loss = 0.0787, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0849, Reg Loss = 72.0222, Reconstruct Loss = 0.0009, Cls Loss = 0.0768, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0854, Reg Loss = 71.7182, Reconstruct Loss = 0.0010, Cls Loss = 0.0772, Learning rate = 1.0000e-03\n",
      "Epoch [93/200], Training Loss: 0.0864, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/200], Validation Loss: 0.3670, Validation Accuracy: 90.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0739, Reg Loss = 74.0993, Reconstruct Loss = 0.0000, Cls Loss = 0.0665, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0998, Reg Loss = 70.4768, Reconstruct Loss = 0.0009, Cls Loss = 0.0918, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0910, Reg Loss = 70.3105, Reconstruct Loss = 0.0009, Cls Loss = 0.0830, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0852, Reg Loss = 70.8798, Reconstruct Loss = 0.0009, Cls Loss = 0.0773, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0857, Reg Loss = 71.6264, Reconstruct Loss = 0.0009, Cls Loss = 0.0776, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0869, Reg Loss = 72.0165, Reconstruct Loss = 0.0012, Cls Loss = 0.0785, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0855, Reg Loss = 72.1528, Reconstruct Loss = 0.0013, Cls Loss = 0.0770, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0864, Reg Loss = 72.1440, Reconstruct Loss = 0.0012, Cls Loss = 0.0780, Learning rate = 1.0000e-03\n",
      "Epoch [94/200], Training Loss: 0.0866, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/200], Validation Loss: 0.3846, Validation Accuracy: 90.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0999, Reg Loss = 72.0718, Reconstruct Loss = 0.0000, Cls Loss = 0.0927, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0875, Reg Loss = 73.2510, Reconstruct Loss = 0.0020, Cls Loss = 0.0782, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0848, Reg Loss = 72.6282, Reconstruct Loss = 0.0020, Cls Loss = 0.0756, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0859, Reg Loss = 72.3084, Reconstruct Loss = 0.0018, Cls Loss = 0.0768, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0831, Reg Loss = 72.4648, Reconstruct Loss = 0.0016, Cls Loss = 0.0743, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0865, Reg Loss = 72.5423, Reconstruct Loss = 0.0014, Cls Loss = 0.0778, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0867, Reg Loss = 72.3955, Reconstruct Loss = 0.0014, Cls Loss = 0.0781, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0854, Reg Loss = 72.2117, Reconstruct Loss = 0.0013, Cls Loss = 0.0769, Learning rate = 1.0000e-03\n",
      "Epoch [95/200], Training Loss: 0.0851, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/200], Validation Loss: 0.3723, Validation Accuracy: 90.68%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0465, Reg Loss = 70.6726, Reconstruct Loss = 0.0000, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0902, Reg Loss = 72.7820, Reconstruct Loss = 0.0009, Cls Loss = 0.0821, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0856, Reg Loss = 72.9588, Reconstruct Loss = 0.0010, Cls Loss = 0.0773, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0852, Reg Loss = 72.5539, Reconstruct Loss = 0.0009, Cls Loss = 0.0770, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0855, Reg Loss = 72.3171, Reconstruct Loss = 0.0008, Cls Loss = 0.0775, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0854, Reg Loss = 72.1563, Reconstruct Loss = 0.0010, Cls Loss = 0.0772, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0841, Reg Loss = 72.2510, Reconstruct Loss = 0.0009, Cls Loss = 0.0759, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0854, Reg Loss = 72.3802, Reconstruct Loss = 0.0009, Cls Loss = 0.0773, Learning rate = 1.0000e-03\n",
      "Epoch [96/200], Training Loss: 0.0857, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/200], Validation Loss: 0.3600, Validation Accuracy: 90.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0350, Reg Loss = 68.9850, Reconstruct Loss = 0.0000, Cls Loss = 0.0281, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0853, Reg Loss = 72.4365, Reconstruct Loss = 0.0006, Cls Loss = 0.0775, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0822, Reg Loss = 71.7661, Reconstruct Loss = 0.0011, Cls Loss = 0.0739, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0832, Reg Loss = 72.3588, Reconstruct Loss = 0.0011, Cls Loss = 0.0749, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0837, Reg Loss = 72.5038, Reconstruct Loss = 0.0010, Cls Loss = 0.0754, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0841, Reg Loss = 72.5524, Reconstruct Loss = 0.0009, Cls Loss = 0.0759, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0859, Reg Loss = 72.4507, Reconstruct Loss = 0.0012, Cls Loss = 0.0774, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0849, Reg Loss = 72.3687, Reconstruct Loss = 0.0010, Cls Loss = 0.0766, Learning rate = 1.0000e-03\n",
      "Epoch [97/200], Training Loss: 0.0849, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/200], Validation Loss: 0.3757, Validation Accuracy: 90.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0304, Reg Loss = 76.3121, Reconstruct Loss = 0.0000, Cls Loss = 0.0227, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0857, Reg Loss = 72.7018, Reconstruct Loss = 0.0015, Cls Loss = 0.0770, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0880, Reg Loss = 72.3141, Reconstruct Loss = 0.0013, Cls Loss = 0.0794, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0855, Reg Loss = 71.9494, Reconstruct Loss = 0.0013, Cls Loss = 0.0771, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0842, Reg Loss = 71.9296, Reconstruct Loss = 0.0013, Cls Loss = 0.0757, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0841, Reg Loss = 71.8274, Reconstruct Loss = 0.0011, Cls Loss = 0.0758, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0842, Reg Loss = 71.7467, Reconstruct Loss = 0.0013, Cls Loss = 0.0757, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0843, Reg Loss = 71.8496, Reconstruct Loss = 0.0012, Cls Loss = 0.0760, Learning rate = 1.0000e-03\n",
      "Epoch [98/200], Training Loss: 0.0841, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/200], Validation Loss: 0.3692, Validation Accuracy: 91.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0453, Reg Loss = 68.3144, Reconstruct Loss = 0.0000, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0814, Reg Loss = 72.4108, Reconstruct Loss = 0.0003, Cls Loss = 0.0739, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0834, Reg Loss = 71.4329, Reconstruct Loss = 0.0006, Cls Loss = 0.0757, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0856, Reg Loss = 71.0229, Reconstruct Loss = 0.0012, Cls Loss = 0.0773, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0872, Reg Loss = 71.0952, Reconstruct Loss = 0.0013, Cls Loss = 0.0788, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0867, Reg Loss = 71.3406, Reconstruct Loss = 0.0015, Cls Loss = 0.0781, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0880, Reg Loss = 71.2914, Reconstruct Loss = 0.0014, Cls Loss = 0.0794, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0878, Reg Loss = 71.3691, Reconstruct Loss = 0.0013, Cls Loss = 0.0793, Learning rate = 1.0000e-03\n",
      "Epoch [99/200], Training Loss: 0.0877, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/200], Validation Loss: 0.3661, Validation Accuracy: 90.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1285, Reg Loss = 73.5124, Reconstruct Loss = 0.0000, Cls Loss = 0.1211, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0818, Reg Loss = 71.8020, Reconstruct Loss = 0.0008, Cls Loss = 0.0739, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0804, Reg Loss = 71.7032, Reconstruct Loss = 0.0008, Cls Loss = 0.0723, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0798, Reg Loss = 72.1869, Reconstruct Loss = 0.0008, Cls Loss = 0.0718, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0804, Reg Loss = 72.5286, Reconstruct Loss = 0.0010, Cls Loss = 0.0722, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0796, Reg Loss = 72.3640, Reconstruct Loss = 0.0010, Cls Loss = 0.0714, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0810, Reg Loss = 72.1985, Reconstruct Loss = 0.0009, Cls Loss = 0.0729, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0811, Reg Loss = 71.9624, Reconstruct Loss = 0.0010, Cls Loss = 0.0729, Learning rate = 1.0000e-03\n",
      "Epoch [100/200], Training Loss: 0.0824, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/200], Validation Loss: 0.3549, Validation Accuracy: 91.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1026, Reg Loss = 67.1269, Reconstruct Loss = 0.0000, Cls Loss = 0.0959, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0642, Reg Loss = 71.6121, Reconstruct Loss = 0.0006, Cls Loss = 0.0564, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0668, Reg Loss = 71.6435, Reconstruct Loss = 0.0006, Cls Loss = 0.0591, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0685, Reg Loss = 71.7471, Reconstruct Loss = 0.0006, Cls Loss = 0.0607, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0674, Reg Loss = 71.7380, Reconstruct Loss = 0.0007, Cls Loss = 0.0595, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0679, Reg Loss = 71.6870, Reconstruct Loss = 0.0007, Cls Loss = 0.0600, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0677, Reg Loss = 71.4943, Reconstruct Loss = 0.0007, Cls Loss = 0.0599, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0666, Reg Loss = 71.4142, Reconstruct Loss = 0.0007, Cls Loss = 0.0587, Learning rate = 1.0000e-04\n",
      "Epoch [101/200], Training Loss: 0.0660, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200], Validation Loss: 0.3826, Validation Accuracy: 91.11%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 100 with accuracy: 91.11%\n",
      "Iteration 0: Loss = 0.0210, Reg Loss = 74.0063, Reconstruct Loss = 0.0000, Cls Loss = 0.0136, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0625, Reg Loss = 70.4588, Reconstruct Loss = 0.0005, Cls Loss = 0.0549, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0658, Reg Loss = 70.4733, Reconstruct Loss = 0.0009, Cls Loss = 0.0578, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0652, Reg Loss = 70.2062, Reconstruct Loss = 0.0006, Cls Loss = 0.0575, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0649, Reg Loss = 70.1941, Reconstruct Loss = 0.0006, Cls Loss = 0.0573, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0647, Reg Loss = 70.1183, Reconstruct Loss = 0.0007, Cls Loss = 0.0570, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0652, Reg Loss = 70.0215, Reconstruct Loss = 0.0009, Cls Loss = 0.0573, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0652, Reg Loss = 69.9415, Reconstruct Loss = 0.0008, Cls Loss = 0.0574, Learning rate = 1.0000e-04\n",
      "Epoch [102/200], Training Loss: 0.0648, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/200], Validation Loss: 0.3715, Validation Accuracy: 91.15%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 101 with accuracy: 91.15%\n",
      "Iteration 0: Loss = 0.0813, Reg Loss = 71.7353, Reconstruct Loss = 0.0000, Cls Loss = 0.0741, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0639, Reg Loss = 69.1494, Reconstruct Loss = 0.0000, Cls Loss = 0.0570, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0621, Reg Loss = 69.2846, Reconstruct Loss = 0.0006, Cls Loss = 0.0546, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0614, Reg Loss = 69.2809, Reconstruct Loss = 0.0004, Cls Loss = 0.0541, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0608, Reg Loss = 69.2541, Reconstruct Loss = 0.0003, Cls Loss = 0.0536, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0617, Reg Loss = 69.3136, Reconstruct Loss = 0.0006, Cls Loss = 0.0542, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0605, Reg Loss = 69.4469, Reconstruct Loss = 0.0008, Cls Loss = 0.0528, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0603, Reg Loss = 69.4785, Reconstruct Loss = 0.0007, Cls Loss = 0.0526, Learning rate = 1.0000e-04\n",
      "Epoch [103/200], Training Loss: 0.0607, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/200], Validation Loss: 0.4033, Validation Accuracy: 91.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0887, Reg Loss = 71.3764, Reconstruct Loss = 0.0000, Cls Loss = 0.0816, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0703, Reg Loss = 69.4188, Reconstruct Loss = 0.0011, Cls Loss = 0.0623, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0658, Reg Loss = 69.3435, Reconstruct Loss = 0.0015, Cls Loss = 0.0574, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0634, Reg Loss = 69.1895, Reconstruct Loss = 0.0018, Cls Loss = 0.0547, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0646, Reg Loss = 69.0928, Reconstruct Loss = 0.0014, Cls Loss = 0.0563, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0635, Reg Loss = 69.0197, Reconstruct Loss = 0.0014, Cls Loss = 0.0552, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0617, Reg Loss = 69.0440, Reconstruct Loss = 0.0013, Cls Loss = 0.0535, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0629, Reg Loss = 69.0302, Reconstruct Loss = 0.0012, Cls Loss = 0.0548, Learning rate = 1.0000e-04\n",
      "Epoch [104/200], Training Loss: 0.0628, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/200], Validation Loss: 0.4000, Validation Accuracy: 90.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0328, Reg Loss = 70.4292, Reconstruct Loss = 0.0000, Cls Loss = 0.0257, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0596, Reg Loss = 68.7891, Reconstruct Loss = 0.0016, Cls Loss = 0.0512, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0605, Reg Loss = 68.4848, Reconstruct Loss = 0.0009, Cls Loss = 0.0527, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0622, Reg Loss = 68.5545, Reconstruct Loss = 0.0011, Cls Loss = 0.0543, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0619, Reg Loss = 68.6263, Reconstruct Loss = 0.0009, Cls Loss = 0.0542, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0619, Reg Loss = 68.6251, Reconstruct Loss = 0.0008, Cls Loss = 0.0542, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0610, Reg Loss = 68.6580, Reconstruct Loss = 0.0008, Cls Loss = 0.0534, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0609, Reg Loss = 68.7044, Reconstruct Loss = 0.0008, Cls Loss = 0.0532, Learning rate = 1.0000e-04\n",
      "Epoch [105/200], Training Loss: 0.0615, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/200], Validation Loss: 0.3780, Validation Accuracy: 91.27%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 104 with accuracy: 91.27%\n",
      "Iteration 0: Loss = 0.0195, Reg Loss = 68.5348, Reconstruct Loss = 0.0000, Cls Loss = 0.0126, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0596, Reg Loss = 68.4456, Reconstruct Loss = 0.0016, Cls Loss = 0.0512, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0616, Reg Loss = 68.8178, Reconstruct Loss = 0.0013, Cls Loss = 0.0534, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0589, Reg Loss = 68.8871, Reconstruct Loss = 0.0011, Cls Loss = 0.0509, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0607, Reg Loss = 68.9102, Reconstruct Loss = 0.0010, Cls Loss = 0.0528, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0609, Reg Loss = 68.8801, Reconstruct Loss = 0.0009, Cls Loss = 0.0532, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0608, Reg Loss = 68.8314, Reconstruct Loss = 0.0008, Cls Loss = 0.0531, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0616, Reg Loss = 68.7943, Reconstruct Loss = 0.0008, Cls Loss = 0.0539, Learning rate = 1.0000e-04\n",
      "Epoch [106/200], Training Loss: 0.0621, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/200], Validation Loss: 0.3900, Validation Accuracy: 90.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1796, Reg Loss = 65.2785, Reconstruct Loss = 0.0000, Cls Loss = 0.1731, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0580, Reg Loss = 68.5109, Reconstruct Loss = 0.0005, Cls Loss = 0.0506, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0604, Reg Loss = 68.5399, Reconstruct Loss = 0.0005, Cls Loss = 0.0530, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0603, Reg Loss = 68.3761, Reconstruct Loss = 0.0008, Cls Loss = 0.0526, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0607, Reg Loss = 68.2900, Reconstruct Loss = 0.0007, Cls Loss = 0.0532, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0608, Reg Loss = 68.3690, Reconstruct Loss = 0.0008, Cls Loss = 0.0533, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0605, Reg Loss = 68.4008, Reconstruct Loss = 0.0008, Cls Loss = 0.0528, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0608, Reg Loss = 68.4447, Reconstruct Loss = 0.0008, Cls Loss = 0.0531, Learning rate = 1.0000e-04\n",
      "Epoch [107/200], Training Loss: 0.0604, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/200], Validation Loss: 0.3790, Validation Accuracy: 91.00%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0779, Reg Loss = 70.5858, Reconstruct Loss = 0.0000, Cls Loss = 0.0708, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0547, Reg Loss = 68.6422, Reconstruct Loss = 0.0011, Cls Loss = 0.0467, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0544, Reg Loss = 68.7190, Reconstruct Loss = 0.0011, Cls Loss = 0.0465, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0561, Reg Loss = 68.8462, Reconstruct Loss = 0.0011, Cls Loss = 0.0481, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0569, Reg Loss = 68.8474, Reconstruct Loss = 0.0009, Cls Loss = 0.0491, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0574, Reg Loss = 68.8028, Reconstruct Loss = 0.0009, Cls Loss = 0.0496, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0588, Reg Loss = 68.7553, Reconstruct Loss = 0.0010, Cls Loss = 0.0509, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0581, Reg Loss = 68.7280, Reconstruct Loss = 0.0009, Cls Loss = 0.0503, Learning rate = 1.0000e-04\n",
      "Epoch [108/200], Training Loss: 0.0574, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/200], Validation Loss: 0.3920, Validation Accuracy: 91.11%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0399, Reg Loss = 71.7524, Reconstruct Loss = 0.0000, Cls Loss = 0.0327, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0616, Reg Loss = 68.7969, Reconstruct Loss = 0.0005, Cls Loss = 0.0542, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0626, Reg Loss = 68.3923, Reconstruct Loss = 0.0009, Cls Loss = 0.0549, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0602, Reg Loss = 68.4218, Reconstruct Loss = 0.0011, Cls Loss = 0.0522, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0596, Reg Loss = 68.4354, Reconstruct Loss = 0.0012, Cls Loss = 0.0515, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0588, Reg Loss = 68.4339, Reconstruct Loss = 0.0012, Cls Loss = 0.0508, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0577, Reg Loss = 68.4925, Reconstruct Loss = 0.0013, Cls Loss = 0.0495, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0581, Reg Loss = 68.5018, Reconstruct Loss = 0.0012, Cls Loss = 0.0500, Learning rate = 1.0000e-04\n",
      "Epoch [109/200], Training Loss: 0.0579, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/200], Validation Loss: 0.3837, Validation Accuracy: 91.34%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 108 with accuracy: 91.34%\n",
      "Iteration 0: Loss = 0.0387, Reg Loss = 71.4651, Reconstruct Loss = 0.0000, Cls Loss = 0.0316, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0520, Reg Loss = 68.6809, Reconstruct Loss = 0.0003, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0557, Reg Loss = 68.7219, Reconstruct Loss = 0.0006, Cls Loss = 0.0482, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0572, Reg Loss = 68.5757, Reconstruct Loss = 0.0006, Cls Loss = 0.0498, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0560, Reg Loss = 68.6991, Reconstruct Loss = 0.0006, Cls Loss = 0.0485, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0574, Reg Loss = 68.7188, Reconstruct Loss = 0.0005, Cls Loss = 0.0500, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0574, Reg Loss = 68.7165, Reconstruct Loss = 0.0005, Cls Loss = 0.0500, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0574, Reg Loss = 68.6857, Reconstruct Loss = 0.0006, Cls Loss = 0.0500, Learning rate = 1.0000e-04\n",
      "Epoch [110/200], Training Loss: 0.0572, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/200], Validation Loss: 0.3819, Validation Accuracy: 91.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0981, Reg Loss = 68.3817, Reconstruct Loss = 0.0000, Cls Loss = 0.0913, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0623, Reg Loss = 68.5287, Reconstruct Loss = 0.0010, Cls Loss = 0.0544, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0605, Reg Loss = 68.2872, Reconstruct Loss = 0.0010, Cls Loss = 0.0526, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0584, Reg Loss = 68.3104, Reconstruct Loss = 0.0010, Cls Loss = 0.0506, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0587, Reg Loss = 68.2539, Reconstruct Loss = 0.0008, Cls Loss = 0.0511, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0591, Reg Loss = 68.2376, Reconstruct Loss = 0.0007, Cls Loss = 0.0515, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0598, Reg Loss = 68.1639, Reconstruct Loss = 0.0007, Cls Loss = 0.0523, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0597, Reg Loss = 68.0395, Reconstruct Loss = 0.0008, Cls Loss = 0.0521, Learning rate = 1.0000e-04\n",
      "Epoch [111/200], Training Loss: 0.0598, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/200], Validation Loss: 0.3908, Validation Accuracy: 90.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0508, Reg Loss = 67.0804, Reconstruct Loss = 0.0000, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0523, Reg Loss = 67.1171, Reconstruct Loss = 0.0008, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0529, Reg Loss = 67.2632, Reconstruct Loss = 0.0004, Cls Loss = 0.0458, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0549, Reg Loss = 67.4549, Reconstruct Loss = 0.0008, Cls Loss = 0.0474, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0555, Reg Loss = 67.5240, Reconstruct Loss = 0.0007, Cls Loss = 0.0480, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0556, Reg Loss = 67.4874, Reconstruct Loss = 0.0007, Cls Loss = 0.0481, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0560, Reg Loss = 67.4926, Reconstruct Loss = 0.0008, Cls Loss = 0.0484, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0566, Reg Loss = 67.4811, Reconstruct Loss = 0.0009, Cls Loss = 0.0490, Learning rate = 1.0000e-04\n",
      "Epoch [112/200], Training Loss: 0.0562, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/200], Validation Loss: 0.3746, Validation Accuracy: 91.40%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 111 with accuracy: 91.40%\n",
      "Iteration 0: Loss = 0.0331, Reg Loss = 69.6010, Reconstruct Loss = 0.0000, Cls Loss = 0.0262, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0539, Reg Loss = 68.0313, Reconstruct Loss = 0.0005, Cls Loss = 0.0466, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0537, Reg Loss = 68.0769, Reconstruct Loss = 0.0010, Cls Loss = 0.0459, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0554, Reg Loss = 68.0884, Reconstruct Loss = 0.0009, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0568, Reg Loss = 67.9754, Reconstruct Loss = 0.0009, Cls Loss = 0.0492, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0566, Reg Loss = 67.9630, Reconstruct Loss = 0.0008, Cls Loss = 0.0490, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0565, Reg Loss = 67.9160, Reconstruct Loss = 0.0009, Cls Loss = 0.0488, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0582, Reg Loss = 67.8530, Reconstruct Loss = 0.0010, Cls Loss = 0.0504, Learning rate = 1.0000e-04\n",
      "Epoch [113/200], Training Loss: 0.0584, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/200], Validation Loss: 0.3786, Validation Accuracy: 91.25%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0539, Reg Loss = 66.8665, Reconstruct Loss = 0.0000, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0557, Reg Loss = 67.7771, Reconstruct Loss = 0.0010, Cls Loss = 0.0480, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0541, Reg Loss = 67.6633, Reconstruct Loss = 0.0005, Cls Loss = 0.0469, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0545, Reg Loss = 67.6837, Reconstruct Loss = 0.0008, Cls Loss = 0.0470, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0544, Reg Loss = 67.6489, Reconstruct Loss = 0.0007, Cls Loss = 0.0469, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0539, Reg Loss = 67.6681, Reconstruct Loss = 0.0006, Cls Loss = 0.0465, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0548, Reg Loss = 67.6524, Reconstruct Loss = 0.0006, Cls Loss = 0.0475, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0546, Reg Loss = 67.6769, Reconstruct Loss = 0.0006, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Epoch [114/200], Training Loss: 0.0544, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/200], Validation Loss: 0.4011, Validation Accuracy: 90.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0099, Reg Loss = 69.6659, Reconstruct Loss = 0.0000, Cls Loss = 0.0029, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0584, Reg Loss = 67.6703, Reconstruct Loss = 0.0007, Cls Loss = 0.0509, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0562, Reg Loss = 67.8338, Reconstruct Loss = 0.0009, Cls Loss = 0.0485, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0553, Reg Loss = 67.8663, Reconstruct Loss = 0.0009, Cls Loss = 0.0476, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0554, Reg Loss = 67.8370, Reconstruct Loss = 0.0009, Cls Loss = 0.0478, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0557, Reg Loss = 67.9298, Reconstruct Loss = 0.0010, Cls Loss = 0.0479, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0554, Reg Loss = 67.9425, Reconstruct Loss = 0.0009, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0550, Reg Loss = 67.9284, Reconstruct Loss = 0.0009, Cls Loss = 0.0473, Learning rate = 1.0000e-04\n",
      "Epoch [115/200], Training Loss: 0.0544, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/200], Validation Loss: 0.4070, Validation Accuracy: 91.18%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0732, Reg Loss = 70.3541, Reconstruct Loss = 0.0000, Cls Loss = 0.0661, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0542, Reg Loss = 67.9076, Reconstruct Loss = 0.0010, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0543, Reg Loss = 67.8302, Reconstruct Loss = 0.0009, Cls Loss = 0.0466, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0534, Reg Loss = 67.8714, Reconstruct Loss = 0.0010, Cls Loss = 0.0455, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0529, Reg Loss = 67.8681, Reconstruct Loss = 0.0009, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0542, Reg Loss = 67.8490, Reconstruct Loss = 0.0010, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0543, Reg Loss = 67.8758, Reconstruct Loss = 0.0011, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0550, Reg Loss = 67.8949, Reconstruct Loss = 0.0010, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Epoch [116/200], Training Loss: 0.0555, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200], Validation Loss: 0.3956, Validation Accuracy: 91.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1255, Reg Loss = 64.3997, Reconstruct Loss = 0.0000, Cls Loss = 0.1191, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0617, Reg Loss = 67.4872, Reconstruct Loss = 0.0010, Cls Loss = 0.0539, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0562, Reg Loss = 67.4567, Reconstruct Loss = 0.0010, Cls Loss = 0.0485, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0555, Reg Loss = 67.5585, Reconstruct Loss = 0.0007, Cls Loss = 0.0481, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0533, Reg Loss = 67.5813, Reconstruct Loss = 0.0006, Cls Loss = 0.0460, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0532, Reg Loss = 67.6395, Reconstruct Loss = 0.0007, Cls Loss = 0.0458, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0537, Reg Loss = 67.6518, Reconstruct Loss = 0.0007, Cls Loss = 0.0462, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0542, Reg Loss = 67.6354, Reconstruct Loss = 0.0007, Cls Loss = 0.0467, Learning rate = 1.0000e-04\n",
      "Epoch [117/200], Training Loss: 0.0544, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/200], Validation Loss: 0.4004, Validation Accuracy: 91.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0284, Reg Loss = 65.4275, Reconstruct Loss = 0.0000, Cls Loss = 0.0218, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0531, Reg Loss = 67.2237, Reconstruct Loss = 0.0010, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0525, Reg Loss = 67.3134, Reconstruct Loss = 0.0013, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0505, Reg Loss = 67.3281, Reconstruct Loss = 0.0011, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0531, Reg Loss = 67.3762, Reconstruct Loss = 0.0009, Cls Loss = 0.0455, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0550, Reg Loss = 67.3477, Reconstruct Loss = 0.0010, Cls Loss = 0.0473, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0553, Reg Loss = 67.3017, Reconstruct Loss = 0.0008, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0556, Reg Loss = 67.2495, Reconstruct Loss = 0.0009, Cls Loss = 0.0480, Learning rate = 1.0000e-04\n",
      "Epoch [118/200], Training Loss: 0.0556, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/200], Validation Loss: 0.3851, Validation Accuracy: 90.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0605, Reg Loss = 68.8914, Reconstruct Loss = 0.0000, Cls Loss = 0.0536, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0563, Reg Loss = 66.6919, Reconstruct Loss = 0.0005, Cls Loss = 0.0491, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0563, Reg Loss = 66.8512, Reconstruct Loss = 0.0007, Cls Loss = 0.0490, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0537, Reg Loss = 66.8137, Reconstruct Loss = 0.0009, Cls Loss = 0.0462, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0528, Reg Loss = 66.8449, Reconstruct Loss = 0.0010, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0523, Reg Loss = 66.8794, Reconstruct Loss = 0.0011, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0525, Reg Loss = 66.8721, Reconstruct Loss = 0.0010, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0526, Reg Loss = 66.9037, Reconstruct Loss = 0.0010, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Epoch [119/200], Training Loss: 0.0531, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/200], Validation Loss: 0.4207, Validation Accuracy: 90.68%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1090, Reg Loss = 65.7930, Reconstruct Loss = 0.0000, Cls Loss = 0.1024, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 66.8206, Reconstruct Loss = 0.0010, Cls Loss = 0.0406, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0526, Reg Loss = 66.9167, Reconstruct Loss = 0.0006, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0494, Reg Loss = 67.0423, Reconstruct Loss = 0.0007, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0513, Reg Loss = 67.1030, Reconstruct Loss = 0.0008, Cls Loss = 0.0438, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0524, Reg Loss = 67.0833, Reconstruct Loss = 0.0007, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0519, Reg Loss = 67.0989, Reconstruct Loss = 0.0008, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0525, Reg Loss = 67.1451, Reconstruct Loss = 0.0008, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Epoch [120/200], Training Loss: 0.0533, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/200], Validation Loss: 0.4049, Validation Accuracy: 90.90%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0278, Reg Loss = 68.5189, Reconstruct Loss = 0.0000, Cls Loss = 0.0210, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0574, Reg Loss = 67.1162, Reconstruct Loss = 0.0008, Cls Loss = 0.0499, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0546, Reg Loss = 67.0879, Reconstruct Loss = 0.0008, Cls Loss = 0.0471, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0547, Reg Loss = 67.0778, Reconstruct Loss = 0.0008, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0554, Reg Loss = 67.0620, Reconstruct Loss = 0.0010, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0545, Reg Loss = 67.0841, Reconstruct Loss = 0.0011, Cls Loss = 0.0467, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0548, Reg Loss = 67.0527, Reconstruct Loss = 0.0011, Cls Loss = 0.0471, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0549, Reg Loss = 67.0424, Reconstruct Loss = 0.0010, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Epoch [121/200], Training Loss: 0.0553, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/200], Validation Loss: 0.3797, Validation Accuracy: 91.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0776, Reg Loss = 66.8333, Reconstruct Loss = 0.0000, Cls Loss = 0.0709, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0512, Reg Loss = 66.9745, Reconstruct Loss = 0.0007, Cls Loss = 0.0438, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0552, Reg Loss = 66.9184, Reconstruct Loss = 0.0010, Cls Loss = 0.0475, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0548, Reg Loss = 66.8115, Reconstruct Loss = 0.0008, Cls Loss = 0.0474, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0561, Reg Loss = 66.8063, Reconstruct Loss = 0.0009, Cls Loss = 0.0485, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0550, Reg Loss = 66.8510, Reconstruct Loss = 0.0008, Cls Loss = 0.0476, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0540, Reg Loss = 66.7814, Reconstruct Loss = 0.0007, Cls Loss = 0.0466, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0551, Reg Loss = 66.7608, Reconstruct Loss = 0.0007, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Epoch [122/200], Training Loss: 0.0557, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/200], Validation Loss: 0.3893, Validation Accuracy: 91.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0588, Reg Loss = 64.1688, Reconstruct Loss = 0.0000, Cls Loss = 0.0524, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0509, Reg Loss = 66.7757, Reconstruct Loss = 0.0018, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0524, Reg Loss = 66.5559, Reconstruct Loss = 0.0011, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0543, Reg Loss = 66.5838, Reconstruct Loss = 0.0008, Cls Loss = 0.0468, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0529, Reg Loss = 66.5561, Reconstruct Loss = 0.0008, Cls Loss = 0.0455, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0536, Reg Loss = 66.5319, Reconstruct Loss = 0.0007, Cls Loss = 0.0462, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0531, Reg Loss = 66.5105, Reconstruct Loss = 0.0009, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0525, Reg Loss = 66.5372, Reconstruct Loss = 0.0009, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Epoch [123/200], Training Loss: 0.0524, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/200], Validation Loss: 0.4020, Validation Accuracy: 90.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0160, Reg Loss = 67.6229, Reconstruct Loss = 0.0000, Cls Loss = 0.0093, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0525, Reg Loss = 66.7596, Reconstruct Loss = 0.0002, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0527, Reg Loss = 66.6933, Reconstruct Loss = 0.0002, Cls Loss = 0.0457, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0537, Reg Loss = 66.5019, Reconstruct Loss = 0.0003, Cls Loss = 0.0467, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0542, Reg Loss = 66.5279, Reconstruct Loss = 0.0004, Cls Loss = 0.0471, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0555, Reg Loss = 66.4844, Reconstruct Loss = 0.0003, Cls Loss = 0.0485, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0547, Reg Loss = 66.5199, Reconstruct Loss = 0.0004, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0545, Reg Loss = 66.5413, Reconstruct Loss = 0.0004, Cls Loss = 0.0474, Learning rate = 1.0000e-04\n",
      "Epoch [124/200], Training Loss: 0.0538, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/200], Validation Loss: 0.3900, Validation Accuracy: 91.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0573, Reg Loss = 68.3268, Reconstruct Loss = 0.0000, Cls Loss = 0.0504, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0494, Reg Loss = 67.0479, Reconstruct Loss = 0.0010, Cls Loss = 0.0416, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0519, Reg Loss = 66.9313, Reconstruct Loss = 0.0005, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0545, Reg Loss = 66.9446, Reconstruct Loss = 0.0004, Cls Loss = 0.0474, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0548, Reg Loss = 66.8665, Reconstruct Loss = 0.0005, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0530, Reg Loss = 66.7875, Reconstruct Loss = 0.0004, Cls Loss = 0.0459, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0530, Reg Loss = 66.8186, Reconstruct Loss = 0.0006, Cls Loss = 0.0457, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0536, Reg Loss = 66.8530, Reconstruct Loss = 0.0006, Cls Loss = 0.0463, Learning rate = 1.0000e-04\n",
      "Epoch [125/200], Training Loss: 0.0531, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/200], Validation Loss: 0.3945, Validation Accuracy: 91.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0287, Reg Loss = 65.1166, Reconstruct Loss = 0.0000, Cls Loss = 0.0222, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 66.8619, Reconstruct Loss = 0.0000, Cls Loss = 0.0416, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0485, Reg Loss = 67.0403, Reconstruct Loss = 0.0003, Cls Loss = 0.0415, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0510, Reg Loss = 67.0612, Reconstruct Loss = 0.0004, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0509, Reg Loss = 67.0473, Reconstruct Loss = 0.0005, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0516, Reg Loss = 66.9961, Reconstruct Loss = 0.0006, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0527, Reg Loss = 66.9321, Reconstruct Loss = 0.0007, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0527, Reg Loss = 66.8460, Reconstruct Loss = 0.0007, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Epoch [126/200], Training Loss: 0.0532, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/200], Validation Loss: 0.3904, Validation Accuracy: 91.24%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0480, Reg Loss = 69.4510, Reconstruct Loss = 0.0268, Cls Loss = 0.0143, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0545, Reg Loss = 66.7478, Reconstruct Loss = 0.0011, Cls Loss = 0.0467, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0538, Reg Loss = 66.8086, Reconstruct Loss = 0.0013, Cls Loss = 0.0458, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0509, Reg Loss = 66.7815, Reconstruct Loss = 0.0012, Cls Loss = 0.0430, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0497, Reg Loss = 66.7873, Reconstruct Loss = 0.0012, Cls Loss = 0.0419, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0509, Reg Loss = 66.8271, Reconstruct Loss = 0.0012, Cls Loss = 0.0430, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0517, Reg Loss = 66.7746, Reconstruct Loss = 0.0011, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0517, Reg Loss = 66.7671, Reconstruct Loss = 0.0012, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Epoch [127/200], Training Loss: 0.0519, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/200], Validation Loss: 0.3995, Validation Accuracy: 91.04%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0574, Reg Loss = 68.3639, Reconstruct Loss = 0.0000, Cls Loss = 0.0506, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0564, Reg Loss = 66.4981, Reconstruct Loss = 0.0003, Cls Loss = 0.0495, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0555, Reg Loss = 66.3034, Reconstruct Loss = 0.0005, Cls Loss = 0.0484, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0542, Reg Loss = 66.3095, Reconstruct Loss = 0.0007, Cls Loss = 0.0469, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0528, Reg Loss = 66.3844, Reconstruct Loss = 0.0008, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0518, Reg Loss = 66.4698, Reconstruct Loss = 0.0008, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0514, Reg Loss = 66.4813, Reconstruct Loss = 0.0007, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0513, Reg Loss = 66.5449, Reconstruct Loss = 0.0007, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Epoch [128/200], Training Loss: 0.0515, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/200], Validation Loss: 0.3868, Validation Accuracy: 91.37%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1018, Reg Loss = 64.1523, Reconstruct Loss = 0.0000, Cls Loss = 0.0953, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0548, Reg Loss = 66.6700, Reconstruct Loss = 0.0010, Cls Loss = 0.0471, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0497, Reg Loss = 66.6220, Reconstruct Loss = 0.0010, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0498, Reg Loss = 66.6069, Reconstruct Loss = 0.0008, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0499, Reg Loss = 66.5290, Reconstruct Loss = 0.0008, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0485, Reg Loss = 66.6078, Reconstruct Loss = 0.0009, Cls Loss = 0.0409, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0483, Reg Loss = 66.6608, Reconstruct Loss = 0.0009, Cls Loss = 0.0408, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0500, Reg Loss = 66.6320, Reconstruct Loss = 0.0009, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Epoch [129/200], Training Loss: 0.0503, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/200], Validation Loss: 0.4028, Validation Accuracy: 91.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0097, Reg Loss = 67.9099, Reconstruct Loss = 0.0000, Cls Loss = 0.0029, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0480, Reg Loss = 67.0513, Reconstruct Loss = 0.0003, Cls Loss = 0.0411, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0493, Reg Loss = 66.9231, Reconstruct Loss = 0.0005, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0513, Reg Loss = 66.9170, Reconstruct Loss = 0.0010, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0520, Reg Loss = 66.8348, Reconstruct Loss = 0.0009, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0516, Reg Loss = 66.8014, Reconstruct Loss = 0.0009, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0513, Reg Loss = 66.7658, Reconstruct Loss = 0.0009, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0510, Reg Loss = 66.6950, Reconstruct Loss = 0.0009, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Epoch [130/200], Training Loss: 0.0505, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/200], Validation Loss: 0.3879, Validation Accuracy: 91.22%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0294, Reg Loss = 67.3775, Reconstruct Loss = 0.0000, Cls Loss = 0.0227, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0474, Reg Loss = 66.5948, Reconstruct Loss = 0.0005, Cls Loss = 0.0402, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0488, Reg Loss = 66.4699, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0529, Reg Loss = 66.3497, Reconstruct Loss = 0.0005, Cls Loss = 0.0458, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0533, Reg Loss = 66.2171, Reconstruct Loss = 0.0005, Cls Loss = 0.0462, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0527, Reg Loss = 66.1499, Reconstruct Loss = 0.0007, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0515, Reg Loss = 66.1806, Reconstruct Loss = 0.0007, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0524, Reg Loss = 66.1774, Reconstruct Loss = 0.0006, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Epoch [131/200], Training Loss: 0.0528, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/200], Validation Loss: 0.4047, Validation Accuracy: 91.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0522, Reg Loss = 66.1349, Reconstruct Loss = 0.0000, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0532, Reg Loss = 65.8533, Reconstruct Loss = 0.0005, Cls Loss = 0.0461, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0521, Reg Loss = 65.9257, Reconstruct Loss = 0.0005, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0543, Reg Loss = 65.9512, Reconstruct Loss = 0.0004, Cls Loss = 0.0473, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0533, Reg Loss = 65.9172, Reconstruct Loss = 0.0006, Cls Loss = 0.0461, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0527, Reg Loss = 65.9480, Reconstruct Loss = 0.0006, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0528, Reg Loss = 65.9272, Reconstruct Loss = 0.0006, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0526, Reg Loss = 65.9126, Reconstruct Loss = 0.0007, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Epoch [132/200], Training Loss: 0.0517, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/200], Validation Loss: 0.3964, Validation Accuracy: 91.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0131, Reg Loss = 67.2180, Reconstruct Loss = 0.0000, Cls Loss = 0.0064, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0522, Reg Loss = 66.2440, Reconstruct Loss = 0.0018, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0514, Reg Loss = 66.1435, Reconstruct Loss = 0.0013, Cls Loss = 0.0435, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0523, Reg Loss = 66.1550, Reconstruct Loss = 0.0011, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0514, Reg Loss = 66.0867, Reconstruct Loss = 0.0010, Cls Loss = 0.0438, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0519, Reg Loss = 66.0848, Reconstruct Loss = 0.0009, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0524, Reg Loss = 66.0856, Reconstruct Loss = 0.0008, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0525, Reg Loss = 66.0384, Reconstruct Loss = 0.0007, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Epoch [133/200], Training Loss: 0.0522, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/200], Validation Loss: 0.3924, Validation Accuracy: 91.17%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0139, Reg Loss = 64.5132, Reconstruct Loss = 0.0000, Cls Loss = 0.0074, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0458, Reg Loss = 65.8683, Reconstruct Loss = 0.0010, Cls Loss = 0.0382, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0500, Reg Loss = 65.8240, Reconstruct Loss = 0.0009, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0514, Reg Loss = 65.7456, Reconstruct Loss = 0.0010, Cls Loss = 0.0438, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0506, Reg Loss = 65.7275, Reconstruct Loss = 0.0009, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0500, Reg Loss = 65.7550, Reconstruct Loss = 0.0009, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0508, Reg Loss = 65.7101, Reconstruct Loss = 0.0009, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0508, Reg Loss = 65.7289, Reconstruct Loss = 0.0008, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Epoch [134/200], Training Loss: 0.0507, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/200], Validation Loss: 0.3948, Validation Accuracy: 91.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0815, Reg Loss = 63.7012, Reconstruct Loss = 0.0000, Cls Loss = 0.0752, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0480, Reg Loss = 66.2535, Reconstruct Loss = 0.0005, Cls Loss = 0.0408, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0486, Reg Loss = 66.2266, Reconstruct Loss = 0.0005, Cls Loss = 0.0414, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0495, Reg Loss = 66.2386, Reconstruct Loss = 0.0006, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0496, Reg Loss = 66.2596, Reconstruct Loss = 0.0007, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0507, Reg Loss = 66.2008, Reconstruct Loss = 0.0008, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0498, Reg Loss = 66.1557, Reconstruct Loss = 0.0008, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0493, Reg Loss = 66.1900, Reconstruct Loss = 0.0008, Cls Loss = 0.0419, Learning rate = 1.0000e-04\n",
      "Epoch [135/200], Training Loss: 0.0492, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/200], Validation Loss: 0.3911, Validation Accuracy: 91.49%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 134 with accuracy: 91.49%\n",
      "Iteration 0: Loss = 0.0261, Reg Loss = 64.9014, Reconstruct Loss = 0.0000, Cls Loss = 0.0196, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0554, Reg Loss = 66.4898, Reconstruct Loss = 0.0007, Cls Loss = 0.0480, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0517, Reg Loss = 66.2267, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0505, Reg Loss = 66.1807, Reconstruct Loss = 0.0005, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0499, Reg Loss = 66.1365, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0498, Reg Loss = 66.0894, Reconstruct Loss = 0.0005, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0504, Reg Loss = 66.0812, Reconstruct Loss = 0.0006, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0502, Reg Loss = 66.0836, Reconstruct Loss = 0.0007, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Epoch [136/200], Training Loss: 0.0502, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/200], Validation Loss: 0.4031, Validation Accuracy: 91.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0760, Reg Loss = 65.9743, Reconstruct Loss = 0.0000, Cls Loss = 0.0694, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0525, Reg Loss = 65.8674, Reconstruct Loss = 0.0010, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0532, Reg Loss = 65.9489, Reconstruct Loss = 0.0010, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0508, Reg Loss = 65.9991, Reconstruct Loss = 0.0009, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0513, Reg Loss = 65.9695, Reconstruct Loss = 0.0008, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0506, Reg Loss = 65.9499, Reconstruct Loss = 0.0007, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0504, Reg Loss = 65.9202, Reconstruct Loss = 0.0008, Cls Loss = 0.0430, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0497, Reg Loss = 65.9053, Reconstruct Loss = 0.0008, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Epoch [137/200], Training Loss: 0.0494, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/200], Validation Loss: 0.3989, Validation Accuracy: 91.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0491, Reg Loss = 67.8222, Reconstruct Loss = 0.0000, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0529, Reg Loss = 65.7798, Reconstruct Loss = 0.0002, Cls Loss = 0.0461, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0513, Reg Loss = 65.8978, Reconstruct Loss = 0.0008, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0504, Reg Loss = 65.8501, Reconstruct Loss = 0.0007, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0505, Reg Loss = 65.8770, Reconstruct Loss = 0.0006, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0499, Reg Loss = 65.8292, Reconstruct Loss = 0.0006, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0503, Reg Loss = 65.8088, Reconstruct Loss = 0.0006, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0507, Reg Loss = 65.7940, Reconstruct Loss = 0.0008, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Epoch [138/200], Training Loss: 0.0502, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/200], Validation Loss: 0.3926, Validation Accuracy: 91.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0078, Reg Loss = 65.4162, Reconstruct Loss = 0.0000, Cls Loss = 0.0012, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0455, Reg Loss = 66.0673, Reconstruct Loss = 0.0018, Cls Loss = 0.0371, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0479, Reg Loss = 65.9599, Reconstruct Loss = 0.0014, Cls Loss = 0.0398, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0511, Reg Loss = 66.0298, Reconstruct Loss = 0.0011, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0507, Reg Loss = 65.9955, Reconstruct Loss = 0.0010, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0498, Reg Loss = 65.9713, Reconstruct Loss = 0.0010, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0507, Reg Loss = 65.9597, Reconstruct Loss = 0.0010, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0497, Reg Loss = 65.9553, Reconstruct Loss = 0.0010, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Epoch [139/200], Training Loss: 0.0494, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/200], Validation Loss: 0.4147, Validation Accuracy: 91.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0518, Reg Loss = 64.7242, Reconstruct Loss = 0.0000, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0512, Reg Loss = 66.1278, Reconstruct Loss = 0.0010, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0474, Reg Loss = 66.0513, Reconstruct Loss = 0.0007, Cls Loss = 0.0400, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0488, Reg Loss = 66.0871, Reconstruct Loss = 0.0007, Cls Loss = 0.0416, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0481, Reg Loss = 66.1263, Reconstruct Loss = 0.0006, Cls Loss = 0.0408, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0469, Reg Loss = 66.1926, Reconstruct Loss = 0.0006, Cls Loss = 0.0397, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0474, Reg Loss = 66.1848, Reconstruct Loss = 0.0007, Cls Loss = 0.0401, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0476, Reg Loss = 66.1403, Reconstruct Loss = 0.0007, Cls Loss = 0.0403, Learning rate = 1.0000e-04\n",
      "Epoch [140/200], Training Loss: 0.0480, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/200], Validation Loss: 0.3975, Validation Accuracy: 91.39%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0573, Reg Loss = 63.6044, Reconstruct Loss = 0.0000, Cls Loss = 0.0509, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0430, Reg Loss = 66.0678, Reconstruct Loss = 0.0010, Cls Loss = 0.0353, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0452, Reg Loss = 66.0757, Reconstruct Loss = 0.0007, Cls Loss = 0.0378, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0443, Reg Loss = 66.0661, Reconstruct Loss = 0.0006, Cls Loss = 0.0371, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0458, Reg Loss = 65.9907, Reconstruct Loss = 0.0006, Cls Loss = 0.0387, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0468, Reg Loss = 65.9586, Reconstruct Loss = 0.0007, Cls Loss = 0.0395, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0474, Reg Loss = 65.8790, Reconstruct Loss = 0.0008, Cls Loss = 0.0401, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0473, Reg Loss = 65.7854, Reconstruct Loss = 0.0007, Cls Loss = 0.0401, Learning rate = 1.0000e-04\n",
      "Epoch [141/200], Training Loss: 0.0471, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/200], Validation Loss: 0.4001, Validation Accuracy: 91.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0278, Reg Loss = 63.6449, Reconstruct Loss = 0.0000, Cls Loss = 0.0214, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0465, Reg Loss = 65.8256, Reconstruct Loss = 0.0003, Cls Loss = 0.0397, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0471, Reg Loss = 65.8143, Reconstruct Loss = 0.0001, Cls Loss = 0.0404, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0478, Reg Loss = 65.7305, Reconstruct Loss = 0.0001, Cls Loss = 0.0412, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0474, Reg Loss = 65.6759, Reconstruct Loss = 0.0003, Cls Loss = 0.0406, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0471, Reg Loss = 65.6589, Reconstruct Loss = 0.0004, Cls Loss = 0.0401, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0484, Reg Loss = 65.6684, Reconstruct Loss = 0.0004, Cls Loss = 0.0414, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0489, Reg Loss = 65.6741, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-04\n",
      "Epoch [142/200], Training Loss: 0.0489, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/200], Validation Loss: 0.4040, Validation Accuracy: 91.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0332, Reg Loss = 64.7156, Reconstruct Loss = 0.0000, Cls Loss = 0.0268, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0443, Reg Loss = 65.1904, Reconstruct Loss = 0.0003, Cls Loss = 0.0375, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0451, Reg Loss = 65.1892, Reconstruct Loss = 0.0005, Cls Loss = 0.0381, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0455, Reg Loss = 65.2746, Reconstruct Loss = 0.0006, Cls Loss = 0.0384, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0475, Reg Loss = 65.2225, Reconstruct Loss = 0.0006, Cls Loss = 0.0404, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0478, Reg Loss = 65.1819, Reconstruct Loss = 0.0006, Cls Loss = 0.0407, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0474, Reg Loss = 65.2381, Reconstruct Loss = 0.0007, Cls Loss = 0.0401, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0474, Reg Loss = 65.3045, Reconstruct Loss = 0.0008, Cls Loss = 0.0401, Learning rate = 1.0000e-04\n",
      "Epoch [143/200], Training Loss: 0.0478, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/200], Validation Loss: 0.4269, Validation Accuracy: 90.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0359, Reg Loss = 63.4141, Reconstruct Loss = 0.0000, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0519, Reg Loss = 65.2689, Reconstruct Loss = 0.0008, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0498, Reg Loss = 65.4491, Reconstruct Loss = 0.0005, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0489, Reg Loss = 65.4367, Reconstruct Loss = 0.0005, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0486, Reg Loss = 65.4439, Reconstruct Loss = 0.0008, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0491, Reg Loss = 65.4772, Reconstruct Loss = 0.0008, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0492, Reg Loss = 65.4401, Reconstruct Loss = 0.0008, Cls Loss = 0.0419, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0490, Reg Loss = 65.3847, Reconstruct Loss = 0.0008, Cls Loss = 0.0417, Learning rate = 1.0000e-04\n",
      "Epoch [144/200], Training Loss: 0.0488, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/200], Validation Loss: 0.4029, Validation Accuracy: 91.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0503, Reg Loss = 66.3794, Reconstruct Loss = 0.0000, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0538, Reg Loss = 65.4695, Reconstruct Loss = 0.0005, Cls Loss = 0.0467, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0505, Reg Loss = 65.3088, Reconstruct Loss = 0.0005, Cls Loss = 0.0435, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0481, Reg Loss = 65.1678, Reconstruct Loss = 0.0006, Cls Loss = 0.0410, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0483, Reg Loss = 65.1100, Reconstruct Loss = 0.0006, Cls Loss = 0.0412, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0488, Reg Loss = 65.0688, Reconstruct Loss = 0.0007, Cls Loss = 0.0417, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0477, Reg Loss = 65.0674, Reconstruct Loss = 0.0007, Cls Loss = 0.0405, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0484, Reg Loss = 65.0728, Reconstruct Loss = 0.0006, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Epoch [145/200], Training Loss: 0.0482, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/200], Validation Loss: 0.3917, Validation Accuracy: 91.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0271, Reg Loss = 66.6072, Reconstruct Loss = 0.0000, Cls Loss = 0.0204, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0500, Reg Loss = 65.4825, Reconstruct Loss = 0.0012, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0506, Reg Loss = 65.5704, Reconstruct Loss = 0.0011, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0488, Reg Loss = 65.6452, Reconstruct Loss = 0.0009, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0473, Reg Loss = 65.6326, Reconstruct Loss = 0.0008, Cls Loss = 0.0400, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0478, Reg Loss = 65.6572, Reconstruct Loss = 0.0007, Cls Loss = 0.0405, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0480, Reg Loss = 65.6451, Reconstruct Loss = 0.0007, Cls Loss = 0.0407, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0475, Reg Loss = 65.6447, Reconstruct Loss = 0.0007, Cls Loss = 0.0403, Learning rate = 1.0000e-04\n",
      "Epoch [146/200], Training Loss: 0.0481, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/200], Validation Loss: 0.4243, Validation Accuracy: 91.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0614, Reg Loss = 63.7742, Reconstruct Loss = 0.0000, Cls Loss = 0.0550, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0502, Reg Loss = 65.3347, Reconstruct Loss = 0.0008, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0495, Reg Loss = 65.4065, Reconstruct Loss = 0.0006, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0484, Reg Loss = 65.4375, Reconstruct Loss = 0.0006, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0479, Reg Loss = 65.4107, Reconstruct Loss = 0.0006, Cls Loss = 0.0408, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0482, Reg Loss = 65.4302, Reconstruct Loss = 0.0007, Cls Loss = 0.0410, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0482, Reg Loss = 65.4021, Reconstruct Loss = 0.0006, Cls Loss = 0.0410, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0475, Reg Loss = 65.3828, Reconstruct Loss = 0.0006, Cls Loss = 0.0404, Learning rate = 1.0000e-04\n",
      "Epoch [147/200], Training Loss: 0.0481, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/200], Validation Loss: 0.4082, Validation Accuracy: 91.25%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0309, Reg Loss = 66.5416, Reconstruct Loss = 0.0000, Cls Loss = 0.0242, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0485, Reg Loss = 64.9644, Reconstruct Loss = 0.0008, Cls Loss = 0.0412, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0501, Reg Loss = 65.0175, Reconstruct Loss = 0.0008, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0508, Reg Loss = 64.9827, Reconstruct Loss = 0.0006, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0497, Reg Loss = 64.9533, Reconstruct Loss = 0.0010, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0501, Reg Loss = 64.9369, Reconstruct Loss = 0.0010, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0502, Reg Loss = 64.9681, Reconstruct Loss = 0.0010, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0496, Reg Loss = 64.9593, Reconstruct Loss = 0.0009, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Epoch [148/200], Training Loss: 0.0486, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/200], Validation Loss: 0.4267, Validation Accuracy: 91.18%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0110, Reg Loss = 64.8692, Reconstruct Loss = 0.0000, Cls Loss = 0.0045, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0540, Reg Loss = 65.1785, Reconstruct Loss = 0.0012, Cls Loss = 0.0462, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0503, Reg Loss = 65.1222, Reconstruct Loss = 0.0011, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0497, Reg Loss = 65.1280, Reconstruct Loss = 0.0008, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0501, Reg Loss = 65.1192, Reconstruct Loss = 0.0006, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0496, Reg Loss = 65.0905, Reconstruct Loss = 0.0007, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0491, Reg Loss = 65.1163, Reconstruct Loss = 0.0008, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0483, Reg Loss = 65.1160, Reconstruct Loss = 0.0008, Cls Loss = 0.0411, Learning rate = 1.0000e-04\n",
      "Epoch [149/200], Training Loss: 0.0492, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/200], Validation Loss: 0.4168, Validation Accuracy: 91.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0882, Reg Loss = 64.6268, Reconstruct Loss = 0.0000, Cls Loss = 0.0818, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0526, Reg Loss = 64.8213, Reconstruct Loss = 0.0007, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0533, Reg Loss = 64.7731, Reconstruct Loss = 0.0006, Cls Loss = 0.0462, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0514, Reg Loss = 64.7361, Reconstruct Loss = 0.0007, Cls Loss = 0.0443, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0498, Reg Loss = 64.7407, Reconstruct Loss = 0.0008, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0490, Reg Loss = 64.7690, Reconstruct Loss = 0.0008, Cls Loss = 0.0417, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0495, Reg Loss = 64.8265, Reconstruct Loss = 0.0008, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0493, Reg Loss = 64.8620, Reconstruct Loss = 0.0009, Cls Loss = 0.0419, Learning rate = 1.0000e-04\n",
      "Epoch [150/200], Training Loss: 0.0488, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/200], Validation Loss: 0.3922, Validation Accuracy: 91.50%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 149 with accuracy: 91.50%\n",
      "Iteration 0: Loss = 0.0394, Reg Loss = 64.4264, Reconstruct Loss = 0.0000, Cls Loss = 0.0329, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0409, Reg Loss = 65.1923, Reconstruct Loss = 0.0005, Cls Loss = 0.0339, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0462, Reg Loss = 65.3332, Reconstruct Loss = 0.0009, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0462, Reg Loss = 65.2922, Reconstruct Loss = 0.0007, Cls Loss = 0.0390, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0480, Reg Loss = 65.2274, Reconstruct Loss = 0.0006, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0461, Reg Loss = 65.2288, Reconstruct Loss = 0.0007, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0461, Reg Loss = 65.2276, Reconstruct Loss = 0.0007, Cls Loss = 0.0388, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0460, Reg Loss = 65.2340, Reconstruct Loss = 0.0008, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Epoch [151/200], Training Loss: 0.0455, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/200], Validation Loss: 0.3989, Validation Accuracy: 91.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0150, Reg Loss = 64.1958, Reconstruct Loss = 0.0000, Cls Loss = 0.0085, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0459, Reg Loss = 65.3107, Reconstruct Loss = 0.0012, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0469, Reg Loss = 65.3177, Reconstruct Loss = 0.0011, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0475, Reg Loss = 65.3012, Reconstruct Loss = 0.0011, Cls Loss = 0.0399, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0482, Reg Loss = 65.3081, Reconstruct Loss = 0.0009, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0480, Reg Loss = 65.2939, Reconstruct Loss = 0.0008, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0477, Reg Loss = 65.3268, Reconstruct Loss = 0.0008, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0468, Reg Loss = 65.2962, Reconstruct Loss = 0.0008, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Epoch [152/200], Training Loss: 0.0461, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/200], Validation Loss: 0.4066, Validation Accuracy: 91.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0136, Reg Loss = 64.5610, Reconstruct Loss = 0.0000, Cls Loss = 0.0072, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0514, Reg Loss = 65.2862, Reconstruct Loss = 0.0010, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0527, Reg Loss = 65.2403, Reconstruct Loss = 0.0006, Cls Loss = 0.0456, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0518, Reg Loss = 65.2447, Reconstruct Loss = 0.0007, Cls Loss = 0.0446, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0497, Reg Loss = 65.2512, Reconstruct Loss = 0.0006, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0495, Reg Loss = 65.2211, Reconstruct Loss = 0.0006, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0489, Reg Loss = 65.2161, Reconstruct Loss = 0.0007, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0477, Reg Loss = 65.2236, Reconstruct Loss = 0.0007, Cls Loss = 0.0405, Learning rate = 1.0000e-05\n",
      "Epoch [153/200], Training Loss: 0.0469, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/200], Validation Loss: 0.3961, Validation Accuracy: 91.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0218, Reg Loss = 66.8494, Reconstruct Loss = 0.0000, Cls Loss = 0.0151, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0446, Reg Loss = 65.0821, Reconstruct Loss = 0.0003, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0455, Reg Loss = 65.0935, Reconstruct Loss = 0.0005, Cls Loss = 0.0385, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0475, Reg Loss = 65.0695, Reconstruct Loss = 0.0006, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 65.1064, Reconstruct Loss = 0.0004, Cls Loss = 0.0398, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0462, Reg Loss = 65.1101, Reconstruct Loss = 0.0003, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0469, Reg Loss = 65.1041, Reconstruct Loss = 0.0005, Cls Loss = 0.0399, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0471, Reg Loss = 65.1226, Reconstruct Loss = 0.0005, Cls Loss = 0.0400, Learning rate = 1.0000e-05\n",
      "Epoch [154/200], Training Loss: 0.0463, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/200], Validation Loss: 0.4041, Validation Accuracy: 91.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1338, Reg Loss = 65.6309, Reconstruct Loss = 0.0000, Cls Loss = 0.1272, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0448, Reg Loss = 65.2108, Reconstruct Loss = 0.0003, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0499, Reg Loss = 65.0601, Reconstruct Loss = 0.0006, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0494, Reg Loss = 65.1159, Reconstruct Loss = 0.0008, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0487, Reg Loss = 65.0921, Reconstruct Loss = 0.0007, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0490, Reg Loss = 65.0533, Reconstruct Loss = 0.0007, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0489, Reg Loss = 65.0214, Reconstruct Loss = 0.0007, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0490, Reg Loss = 65.0297, Reconstruct Loss = 0.0006, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Epoch [155/200], Training Loss: 0.0491, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [155/200], Validation Loss: 0.3952, Validation Accuracy: 91.50%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0581, Reg Loss = 66.2521, Reconstruct Loss = 0.0000, Cls Loss = 0.0514, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 64.8503, Reconstruct Loss = 0.0015, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0467, Reg Loss = 64.9006, Reconstruct Loss = 0.0016, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0460, Reg Loss = 64.8812, Reconstruct Loss = 0.0014, Cls Loss = 0.0381, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0456, Reg Loss = 64.9284, Reconstruct Loss = 0.0012, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0468, Reg Loss = 64.9250, Reconstruct Loss = 0.0010, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0464, Reg Loss = 64.9398, Reconstruct Loss = 0.0009, Cls Loss = 0.0390, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0458, Reg Loss = 64.9515, Reconstruct Loss = 0.0010, Cls Loss = 0.0384, Learning rate = 1.0000e-05\n",
      "Epoch [156/200], Training Loss: 0.0460, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [156/200], Validation Loss: 0.3986, Validation Accuracy: 91.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0665, Reg Loss = 66.4177, Reconstruct Loss = 0.0262, Cls Loss = 0.0336, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0439, Reg Loss = 64.9906, Reconstruct Loss = 0.0012, Cls Loss = 0.0362, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0466, Reg Loss = 64.9218, Reconstruct Loss = 0.0010, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0470, Reg Loss = 64.9667, Reconstruct Loss = 0.0009, Cls Loss = 0.0396, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0459, Reg Loss = 64.9559, Reconstruct Loss = 0.0010, Cls Loss = 0.0384, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0455, Reg Loss = 64.9419, Reconstruct Loss = 0.0010, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0452, Reg Loss = 64.9376, Reconstruct Loss = 0.0009, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0459, Reg Loss = 64.9343, Reconstruct Loss = 0.0010, Cls Loss = 0.0384, Learning rate = 1.0000e-05\n",
      "Epoch [157/200], Training Loss: 0.0459, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/200], Validation Loss: 0.4070, Validation Accuracy: 91.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0156, Reg Loss = 66.4419, Reconstruct Loss = 0.0000, Cls Loss = 0.0090, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0502, Reg Loss = 64.8463, Reconstruct Loss = 0.0010, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0467, Reg Loss = 64.7965, Reconstruct Loss = 0.0010, Cls Loss = 0.0392, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0494, Reg Loss = 64.9163, Reconstruct Loss = 0.0009, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0478, Reg Loss = 64.9038, Reconstruct Loss = 0.0009, Cls Loss = 0.0405, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0489, Reg Loss = 64.9001, Reconstruct Loss = 0.0007, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0477, Reg Loss = 64.9268, Reconstruct Loss = 0.0008, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0475, Reg Loss = 64.9166, Reconstruct Loss = 0.0008, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Epoch [158/200], Training Loss: 0.0471, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/200], Validation Loss: 0.4170, Validation Accuracy: 91.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0186, Reg Loss = 64.0019, Reconstruct Loss = 0.0000, Cls Loss = 0.0122, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0493, Reg Loss = 65.0121, Reconstruct Loss = 0.0008, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0464, Reg Loss = 64.9878, Reconstruct Loss = 0.0008, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0467, Reg Loss = 64.9884, Reconstruct Loss = 0.0008, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0458, Reg Loss = 64.9937, Reconstruct Loss = 0.0008, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0460, Reg Loss = 65.0157, Reconstruct Loss = 0.0007, Cls Loss = 0.0388, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0466, Reg Loss = 65.0268, Reconstruct Loss = 0.0008, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0465, Reg Loss = 64.9977, Reconstruct Loss = 0.0008, Cls Loss = 0.0392, Learning rate = 1.0000e-05\n",
      "Epoch [159/200], Training Loss: 0.0463, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/200], Validation Loss: 0.3950, Validation Accuracy: 91.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0345, Reg Loss = 63.8133, Reconstruct Loss = 0.0000, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0459, Reg Loss = 64.8878, Reconstruct Loss = 0.0005, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0456, Reg Loss = 64.8780, Reconstruct Loss = 0.0003, Cls Loss = 0.0388, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0460, Reg Loss = 64.9011, Reconstruct Loss = 0.0005, Cls Loss = 0.0390, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0468, Reg Loss = 64.9376, Reconstruct Loss = 0.0005, Cls Loss = 0.0398, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0471, Reg Loss = 64.9061, Reconstruct Loss = 0.0006, Cls Loss = 0.0400, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0469, Reg Loss = 64.9043, Reconstruct Loss = 0.0005, Cls Loss = 0.0399, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0464, Reg Loss = 64.8927, Reconstruct Loss = 0.0005, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Epoch [160/200], Training Loss: 0.0473, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/200], Validation Loss: 0.3966, Validation Accuracy: 91.49%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0501, Reg Loss = 63.8915, Reconstruct Loss = 0.0000, Cls Loss = 0.0437, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0438, Reg Loss = 64.7959, Reconstruct Loss = 0.0007, Cls Loss = 0.0366, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0481, Reg Loss = 64.8230, Reconstruct Loss = 0.0008, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0487, Reg Loss = 64.8263, Reconstruct Loss = 0.0009, Cls Loss = 0.0413, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0476, Reg Loss = 64.8444, Reconstruct Loss = 0.0009, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0464, Reg Loss = 64.8651, Reconstruct Loss = 0.0010, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0460, Reg Loss = 64.8739, Reconstruct Loss = 0.0010, Cls Loss = 0.0385, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0455, Reg Loss = 64.8849, Reconstruct Loss = 0.0010, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Epoch [161/200], Training Loss: 0.0453, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/200], Validation Loss: 0.4025, Validation Accuracy: 91.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0794, Reg Loss = 66.0212, Reconstruct Loss = 0.0000, Cls Loss = 0.0728, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0444, Reg Loss = 65.1350, Reconstruct Loss = 0.0005, Cls Loss = 0.0374, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0454, Reg Loss = 64.9616, Reconstruct Loss = 0.0006, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0433, Reg Loss = 65.0158, Reconstruct Loss = 0.0007, Cls Loss = 0.0361, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0439, Reg Loss = 64.9586, Reconstruct Loss = 0.0009, Cls Loss = 0.0365, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0439, Reg Loss = 64.9717, Reconstruct Loss = 0.0009, Cls Loss = 0.0365, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0444, Reg Loss = 64.9332, Reconstruct Loss = 0.0009, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0447, Reg Loss = 64.9424, Reconstruct Loss = 0.0008, Cls Loss = 0.0375, Learning rate = 1.0000e-05\n",
      "Epoch [162/200], Training Loss: 0.0448, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/200], Validation Loss: 0.3894, Validation Accuracy: 91.59%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 161 with accuracy: 91.59%\n",
      "Iteration 0: Loss = 0.0187, Reg Loss = 65.6399, Reconstruct Loss = 0.0000, Cls Loss = 0.0122, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0516, Reg Loss = 64.8422, Reconstruct Loss = 0.0005, Cls Loss = 0.0447, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0473, Reg Loss = 64.9382, Reconstruct Loss = 0.0004, Cls Loss = 0.0405, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0477, Reg Loss = 64.9448, Reconstruct Loss = 0.0004, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0483, Reg Loss = 64.9137, Reconstruct Loss = 0.0004, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0472, Reg Loss = 64.9174, Reconstruct Loss = 0.0004, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0473, Reg Loss = 64.9291, Reconstruct Loss = 0.0005, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0473, Reg Loss = 64.9506, Reconstruct Loss = 0.0006, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Epoch [163/200], Training Loss: 0.0476, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/200], Validation Loss: 0.3986, Validation Accuracy: 91.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0727, Reg Loss = 64.1979, Reconstruct Loss = 0.0000, Cls Loss = 0.0663, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0496, Reg Loss = 64.9754, Reconstruct Loss = 0.0003, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0482, Reg Loss = 64.9986, Reconstruct Loss = 0.0008, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0460, Reg Loss = 64.9666, Reconstruct Loss = 0.0008, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 64.9505, Reconstruct Loss = 0.0008, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0461, Reg Loss = 64.9264, Reconstruct Loss = 0.0007, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0470, Reg Loss = 64.9183, Reconstruct Loss = 0.0007, Cls Loss = 0.0398, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0472, Reg Loss = 64.8888, Reconstruct Loss = 0.0006, Cls Loss = 0.0400, Learning rate = 1.0000e-05\n",
      "Epoch [164/200], Training Loss: 0.0469, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/200], Validation Loss: 0.3932, Validation Accuracy: 91.25%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0129, Reg Loss = 62.4293, Reconstruct Loss = 0.0000, Cls Loss = 0.0067, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0407, Reg Loss = 64.8266, Reconstruct Loss = 0.0008, Cls Loss = 0.0334, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0421, Reg Loss = 64.7851, Reconstruct Loss = 0.0005, Cls Loss = 0.0351, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0435, Reg Loss = 64.9072, Reconstruct Loss = 0.0004, Cls Loss = 0.0366, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0440, Reg Loss = 64.9202, Reconstruct Loss = 0.0006, Cls Loss = 0.0369, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0441, Reg Loss = 64.8729, Reconstruct Loss = 0.0005, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0443, Reg Loss = 64.8728, Reconstruct Loss = 0.0004, Cls Loss = 0.0374, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0451, Reg Loss = 64.8789, Reconstruct Loss = 0.0005, Cls Loss = 0.0381, Learning rate = 1.0000e-05\n",
      "Epoch [165/200], Training Loss: 0.0446, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/200], Validation Loss: 0.4028, Validation Accuracy: 91.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0374, Reg Loss = 65.9045, Reconstruct Loss = 0.0000, Cls Loss = 0.0308, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0496, Reg Loss = 64.8915, Reconstruct Loss = 0.0003, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0473, Reg Loss = 64.9074, Reconstruct Loss = 0.0005, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0451, Reg Loss = 64.8649, Reconstruct Loss = 0.0004, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0440, Reg Loss = 64.8837, Reconstruct Loss = 0.0005, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0440, Reg Loss = 64.8478, Reconstruct Loss = 0.0005, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0441, Reg Loss = 64.8775, Reconstruct Loss = 0.0006, Cls Loss = 0.0369, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0443, Reg Loss = 64.8723, Reconstruct Loss = 0.0006, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Epoch [166/200], Training Loss: 0.0442, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/200], Validation Loss: 0.4104, Validation Accuracy: 91.50%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0282, Reg Loss = 66.6289, Reconstruct Loss = 0.0000, Cls Loss = 0.0215, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0469, Reg Loss = 64.6229, Reconstruct Loss = 0.0003, Cls Loss = 0.0401, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0514, Reg Loss = 64.7695, Reconstruct Loss = 0.0005, Cls Loss = 0.0444, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0471, Reg Loss = 64.7848, Reconstruct Loss = 0.0007, Cls Loss = 0.0399, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0477, Reg Loss = 64.8029, Reconstruct Loss = 0.0009, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0480, Reg Loss = 64.8352, Reconstruct Loss = 0.0010, Cls Loss = 0.0406, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0479, Reg Loss = 64.8464, Reconstruct Loss = 0.0010, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0469, Reg Loss = 64.8670, Reconstruct Loss = 0.0009, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Epoch [167/200], Training Loss: 0.0464, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/200], Validation Loss: 0.4063, Validation Accuracy: 91.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0524, Reg Loss = 65.8600, Reconstruct Loss = 0.0000, Cls Loss = 0.0458, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0486, Reg Loss = 65.0610, Reconstruct Loss = 0.0008, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0466, Reg Loss = 64.9880, Reconstruct Loss = 0.0009, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0460, Reg Loss = 64.9303, Reconstruct Loss = 0.0008, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0460, Reg Loss = 64.8762, Reconstruct Loss = 0.0008, Cls Loss = 0.0388, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0461, Reg Loss = 64.8552, Reconstruct Loss = 0.0008, Cls Loss = 0.0388, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0456, Reg Loss = 64.8413, Reconstruct Loss = 0.0008, Cls Loss = 0.0384, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0458, Reg Loss = 64.8259, Reconstruct Loss = 0.0008, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Epoch [168/200], Training Loss: 0.0457, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [168/200], Validation Loss: 0.4072, Validation Accuracy: 91.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0343, Reg Loss = 64.9149, Reconstruct Loss = 0.0000, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0427, Reg Loss = 64.8924, Reconstruct Loss = 0.0005, Cls Loss = 0.0357, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0444, Reg Loss = 64.8807, Reconstruct Loss = 0.0005, Cls Loss = 0.0374, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0443, Reg Loss = 64.9080, Reconstruct Loss = 0.0005, Cls Loss = 0.0373, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0428, Reg Loss = 64.9060, Reconstruct Loss = 0.0008, Cls Loss = 0.0355, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0437, Reg Loss = 64.8580, Reconstruct Loss = 0.0007, Cls Loss = 0.0365, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0440, Reg Loss = 64.8404, Reconstruct Loss = 0.0008, Cls Loss = 0.0367, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0437, Reg Loss = 64.7965, Reconstruct Loss = 0.0008, Cls Loss = 0.0364, Learning rate = 1.0000e-05\n",
      "Epoch [169/200], Training Loss: 0.0442, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/200], Validation Loss: 0.4016, Validation Accuracy: 91.24%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0640, Reg Loss = 65.7094, Reconstruct Loss = 0.0000, Cls Loss = 0.0574, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0480, Reg Loss = 64.9577, Reconstruct Loss = 0.0005, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0488, Reg Loss = 64.9029, Reconstruct Loss = 0.0011, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0460, Reg Loss = 64.8706, Reconstruct Loss = 0.0011, Cls Loss = 0.0384, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0451, Reg Loss = 64.8352, Reconstruct Loss = 0.0009, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0453, Reg Loss = 64.8291, Reconstruct Loss = 0.0009, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0446, Reg Loss = 64.8125, Reconstruct Loss = 0.0009, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0456, Reg Loss = 64.8356, Reconstruct Loss = 0.0009, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Epoch [170/200], Training Loss: 0.0452, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/200], Validation Loss: 0.4187, Validation Accuracy: 91.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0249, Reg Loss = 62.9959, Reconstruct Loss = 0.0000, Cls Loss = 0.0186, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0459, Reg Loss = 64.5631, Reconstruct Loss = 0.0005, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0459, Reg Loss = 64.7225, Reconstruct Loss = 0.0010, Cls Loss = 0.0385, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0464, Reg Loss = 64.7733, Reconstruct Loss = 0.0010, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 64.7965, Reconstruct Loss = 0.0009, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0465, Reg Loss = 64.8094, Reconstruct Loss = 0.0009, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0469, Reg Loss = 64.7845, Reconstruct Loss = 0.0008, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0478, Reg Loss = 64.7731, Reconstruct Loss = 0.0008, Cls Loss = 0.0406, Learning rate = 1.0000e-05\n",
      "Epoch [171/200], Training Loss: 0.0475, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/200], Validation Loss: 0.4058, Validation Accuracy: 91.37%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0307, Reg Loss = 66.3780, Reconstruct Loss = 0.0000, Cls Loss = 0.0241, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0430, Reg Loss = 64.7888, Reconstruct Loss = 0.0008, Cls Loss = 0.0358, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0472, Reg Loss = 64.6579, Reconstruct Loss = 0.0010, Cls Loss = 0.0398, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0474, Reg Loss = 64.6369, Reconstruct Loss = 0.0010, Cls Loss = 0.0399, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0499, Reg Loss = 64.6383, Reconstruct Loss = 0.0009, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0484, Reg Loss = 64.6873, Reconstruct Loss = 0.0009, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0480, Reg Loss = 64.6927, Reconstruct Loss = 0.0010, Cls Loss = 0.0406, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0478, Reg Loss = 64.6941, Reconstruct Loss = 0.0009, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Epoch [172/200], Training Loss: 0.0473, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/200], Validation Loss: 0.3953, Validation Accuracy: 91.43%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0334, Reg Loss = 63.9932, Reconstruct Loss = 0.0000, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0471, Reg Loss = 64.6439, Reconstruct Loss = 0.0007, Cls Loss = 0.0399, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0427, Reg Loss = 64.6999, Reconstruct Loss = 0.0006, Cls Loss = 0.0356, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0443, Reg Loss = 64.7404, Reconstruct Loss = 0.0005, Cls Loss = 0.0373, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0426, Reg Loss = 64.7214, Reconstruct Loss = 0.0006, Cls Loss = 0.0356, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0432, Reg Loss = 64.6642, Reconstruct Loss = 0.0005, Cls Loss = 0.0362, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0430, Reg Loss = 64.6501, Reconstruct Loss = 0.0005, Cls Loss = 0.0361, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0437, Reg Loss = 64.6477, Reconstruct Loss = 0.0006, Cls Loss = 0.0366, Learning rate = 1.0000e-05\n",
      "Epoch [173/200], Training Loss: 0.0442, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/200], Validation Loss: 0.4092, Validation Accuracy: 91.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1358, Reg Loss = 65.2942, Reconstruct Loss = 0.0000, Cls Loss = 0.1293, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0525, Reg Loss = 64.7415, Reconstruct Loss = 0.0005, Cls Loss = 0.0456, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0487, Reg Loss = 64.7498, Reconstruct Loss = 0.0003, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0482, Reg Loss = 64.7317, Reconstruct Loss = 0.0005, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0466, Reg Loss = 64.7300, Reconstruct Loss = 0.0004, Cls Loss = 0.0397, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0465, Reg Loss = 64.6939, Reconstruct Loss = 0.0004, Cls Loss = 0.0397, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0466, Reg Loss = 64.7103, Reconstruct Loss = 0.0007, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0468, Reg Loss = 64.6995, Reconstruct Loss = 0.0007, Cls Loss = 0.0397, Learning rate = 1.0000e-05\n",
      "Epoch [174/200], Training Loss: 0.0470, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200], Validation Loss: 0.4098, Validation Accuracy: 91.49%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0177, Reg Loss = 64.8683, Reconstruct Loss = 0.0000, Cls Loss = 0.0112, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0450, Reg Loss = 64.5653, Reconstruct Loss = 0.0008, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0440, Reg Loss = 64.6086, Reconstruct Loss = 0.0010, Cls Loss = 0.0365, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0455, Reg Loss = 64.5856, Reconstruct Loss = 0.0012, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0456, Reg Loss = 64.5621, Reconstruct Loss = 0.0009, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0455, Reg Loss = 64.5363, Reconstruct Loss = 0.0008, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0455, Reg Loss = 64.5335, Reconstruct Loss = 0.0008, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0460, Reg Loss = 64.5215, Reconstruct Loss = 0.0008, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Epoch [175/200], Training Loss: 0.0458, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/200], Validation Loss: 0.4206, Validation Accuracy: 91.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0317, Reg Loss = 65.2212, Reconstruct Loss = 0.0000, Cls Loss = 0.0252, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0433, Reg Loss = 64.6240, Reconstruct Loss = 0.0007, Cls Loss = 0.0361, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0461, Reg Loss = 64.5244, Reconstruct Loss = 0.0010, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0445, Reg Loss = 64.5934, Reconstruct Loss = 0.0010, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0443, Reg Loss = 64.5517, Reconstruct Loss = 0.0009, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0442, Reg Loss = 64.5383, Reconstruct Loss = 0.0007, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0444, Reg Loss = 64.5540, Reconstruct Loss = 0.0007, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0439, Reg Loss = 64.5567, Reconstruct Loss = 0.0007, Cls Loss = 0.0367, Learning rate = 1.0000e-05\n",
      "Epoch [176/200], Training Loss: 0.0435, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/200], Validation Loss: 0.4280, Validation Accuracy: 91.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0281, Reg Loss = 63.0667, Reconstruct Loss = 0.0000, Cls Loss = 0.0218, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0452, Reg Loss = 64.6239, Reconstruct Loss = 0.0008, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0432, Reg Loss = 64.6317, Reconstruct Loss = 0.0008, Cls Loss = 0.0360, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0435, Reg Loss = 64.5910, Reconstruct Loss = 0.0007, Cls Loss = 0.0363, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0448, Reg Loss = 64.5860, Reconstruct Loss = 0.0006, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0450, Reg Loss = 64.6172, Reconstruct Loss = 0.0007, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0458, Reg Loss = 64.6180, Reconstruct Loss = 0.0007, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0464, Reg Loss = 64.6232, Reconstruct Loss = 0.0006, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Epoch [177/200], Training Loss: 0.0466, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/200], Validation Loss: 0.4000, Validation Accuracy: 91.36%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0267, Reg Loss = 63.9918, Reconstruct Loss = 0.0000, Cls Loss = 0.0203, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0445, Reg Loss = 64.4527, Reconstruct Loss = 0.0005, Cls Loss = 0.0376, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0433, Reg Loss = 64.5336, Reconstruct Loss = 0.0006, Cls Loss = 0.0362, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0450, Reg Loss = 64.5714, Reconstruct Loss = 0.0005, Cls Loss = 0.0381, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0462, Reg Loss = 64.5235, Reconstruct Loss = 0.0004, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0454, Reg Loss = 64.5699, Reconstruct Loss = 0.0004, Cls Loss = 0.0385, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0464, Reg Loss = 64.5964, Reconstruct Loss = 0.0005, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0460, Reg Loss = 64.5663, Reconstruct Loss = 0.0005, Cls Loss = 0.0390, Learning rate = 1.0000e-05\n",
      "Epoch [178/200], Training Loss: 0.0463, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/200], Validation Loss: 0.3956, Validation Accuracy: 91.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0772, Reg Loss = 63.6386, Reconstruct Loss = 0.0000, Cls Loss = 0.0708, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0466, Reg Loss = 64.4546, Reconstruct Loss = 0.0002, Cls Loss = 0.0400, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0482, Reg Loss = 64.4826, Reconstruct Loss = 0.0005, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0475, Reg Loss = 64.4815, Reconstruct Loss = 0.0007, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0468, Reg Loss = 64.4834, Reconstruct Loss = 0.0009, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0456, Reg Loss = 64.5055, Reconstruct Loss = 0.0008, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0463, Reg Loss = 64.4876, Reconstruct Loss = 0.0008, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0462, Reg Loss = 64.4770, Reconstruct Loss = 0.0007, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Epoch [179/200], Training Loss: 0.0462, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/200], Validation Loss: 0.3979, Validation Accuracy: 91.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0183, Reg Loss = 63.6306, Reconstruct Loss = 0.0000, Cls Loss = 0.0119, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 64.1115, Reconstruct Loss = 0.0010, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0466, Reg Loss = 64.3304, Reconstruct Loss = 0.0010, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0454, Reg Loss = 64.3799, Reconstruct Loss = 0.0009, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0459, Reg Loss = 64.4211, Reconstruct Loss = 0.0009, Cls Loss = 0.0385, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0461, Reg Loss = 64.4133, Reconstruct Loss = 0.0011, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0467, Reg Loss = 64.3990, Reconstruct Loss = 0.0011, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0470, Reg Loss = 64.3954, Reconstruct Loss = 0.0010, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Epoch [180/200], Training Loss: 0.0461, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/200], Validation Loss: 0.4165, Validation Accuracy: 91.25%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0445, Reg Loss = 63.4260, Reconstruct Loss = 0.0000, Cls Loss = 0.0381, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0455, Reg Loss = 64.4055, Reconstruct Loss = 0.0008, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0478, Reg Loss = 64.2960, Reconstruct Loss = 0.0006, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0462, Reg Loss = 64.3544, Reconstruct Loss = 0.0007, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0464, Reg Loss = 64.3790, Reconstruct Loss = 0.0008, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0473, Reg Loss = 64.3867, Reconstruct Loss = 0.0008, Cls Loss = 0.0401, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0458, Reg Loss = 64.4069, Reconstruct Loss = 0.0008, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0464, Reg Loss = 64.4139, Reconstruct Loss = 0.0008, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Epoch [181/200], Training Loss: 0.0459, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/200], Validation Loss: 0.3948, Validation Accuracy: 91.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0166, Reg Loss = 64.4061, Reconstruct Loss = 0.0000, Cls Loss = 0.0102, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0412, Reg Loss = 64.3331, Reconstruct Loss = 0.0003, Cls Loss = 0.0345, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0429, Reg Loss = 64.3532, Reconstruct Loss = 0.0004, Cls Loss = 0.0361, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0444, Reg Loss = 64.3668, Reconstruct Loss = 0.0004, Cls Loss = 0.0376, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0440, Reg Loss = 64.3648, Reconstruct Loss = 0.0004, Cls Loss = 0.0371, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0451, Reg Loss = 64.3511, Reconstruct Loss = 0.0005, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0451, Reg Loss = 64.3996, Reconstruct Loss = 0.0006, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0443, Reg Loss = 64.3930, Reconstruct Loss = 0.0006, Cls Loss = 0.0373, Learning rate = 1.0000e-05\n",
      "Epoch [182/200], Training Loss: 0.0444, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/200], Validation Loss: 0.4050, Validation Accuracy: 91.18%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0291, Reg Loss = 63.1553, Reconstruct Loss = 0.0000, Cls Loss = 0.0228, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0399, Reg Loss = 64.5850, Reconstruct Loss = 0.0005, Cls Loss = 0.0329, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0430, Reg Loss = 64.4746, Reconstruct Loss = 0.0006, Cls Loss = 0.0359, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0428, Reg Loss = 64.4799, Reconstruct Loss = 0.0008, Cls Loss = 0.0356, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0420, Reg Loss = 64.5417, Reconstruct Loss = 0.0007, Cls Loss = 0.0349, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0425, Reg Loss = 64.5167, Reconstruct Loss = 0.0007, Cls Loss = 0.0353, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0429, Reg Loss = 64.5136, Reconstruct Loss = 0.0007, Cls Loss = 0.0358, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0435, Reg Loss = 64.5170, Reconstruct Loss = 0.0007, Cls Loss = 0.0363, Learning rate = 1.0000e-05\n",
      "Epoch [183/200], Training Loss: 0.0433, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/200], Validation Loss: 0.4064, Validation Accuracy: 91.58%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0172, Reg Loss = 63.2864, Reconstruct Loss = 0.0000, Cls Loss = 0.0109, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0481, Reg Loss = 64.3309, Reconstruct Loss = 0.0002, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0474, Reg Loss = 64.4204, Reconstruct Loss = 0.0005, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0473, Reg Loss = 64.4619, Reconstruct Loss = 0.0006, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0469, Reg Loss = 64.5083, Reconstruct Loss = 0.0007, Cls Loss = 0.0397, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0480, Reg Loss = 64.4814, Reconstruct Loss = 0.0008, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0479, Reg Loss = 64.4929, Reconstruct Loss = 0.0008, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0470, Reg Loss = 64.4852, Reconstruct Loss = 0.0007, Cls Loss = 0.0399, Learning rate = 1.0000e-05\n",
      "Epoch [184/200], Training Loss: 0.0467, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/200], Validation Loss: 0.4017, Validation Accuracy: 91.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0500, Reg Loss = 64.1364, Reconstruct Loss = 0.0000, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0458, Reg Loss = 64.4684, Reconstruct Loss = 0.0007, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0446, Reg Loss = 64.4653, Reconstruct Loss = 0.0006, Cls Loss = 0.0375, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0440, Reg Loss = 64.4523, Reconstruct Loss = 0.0005, Cls Loss = 0.0371, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0445, Reg Loss = 64.4779, Reconstruct Loss = 0.0005, Cls Loss = 0.0375, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0443, Reg Loss = 64.4693, Reconstruct Loss = 0.0005, Cls Loss = 0.0373, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0443, Reg Loss = 64.4299, Reconstruct Loss = 0.0005, Cls Loss = 0.0373, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0450, Reg Loss = 64.4050, Reconstruct Loss = 0.0005, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Epoch [185/200], Training Loss: 0.0454, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/200], Validation Loss: 0.4130, Validation Accuracy: 91.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0567, Reg Loss = 64.3358, Reconstruct Loss = 0.0000, Cls Loss = 0.0503, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0401, Reg Loss = 64.2386, Reconstruct Loss = 0.0005, Cls Loss = 0.0331, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0426, Reg Loss = 64.2614, Reconstruct Loss = 0.0007, Cls Loss = 0.0356, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0425, Reg Loss = 64.2654, Reconstruct Loss = 0.0009, Cls Loss = 0.0352, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0429, Reg Loss = 64.2825, Reconstruct Loss = 0.0008, Cls Loss = 0.0357, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0428, Reg Loss = 64.2856, Reconstruct Loss = 0.0010, Cls Loss = 0.0354, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0420, Reg Loss = 64.3200, Reconstruct Loss = 0.0009, Cls Loss = 0.0347, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0432, Reg Loss = 64.3419, Reconstruct Loss = 0.0009, Cls Loss = 0.0359, Learning rate = 1.0000e-05\n",
      "Epoch [186/200], Training Loss: 0.0434, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/200], Validation Loss: 0.4073, Validation Accuracy: 91.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0307, Reg Loss = 66.2033, Reconstruct Loss = 0.0000, Cls Loss = 0.0240, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0446, Reg Loss = 64.7385, Reconstruct Loss = 0.0015, Cls Loss = 0.0366, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0447, Reg Loss = 64.5726, Reconstruct Loss = 0.0014, Cls Loss = 0.0368, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 64.5057, Reconstruct Loss = 0.0009, Cls Loss = 0.0369, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0428, Reg Loss = 64.4856, Reconstruct Loss = 0.0009, Cls Loss = 0.0354, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 64.4846, Reconstruct Loss = 0.0009, Cls Loss = 0.0371, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0443, Reg Loss = 64.4753, Reconstruct Loss = 0.0008, Cls Loss = 0.0371, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0456, Reg Loss = 64.4691, Reconstruct Loss = 0.0008, Cls Loss = 0.0384, Learning rate = 1.0000e-05\n",
      "Epoch [187/200], Training Loss: 0.0454, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/200], Validation Loss: 0.4161, Validation Accuracy: 91.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0187, Reg Loss = 64.1817, Reconstruct Loss = 0.0000, Cls Loss = 0.0123, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0428, Reg Loss = 64.2441, Reconstruct Loss = 0.0007, Cls Loss = 0.0356, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0434, Reg Loss = 64.3301, Reconstruct Loss = 0.0008, Cls Loss = 0.0362, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 64.3304, Reconstruct Loss = 0.0006, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0450, Reg Loss = 64.3552, Reconstruct Loss = 0.0008, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 64.3881, Reconstruct Loss = 0.0009, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0444, Reg Loss = 64.4041, Reconstruct Loss = 0.0008, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0448, Reg Loss = 64.4207, Reconstruct Loss = 0.0008, Cls Loss = 0.0376, Learning rate = 1.0000e-05\n",
      "Epoch [188/200], Training Loss: 0.0452, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/200], Validation Loss: 0.3992, Validation Accuracy: 91.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0198, Reg Loss = 65.3925, Reconstruct Loss = 0.0000, Cls Loss = 0.0133, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 64.4275, Reconstruct Loss = 0.0010, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0477, Reg Loss = 64.3787, Reconstruct Loss = 0.0011, Cls Loss = 0.0401, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0457, Reg Loss = 64.4061, Reconstruct Loss = 0.0010, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 64.4245, Reconstruct Loss = 0.0010, Cls Loss = 0.0392, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0462, Reg Loss = 64.4352, Reconstruct Loss = 0.0010, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0460, Reg Loss = 64.4392, Reconstruct Loss = 0.0009, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0459, Reg Loss = 64.4212, Reconstruct Loss = 0.0009, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Epoch [189/200], Training Loss: 0.0462, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/200], Validation Loss: 0.4142, Validation Accuracy: 91.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0185, Reg Loss = 62.8336, Reconstruct Loss = 0.0000, Cls Loss = 0.0122, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0500, Reg Loss = 64.2791, Reconstruct Loss = 0.0000, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0471, Reg Loss = 64.4046, Reconstruct Loss = 0.0004, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0457, Reg Loss = 64.4675, Reconstruct Loss = 0.0003, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0455, Reg Loss = 64.5341, Reconstruct Loss = 0.0004, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0462, Reg Loss = 64.4979, Reconstruct Loss = 0.0005, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0450, Reg Loss = 64.5129, Reconstruct Loss = 0.0006, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0454, Reg Loss = 64.4867, Reconstruct Loss = 0.0007, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Epoch [190/200], Training Loss: 0.0447, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 51.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/200], Validation Loss: 0.4179, Validation Accuracy: 91.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0258, Reg Loss = 63.6734, Reconstruct Loss = 0.0000, Cls Loss = 0.0194, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0430, Reg Loss = 64.4487, Reconstruct Loss = 0.0012, Cls Loss = 0.0353, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0444, Reg Loss = 64.4056, Reconstruct Loss = 0.0010, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0449, Reg Loss = 64.4194, Reconstruct Loss = 0.0007, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0448, Reg Loss = 64.4565, Reconstruct Loss = 0.0008, Cls Loss = 0.0376, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0443, Reg Loss = 64.4534, Reconstruct Loss = 0.0008, Cls Loss = 0.0371, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0451, Reg Loss = 64.4626, Reconstruct Loss = 0.0008, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0447, Reg Loss = 64.4713, Reconstruct Loss = 0.0008, Cls Loss = 0.0374, Learning rate = 1.0000e-05\n",
      "Epoch [191/200], Training Loss: 0.0449, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/200], Validation Loss: 0.4161, Validation Accuracy: 91.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0157, Reg Loss = 65.8019, Reconstruct Loss = 0.0000, Cls Loss = 0.0091, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0433, Reg Loss = 64.4681, Reconstruct Loss = 0.0005, Cls Loss = 0.0364, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0466, Reg Loss = 64.4871, Reconstruct Loss = 0.0006, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0463, Reg Loss = 64.5017, Reconstruct Loss = 0.0007, Cls Loss = 0.0392, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0448, Reg Loss = 64.4573, Reconstruct Loss = 0.0007, Cls Loss = 0.0377, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0456, Reg Loss = 64.5054, Reconstruct Loss = 0.0007, Cls Loss = 0.0385, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0450, Reg Loss = 64.5110, Reconstruct Loss = 0.0006, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0453, Reg Loss = 64.4987, Reconstruct Loss = 0.0007, Cls Loss = 0.0381, Learning rate = 1.0000e-05\n",
      "Epoch [192/200], Training Loss: 0.0448, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/200], Validation Loss: 0.4105, Validation Accuracy: 91.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0292, Reg Loss = 65.2270, Reconstruct Loss = 0.0000, Cls Loss = 0.0227, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0480, Reg Loss = 64.4398, Reconstruct Loss = 0.0007, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0451, Reg Loss = 64.4471, Reconstruct Loss = 0.0004, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0452, Reg Loss = 64.4548, Reconstruct Loss = 0.0003, Cls Loss = 0.0384, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0442, Reg Loss = 64.5050, Reconstruct Loss = 0.0006, Cls Loss = 0.0372, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0447, Reg Loss = 64.4797, Reconstruct Loss = 0.0007, Cls Loss = 0.0376, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0455, Reg Loss = 64.5127, Reconstruct Loss = 0.0008, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0461, Reg Loss = 64.5121, Reconstruct Loss = 0.0010, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Epoch [193/200], Training Loss: 0.0464, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/200], Validation Loss: 0.3982, Validation Accuracy: 91.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1050, Reg Loss = 64.2439, Reconstruct Loss = 0.0000, Cls Loss = 0.0986, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0451, Reg Loss = 64.3920, Reconstruct Loss = 0.0007, Cls Loss = 0.0379, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0441, Reg Loss = 64.4716, Reconstruct Loss = 0.0006, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 64.4358, Reconstruct Loss = 0.0004, Cls Loss = 0.0373, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0445, Reg Loss = 64.4274, Reconstruct Loss = 0.0005, Cls Loss = 0.0376, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0440, Reg Loss = 64.4492, Reconstruct Loss = 0.0006, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0444, Reg Loss = 64.4529, Reconstruct Loss = 0.0006, Cls Loss = 0.0374, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0451, Reg Loss = 64.4299, Reconstruct Loss = 0.0006, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Epoch [194/200], Training Loss: 0.0459, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/200], Validation Loss: 0.4086, Validation Accuracy: 91.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0153, Reg Loss = 65.8266, Reconstruct Loss = 0.0000, Cls Loss = 0.0087, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0452, Reg Loss = 64.4737, Reconstruct Loss = 0.0007, Cls Loss = 0.0380, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0459, Reg Loss = 64.4655, Reconstruct Loss = 0.0009, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0453, Reg Loss = 64.4730, Reconstruct Loss = 0.0007, Cls Loss = 0.0382, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 64.4592, Reconstruct Loss = 0.0006, Cls Loss = 0.0396, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0472, Reg Loss = 64.4473, Reconstruct Loss = 0.0006, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0473, Reg Loss = 64.4653, Reconstruct Loss = 0.0008, Cls Loss = 0.0401, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0466, Reg Loss = 64.4580, Reconstruct Loss = 0.0008, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Epoch [195/200], Training Loss: 0.0468, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [195/200], Validation Loss: 0.4209, Validation Accuracy: 91.24%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0165, Reg Loss = 64.0628, Reconstruct Loss = 0.0000, Cls Loss = 0.0101, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0426, Reg Loss = 64.3104, Reconstruct Loss = 0.0005, Cls Loss = 0.0357, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0432, Reg Loss = 64.3895, Reconstruct Loss = 0.0005, Cls Loss = 0.0363, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0454, Reg Loss = 64.3703, Reconstruct Loss = 0.0009, Cls Loss = 0.0381, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0446, Reg Loss = 64.3593, Reconstruct Loss = 0.0008, Cls Loss = 0.0373, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0461, Reg Loss = 64.3602, Reconstruct Loss = 0.0010, Cls Loss = 0.0387, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0463, Reg Loss = 64.3627, Reconstruct Loss = 0.0008, Cls Loss = 0.0390, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0464, Reg Loss = 64.3635, Reconstruct Loss = 0.0009, Cls Loss = 0.0390, Learning rate = 1.0000e-05\n",
      "Epoch [196/200], Training Loss: 0.0462, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/200], Validation Loss: 0.4086, Validation Accuracy: 91.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0687, Reg Loss = 63.8894, Reconstruct Loss = 0.0000, Cls Loss = 0.0623, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0434, Reg Loss = 64.5405, Reconstruct Loss = 0.0007, Cls Loss = 0.0362, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0412, Reg Loss = 64.4675, Reconstruct Loss = 0.0007, Cls Loss = 0.0340, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0409, Reg Loss = 64.4300, Reconstruct Loss = 0.0007, Cls Loss = 0.0338, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0415, Reg Loss = 64.3980, Reconstruct Loss = 0.0007, Cls Loss = 0.0343, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0431, Reg Loss = 64.3912, Reconstruct Loss = 0.0007, Cls Loss = 0.0359, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0426, Reg Loss = 64.3992, Reconstruct Loss = 0.0009, Cls Loss = 0.0352, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0426, Reg Loss = 64.4188, Reconstruct Loss = 0.0008, Cls Loss = 0.0353, Learning rate = 1.0000e-05\n",
      "Epoch [197/200], Training Loss: 0.0427, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [197/200], Validation Loss: 0.4103, Validation Accuracy: 91.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0311, Reg Loss = 64.4341, Reconstruct Loss = 0.0000, Cls Loss = 0.0247, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0458, Reg Loss = 64.2603, Reconstruct Loss = 0.0008, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0424, Reg Loss = 64.2822, Reconstruct Loss = 0.0006, Cls Loss = 0.0353, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0418, Reg Loss = 64.3039, Reconstruct Loss = 0.0005, Cls Loss = 0.0348, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0433, Reg Loss = 64.3350, Reconstruct Loss = 0.0004, Cls Loss = 0.0365, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0432, Reg Loss = 64.3513, Reconstruct Loss = 0.0004, Cls Loss = 0.0364, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0438, Reg Loss = 64.3532, Reconstruct Loss = 0.0005, Cls Loss = 0.0369, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0436, Reg Loss = 64.3666, Reconstruct Loss = 0.0005, Cls Loss = 0.0367, Learning rate = 1.0000e-05\n",
      "Epoch [198/200], Training Loss: 0.0440, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [198/200], Validation Loss: 0.3949, Validation Accuracy: 91.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0466, Reg Loss = 65.8899, Reconstruct Loss = 0.0271, Cls Loss = 0.0129, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0508, Reg Loss = 64.1903, Reconstruct Loss = 0.0005, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0459, Reg Loss = 64.2664, Reconstruct Loss = 0.0009, Cls Loss = 0.0386, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0444, Reg Loss = 64.3702, Reconstruct Loss = 0.0010, Cls Loss = 0.0369, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0442, Reg Loss = 64.4082, Reconstruct Loss = 0.0009, Cls Loss = 0.0368, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0428, Reg Loss = 64.3859, Reconstruct Loss = 0.0009, Cls Loss = 0.0355, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0435, Reg Loss = 64.3869, Reconstruct Loss = 0.0008, Cls Loss = 0.0363, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0439, Reg Loss = 64.3812, Reconstruct Loss = 0.0008, Cls Loss = 0.0367, Learning rate = 1.0000e-05\n",
      "Epoch [199/200], Training Loss: 0.0441, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/200], Validation Loss: 0.4051, Validation Accuracy: 91.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0734, Reg Loss = 65.9154, Reconstruct Loss = 0.0000, Cls Loss = 0.0668, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0416, Reg Loss = 64.5216, Reconstruct Loss = 0.0005, Cls Loss = 0.0346, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0453, Reg Loss = 64.5531, Reconstruct Loss = 0.0010, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0457, Reg Loss = 64.5367, Reconstruct Loss = 0.0007, Cls Loss = 0.0385, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0454, Reg Loss = 64.5234, Reconstruct Loss = 0.0006, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0453, Reg Loss = 64.5019, Reconstruct Loss = 0.0006, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0441, Reg Loss = 64.4987, Reconstruct Loss = 0.0006, Cls Loss = 0.0370, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0438, Reg Loss = 64.4882, Reconstruct Loss = 0.0006, Cls Loss = 0.0367, Learning rate = 1.0000e-05\n",
      "Epoch [200/200], Training Loss: 0.0438, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/200], Validation Loss: 0.4004, Validation Accuracy: 91.34%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the epochs\n",
    "for epoch in range(start_epoch, args.experiment.num_epochs):\n",
    "    # Train the hypernetwork to generate a model with random dimension for one epoch\n",
    "    train_loss, dim_dict, gt_model_dict = train_one_epoch(hyper_model, train_loader, optimizer, criterion, \n",
    "                                                          dim_dict, gt_model_dict, epoch_idx=epoch, ema=ema, \n",
    "                                                          args=args, device=device)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the training loss and learning rate\n",
    "    print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Training Loss: {train_loss:.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # If it's time to evaluate the model\n",
    "    if (epoch + 1) % args.experiment.eval_interval == 0:\n",
    "        # Apply EMA if it is specified\n",
    "        if ema:\n",
    "            ema.apply()  # Save the weights of original model created before training_loop\n",
    "        \n",
    "        # Sample the merged model (create model of same structure before training loop by using the hypernetwork)\n",
    "        # And then test the performance of the hypernetwork by seeing how good it is in generating the weights\n",
    "        model = sample_merge_model(hyper_model, model, args) \n",
    "        # Validate the merged model\n",
    "        val_loss, acc = validate_single(model, val_loader, val_criterion, args=args)\n",
    "\n",
    "        # If EMA is specified, restore the original weights\n",
    "        if ema:\n",
    "            ema.restore()  # Restore the original weights to the weights of the pretrained networks\n",
    "\n",
    "        # Log the validation loss and accuracy to wandb\n",
    "        wandb.log({\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": acc\n",
    "        })\n",
    "        # Print the validation loss and accuracy\n",
    "        print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Save the checkpoint if the accuracy is better than the previous best\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_checkpoint(f\"{args.training.save_model_path}/cifar10_nerf_best.pth\",hyper_model,optimizer,ema,epoch,best_acc)\n",
    "            print(f\"Checkpoint saved at epoch {epoch} with accuracy: {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ee9bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.4375, Validation Accuracy: 90.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(dim_dict['32'][0], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b21c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.4127, Validation Accuracy: 91.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(dim_dict['64'][0], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17b7b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.2825, Validation Accuracy: 92.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(gt_model_dict['64'], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15464fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>███▇▆▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning rate</td><td>███████████████████▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss</td><td>██▇▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Reconstruct Loss</td><td>█▁▇▆▇▃▇▁▆▅▅▅▄▄▄▄▁▄▃▄▁▄▁▄▃▁▄▄▄▃▃▁▂▆▄▄▁▃▄▄</td></tr><tr><td>Reg Loss</td><td>▁███▆▆▄▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Validation Accuracy</td><td>▅▂▁▆▇▇██████████████████████████████████</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>0.03671</td></tr><tr><td>Learning rate</td><td>1e-05</td></tr><tr><td>Loss</td><td>0.04377</td></tr><tr><td>Reconstruct Loss</td><td>0.00061</td></tr><tr><td>Reg Loss</td><td>64.48821</td></tr><tr><td>Validation Accuracy</td><td>0.9134</td></tr><tr><td>Validation Loss</td><td>0.40038</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20250520015346-ninr_resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16</strong> at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/quvsqrph' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/quvsqrph</a><br> View project at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_015347-quvsqrph\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# End the wandb tracking\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6054a4",
   "metadata": {},
   "source": [
    "### 7 Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43945b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_hypernet_path = args.training.save_model_path + '/cifar10_nerf_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f139172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "hyper_model_test = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4431caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(saved_hypernet_path, map_location=\"cpu\")  # or \"cuda\" if using GPU\n",
    "hyper_model_test.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eaa63eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 16\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 16, Validation Loss: 0.5090, Validation Accuracy: 88.24%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 17\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 17, Validation Loss: 0.6210, Validation Accuracy: 85.78%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 18\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 18, Validation Loss: 0.4013, Validation Accuracy: 89.99%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 19\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 19, Validation Loss: 0.4804, Validation Accuracy: 89.18%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 20\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 20, Validation Loss: 0.4402, Validation Accuracy: 90.30%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 21\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 21, Validation Loss: 0.4344, Validation Accuracy: 90.43%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 22\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 22, Validation Loss: 0.4337, Validation Accuracy: 90.45%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 23\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 23, Validation Loss: 0.5850, Validation Accuracy: 89.05%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 24\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 24, Validation Loss: 0.3913, Validation Accuracy: 90.84%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 25\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 25, Validation Loss: 0.4259, Validation Accuracy: 90.61%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 26\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 26, Validation Loss: 0.4241, Validation Accuracy: 90.93%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 27\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 27, Validation Loss: 0.4169, Validation Accuracy: 91.22%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 28\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 28, Validation Loss: 0.4426, Validation Accuracy: 90.68%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 29\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 29, Validation Loss: 0.4281, Validation Accuracy: 90.77%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 30\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 30, Validation Loss: 0.4319, Validation Accuracy: 90.92%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 31\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 31, Validation Loss: 0.4168, Validation Accuracy: 91.01%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 32, Validation Loss: 0.4358, Validation Accuracy: 90.84%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 33, Validation Loss: 0.4087, Validation Accuracy: 91.13%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 34, Validation Loss: 0.4137, Validation Accuracy: 91.08%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 35, Validation Loss: 0.4178, Validation Accuracy: 91.18%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 36, Validation Loss: 0.4061, Validation Accuracy: 90.91%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 37, Validation Loss: 0.4170, Validation Accuracy: 91.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 38, Validation Loss: 0.4165, Validation Accuracy: 91.30%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 39, Validation Loss: 0.4099, Validation Accuracy: 91.29%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 40, Validation Loss: 0.4269, Validation Accuracy: 91.17%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 41, Validation Loss: 0.4184, Validation Accuracy: 91.27%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 42, Validation Loss: 0.4126, Validation Accuracy: 91.37%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 43, Validation Loss: 0.4309, Validation Accuracy: 91.20%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 44, Validation Loss: 0.4555, Validation Accuracy: 90.88%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 45, Validation Loss: 0.4101, Validation Accuracy: 91.08%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 46, Validation Loss: 0.4248, Validation Accuracy: 91.02%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 47, Validation Loss: 0.4248, Validation Accuracy: 91.26%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 48, Validation Loss: 0.4273, Validation Accuracy: 91.23%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 49, Validation Loss: 0.4054, Validation Accuracy: 91.09%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 50, Validation Loss: 0.4047, Validation Accuracy: 91.28%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 51, Validation Loss: 0.4225, Validation Accuracy: 91.37%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 52, Validation Loss: 0.4140, Validation Accuracy: 91.30%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 53, Validation Loss: 0.4105, Validation Accuracy: 91.34%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 54, Validation Loss: 0.4334, Validation Accuracy: 91.18%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 55, Validation Loss: 0.4240, Validation Accuracy: 91.12%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 56, Validation Loss: 0.4096, Validation Accuracy: 91.18%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 57, Validation Loss: 0.4279, Validation Accuracy: 91.10%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 58, Validation Loss: 0.4148, Validation Accuracy: 91.20%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 59, Validation Loss: 0.4242, Validation Accuracy: 91.30%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 60, Validation Loss: 0.4115, Validation Accuracy: 91.49%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 61, Validation Loss: 0.4178, Validation Accuracy: 91.15%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 62, Validation Loss: 0.4183, Validation Accuracy: 91.32%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 63, Validation Loss: 0.4086, Validation Accuracy: 91.48%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': False}: hidden_dim 64, Validation Loss: 0.4185, Validation Accuracy: 91.00%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in range(16, 65):\n",
    "    # Create a model for this given dimension\n",
    "    model = create_model(args.model.type,\n",
    "                         hidden_dim=hidden_dim,\n",
    "                         path=args.model.pretrained_path,\n",
    "                         smooth=args.model.smooth).to(device)\n",
    "    \n",
    "    # If EMA is specified, apply it\n",
    "    if ema:\n",
    "        print('Applying EMA')\n",
    "        ema.apply()\n",
    "\n",
    "    # Sample the merged model\n",
    "    accumulated_model = sample_merge_model(hyper_model_test, model, args, K=100)\n",
    "\n",
    "    # Validate the merged model\n",
    "    val_loss, acc = validate_single(accumulated_model, val_loader, val_criterion, args=args)\n",
    "\n",
    "    # If EMA is specified, restore the original weights after applying EMA\n",
    "    if ema:\n",
    "        ema.restore()  # Restore the original weights after applying \n",
    "        \n",
    "    # Save the model\n",
    "    save_name = os.path.join(args.training.save_model_path, f\"cifar10_{accumulated_model.__class__.__name__}_dim{hidden_dim}_single.pth\")\n",
    "    torch.save(accumulated_model.state_dict(),save_name)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test using model {args.model}: hidden_dim {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Define the directory and filename structure\n",
    "    filename = f\"cifar10_results_{args.experiment.name}.txt\"\n",
    "    filepath = os.path.join(args.training.save_model_path, filename)\n",
    "\n",
    "    # Write the results. 'a' is used to append the results; a new file will be created if it doesn't exist.\n",
    "    with open(filepath, \"a\") as file:\n",
    "        file.write(f\"Hidden_dim: {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
