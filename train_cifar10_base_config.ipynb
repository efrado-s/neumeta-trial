{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4faf3c9",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7f334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e39782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe9dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_model_cifar10 as create_model\n",
    "from neumeta.utils import (\n",
    "    parse_args, print_omegaconf,\n",
    "    load_checkpoint, save_checkpoint,\n",
    "    set_seed,\n",
    "    get_cifar10, \n",
    "    sample_coordinates, sample_subset, shuffle_coordinates_all,\n",
    "    get_hypernetwork, get_optimizer, \n",
    "    sample_weights,\n",
    "    weighted_regression_loss, validate_single, AverageMeter, EMA,\n",
    "    sample_single_model, sample_merge_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cea0a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad05e8",
   "metadata": {},
   "source": [
    "### 1 Find maximum dimension of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504abeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dim(model_cls):\n",
    "    \"\"\"Find maximum dimension of the model\"\"\"\n",
    "    # Get the learnable parameters of the model\n",
    "    checkpoint = model_cls.learnable_parameter \n",
    "\n",
    "    # Set the maximum value to the length of the checkpoint\n",
    "    max_value = len(checkpoint)\n",
    "\n",
    "    # Iterate over the new model's weight\n",
    "    for i, (k, tensor) in enumerate(checkpoint.items()):\n",
    "        # Handle 2D tensors (e.g., weight matrices) \n",
    "        if len(tensor.shape) == 4:\n",
    "            coords = [tensor.shape[0], tensor.shape[1]]\n",
    "            max_value = max(max_value, max(coords))\n",
    "        # Handle 1D tensors (e.g., biases)\n",
    "        elif len(tensor.shape) == 1:\n",
    "            max_value = max(max_value, tensor.shape[0])\n",
    "    \n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413443e",
   "metadata": {},
   "source": [
    "### 2 Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f49acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(config):\n",
    "    import time\n",
    "    \"\"\"\n",
    "    Initializes Weights and Biases (wandb) with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        configuration (dict): Configuration parameters for the run.\n",
    "    \"\"\"\n",
    "    # Name the run using current time and configuration name\n",
    "    run_name = f\"{time.strftime('%Y%m%d%H%M%S')}-{config.experiment.name}\"\n",
    "    \n",
    "    wandb.init(project=\"ninr-trial\", name=run_name, config=dict(config), group='cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cc73b",
   "metadata": {},
   "source": [
    "### 3 Initialize model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed520bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(args, device):\n",
    "    \"\"\"\n",
    "    Initializes a dictionary of models for each dimension in the given range, along with ground truth models for the starting dimension.\n",
    "\n",
    "    Args:\n",
    "        args: An object containing the arguments for initializing the models.\n",
    "\n",
    "    Returns:\n",
    "        dim_dict: A dictionary containing the models for each dimension, along with their corresponding coordinates, keys, indices, size, and ground truth models.\n",
    "        gt_model_dict: A dictionary containing the ground truth models for the starting dimension.\n",
    "    \"\"\"\n",
    "    dim_dict = {}\n",
    "    gt_model_dict = {}\n",
    "    \n",
    "    # Create a model for each dimension in dimensions range\n",
    "    for dim in args.dimensions.range:\n",
    "        model_cls = create_model(args.model.type,\n",
    "                                 hidden_dim=dim,\n",
    "                                 path=args.model.pretrained_path,\n",
    "                                 smooth=args.model.smooth).to(device)\n",
    "        # Sample the coordinates, keys, indices, and the size for the model\n",
    "        coords_tensor, keys_list, indices_list, size_list = sample_coordinates(model_cls)\n",
    "        # Add the model, coordinates, keys, indices, size, and key mask to the dictionary\n",
    "        dim_dict[f\"{dim}\"] = (model_cls, coords_tensor, keys_list, indices_list, size_list, None)\n",
    "\n",
    "        # Print to makes line better\n",
    "        print('\\n')\n",
    "        \n",
    "        # If the dimension is the starting dimension (the dimension of pretrained_model), add the ground truth model to the dictionary\n",
    "        if dim == args.dimensions.start:\n",
    "            print(f\"Loading model for dim {dim}\")\n",
    "            model_trained = create_model(args.model.type, \n",
    "                                         hidden_dim=dim, \n",
    "                                         path=args.model.pretrained_path, \n",
    "                                         smooth=args.model.smooth).to(device)\n",
    "            model_trained.eval()\n",
    "            gt_model_dict[f'{dim}'] = model_trained\n",
    "\n",
    "    \n",
    "    return dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b8aa0",
   "metadata": {},
   "source": [
    "### 4 Training function for target model of a random dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab93eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, dim_dict, gt_model_dict, epoch_idx, ema=None, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    reconstruct_losses = AverageMeter()\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Preprocess input\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Move the data to the device\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # Choose a random hidden dimension\n",
    "        hidden_dim = random.choice(args.dimensions.range)\n",
    "        # Get the model class, coordinates, keys, indices, size, and key mask for the chosen dimension\n",
    "        model_cls, coords_tensor, keys_list, indices_list, size_list, key_mask = dim_dict[f\"{hidden_dim}\"]\n",
    "        # Sample a subset the input tensor of the coordinates, keys, indices, size, and selected keys\n",
    "        coords_tensor, keys_list, indices_list, size_list, selected_keys = sample_subset(coords_tensor,\n",
    "                                                                                         keys_list,\n",
    "                                                                                         indices_list,\n",
    "                                                                                         size_list,\n",
    "                                                                                         key_mask,\n",
    "                                                                                         ratio=args.ratio)\n",
    "        # Add noise to the coordinates if specified\n",
    "        if args.training.coordinate_noise > 0.0:\n",
    "            coords_tensor = coords_tensor + (torch.rand_like(coords_tensor) - 0.5) * args.training.coordinate_noise\n",
    "\n",
    "\n",
    "        # Main task of hypernetwork and target network\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Sample the weights for the target model using hypernetwork\n",
    "        model_cls, reconstructed_weights = sample_weights(model, model_cls,\n",
    "                                                          coords_tensor, keys_list, indices_list, size_list, key_mask, selected_keys,\n",
    "                                                          device=device, NORM=args.dimensions.norm)\n",
    "        # Forward pass\n",
    "        predict = model_cls(x)\n",
    "\n",
    "\n",
    "        # Compute losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Compute classification loss\n",
    "        cls_loss = criterion(predict, target) \n",
    "        # Compute regularization loss\n",
    "        reg_loss = sum([torch.norm(w, p=2) for w in reconstructed_weights])\n",
    "        # Compute reconstruction loss if ground truth model is available\n",
    "        if f\"{hidden_dim}\" in gt_model_dict:\n",
    "            gt_model = gt_model_dict[f\"{hidden_dim}\"]\n",
    "            gt_selected_weights = [\n",
    "                w for k, w in gt_model.learnable_parameter.items() if k in selected_keys]\n",
    "\n",
    "            reconstruct_loss = weighted_regression_loss(\n",
    "                reconstructed_weights, gt_selected_weights)\n",
    "        else:\n",
    "            reconstruct_loss = torch.tensor(0.0)\n",
    "        # Compute the total loss\n",
    "        loss = args.hyper_model.loss_weight.ce_weight * cls_loss + args.hyper_model.loss_weight.reg_weight * \\\n",
    "            reg_loss + args.hyper_model.loss_weight.recon_weight * reconstruct_loss\n",
    "\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Zero the gradients of the updated weights\n",
    "        for updated_weight in model_cls.parameters():\n",
    "            updated_weight.grad = None\n",
    "\n",
    "        # Compute the gradients of the reconstructed weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.autograd.backward(reconstructed_weights, [\n",
    "                                w.grad for k, w in model_cls.named_parameters() if k in selected_keys])\n",
    "        \n",
    "        # Clip the gradients if specified\n",
    "        if args.training.get('clip_grad', 0.0) > 0:\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), args.training.clip_grad)\n",
    "            \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA if specified\n",
    "        if ema:\n",
    "            ema.update()  # Update the EMA after each training step\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update the AverageMeter objects\n",
    "        losses.update(loss.item())\n",
    "        cls_losses.update(cls_loss.item())\n",
    "        reg_losses.update(reg_loss.item())\n",
    "        reconstruct_losses.update(reconstruct_loss.item())\n",
    "\n",
    "\n",
    "        # Log (or plot) losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Log the losses and learning rate to wandb\n",
    "        if batch_idx % args.experiment.log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"Loss\": losses.avg,\n",
    "                \"Cls Loss\": cls_losses.avg,\n",
    "                \"Reg Loss\": reg_losses.avg,\n",
    "                \"Reconstruct Loss\": reconstruct_losses.avg,\n",
    "                \"Learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }, step=batch_idx + epoch_idx * len(train_loader))\n",
    "            # Print the losses and learning rate\n",
    "            print(\n",
    "                f\"Iteration {batch_idx}: Loss = {losses.avg:.4f}, Reg Loss = {reg_losses.avg:.4f}, Reconstruct Loss = {reconstruct_losses.avg:.4f}, Cls Loss = {cls_losses.avg:.4f}, Learning rate = {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "    \n",
    "    # Returns the training loss, structure of network in each dimension, and the original structure of pretrained network\n",
    "    return losses.avg, dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d8965",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e292aae",
   "metadata": {},
   "source": [
    "### 0 Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670c10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd9af3",
   "metadata": {},
   "source": [
    "### 1 Parsing arguments for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = 'neumeta/config/base_config.yaml'\n",
    "RATIO = '1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6fd9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv_train = ['--config', CONFIG_PATH, '--ratio', RATIO]\n",
    "argv_test = ['--config', CONFIG_PATH, '--test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebf601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                 Key                  |                                                                Value                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|           experiment.name            |                                                 ninr_resnet20_cifar10_personal_tries                                                 |\n",
      "|         experiment.recononly         |                                                                  0                                                                   |\n",
      "|        experiment.num_epochs         |                                                                  30                                                                  |\n",
      "|       experiment.log_interval        |                                                                  25                                                                  |\n",
      "|       experiment.eval_interval       |                                                                  1                                                                   |\n",
      "|           experiment.seed            |                                                                  42                                                                  |\n",
      "|              model.type              |                                                               ResNet20                                                               |\n",
      "|        model.pretrained_path         |                                                         resnet20-12fca82f.th                                                         |\n",
      "|             model.smooth             |                                                                False                                                                 |\n",
      "|          training.optimizer          |                                                                adamw                                                                 |\n",
      "|        training.learning_rate        |                                                                0.001                                                                 |\n",
      "|         training.batch_size          |                                                                  64                                                                  |\n",
      "|      training.coordinate_noise       |                                                                 0.0                                                                  |\n",
      "|          training.lr_steps           |                                                              [100, 150]                                                              |\n",
      "|        training.weight_decay         |                                                                 0.01                                                                 |\n",
      "|          training.clip_grad          |                                                                 10.0                                                                 |\n",
      "|       training.save_model_path       |                                         toy/experiments/ninr_resnet20_cifar10_personal_tries                                         |\n",
      "|           hyper_model.type           |                                                                 mlp                                                                  |\n",
      "|        hyper_model.input_dim         |                                                                  6                                                                   |\n",
      "|        hyper_model.hidden_dim        |                                                                 256                                                                  |\n",
      "|        hyper_model.num_layers        |                                                                  4                                                                   |\n",
      "|        hyper_model.num_freqs         |                                                                  16                                                                  |\n",
      "|        hyper_model.output_dim        |                                                                  9                                                                   |\n",
      "|        hyper_model.ema_decay         |                                                                0.995                                                                 |\n",
      "|  hyper_model.loss_weight.ce_weight   |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.reg_weight  |                                                                0.0001                                                                |\n",
      "| hyper_model.loss_weight.recon_weight |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.kd_weight   |                                                                 0.1                                                                  |\n",
      "|           dimensions.range           | [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64] |\n",
      "|           dimensions.test            |                                                                  32                                                                  |\n",
      "|           dimensions.norm            |                                                                  64                                                                  |\n",
      "|           dimensions.start           |                                                                  64                                                                  |\n",
      "|                config                |                                neumeta/config/paper_configs/ninr_resnet20_cifar10_personal_tries.yaml                                |\n",
      "|                ratio                 |                                                                 1.0                                                                  |\n",
      "|             resume_from              |                                                                 None                                                                 |\n",
      "|              load_from               |                                                                 None                                                                 |\n",
      "|           test_result_path           |                                                                 None                                                                 |\n",
      "|                 test                 |                                                                False                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(argv_train)  # Parse arguments\n",
    "print_omegaconf(args)  # Print arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84954fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed... 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.experiment.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2086b8",
   "metadata": {},
   "source": [
    "### 2 Get training and validation data (in dataloader format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633b90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10(args.training.batch_size, strong_transform=args.training.get('strong_aug', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685e32a",
   "metadata": {},
   "source": [
    "### 3 Create target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d8f75",
   "metadata": {},
   "source": [
    "#### 3.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47436d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args.model.type,\n",
    "                     hidden_dim=args.dimensions.start,\n",
    "                     path=args.model.pretrained_path,\n",
    "                     smooth=args.model.smooth).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb133f",
   "metadata": {},
   "source": [
    "#### 3.1 Print the structure and shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09f9614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): Identity()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock_Resize(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b86d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3.2.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv1.bias torch.Size([64])\n",
      "layer3.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, (k, tensor) in enumerate(model.learnable_parameter.items()):\n",
    "    print(k, tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f7b45",
   "metadata": {},
   "source": [
    "#### 3.2 The maximum dimension of the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad8c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum DIM: 64\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum dimension of the model\n",
    "print(f'Maximum DIM: {find_max_dim(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195929e",
   "metadata": {},
   "source": [
    "#### 3.3 Validate the accuracy of pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d75f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.2825, Validation Accuracy: 92.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(model, val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb61dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learnable parameters of the model\n",
    "checkpoint = model.learnable_parameter\n",
    "# Get the number of parameters\n",
    "number_param = len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2fe99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters keys: ['layer3.2.conv1.weight', 'layer3.2.conv1.bias', 'layer3.2.conv2.weight', 'layer3.2.conv2.bias']\n",
      "Number of parameters to be learned: 4\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the parameters and the number of parameters\n",
    "print(f\"Parameters keys: {model.keys}\")\n",
    "print(f\"Number of parameters to be learned: {number_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5fa6f",
   "metadata": {},
   "source": [
    "### 4 Create the hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa4a2f",
   "metadata": {},
   "source": [
    "#### 4.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82e9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: mlp\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Get the hypermodel\n",
    "hyper_model = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297bd73",
   "metadata": {},
   "source": [
    "#### 4.1 Print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903829b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_MLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-3): 4 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d592e",
   "metadata": {},
   "source": [
    "#### 4.2 Initialize EMA to track only a smooth version of the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a4812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA\n",
    "ema = EMA(hyper_model, decay=args.hyper_model.ema_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffae0",
   "metadata": {},
   "source": [
    "### 5 Get Loss function, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079aa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, val_criterion, optimizer, scheduler = get_optimizer(args, hyper_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7561c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Val_criterion: CrossEntropyLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001DCE2915710>\n"
     ]
    }
   ],
   "source": [
    "print(f'Criterion: {criterion}\\nVal_criterion: {val_criterion}\\nOptimizer: {optimizer}\\nScheduler: {scheduler}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906454",
   "metadata": {},
   "source": [
    "### 6 Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d1d4f",
   "metadata": {},
   "source": [
    "#### 6.1 Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2cdca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting epoch and best accuracy\n",
    "start_epoch = 0\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373217",
   "metadata": {},
   "source": [
    "#### 6.2 Directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35a2746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the model\n",
    "os.makedirs(args.training.save_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504af23",
   "metadata": {},
   "source": [
    "#### 6.3 Resume training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "714db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_from:\n",
    "        print(f\"Resuming from checkpoint: {args.resume_from}\")\n",
    "        checkpoint_info = load_checkpoint(args.resume_from, hyper_model, optimizer, ema)\n",
    "        start_epoch = checkpoint_info['epoch']\n",
    "        best_acc = checkpoint_info['best_acc']\n",
    "        print(f\"Resuming from epoch: {start_epoch}, best accuracy: {best_acc*100:.2f}%\")\n",
    "        # Note: If there are more elements to retrieve, do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a3248",
   "metadata": {},
   "source": [
    "#### 6.4 Initialize wandb for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9fd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mefradosuryadi\u001b[0m (\u001b[33mefradosuryadi-universitas-indonesia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\wandb\\run-20250519_000921-r5svprpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/r5svprpg' target=\"_blank\">20250519000920-ninr_resnet20_cifar10_personal_tries</a></strong> to <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/r5svprpg' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/r5svprpg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "initialize_wandb(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46056e65",
   "metadata": {},
   "source": [
    "#### 6.5 Initialize model dictionary for each dimension and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641149b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Loading model for dim 64\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n"
     ]
    }
   ],
   "source": [
    "# Initialize model dictionary\n",
    "dim_dict, gt_model_dict = init_model_dict(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d01d9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'64': CifarResNet(\n",
       "   (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn1): Identity()\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock_Resize(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26d9c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7476d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict = shuffle_coordinates_all(dim_dict)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d6ad4",
   "metadata": {},
   "source": [
    "#### 6.6 Hypernetwork training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332580b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.experiment.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f486f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 1.9667, Reg Loss = 2.5919, Reconstruct Loss = 0.0000, Cls Loss = 1.9664, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8506, Reg Loss = 11.1391, Reconstruct Loss = 0.0065, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8486, Reg Loss = 8.1922, Reconstruct Loss = 0.0033, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8448, Reg Loss = 6.9007, Reconstruct Loss = 0.0022, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8415, Reg Loss = 6.4255, Reconstruct Loss = 0.0020, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8407, Reg Loss = 7.2159, Reconstruct Loss = 0.0026, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8398, Reg Loss = 7.6324, Reconstruct Loss = 0.0022, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8409, Reg Loss = 7.7143, Reconstruct Loss = 0.0020, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8414, Reg Loss = 7.4661, Reconstruct Loss = 0.0018, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8426, Reg Loss = 7.2180, Reconstruct Loss = 0.0016, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8430, Reg Loss = 6.9349, Reconstruct Loss = 0.0016, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8427, Reg Loss = 6.7079, Reconstruct Loss = 0.0016, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8425, Reg Loss = 6.5148, Reconstruct Loss = 0.0015, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8428, Reg Loss = 6.2761, Reconstruct Loss = 0.0014, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8423, Reg Loss = 6.0593, Reconstruct Loss = 0.0013, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8425, Reg Loss = 5.9695, Reconstruct Loss = 0.0013, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8422, Reg Loss = 5.7972, Reconstruct Loss = 0.0013, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8422, Reg Loss = 6.2256, Reconstruct Loss = 0.0015, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8422, Reg Loss = 6.6735, Reconstruct Loss = 0.0014, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8423, Reg Loss = 6.8913, Reconstruct Loss = 0.0014, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8426, Reg Loss = 6.9633, Reconstruct Loss = 0.0013, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8427, Reg Loss = 6.9541, Reconstruct Loss = 0.0013, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8423, Reg Loss = 6.8179, Reconstruct Loss = 0.0012, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8428, Reg Loss = 6.7229, Reconstruct Loss = 0.0012, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8436, Reg Loss = 6.6770, Reconstruct Loss = 0.0012, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8432, Reg Loss = 7.4679, Reconstruct Loss = 0.0011, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8429, Reg Loss = 8.0965, Reconstruct Loss = 0.0011, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8426, Reg Loss = 8.4470, Reconstruct Loss = 0.0010, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8425, Reg Loss = 8.4387, Reconstruct Loss = 0.0010, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8424, Reg Loss = 9.1476, Reconstruct Loss = 0.0010, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8432, Reg Loss = 9.8990, Reconstruct Loss = 0.0013, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8431, Reg Loss = 10.3081, Reconstruct Loss = 0.0013, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Epoch [1/30], Training Loss: 1.8430, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Validation Loss: 1.8040, Validation Accuracy: 79.61%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 0 with accuracy: 79.61%\n",
      "Iteration 0: Loss = 1.8210, Reg Loss = 23.0128, Reconstruct Loss = 0.0000, Cls Loss = 1.8187, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8375, Reg Loss = 19.0556, Reconstruct Loss = 0.0010, Cls Loss = 1.8345, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8423, Reg Loss = 16.8628, Reconstruct Loss = 0.0016, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8412, Reg Loss = 13.3779, Reconstruct Loss = 0.0014, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8394, Reg Loss = 15.1151, Reconstruct Loss = 0.0011, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8404, Reg Loss = 16.8908, Reconstruct Loss = 0.0008, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8410, Reg Loss = 17.3741, Reconstruct Loss = 0.0007, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8420, Reg Loss = 16.4586, Reconstruct Loss = 0.0008, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8418, Reg Loss = 16.8384, Reconstruct Loss = 0.0007, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8417, Reg Loss = 19.6435, Reconstruct Loss = 0.0006, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8420, Reg Loss = 21.6688, Reconstruct Loss = 0.0005, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8420, Reg Loss = 22.8475, Reconstruct Loss = 0.0005, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8427, Reg Loss = 23.5762, Reconstruct Loss = 0.0009, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8424, Reg Loss = 23.7120, Reconstruct Loss = 0.0009, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8423, Reg Loss = 23.3987, Reconstruct Loss = 0.0009, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8427, Reg Loss = 22.7522, Reconstruct Loss = 0.0009, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8429, Reg Loss = 21.8876, Reconstruct Loss = 0.0009, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8425, Reg Loss = 22.2730, Reconstruct Loss = 0.0008, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8421, Reg Loss = 22.5061, Reconstruct Loss = 0.0009, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8421, Reg Loss = 22.3490, Reconstruct Loss = 0.0009, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8419, Reg Loss = 21.9212, Reconstruct Loss = 0.0009, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8417, Reg Loss = 21.2986, Reconstruct Loss = 0.0010, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8418, Reg Loss = 21.2594, Reconstruct Loss = 0.0010, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8420, Reg Loss = 22.6821, Reconstruct Loss = 0.0011, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8419, Reg Loss = 23.9708, Reconstruct Loss = 0.0011, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8421, Reg Loss = 24.9204, Reconstruct Loss = 0.0012, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8422, Reg Loss = 25.6045, Reconstruct Loss = 0.0011, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8420, Reg Loss = 26.0460, Reconstruct Loss = 0.0012, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8423, Reg Loss = 26.2497, Reconstruct Loss = 0.0012, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8424, Reg Loss = 26.2134, Reconstruct Loss = 0.0012, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8424, Reg Loss = 25.9295, Reconstruct Loss = 0.0011, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8426, Reg Loss = 25.9585, Reconstruct Loss = 0.0011, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Epoch [2/30], Training Loss: 1.8426, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Validation Loss: 1.8041, Validation Accuracy: 79.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8644, Reg Loss = 72.6936, Reconstruct Loss = 0.0000, Cls Loss = 1.8571, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8466, Reg Loss = 78.4748, Reconstruct Loss = 0.0000, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8516, Reg Loss = 76.1626, Reconstruct Loss = 0.0037, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8502, Reg Loss = 72.1704, Reconstruct Loss = 0.0033, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8497, Reg Loss = 68.7382, Reconstruct Loss = 0.0030, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8484, Reg Loss = 66.3899, Reconstruct Loss = 0.0027, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8486, Reg Loss = 64.1370, Reconstruct Loss = 0.0027, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8480, Reg Loss = 61.4799, Reconstruct Loss = 0.0025, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8484, Reg Loss = 58.9212, Reconstruct Loss = 0.0027, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8474, Reg Loss = 56.3296, Reconstruct Loss = 0.0027, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8477, Reg Loss = 53.7299, Reconstruct Loss = 0.0025, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8470, Reg Loss = 50.7702, Reconstruct Loss = 0.0023, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8461, Reg Loss = 47.2588, Reconstruct Loss = 0.0021, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8458, Reg Loss = 44.2422, Reconstruct Loss = 0.0020, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8458, Reg Loss = 42.8029, Reconstruct Loss = 0.0020, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8453, Reg Loss = 43.2246, Reconstruct Loss = 0.0019, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8451, Reg Loss = 43.3579, Reconstruct Loss = 0.0019, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8452, Reg Loss = 43.1302, Reconstruct Loss = 0.0019, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8451, Reg Loss = 42.5350, Reconstruct Loss = 0.0018, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8451, Reg Loss = 41.5436, Reconstruct Loss = 0.0017, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8447, Reg Loss = 40.6149, Reconstruct Loss = 0.0017, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8441, Reg Loss = 40.1596, Reconstruct Loss = 0.0016, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8440, Reg Loss = 39.5439, Reconstruct Loss = 0.0015, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8437, Reg Loss = 38.7107, Reconstruct Loss = 0.0015, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8435, Reg Loss = 37.6952, Reconstruct Loss = 0.0015, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8433, Reg Loss = 36.6494, Reconstruct Loss = 0.0015, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8463, Reg Loss = 35.7877, Reconstruct Loss = 0.0014, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8468, Reg Loss = 38.6986, Reconstruct Loss = 0.0017, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8470, Reg Loss = 41.9196, Reconstruct Loss = 0.0017, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8472, Reg Loss = 44.0246, Reconstruct Loss = 0.0018, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8473, Reg Loss = 44.7373, Reconstruct Loss = 0.0017, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8477, Reg Loss = 45.1258, Reconstruct Loss = 0.0017, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Epoch [3/30], Training Loss: 1.8478, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Validation Loss: 1.8041, Validation Accuracy: 79.51%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8489, Reg Loss = 85.6659, Reconstruct Loss = 0.0000, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8611, Reg Loss = 87.4463, Reconstruct Loss = 0.0076, Cls Loss = 1.8447, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8554, Reg Loss = 80.4397, Reconstruct Loss = 0.0079, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8490, Reg Loss = 73.6799, Reconstruct Loss = 0.0053, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8470, Reg Loss = 67.8654, Reconstruct Loss = 0.0040, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8465, Reg Loss = 60.3471, Reconstruct Loss = 0.0032, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8493, Reg Loss = 60.3512, Reconstruct Loss = 0.0036, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8483, Reg Loss = 65.1007, Reconstruct Loss = 0.0035, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8483, Reg Loss = 67.7600, Reconstruct Loss = 0.0031, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8487, Reg Loss = 68.8132, Reconstruct Loss = 0.0032, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8483, Reg Loss = 68.6875, Reconstruct Loss = 0.0029, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8483, Reg Loss = 67.5709, Reconstruct Loss = 0.0026, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8482, Reg Loss = 65.7523, Reconstruct Loss = 0.0024, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8479, Reg Loss = 63.5226, Reconstruct Loss = 0.0022, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8478, Reg Loss = 61.0146, Reconstruct Loss = 0.0021, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8477, Reg Loss = 61.0200, Reconstruct Loss = 0.0023, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8474, Reg Loss = 61.1085, Reconstruct Loss = 0.0021, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8473, Reg Loss = 60.6627, Reconstruct Loss = 0.0022, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8472, Reg Loss = 59.7152, Reconstruct Loss = 0.0021, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8466, Reg Loss = 58.3741, Reconstruct Loss = 0.0020, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8466, Reg Loss = 56.6583, Reconstruct Loss = 0.0020, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8469, Reg Loss = 59.1457, Reconstruct Loss = 0.0019, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8474, Reg Loss = 63.3303, Reconstruct Loss = 0.0020, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8477, Reg Loss = 66.5909, Reconstruct Loss = 0.0020, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8481, Reg Loss = 69.3622, Reconstruct Loss = 0.0019, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8479, Reg Loss = 70.9107, Reconstruct Loss = 0.0019, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8476, Reg Loss = 70.7587, Reconstruct Loss = 0.0018, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8483, Reg Loss = 69.2968, Reconstruct Loss = 0.0017, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8481, Reg Loss = 68.5456, Reconstruct Loss = 0.0017, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8479, Reg Loss = 67.4683, Reconstruct Loss = 0.0016, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8476, Reg Loss = 66.0193, Reconstruct Loss = 0.0016, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8469, Reg Loss = 64.2752, Reconstruct Loss = 0.0015, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Epoch [4/30], Training Loss: 1.8468, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Validation Loss: 1.8041, Validation Accuracy: 79.57%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8365, Reg Loss = 13.0680, Reconstruct Loss = 0.0000, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8449, Reg Loss = 23.3376, Reconstruct Loss = 0.0000, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8499, Reg Loss = 21.7972, Reconstruct Loss = 0.0026, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8458, Reg Loss = 18.9458, Reconstruct Loss = 0.0018, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8455, Reg Loss = 34.3504, Reconstruct Loss = 0.0013, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8470, Reg Loss = 50.6393, Reconstruct Loss = 0.0030, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8466, Reg Loss = 59.5065, Reconstruct Loss = 0.0028, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8469, Reg Loss = 64.0902, Reconstruct Loss = 0.0026, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8474, Reg Loss = 66.8155, Reconstruct Loss = 0.0025, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8475, Reg Loss = 67.7955, Reconstruct Loss = 0.0023, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8473, Reg Loss = 67.4966, Reconstruct Loss = 0.0022, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8473, Reg Loss = 65.7621, Reconstruct Loss = 0.0020, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8476, Reg Loss = 62.5217, Reconstruct Loss = 0.0020, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8484, Reg Loss = 64.4904, Reconstruct Loss = 0.0020, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8486, Reg Loss = 66.8391, Reconstruct Loss = 0.0019, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8485, Reg Loss = 68.1974, Reconstruct Loss = 0.0018, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8485, Reg Loss = 68.6388, Reconstruct Loss = 0.0018, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8484, Reg Loss = 68.4108, Reconstruct Loss = 0.0017, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8477, Reg Loss = 67.3251, Reconstruct Loss = 0.0016, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8472, Reg Loss = 65.5394, Reconstruct Loss = 0.0017, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8471, Reg Loss = 63.1026, Reconstruct Loss = 0.0016, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8468, Reg Loss = 61.5886, Reconstruct Loss = 0.0016, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8463, Reg Loss = 59.7338, Reconstruct Loss = 0.0017, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8462, Reg Loss = 57.6453, Reconstruct Loss = 0.0017, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8460, Reg Loss = 56.2760, Reconstruct Loss = 0.0017, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8456, Reg Loss = 55.8813, Reconstruct Loss = 0.0017, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8453, Reg Loss = 55.0671, Reconstruct Loss = 0.0017, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8452, Reg Loss = 53.6915, Reconstruct Loss = 0.0017, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8452, Reg Loss = 53.2840, Reconstruct Loss = 0.0017, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8453, Reg Loss = 53.1442, Reconstruct Loss = 0.0017, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8448, Reg Loss = 52.5510, Reconstruct Loss = 0.0016, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8449, Reg Loss = 51.4837, Reconstruct Loss = 0.0016, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Epoch [5/30], Training Loss: 1.8450, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Validation Loss: 1.8044, Validation Accuracy: 78.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9151, Reg Loss = 8.7658, Reconstruct Loss = 0.0000, Cls Loss = 1.9142, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8405, Reg Loss = 80.3879, Reconstruct Loss = 0.0000, Cls Loss = 1.8324, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8485, Reg Loss = 99.9653, Reconstruct Loss = 0.0039, Cls Loss = 1.8346, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8477, Reg Loss = 99.4239, Reconstruct Loss = 0.0032, Cls Loss = 1.8345, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8482, Reg Loss = 95.8327, Reconstruct Loss = 0.0028, Cls Loss = 1.8358, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8487, Reg Loss = 88.9791, Reconstruct Loss = 0.0028, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8490, Reg Loss = 79.7792, Reconstruct Loss = 0.0025, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8490, Reg Loss = 80.4120, Reconstruct Loss = 0.0025, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8508, Reg Loss = 93.2425, Reconstruct Loss = 0.0022, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8513, Reg Loss = 103.1276, Reconstruct Loss = 0.0020, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8519, Reg Loss = 109.3769, Reconstruct Loss = 0.0020, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8525, Reg Loss = 112.8684, Reconstruct Loss = 0.0021, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8526, Reg Loss = 114.8926, Reconstruct Loss = 0.0024, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8534, Reg Loss = 114.7010, Reconstruct Loss = 0.0022, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8529, Reg Loss = 112.8579, Reconstruct Loss = 0.0020, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8520, Reg Loss = 110.5178, Reconstruct Loss = 0.0021, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8516, Reg Loss = 107.5810, Reconstruct Loss = 0.0020, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8514, Reg Loss = 104.0980, Reconstruct Loss = 0.0019, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8504, Reg Loss = 100.3494, Reconstruct Loss = 0.0018, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8497, Reg Loss = 96.1555, Reconstruct Loss = 0.0017, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8495, Reg Loss = 92.7522, Reconstruct Loss = 0.0017, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8490, Reg Loss = 92.2967, Reconstruct Loss = 0.0016, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8488, Reg Loss = 91.3481, Reconstruct Loss = 0.0015, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8484, Reg Loss = 89.6795, Reconstruct Loss = 0.0014, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8480, Reg Loss = 87.6027, Reconstruct Loss = 0.0014, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8477, Reg Loss = 85.1212, Reconstruct Loss = 0.0013, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8537, Reg Loss = 82.8033, Reconstruct Loss = 0.0013, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8544, Reg Loss = 91.8432, Reconstruct Loss = 0.0012, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8554, Reg Loss = 100.3471, Reconstruct Loss = 0.0018, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8555, Reg Loss = 101.3628, Reconstruct Loss = 0.0018, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8552, Reg Loss = 100.8004, Reconstruct Loss = 0.0017, Cls Loss = 1.8434, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8574, Reg Loss = 104.3651, Reconstruct Loss = 0.0017, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Epoch [6/30], Training Loss: 1.8575, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Validation Loss: 1.8037, Validation Accuracy: 80.25%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 5 with accuracy: 80.25%\n",
      "Iteration 0: Loss = 1.8696, Reg Loss = 401.8246, Reconstruct Loss = 0.0000, Cls Loss = 1.8294, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9429, Reg Loss = 483.5670, Reconstruct Loss = 0.0490, Cls Loss = 1.8456, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9297, Reg Loss = 481.8327, Reconstruct Loss = 0.0369, Cls Loss = 1.8446, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9239, Reg Loss = 474.4012, Reconstruct Loss = 0.0344, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9125, Reg Loss = 463.7218, Reconstruct Loss = 0.0259, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9052, Reg Loss = 450.3323, Reconstruct Loss = 0.0207, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9030, Reg Loss = 437.7337, Reconstruct Loss = 0.0195, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9024, Reg Loss = 429.1522, Reconstruct Loss = 0.0193, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8975, Reg Loss = 418.2622, Reconstruct Loss = 0.0169, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8947, Reg Loss = 404.8231, Reconstruct Loss = 0.0150, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8921, Reg Loss = 388.8237, Reconstruct Loss = 0.0140, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8885, Reg Loss = 368.7875, Reconstruct Loss = 0.0127, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8854, Reg Loss = 343.7730, Reconstruct Loss = 0.0118, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8822, Reg Loss = 320.4751, Reconstruct Loss = 0.0110, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8800, Reg Loss = 304.1679, Reconstruct Loss = 0.0102, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8786, Reg Loss = 290.6073, Reconstruct Loss = 0.0096, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8780, Reg Loss = 295.2916, Reconstruct Loss = 0.0090, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8786, Reg Loss = 300.8262, Reconstruct Loss = 0.0084, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8788, Reg Loss = 304.5823, Reconstruct Loss = 0.0086, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8792, Reg Loss = 306.2798, Reconstruct Loss = 0.0082, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8790, Reg Loss = 306.3938, Reconstruct Loss = 0.0084, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8781, Reg Loss = 304.1502, Reconstruct Loss = 0.0080, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8769, Reg Loss = 298.3772, Reconstruct Loss = 0.0078, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8756, Reg Loss = 288.7757, Reconstruct Loss = 0.0075, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8746, Reg Loss = 281.5133, Reconstruct Loss = 0.0072, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8735, Reg Loss = 275.2811, Reconstruct Loss = 0.0069, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8726, Reg Loss = 268.3716, Reconstruct Loss = 0.0067, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8716, Reg Loss = 260.9491, Reconstruct Loss = 0.0065, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8703, Reg Loss = 252.9777, Reconstruct Loss = 0.0063, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8694, Reg Loss = 245.4672, Reconstruct Loss = 0.0061, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8688, Reg Loss = 238.8513, Reconstruct Loss = 0.0060, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8688, Reg Loss = 242.1518, Reconstruct Loss = 0.0059, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Epoch [7/30], Training Loss: 1.8690, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Validation Loss: 1.8037, Validation Accuracy: 80.42%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 6 with accuracy: 80.42%\n",
      "Iteration 0: Loss = 1.8395, Reg Loss = 437.4119, Reconstruct Loss = 0.0000, Cls Loss = 1.7957, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8721, Reg Loss = 398.7425, Reconstruct Loss = 0.0000, Cls Loss = 1.8322, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8719, Reg Loss = 380.1166, Reconstruct Loss = 0.0000, Cls Loss = 1.8339, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8721, Reg Loss = 364.7798, Reconstruct Loss = 0.0000, Cls Loss = 1.8356, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8705, Reg Loss = 352.7127, Reconstruct Loss = 0.0000, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8692, Reg Loss = 339.9001, Reconstruct Loss = 0.0011, Cls Loss = 1.8341, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8687, Reg Loss = 328.1522, Reconstruct Loss = 0.0009, Cls Loss = 1.8349, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8681, Reg Loss = 316.2403, Reconstruct Loss = 0.0008, Cls Loss = 1.8356, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8661, Reg Loss = 300.0156, Reconstruct Loss = 0.0007, Cls Loss = 1.8354, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8641, Reg Loss = 276.0429, Reconstruct Loss = 0.0006, Cls Loss = 1.8359, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8622, Reg Loss = 260.9338, Reconstruct Loss = 0.0006, Cls Loss = 1.8356, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8614, Reg Loss = 249.9635, Reconstruct Loss = 0.0007, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8610, Reg Loss = 238.5355, Reconstruct Loss = 0.0008, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8603, Reg Loss = 226.3230, Reconstruct Loss = 0.0007, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8793, Reg Loss = 243.5352, Reconstruct Loss = 0.0007, Cls Loss = 1.8543, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8959, Reg Loss = 320.8922, Reconstruct Loss = 0.0101, Cls Loss = 1.8538, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9005, Reg Loss = 383.0367, Reconstruct Loss = 0.0094, Cls Loss = 1.8528, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9084, Reg Loss = 425.6424, Reconstruct Loss = 0.0139, Cls Loss = 1.8519, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9143, Reg Loss = 451.6497, Reconstruct Loss = 0.0186, Cls Loss = 1.8506, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9142, Reg Loss = 461.9440, Reconstruct Loss = 0.0176, Cls Loss = 1.8504, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9120, Reg Loss = 454.2000, Reconstruct Loss = 0.0167, Cls Loss = 1.8499, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9096, Reg Loss = 442.7392, Reconstruct Loss = 0.0159, Cls Loss = 1.8494, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9075, Reg Loss = 430.3950, Reconstruct Loss = 0.0154, Cls Loss = 1.8491, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9054, Reg Loss = 415.6904, Reconstruct Loss = 0.0149, Cls Loss = 1.8490, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9030, Reg Loss = 404.8096, Reconstruct Loss = 0.0142, Cls Loss = 1.8483, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9003, Reg Loss = 392.4306, Reconstruct Loss = 0.0137, Cls Loss = 1.8474, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8981, Reg Loss = 379.4402, Reconstruct Loss = 0.0132, Cls Loss = 1.8469, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8962, Reg Loss = 367.4727, Reconstruct Loss = 0.0128, Cls Loss = 1.8467, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8944, Reg Loss = 356.5062, Reconstruct Loss = 0.0124, Cls Loss = 1.8464, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8927, Reg Loss = 347.7253, Reconstruct Loss = 0.0120, Cls Loss = 1.8460, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8924, Reg Loss = 339.6585, Reconstruct Loss = 0.0117, Cls Loss = 1.8468, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8961, Reg Loss = 353.3492, Reconstruct Loss = 0.0142, Cls Loss = 1.8465, Learning rate = 1.0000e-03\n",
      "Epoch [8/30], Training Loss: 1.8961, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Validation Loss: 1.8036, Validation Accuracy: 80.27%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9222, Reg Loss = 909.6935, Reconstruct Loss = 0.0000, Cls Loss = 1.8313, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9311, Reg Loss = 871.5613, Reconstruct Loss = 0.0000, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9488, Reg Loss = 857.8213, Reconstruct Loss = 0.0209, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9371, Reg Loss = 822.8188, Reconstruct Loss = 0.0141, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9361, Reg Loss = 795.7252, Reconstruct Loss = 0.0185, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9353, Reg Loss = 769.9224, Reconstruct Loss = 0.0203, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9320, Reg Loss = 741.1404, Reconstruct Loss = 0.0204, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9288, Reg Loss = 708.3277, Reconstruct Loss = 0.0199, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9216, Reg Loss = 653.4386, Reconstruct Loss = 0.0184, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9625, Reg Loss = 653.1809, Reconstruct Loss = 0.0164, Cls Loss = 1.8808, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9594, Reg Loss = 687.3604, Reconstruct Loss = 0.0147, Cls Loss = 1.8759, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9654, Reg Loss = 703.0980, Reconstruct Loss = 0.0227, Cls Loss = 1.8724, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9609, Reg Loss = 700.8622, Reconstruct Loss = 0.0208, Cls Loss = 1.8700, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9548, Reg Loss = 675.4056, Reconstruct Loss = 0.0192, Cls Loss = 1.8680, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9514, Reg Loss = 645.2963, Reconstruct Loss = 0.0202, Cls Loss = 1.8667, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9462, Reg Loss = 622.8451, Reconstruct Loss = 0.0188, Cls Loss = 1.8651, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9402, Reg Loss = 594.9953, Reconstruct Loss = 0.0177, Cls Loss = 1.8631, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9350, Reg Loss = 570.3127, Reconstruct Loss = 0.0166, Cls Loss = 1.8613, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9458, Reg Loss = 559.2167, Reconstruct Loss = 0.0218, Cls Loss = 1.8681, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9467, Reg Loss = 596.8266, Reconstruct Loss = 0.0206, Cls Loss = 1.8664, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9473, Reg Loss = 633.2959, Reconstruct Loss = 0.0196, Cls Loss = 1.8644, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9554, Reg Loss = 659.4218, Reconstruct Loss = 0.0261, Cls Loss = 1.8634, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9549, Reg Loss = 677.4055, Reconstruct Loss = 0.0249, Cls Loss = 1.8622, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9570, Reg Loss = 686.5129, Reconstruct Loss = 0.0269, Cls Loss = 1.8614, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9567, Reg Loss = 682.4172, Reconstruct Loss = 0.0278, Cls Loss = 1.8606, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9555, Reg Loss = 664.2379, Reconstruct Loss = 0.0288, Cls Loss = 1.8602, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9522, Reg Loss = 650.3475, Reconstruct Loss = 0.0277, Cls Loss = 1.8594, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9485, Reg Loss = 633.9405, Reconstruct Loss = 0.0267, Cls Loss = 1.8584, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9509, Reg Loss = 630.4084, Reconstruct Loss = 0.0285, Cls Loss = 1.8594, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9558, Reg Loss = 655.1446, Reconstruct Loss = 0.0314, Cls Loss = 1.8589, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9563, Reg Loss = 678.0956, Reconstruct Loss = 0.0304, Cls Loss = 1.8581, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9623, Reg Loss = 696.5632, Reconstruct Loss = 0.0355, Cls Loss = 1.8571, Learning rate = 1.0000e-03\n",
      "Epoch [9/30], Training Loss: 1.9649, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 39.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Validation Loss: 1.8036, Validation Accuracy: 80.55%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 8 with accuracy: 80.55%\n",
      "Iteration 0: Loss = 1.9049, Reg Loss = 1059.5695, Reconstruct Loss = 0.0000, Cls Loss = 1.7989, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.0846, Reg Loss = 1140.8508, Reconstruct Loss = 0.1359, Cls Loss = 1.8346, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.0210, Reg Loss = 1093.6797, Reconstruct Loss = 0.0693, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9923, Reg Loss = 1059.5090, Reconstruct Loss = 0.0465, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.0064, Reg Loss = 1014.0120, Reconstruct Loss = 0.0667, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9858, Reg Loss = 948.2944, Reconstruct Loss = 0.0534, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9735, Reg Loss = 878.5545, Reconstruct Loss = 0.0482, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9573, Reg Loss = 777.7644, Reconstruct Loss = 0.0413, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.0257, Reg Loss = 725.3275, Reconstruct Loss = 0.0377, Cls Loss = 1.9155, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.0547, Reg Loss = 844.5964, Reconstruct Loss = 0.0645, Cls Loss = 1.9057, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.0526, Reg Loss = 952.9967, Reconstruct Loss = 0.0581, Cls Loss = 1.8991, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.0697, Reg Loss = 1034.0989, Reconstruct Loss = 0.0725, Cls Loss = 1.8938, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.0942, Reg Loss = 1084.4722, Reconstruct Loss = 0.0961, Cls Loss = 1.8896, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.0935, Reg Loss = 1107.2331, Reconstruct Loss = 0.0972, Cls Loss = 1.8856, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.0905, Reg Loss = 1112.6205, Reconstruct Loss = 0.0968, Cls Loss = 1.8825, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.0804, Reg Loss = 1106.8101, Reconstruct Loss = 0.0904, Cls Loss = 1.8793, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.0731, Reg Loss = 1093.5982, Reconstruct Loss = 0.0878, Cls Loss = 1.8760, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.0641, Reg Loss = 1075.7239, Reconstruct Loss = 0.0826, Cls Loss = 1.8739, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.0545, Reg Loss = 1055.0948, Reconstruct Loss = 0.0780, Cls Loss = 1.8709, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.0460, Reg Loss = 1032.0659, Reconstruct Loss = 0.0739, Cls Loss = 1.8688, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.0393, Reg Loss = 1008.0106, Reconstruct Loss = 0.0711, Cls Loss = 1.8674, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.0321, Reg Loss = 978.8213, Reconstruct Loss = 0.0682, Cls Loss = 1.8661, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.0242, Reg Loss = 942.4739, Reconstruct Loss = 0.0654, Cls Loss = 1.8646, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.0172, Reg Loss = 904.0019, Reconstruct Loss = 0.0625, Cls Loss = 1.8643, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.0112, Reg Loss = 879.3167, Reconstruct Loss = 0.0599, Cls Loss = 1.8634, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.0063, Reg Loss = 857.8666, Reconstruct Loss = 0.0581, Cls Loss = 1.8624, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.0016, Reg Loss = 831.8375, Reconstruct Loss = 0.0567, Cls Loss = 1.8618, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9960, Reg Loss = 804.2374, Reconstruct Loss = 0.0547, Cls Loss = 1.8609, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9910, Reg Loss = 778.1112, Reconstruct Loss = 0.0530, Cls Loss = 1.8601, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9874, Reg Loss = 756.5296, Reconstruct Loss = 0.0514, Cls Loss = 1.8604, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9834, Reg Loss = 739.5532, Reconstruct Loss = 0.0497, Cls Loss = 1.8598, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9792, Reg Loss = 720.0099, Reconstruct Loss = 0.0481, Cls Loss = 1.8591, Learning rate = 1.0000e-03\n",
      "Epoch [10/30], Training Loss: 1.9781, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Validation Loss: 1.8036, Validation Accuracy: 80.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8812, Reg Loss = 128.7102, Reconstruct Loss = 0.0000, Cls Loss = 1.8683, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8453, Reg Loss = 100.7470, Reconstruct Loss = 0.0000, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8508, Reg Loss = 97.7947, Reconstruct Loss = 0.0019, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8501, Reg Loss = 87.6291, Reconstruct Loss = 0.0024, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8470, Reg Loss = 79.4719, Reconstruct Loss = 0.0025, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8495, Reg Loss = 92.2085, Reconstruct Loss = 0.0020, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8564, Reg Loss = 157.1510, Reconstruct Loss = 0.0017, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8652, Reg Loss = 208.4709, Reconstruct Loss = 0.0042, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8694, Reg Loss = 241.6770, Reconstruct Loss = 0.0053, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8701, Reg Loss = 249.6345, Reconstruct Loss = 0.0061, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8697, Reg Loss = 244.1083, Reconstruct Loss = 0.0055, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8701, Reg Loss = 250.8955, Reconstruct Loss = 0.0057, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8698, Reg Loss = 247.8021, Reconstruct Loss = 0.0057, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8681, Reg Loss = 238.4729, Reconstruct Loss = 0.0055, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8667, Reg Loss = 228.3871, Reconstruct Loss = 0.0053, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8654, Reg Loss = 220.1505, Reconstruct Loss = 0.0052, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8647, Reg Loss = 211.3309, Reconstruct Loss = 0.0049, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8640, Reg Loss = 205.4967, Reconstruct Loss = 0.0047, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8633, Reg Loss = 201.7708, Reconstruct Loss = 0.0044, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8617, Reg Loss = 194.6969, Reconstruct Loss = 0.0043, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8623, Reg Loss = 189.6881, Reconstruct Loss = 0.0042, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8657, Reg Loss = 222.4522, Reconstruct Loss = 0.0040, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8692, Reg Loss = 262.7169, Reconstruct Loss = 0.0038, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8756, Reg Loss = 298.0342, Reconstruct Loss = 0.0063, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8782, Reg Loss = 328.9766, Reconstruct Loss = 0.0061, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8822, Reg Loss = 353.8164, Reconstruct Loss = 0.0078, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8848, Reg Loss = 373.4369, Reconstruct Loss = 0.0090, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8858, Reg Loss = 387.1116, Reconstruct Loss = 0.0087, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8884, Reg Loss = 397.4950, Reconstruct Loss = 0.0102, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8888, Reg Loss = 404.2988, Reconstruct Loss = 0.0099, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8895, Reg Loss = 408.4417, Reconstruct Loss = 0.0102, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8895, Reg Loss = 409.9883, Reconstruct Loss = 0.0098, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Epoch [11/30], Training Loss: 1.8900, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Validation Loss: 1.8037, Validation Accuracy: 80.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8778, Reg Loss = 416.9962, Reconstruct Loss = 0.0000, Cls Loss = 1.8361, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8853, Reg Loss = 359.4093, Reconstruct Loss = 0.0088, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9002, Reg Loss = 270.7830, Reconstruct Loss = 0.0073, Cls Loss = 1.8658, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9525, Reg Loss = 542.5410, Reconstruct Loss = 0.0405, Cls Loss = 1.8577, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9758, Reg Loss = 724.0043, Reconstruct Loss = 0.0497, Cls Loss = 1.8537, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9729, Reg Loss = 821.6126, Reconstruct Loss = 0.0398, Cls Loss = 1.8509, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9815, Reg Loss = 872.2597, Reconstruct Loss = 0.0442, Cls Loss = 1.8501, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9936, Reg Loss = 897.0375, Reconstruct Loss = 0.0552, Cls Loss = 1.8487, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9920, Reg Loss = 904.2366, Reconstruct Loss = 0.0551, Cls Loss = 1.8465, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9900, Reg Loss = 902.5574, Reconstruct Loss = 0.0543, Cls Loss = 1.8455, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9837, Reg Loss = 895.1745, Reconstruct Loss = 0.0489, Cls Loss = 1.8454, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9762, Reg Loss = 881.4380, Reconstruct Loss = 0.0444, Cls Loss = 1.8437, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9748, Reg Loss = 858.3193, Reconstruct Loss = 0.0465, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9688, Reg Loss = 816.3292, Reconstruct Loss = 0.0449, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9597, Reg Loss = 762.8783, Reconstruct Loss = 0.0417, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9522, Reg Loss = 717.0290, Reconstruct Loss = 0.0389, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9455, Reg Loss = 675.6542, Reconstruct Loss = 0.0365, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9431, Reg Loss = 659.6043, Reconstruct Loss = 0.0356, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9418, Reg Loss = 665.8168, Reconstruct Loss = 0.0336, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9397, Reg Loss = 668.7428, Reconstruct Loss = 0.0318, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9382, Reg Loss = 667.7737, Reconstruct Loss = 0.0302, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9361, Reg Loss = 660.5102, Reconstruct Loss = 0.0288, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9336, Reg Loss = 650.9324, Reconstruct Loss = 0.0275, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9322, Reg Loss = 639.6557, Reconstruct Loss = 0.0274, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9293, Reg Loss = 623.4871, Reconstruct Loss = 0.0263, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9259, Reg Loss = 601.5798, Reconstruct Loss = 0.0252, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9242, Reg Loss = 593.0769, Reconstruct Loss = 0.0245, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9265, Reg Loss = 607.7572, Reconstruct Loss = 0.0256, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9267, Reg Loss = 620.5409, Reconstruct Loss = 0.0246, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9299, Reg Loss = 627.0677, Reconstruct Loss = 0.0269, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9282, Reg Loss = 621.9478, Reconstruct Loss = 0.0260, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9260, Reg Loss = 607.8098, Reconstruct Loss = 0.0252, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Epoch [12/30], Training Loss: 1.9254, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Validation Loss: 1.8037, Validation Accuracy: 80.19%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8301, Reg Loss = 190.3705, Reconstruct Loss = 0.0000, Cls Loss = 1.8111, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.3206, Reg Loss = 134.2944, Reconstruct Loss = 0.0000, Cls Loss = 2.3072, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.4117, Reg Loss = 1193.3559, Reconstruct Loss = 0.2161, Cls Loss = 2.0763, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.3124, Reg Loss = 1732.2630, Reconstruct Loss = 0.1450, Cls Loss = 1.9942, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.4104, Reg Loss = 1933.1892, Reconstruct Loss = 0.2611, Cls Loss = 1.9560, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.3381, Reg Loss = 1958.2888, Reconstruct Loss = 0.2093, Cls Loss = 1.9329, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.3117, Reg Loss = 1911.3566, Reconstruct Loss = 0.2037, Cls Loss = 1.9169, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.2652, Reg Loss = 1848.9852, Reconstruct Loss = 0.1747, Cls Loss = 1.9056, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.2299, Reg Loss = 1786.5067, Reconstruct Loss = 0.1530, Cls Loss = 1.8983, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.2088, Reg Loss = 1718.5446, Reconstruct Loss = 0.1456, Cls Loss = 1.8914, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.1886, Reg Loss = 1650.9116, Reconstruct Loss = 0.1373, Cls Loss = 1.8862, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.1680, Reg Loss = 1572.1771, Reconstruct Loss = 0.1284, Cls Loss = 1.8824, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.1429, Reg Loss = 1472.9853, Reconstruct Loss = 0.1177, Cls Loss = 1.8779, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.1214, Reg Loss = 1373.1863, Reconstruct Loss = 0.1087, Cls Loss = 1.8754, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.1028, Reg Loss = 1283.2487, Reconstruct Loss = 0.1009, Cls Loss = 1.8735, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.0860, Reg Loss = 1206.7056, Reconstruct Loss = 0.0942, Cls Loss = 1.8711, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.0716, Reg Loss = 1138.5843, Reconstruct Loss = 0.0884, Cls Loss = 1.8694, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.0598, Reg Loss = 1080.2421, Reconstruct Loss = 0.0836, Cls Loss = 1.8682, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.0513, Reg Loss = 1054.9014, Reconstruct Loss = 0.0790, Cls Loss = 1.8669, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.0459, Reg Loss = 1033.4442, Reconstruct Loss = 0.0777, Cls Loss = 1.8648, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.0548, Reg Loss = 1008.4416, Reconstruct Loss = 0.0739, Cls Loss = 1.8801, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.0611, Reg Loss = 1045.6943, Reconstruct Loss = 0.0784, Cls Loss = 1.8781, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.0653, Reg Loss = 1076.7447, Reconstruct Loss = 0.0815, Cls Loss = 1.8761, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.0610, Reg Loss = 1088.9001, Reconstruct Loss = 0.0780, Cls Loss = 1.8741, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.0554, Reg Loss = 1082.8329, Reconstruct Loss = 0.0747, Cls Loss = 1.8724, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.0484, Reg Loss = 1052.1134, Reconstruct Loss = 0.0722, Cls Loss = 1.8710, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.0417, Reg Loss = 1024.4553, Reconstruct Loss = 0.0695, Cls Loss = 1.8698, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.0367, Reg Loss = 1002.4676, Reconstruct Loss = 0.0674, Cls Loss = 1.8691, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0310, Reg Loss = 976.4325, Reconstruct Loss = 0.0653, Cls Loss = 1.8680, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0495, Reg Loss = 950.2473, Reconstruct Loss = 0.0632, Cls Loss = 1.8913, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0655, Reg Loss = 979.8227, Reconstruct Loss = 0.0779, Cls Loss = 1.8896, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0649, Reg Loss = 1017.5221, Reconstruct Loss = 0.0754, Cls Loss = 1.8878, Learning rate = 1.0000e-03\n",
      "Epoch [13/30], Training Loss: 2.0648, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Validation Loss: 1.8038, Validation Accuracy: 79.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9801, Reg Loss = 1687.4399, Reconstruct Loss = 0.0000, Cls Loss = 1.8114, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.7589, Reg Loss = 1782.4382, Reconstruct Loss = 0.7413, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.3743, Reg Loss = 1621.8493, Reconstruct Loss = 0.3779, Cls Loss = 1.8342, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.2415, Reg Loss = 1513.9375, Reconstruct Loss = 0.2536, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.1797, Reg Loss = 1417.3753, Reconstruct Loss = 0.2041, Cls Loss = 1.8339, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.1391, Reg Loss = 1326.1575, Reconstruct Loss = 0.1708, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.0996, Reg Loss = 1214.6705, Reconstruct Loss = 0.1425, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.0721, Reg Loss = 1110.9015, Reconstruct Loss = 0.1241, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.0491, Reg Loss = 1037.8804, Reconstruct Loss = 0.1087, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.0309, Reg Loss = 966.8656, Reconstruct Loss = 0.0980, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.0136, Reg Loss = 892.4901, Reconstruct Loss = 0.0882, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9998, Reg Loss = 830.6499, Reconstruct Loss = 0.0802, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9894, Reg Loss = 787.3031, Reconstruct Loss = 0.0736, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9795, Reg Loss = 743.4244, Reconstruct Loss = 0.0679, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9712, Reg Loss = 699.4794, Reconstruct Loss = 0.0636, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9634, Reg Loss = 659.8836, Reconstruct Loss = 0.0603, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9568, Reg Loss = 624.2449, Reconstruct Loss = 0.0575, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9502, Reg Loss = 592.6641, Reconstruct Loss = 0.0543, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9444, Reg Loss = 564.1229, Reconstruct Loss = 0.0515, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9387, Reg Loss = 538.3182, Reconstruct Loss = 0.0489, Cls Loss = 1.8359, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9343, Reg Loss = 514.6914, Reconstruct Loss = 0.0469, Cls Loss = 1.8360, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9301, Reg Loss = 493.1913, Reconstruct Loss = 0.0446, Cls Loss = 1.8361, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9265, Reg Loss = 473.4128, Reconstruct Loss = 0.0427, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9237, Reg Loss = 459.0384, Reconstruct Loss = 0.0411, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9223, Reg Loss = 457.1966, Reconstruct Loss = 0.0394, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9203, Reg Loss = 451.8617, Reconstruct Loss = 0.0378, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9177, Reg Loss = 439.2954, Reconstruct Loss = 0.0364, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9150, Reg Loss = 426.8996, Reconstruct Loss = 0.0351, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9127, Reg Loss = 414.4718, Reconstruct Loss = 0.0339, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9117, Reg Loss = 410.7147, Reconstruct Loss = 0.0331, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9103, Reg Loss = 406.6618, Reconstruct Loss = 0.0322, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9089, Reg Loss = 400.2459, Reconstruct Loss = 0.0312, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Epoch [14/30], Training Loss: 1.9085, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Validation Loss: 1.8036, Validation Accuracy: 80.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8137, Reg Loss = 162.9196, Reconstruct Loss = 0.0000, Cls Loss = 1.7974, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8424, Reg Loss = 122.0794, Reconstruct Loss = 0.0021, Cls Loss = 1.8281, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9194, Reg Loss = 447.7417, Reconstruct Loss = 0.0011, Cls Loss = 1.8735, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9502, Reg Loss = 870.7372, Reconstruct Loss = 0.0007, Cls Loss = 1.8624, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9646, Reg Loss = 1091.9474, Reconstruct Loss = 0.0005, Cls Loss = 1.8549, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.0156, Reg Loss = 1203.4639, Reconstruct Loss = 0.0439, Cls Loss = 1.8514, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.0103, Reg Loss = 1253.0620, Reconstruct Loss = 0.0366, Cls Loss = 1.8484, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.0161, Reg Loss = 1260.8634, Reconstruct Loss = 0.0428, Cls Loss = 1.8473, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.0074, Reg Loss = 1245.3028, Reconstruct Loss = 0.0374, Cls Loss = 1.8455, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.0141, Reg Loss = 1228.7762, Reconstruct Loss = 0.0471, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.0052, Reg Loss = 1204.1219, Reconstruct Loss = 0.0424, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9993, Reg Loss = 1185.4668, Reconstruct Loss = 0.0385, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.0004, Reg Loss = 1163.8797, Reconstruct Loss = 0.0425, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9933, Reg Loss = 1139.1030, Reconstruct Loss = 0.0393, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9920, Reg Loss = 1113.7237, Reconstruct Loss = 0.0408, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9872, Reg Loss = 1087.2709, Reconstruct Loss = 0.0381, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9826, Reg Loss = 1063.2917, Reconstruct Loss = 0.0357, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9791, Reg Loss = 1039.7144, Reconstruct Loss = 0.0350, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9757, Reg Loss = 1016.1349, Reconstruct Loss = 0.0341, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9741, Reg Loss = 993.3952, Reconstruct Loss = 0.0340, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9697, Reg Loss = 968.7208, Reconstruct Loss = 0.0323, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9656, Reg Loss = 939.5504, Reconstruct Loss = 0.0310, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9605, Reg Loss = 903.8758, Reconstruct Loss = 0.0298, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9558, Reg Loss = 869.9354, Reconstruct Loss = 0.0285, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9517, Reg Loss = 838.3261, Reconstruct Loss = 0.0273, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9476, Reg Loss = 807.9175, Reconstruct Loss = 0.0262, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9438, Reg Loss = 779.6050, Reconstruct Loss = 0.0253, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9403, Reg Loss = 753.1732, Reconstruct Loss = 0.0244, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9369, Reg Loss = 728.0247, Reconstruct Loss = 0.0236, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9341, Reg Loss = 706.7730, Reconstruct Loss = 0.0229, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9314, Reg Loss = 690.1213, Reconstruct Loss = 0.0221, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9290, Reg Loss = 673.2637, Reconstruct Loss = 0.0214, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Epoch [15/30], Training Loss: 1.9286, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Validation Loss: 1.8036, Validation Accuracy: 80.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8973, Reg Loss = 128.2724, Reconstruct Loss = 0.0000, Cls Loss = 1.8845, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8554, Reg Loss = 98.4427, Reconstruct Loss = 0.0017, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8529, Reg Loss = 80.9676, Reconstruct Loss = 0.0016, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8485, Reg Loss = 73.1395, Reconstruct Loss = 0.0011, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8488, Reg Loss = 82.7697, Reconstruct Loss = 0.0024, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8550, Reg Loss = 140.2580, Reconstruct Loss = 0.0041, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8567, Reg Loss = 166.9773, Reconstruct Loss = 0.0034, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8564, Reg Loss = 179.5729, Reconstruct Loss = 0.0029, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8577, Reg Loss = 183.3264, Reconstruct Loss = 0.0030, Cls Loss = 1.8363, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8569, Reg Loss = 181.2915, Reconstruct Loss = 0.0027, Cls Loss = 1.8361, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8567, Reg Loss = 175.5887, Reconstruct Loss = 0.0026, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8557, Reg Loss = 165.2122, Reconstruct Loss = 0.0027, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8551, Reg Loss = 162.4821, Reconstruct Loss = 0.0024, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8537, Reg Loss = 162.1455, Reconstruct Loss = 0.0023, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8527, Reg Loss = 155.9931, Reconstruct Loss = 0.0023, Cls Loss = 1.8348, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8528, Reg Loss = 157.3425, Reconstruct Loss = 0.0022, Cls Loss = 1.8348, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8536, Reg Loss = 163.5180, Reconstruct Loss = 0.0021, Cls Loss = 1.8351, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8540, Reg Loss = 164.7239, Reconstruct Loss = 0.0020, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8539, Reg Loss = 162.8288, Reconstruct Loss = 0.0020, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9100, Reg Loss = 173.7104, Reconstruct Loss = 0.0019, Cls Loss = 1.8908, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9227, Reg Loss = 261.1684, Reconstruct Loss = 0.0080, Cls Loss = 1.8885, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9382, Reg Loss = 343.6461, Reconstruct Loss = 0.0174, Cls Loss = 1.8864, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9422, Reg Loss = 411.9066, Reconstruct Loss = 0.0166, Cls Loss = 1.8845, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9452, Reg Loss = 469.7614, Reconstruct Loss = 0.0159, Cls Loss = 1.8823, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9477, Reg Loss = 519.6020, Reconstruct Loss = 0.0152, Cls Loss = 1.8806, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9518, Reg Loss = 562.8186, Reconstruct Loss = 0.0169, Cls Loss = 1.8786, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9535, Reg Loss = 597.9964, Reconstruct Loss = 0.0163, Cls Loss = 1.8775, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9543, Reg Loss = 627.6919, Reconstruct Loss = 0.0157, Cls Loss = 1.8759, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9548, Reg Loss = 652.3705, Reconstruct Loss = 0.0151, Cls Loss = 1.8744, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9563, Reg Loss = 671.1665, Reconstruct Loss = 0.0158, Cls Loss = 1.8733, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9561, Reg Loss = 683.6567, Reconstruct Loss = 0.0153, Cls Loss = 1.8724, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9565, Reg Loss = 691.9601, Reconstruct Loss = 0.0155, Cls Loss = 1.8718, Learning rate = 1.0000e-03\n",
      "Epoch [16/30], Training Loss: 1.9561, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Validation Loss: 1.8037, Validation Accuracy: 80.11%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9063, Reg Loss = 797.8169, Reconstruct Loss = 0.0000, Cls Loss = 1.8265, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9061, Reg Loss = 676.3164, Reconstruct Loss = 0.0000, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8990, Reg Loss = 548.1136, Reconstruct Loss = 0.0050, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8861, Reg Loss = 443.1866, Reconstruct Loss = 0.0033, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8791, Reg Loss = 381.3504, Reconstruct Loss = 0.0025, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8762, Reg Loss = 345.4627, Reconstruct Loss = 0.0027, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8712, Reg Loss = 305.6442, Reconstruct Loss = 0.0022, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8674, Reg Loss = 268.3989, Reconstruct Loss = 0.0019, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8666, Reg Loss = 261.6820, Reconstruct Loss = 0.0020, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8686, Reg Loss = 279.0632, Reconstruct Loss = 0.0018, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8685, Reg Loss = 286.7597, Reconstruct Loss = 0.0016, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8684, Reg Loss = 288.1012, Reconstruct Loss = 0.0015, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8691, Reg Loss = 284.0400, Reconstruct Loss = 0.0021, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8678, Reg Loss = 275.0281, Reconstruct Loss = 0.0020, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8665, Reg Loss = 264.1398, Reconstruct Loss = 0.0018, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8665, Reg Loss = 262.3885, Reconstruct Loss = 0.0017, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8697, Reg Loss = 292.2510, Reconstruct Loss = 0.0016, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8722, Reg Loss = 316.5372, Reconstruct Loss = 0.0015, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8737, Reg Loss = 336.6301, Reconstruct Loss = 0.0014, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8753, Reg Loss = 353.9985, Reconstruct Loss = 0.0013, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8777, Reg Loss = 367.5490, Reconstruct Loss = 0.0023, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8787, Reg Loss = 377.6685, Reconstruct Loss = 0.0022, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8804, Reg Loss = 385.4429, Reconstruct Loss = 0.0036, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8804, Reg Loss = 387.7901, Reconstruct Loss = 0.0034, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8804, Reg Loss = 389.3309, Reconstruct Loss = 0.0037, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8806, Reg Loss = 388.1718, Reconstruct Loss = 0.0039, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8801, Reg Loss = 383.9682, Reconstruct Loss = 0.0038, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8792, Reg Loss = 374.1749, Reconstruct Loss = 0.0036, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8792, Reg Loss = 372.1723, Reconstruct Loss = 0.0035, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8802, Reg Loss = 383.9974, Reconstruct Loss = 0.0034, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8818, Reg Loss = 394.8982, Reconstruct Loss = 0.0041, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8824, Reg Loss = 403.1160, Reconstruct Loss = 0.0039, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Epoch [17/30], Training Loss: 1.8827, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Validation Loss: 1.8038, Validation Accuracy: 79.91%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8989, Reg Loss = 514.1389, Reconstruct Loss = 0.0000, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9189, Reg Loss = 566.2324, Reconstruct Loss = 0.0178, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9080, Reg Loss = 539.3674, Reconstruct Loss = 0.0091, Cls Loss = 1.8450, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9067, Reg Loss = 505.2630, Reconstruct Loss = 0.0102, Cls Loss = 1.8460, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9004, Reg Loss = 471.4461, Reconstruct Loss = 0.0096, Cls Loss = 1.8437, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8954, Reg Loss = 435.1279, Reconstruct Loss = 0.0100, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8904, Reg Loss = 397.6254, Reconstruct Loss = 0.0095, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8853, Reg Loss = 363.9315, Reconstruct Loss = 0.0085, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8814, Reg Loss = 337.2593, Reconstruct Loss = 0.0074, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8770, Reg Loss = 309.8996, Reconstruct Loss = 0.0066, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8733, Reg Loss = 283.7998, Reconstruct Loss = 0.0060, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8737, Reg Loss = 293.8870, Reconstruct Loss = 0.0054, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8811, Reg Loss = 345.1446, Reconstruct Loss = 0.0082, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8894, Reg Loss = 379.4567, Reconstruct Loss = 0.0125, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8902, Reg Loss = 399.3424, Reconstruct Loss = 0.0116, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8904, Reg Loss = 412.0367, Reconstruct Loss = 0.0109, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8889, Reg Loss = 408.5654, Reconstruct Loss = 0.0104, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8864, Reg Loss = 388.7362, Reconstruct Loss = 0.0099, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8840, Reg Loss = 370.9151, Reconstruct Loss = 0.0093, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8892, Reg Loss = 393.5212, Reconstruct Loss = 0.0117, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9031, Reg Loss = 461.5900, Reconstruct Loss = 0.0188, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9199, Reg Loss = 518.1684, Reconstruct Loss = 0.0304, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9265, Reg Loss = 557.1268, Reconstruct Loss = 0.0333, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9306, Reg Loss = 583.4265, Reconstruct Loss = 0.0349, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9326, Reg Loss = 595.7684, Reconstruct Loss = 0.0356, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9313, Reg Loss = 593.3761, Reconstruct Loss = 0.0342, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9286, Reg Loss = 578.2197, Reconstruct Loss = 0.0331, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9263, Reg Loss = 568.0093, Reconstruct Loss = 0.0319, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9238, Reg Loss = 552.6489, Reconstruct Loss = 0.0307, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9212, Reg Loss = 535.2810, Reconstruct Loss = 0.0297, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9183, Reg Loss = 519.0457, Reconstruct Loss = 0.0287, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9171, Reg Loss = 515.3625, Reconstruct Loss = 0.0278, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Epoch [18/30], Training Loss: 1.9170, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Validation Loss: 1.8037, Validation Accuracy: 80.11%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9110, Reg Loss = 627.3620, Reconstruct Loss = 0.0000, Cls Loss = 1.8482, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8983, Reg Loss = 618.9424, Reconstruct Loss = 0.0000, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9257, Reg Loss = 588.9038, Reconstruct Loss = 0.0262, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9182, Reg Loss = 546.1026, Reconstruct Loss = 0.0207, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9074, Reg Loss = 498.9434, Reconstruct Loss = 0.0156, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8971, Reg Loss = 454.8604, Reconstruct Loss = 0.0125, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8922, Reg Loss = 408.8533, Reconstruct Loss = 0.0119, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8859, Reg Loss = 366.0324, Reconstruct Loss = 0.0106, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8805, Reg Loss = 330.4186, Reconstruct Loss = 0.0093, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8759, Reg Loss = 305.3813, Reconstruct Loss = 0.0086, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8770, Reg Loss = 314.1803, Reconstruct Loss = 0.0086, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8763, Reg Loss = 316.8258, Reconstruct Loss = 0.0078, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8751, Reg Loss = 309.2111, Reconstruct Loss = 0.0071, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8738, Reg Loss = 295.6633, Reconstruct Loss = 0.0067, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8755, Reg Loss = 303.3474, Reconstruct Loss = 0.0063, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8812, Reg Loss = 363.7006, Reconstruct Loss = 0.0059, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8911, Reg Loss = 419.1310, Reconstruct Loss = 0.0100, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9017, Reg Loss = 460.6927, Reconstruct Loss = 0.0165, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9041, Reg Loss = 489.5800, Reconstruct Loss = 0.0156, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9088, Reg Loss = 510.4755, Reconstruct Loss = 0.0180, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9088, Reg Loss = 525.1116, Reconstruct Loss = 0.0171, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9124, Reg Loss = 536.0675, Reconstruct Loss = 0.0195, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9132, Reg Loss = 542.6384, Reconstruct Loss = 0.0197, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9119, Reg Loss = 542.7432, Reconstruct Loss = 0.0188, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9106, Reg Loss = 539.1372, Reconstruct Loss = 0.0180, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9088, Reg Loss = 529.0251, Reconstruct Loss = 0.0173, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9067, Reg Loss = 519.5425, Reconstruct Loss = 0.0167, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9053, Reg Loss = 508.8039, Reconstruct Loss = 0.0162, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9035, Reg Loss = 495.5635, Reconstruct Loss = 0.0156, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9017, Reg Loss = 483.7567, Reconstruct Loss = 0.0151, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8999, Reg Loss = 471.2951, Reconstruct Loss = 0.0146, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8982, Reg Loss = 460.2063, Reconstruct Loss = 0.0142, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Epoch [19/30], Training Loss: 1.8978, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Validation Loss: 1.8036, Validation Accuracy: 80.20%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8797, Reg Loss = 78.9642, Reconstruct Loss = 0.0000, Cls Loss = 1.8719, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.2176, Reg Loss = 585.5261, Reconstruct Loss = 0.0000, Cls Loss = 2.1591, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.1753, Reg Loss = 1690.5782, Reconstruct Loss = 0.0000, Cls Loss = 2.0062, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.1558, Reg Loss = 2070.7987, Reconstruct Loss = 0.0000, Cls Loss = 1.9487, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.2172, Reg Loss = 2186.0316, Reconstruct Loss = 0.0798, Cls Loss = 1.9188, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.1854, Reg Loss = 2183.0128, Reconstruct Loss = 0.0640, Cls Loss = 1.9031, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.1611, Reg Loss = 2152.0369, Reconstruct Loss = 0.0534, Cls Loss = 1.8925, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.1408, Reg Loss = 2105.1449, Reconstruct Loss = 0.0458, Cls Loss = 1.8845, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.1443, Reg Loss = 2047.5810, Reconstruct Loss = 0.0610, Cls Loss = 1.8785, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.1269, Reg Loss = 1984.0166, Reconstruct Loss = 0.0543, Cls Loss = 1.8742, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.1447, Reg Loss = 1931.8861, Reconstruct Loss = 0.0808, Cls Loss = 1.8707, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.1361, Reg Loss = 1870.8784, Reconstruct Loss = 0.0807, Cls Loss = 1.8684, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.1207, Reg Loss = 1808.9004, Reconstruct Loss = 0.0740, Cls Loss = 1.8658, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.1068, Reg Loss = 1754.0172, Reconstruct Loss = 0.0683, Cls Loss = 1.8631, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.0953, Reg Loss = 1704.0959, Reconstruct Loss = 0.0634, Cls Loss = 1.8615, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.0961, Reg Loss = 1657.4331, Reconstruct Loss = 0.0701, Cls Loss = 1.8602, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.0849, Reg Loss = 1604.7843, Reconstruct Loss = 0.0658, Cls Loss = 1.8587, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.0773, Reg Loss = 1549.0193, Reconstruct Loss = 0.0644, Cls Loss = 1.8581, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.0654, Reg Loss = 1480.8430, Reconstruct Loss = 0.0608, Cls Loss = 1.8566, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.1827, Reg Loss = 1441.8921, Reconstruct Loss = 0.0645, Cls Loss = 1.9740, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.1767, Reg Loss = 1478.5828, Reconstruct Loss = 0.0613, Cls Loss = 1.9676, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.1828, Reg Loss = 1514.3033, Reconstruct Loss = 0.0698, Cls Loss = 1.9616, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.1772, Reg Loss = 1542.6210, Reconstruct Loss = 0.0666, Cls Loss = 1.9563, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.1787, Reg Loss = 1563.4048, Reconstruct Loss = 0.0714, Cls Loss = 1.9510, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.1787, Reg Loss = 1576.4153, Reconstruct Loss = 0.0746, Cls Loss = 1.9465, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.1712, Reg Loss = 1579.0537, Reconstruct Loss = 0.0716, Cls Loss = 1.9416, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.1630, Reg Loss = 1565.6051, Reconstruct Loss = 0.0689, Cls Loss = 1.9376, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.1548, Reg Loss = 1526.5101, Reconstruct Loss = 0.0675, Cls Loss = 1.9346, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.1446, Reg Loss = 1487.2798, Reconstruct Loss = 0.0650, Cls Loss = 1.9308, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.1352, Reg Loss = 1448.4938, Reconstruct Loss = 0.0628, Cls Loss = 1.9275, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.1259, Reg Loss = 1408.5378, Reconstruct Loss = 0.0607, Cls Loss = 1.9243, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.1180, Reg Loss = 1373.4788, Reconstruct Loss = 0.0591, Cls Loss = 1.9216, Learning rate = 1.0000e-03\n",
      "Epoch [20/30], Training Loss: 2.1159, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Validation Loss: 1.8037, Validation Accuracy: 80.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9016, Reg Loss = 132.3608, Reconstruct Loss = 0.0781, Cls Loss = 1.8103, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8575, Reg Loss = 98.3732, Reconstruct Loss = 0.0046, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8764, Reg Loss = 275.0781, Reconstruct Loss = 0.0104, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8841, Reg Loss = 360.7533, Reconstruct Loss = 0.0070, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8822, Reg Loss = 372.0721, Reconstruct Loss = 0.0052, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8795, Reg Loss = 339.6830, Reconstruct Loss = 0.0070, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8772, Reg Loss = 314.1489, Reconstruct Loss = 0.0064, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8765, Reg Loss = 336.4378, Reconstruct Loss = 0.0055, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8765, Reg Loss = 334.9763, Reconstruct Loss = 0.0048, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8745, Reg Loss = 314.6075, Reconstruct Loss = 0.0045, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8764, Reg Loss = 327.0776, Reconstruct Loss = 0.0050, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8754, Reg Loss = 321.7758, Reconstruct Loss = 0.0045, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8734, Reg Loss = 304.3021, Reconstruct Loss = 0.0044, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8720, Reg Loss = 293.6988, Reconstruct Loss = 0.0044, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8701, Reg Loss = 280.6767, Reconstruct Loss = 0.0041, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8688, Reg Loss = 269.9345, Reconstruct Loss = 0.0039, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8704, Reg Loss = 284.4368, Reconstruct Loss = 0.0037, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8714, Reg Loss = 296.8775, Reconstruct Loss = 0.0040, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8714, Reg Loss = 291.0043, Reconstruct Loss = 0.0038, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8789, Reg Loss = 365.2788, Reconstruct Loss = 0.0036, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8879, Reg Loss = 458.5759, Reconstruct Loss = 0.0034, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9251, Reg Loss = 534.7317, Reconstruct Loss = 0.0328, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9275, Reg Loss = 577.0200, Reconstruct Loss = 0.0313, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9337, Reg Loss = 608.8812, Reconstruct Loss = 0.0343, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9348, Reg Loss = 634.0023, Reconstruct Loss = 0.0329, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9355, Reg Loss = 655.5438, Reconstruct Loss = 0.0316, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9354, Reg Loss = 674.1768, Reconstruct Loss = 0.0304, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9357, Reg Loss = 689.5751, Reconstruct Loss = 0.0292, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9364, Reg Loss = 702.3099, Reconstruct Loss = 0.0282, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9369, Reg Loss = 714.0222, Reconstruct Loss = 0.0272, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9388, Reg Loss = 722.1276, Reconstruct Loss = 0.0283, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9399, Reg Loss = 728.7102, Reconstruct Loss = 0.0290, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Epoch [21/30], Training Loss: 1.9398, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Validation Loss: 1.8036, Validation Accuracy: 80.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9433, Reg Loss = 959.2996, Reconstruct Loss = 0.0000, Cls Loss = 1.8474, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9235, Reg Loss = 888.5450, Reconstruct Loss = 0.0000, Cls Loss = 1.8346, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9265, Reg Loss = 858.7795, Reconstruct Loss = 0.0000, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9379, Reg Loss = 847.9257, Reconstruct Loss = 0.0130, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9429, Reg Loss = 832.6803, Reconstruct Loss = 0.0182, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9542, Reg Loss = 809.4389, Reconstruct Loss = 0.0319, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9582, Reg Loss = 781.1619, Reconstruct Loss = 0.0417, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9550, Reg Loss = 746.5466, Reconstruct Loss = 0.0402, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9449, Reg Loss = 711.9482, Reconstruct Loss = 0.0352, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9384, Reg Loss = 678.2975, Reconstruct Loss = 0.0324, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9330, Reg Loss = 645.5150, Reconstruct Loss = 0.0307, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9276, Reg Loss = 618.1547, Reconstruct Loss = 0.0288, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9239, Reg Loss = 598.9955, Reconstruct Loss = 0.0264, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9196, Reg Loss = 574.3994, Reconstruct Loss = 0.0244, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9164, Reg Loss = 552.7532, Reconstruct Loss = 0.0228, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9172, Reg Loss = 562.4173, Reconstruct Loss = 0.0230, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9168, Reg Loss = 569.0444, Reconstruct Loss = 0.0216, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9169, Reg Loss = 569.1729, Reconstruct Loss = 0.0215, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9147, Reg Loss = 564.0812, Reconstruct Loss = 0.0203, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9134, Reg Loss = 555.6379, Reconstruct Loss = 0.0198, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9118, Reg Loss = 543.6724, Reconstruct Loss = 0.0190, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9090, Reg Loss = 525.5575, Reconstruct Loss = 0.0183, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9111, Reg Loss = 547.8392, Reconstruct Loss = 0.0174, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9542, Reg Loss = 622.0138, Reconstruct Loss = 0.0531, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9563, Reg Loss = 668.3836, Reconstruct Loss = 0.0509, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9708, Reg Loss = 700.2197, Reconstruct Loss = 0.0625, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9732, Reg Loss = 721.1906, Reconstruct Loss = 0.0630, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9748, Reg Loss = 736.4648, Reconstruct Loss = 0.0631, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9757, Reg Loss = 748.0192, Reconstruct Loss = 0.0630, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9744, Reg Loss = 756.0123, Reconstruct Loss = 0.0609, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9733, Reg Loss = 763.1999, Reconstruct Loss = 0.0588, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9717, Reg Loss = 768.8727, Reconstruct Loss = 0.0569, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Epoch [22/30], Training Loss: 1.9715, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Validation Loss: 1.8037, Validation Accuracy: 80.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9600, Reg Loss = 798.3544, Reconstruct Loss = 0.0000, Cls Loss = 1.8802, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9785, Reg Loss = 914.4632, Reconstruct Loss = 0.0456, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9920, Reg Loss = 890.4176, Reconstruct Loss = 0.0640, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9770, Reg Loss = 862.8658, Reconstruct Loss = 0.0550, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9643, Reg Loss = 834.4890, Reconstruct Loss = 0.0414, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9541, Reg Loss = 812.8661, Reconstruct Loss = 0.0332, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9565, Reg Loss = 799.5173, Reconstruct Loss = 0.0374, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9505, Reg Loss = 780.2573, Reconstruct Loss = 0.0321, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9476, Reg Loss = 761.4408, Reconstruct Loss = 0.0310, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9419, Reg Loss = 739.0904, Reconstruct Loss = 0.0276, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9375, Reg Loss = 716.1598, Reconstruct Loss = 0.0266, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9317, Reg Loss = 692.9016, Reconstruct Loss = 0.0241, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9269, Reg Loss = 667.4326, Reconstruct Loss = 0.0221, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9231, Reg Loss = 640.2059, Reconstruct Loss = 0.0211, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9190, Reg Loss = 608.8595, Reconstruct Loss = 0.0198, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.1223, Reg Loss = 587.0229, Reconstruct Loss = 0.0185, Cls Loss = 2.0451, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.1265, Reg Loss = 658.6502, Reconstruct Loss = 0.0282, Cls Loss = 2.0325, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.1213, Reg Loss = 734.4615, Reconstruct Loss = 0.0265, Cls Loss = 2.0213, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.1153, Reg Loss = 794.1428, Reconstruct Loss = 0.0250, Cls Loss = 2.0109, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.1160, Reg Loss = 842.6716, Reconstruct Loss = 0.0295, Cls Loss = 2.0022, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.1234, Reg Loss = 880.2548, Reconstruct Loss = 0.0417, Cls Loss = 1.9936, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.1168, Reg Loss = 908.1997, Reconstruct Loss = 0.0397, Cls Loss = 1.9863, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.1139, Reg Loss = 932.6119, Reconstruct Loss = 0.0410, Cls Loss = 1.9796, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.1082, Reg Loss = 952.1027, Reconstruct Loss = 0.0392, Cls Loss = 1.9738, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.1048, Reg Loss = 967.9453, Reconstruct Loss = 0.0399, Cls Loss = 1.9681, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.1014, Reg Loss = 978.1833, Reconstruct Loss = 0.0404, Cls Loss = 1.9633, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.0984, Reg Loss = 983.7789, Reconstruct Loss = 0.0417, Cls Loss = 1.9583, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.0924, Reg Loss = 983.2199, Reconstruct Loss = 0.0402, Cls Loss = 1.9539, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0862, Reg Loss = 978.4096, Reconstruct Loss = 0.0387, Cls Loss = 1.9496, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0805, Reg Loss = 966.5090, Reconstruct Loss = 0.0382, Cls Loss = 1.9456, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0735, Reg Loss = 945.4106, Reconstruct Loss = 0.0370, Cls Loss = 1.9420, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0665, Reg Loss = 922.7494, Reconstruct Loss = 0.0358, Cls Loss = 1.9385, Learning rate = 1.0000e-03\n",
      "Epoch [23/30], Training Loss: 2.0649, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8603, Reg Loss = 412.1882, Reconstruct Loss = 0.0000, Cls Loss = 1.8191, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8936, Reg Loss = 431.1499, Reconstruct Loss = 0.0065, Cls Loss = 1.8440, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8807, Reg Loss = 376.0839, Reconstruct Loss = 0.0033, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8742, Reg Loss = 307.9555, Reconstruct Loss = 0.0022, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8688, Reg Loss = 254.5696, Reconstruct Loss = 0.0017, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8681, Reg Loss = 218.2002, Reconstruct Loss = 0.0025, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8816, Reg Loss = 310.2822, Reconstruct Loss = 0.0087, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8878, Reg Loss = 392.0472, Reconstruct Loss = 0.0075, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8957, Reg Loss = 444.9337, Reconstruct Loss = 0.0106, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8980, Reg Loss = 472.6967, Reconstruct Loss = 0.0094, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8970, Reg Loss = 479.3834, Reconstruct Loss = 0.0085, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8950, Reg Loss = 468.3192, Reconstruct Loss = 0.0077, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8950, Reg Loss = 456.3957, Reconstruct Loss = 0.0073, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8988, Reg Loss = 504.4471, Reconstruct Loss = 0.0067, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9019, Reg Loss = 545.1224, Reconstruct Loss = 0.0062, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9036, Reg Loss = 571.6240, Reconstruct Loss = 0.0058, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9046, Reg Loss = 587.2316, Reconstruct Loss = 0.0054, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9052, Reg Loss = 586.3869, Reconstruct Loss = 0.0061, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9034, Reg Loss = 572.0389, Reconstruct Loss = 0.0058, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9045, Reg Loss = 573.9213, Reconstruct Loss = 0.0055, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9054, Reg Loss = 587.5109, Reconstruct Loss = 0.0052, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9048, Reg Loss = 582.7197, Reconstruct Loss = 0.0053, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9030, Reg Loss = 571.3155, Reconstruct Loss = 0.0051, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9011, Reg Loss = 557.2024, Reconstruct Loss = 0.0049, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8989, Reg Loss = 541.8320, Reconstruct Loss = 0.0047, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8970, Reg Loss = 527.8418, Reconstruct Loss = 0.0045, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8957, Reg Loss = 512.3658, Reconstruct Loss = 0.0044, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8939, Reg Loss = 497.5206, Reconstruct Loss = 0.0044, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8925, Reg Loss = 484.1996, Reconstruct Loss = 0.0042, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8938, Reg Loss = 491.9168, Reconstruct Loss = 0.0049, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8951, Reg Loss = 494.2246, Reconstruct Loss = 0.0060, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8944, Reg Loss = 487.4613, Reconstruct Loss = 0.0059, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Epoch [24/30], Training Loss: 1.8942, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Validation Loss: 1.8037, Validation Accuracy: 79.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8190, Reg Loss = 150.9864, Reconstruct Loss = 0.0000, Cls Loss = 1.8039, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8509, Reg Loss = 125.2472, Reconstruct Loss = 0.0018, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8524, Reg Loss = 138.0843, Reconstruct Loss = 0.0018, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8504, Reg Loss = 120.3719, Reconstruct Loss = 0.0017, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8608, Reg Loss = 160.5194, Reconstruct Loss = 0.0035, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8654, Reg Loss = 214.1753, Reconstruct Loss = 0.0043, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8708, Reg Loss = 265.4518, Reconstruct Loss = 0.0036, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9255, Reg Loss = 462.7476, Reconstruct Loss = 0.0391, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9545, Reg Loss = 569.9912, Reconstruct Loss = 0.0584, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9590, Reg Loss = 621.8154, Reconstruct Loss = 0.0579, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9596, Reg Loss = 645.1155, Reconstruct Loss = 0.0559, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9581, Reg Loss = 651.3127, Reconstruct Loss = 0.0548, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9533, Reg Loss = 639.1720, Reconstruct Loss = 0.0511, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9455, Reg Loss = 605.6334, Reconstruct Loss = 0.0472, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9386, Reg Loss = 573.2554, Reconstruct Loss = 0.0438, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9326, Reg Loss = 541.2697, Reconstruct Loss = 0.0410, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9266, Reg Loss = 512.9607, Reconstruct Loss = 0.0384, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9350, Reg Loss = 581.0189, Reconstruct Loss = 0.0362, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9456, Reg Loss = 704.4023, Reconstruct Loss = 0.0342, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9647, Reg Loss = 799.5774, Reconstruct Loss = 0.0438, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9686, Reg Loss = 852.1539, Reconstruct Loss = 0.0416, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9718, Reg Loss = 873.0543, Reconstruct Loss = 0.0426, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9711, Reg Loss = 861.8606, Reconstruct Loss = 0.0433, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9666, Reg Loss = 834.1598, Reconstruct Loss = 0.0417, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9622, Reg Loss = 810.6040, Reconstruct Loss = 0.0400, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9577, Reg Loss = 783.3679, Reconstruct Loss = 0.0385, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9535, Reg Loss = 756.8520, Reconstruct Loss = 0.0371, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9672, Reg Loss = 744.9898, Reconstruct Loss = 0.0398, Cls Loss = 1.8529, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9711, Reg Loss = 802.2442, Reconstruct Loss = 0.0384, Cls Loss = 1.8525, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9931, Reg Loss = 862.7757, Reconstruct Loss = 0.0548, Cls Loss = 1.8520, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9961, Reg Loss = 915.0863, Reconstruct Loss = 0.0530, Cls Loss = 1.8517, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0051, Reg Loss = 959.4360, Reconstruct Loss = 0.0579, Cls Loss = 1.8512, Learning rate = 1.0000e-03\n",
      "Epoch [25/30], Training Loss: 2.0053, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Validation Loss: 1.8038, Validation Accuracy: 79.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 2.0400, Reg Loss = 2002.6947, Reconstruct Loss = 0.0000, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.2251, Reg Loss = 2130.6474, Reconstruct Loss = 0.1680, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.2871, Reg Loss = 2083.1341, Reconstruct Loss = 0.2401, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.2877, Reg Loss = 2006.3712, Reconstruct Loss = 0.2491, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.2778, Reg Loss = 1928.7885, Reconstruct Loss = 0.2462, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.2200, Reg Loss = 1849.4477, Reconstruct Loss = 0.1974, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.1811, Reg Loss = 1792.1341, Reconstruct Loss = 0.1647, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.1536, Reg Loss = 1742.2705, Reconstruct Loss = 0.1413, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.1314, Reg Loss = 1700.9259, Reconstruct Loss = 0.1237, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.1234, Reg Loss = 1664.5297, Reconstruct Loss = 0.1198, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.1071, Reg Loss = 1630.4721, Reconstruct Loss = 0.1079, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.0947, Reg Loss = 1597.1268, Reconstruct Loss = 0.0981, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.0832, Reg Loss = 1566.6925, Reconstruct Loss = 0.0899, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.0892, Reg Loss = 1538.4885, Reconstruct Loss = 0.0985, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.0822, Reg Loss = 1501.2955, Reconstruct Loss = 0.0951, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.0744, Reg Loss = 1456.1278, Reconstruct Loss = 0.0919, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.0642, Reg Loss = 1409.4690, Reconstruct Loss = 0.0861, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.0560, Reg Loss = 1363.9362, Reconstruct Loss = 0.0823, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.0466, Reg Loss = 1310.7083, Reconstruct Loss = 0.0784, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.0407, Reg Loss = 1251.3230, Reconstruct Loss = 0.0747, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.0406, Reg Loss = 1260.0325, Reconstruct Loss = 0.0740, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.0395, Reg Loss = 1282.7909, Reconstruct Loss = 0.0704, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.0385, Reg Loss = 1301.3712, Reconstruct Loss = 0.0672, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.0370, Reg Loss = 1318.1764, Reconstruct Loss = 0.0643, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.0401, Reg Loss = 1331.8473, Reconstruct Loss = 0.0658, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.0491, Reg Loss = 1338.6464, Reconstruct Loss = 0.0739, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.0461, Reg Loss = 1339.3703, Reconstruct Loss = 0.0711, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.0484, Reg Loss = 1338.1305, Reconstruct Loss = 0.0739, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0452, Reg Loss = 1332.6406, Reconstruct Loss = 0.0713, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0440, Reg Loss = 1324.8316, Reconstruct Loss = 0.0711, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0428, Reg Loss = 1317.0918, Reconstruct Loss = 0.0707, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0411, Reg Loss = 1308.0329, Reconstruct Loss = 0.0702, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Epoch [26/30], Training Loss: 2.0404, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Validation Loss: 1.8036, Validation Accuracy: 80.07%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8952, Reg Loss = 976.1795, Reconstruct Loss = 0.0000, Cls Loss = 1.7976, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9940, Reg Loss = 976.8657, Reconstruct Loss = 0.0489, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9679, Reg Loss = 960.1448, Reconstruct Loss = 0.0249, Cls Loss = 1.8470, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9673, Reg Loss = 936.0748, Reconstruct Loss = 0.0309, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9567, Reg Loss = 915.8233, Reconstruct Loss = 0.0233, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9561, Reg Loss = 899.4579, Reconstruct Loss = 0.0260, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9565, Reg Loss = 875.9721, Reconstruct Loss = 0.0270, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9518, Reg Loss = 844.8951, Reconstruct Loss = 0.0265, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9448, Reg Loss = 802.7216, Reconstruct Loss = 0.0251, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9371, Reg Loss = 747.3650, Reconstruct Loss = 0.0227, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9298, Reg Loss = 694.0225, Reconstruct Loss = 0.0204, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9232, Reg Loss = 651.1922, Reconstruct Loss = 0.0188, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9173, Reg Loss = 608.5624, Reconstruct Loss = 0.0172, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9144, Reg Loss = 593.1588, Reconstruct Loss = 0.0159, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9111, Reg Loss = 576.4461, Reconstruct Loss = 0.0148, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9080, Reg Loss = 556.1704, Reconstruct Loss = 0.0138, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9041, Reg Loss = 532.1546, Reconstruct Loss = 0.0129, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9006, Reg Loss = 504.8284, Reconstruct Loss = 0.0123, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8978, Reg Loss = 481.5025, Reconstruct Loss = 0.0116, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8959, Reg Loss = 466.6703, Reconstruct Loss = 0.0111, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8934, Reg Loss = 448.5813, Reconstruct Loss = 0.0106, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8917, Reg Loss = 441.0488, Reconstruct Loss = 0.0101, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8910, Reg Loss = 437.1290, Reconstruct Loss = 0.0100, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8897, Reg Loss = 429.1973, Reconstruct Loss = 0.0096, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8883, Reg Loss = 416.5287, Reconstruct Loss = 0.0093, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8871, Reg Loss = 406.8285, Reconstruct Loss = 0.0091, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8857, Reg Loss = 397.5314, Reconstruct Loss = 0.0088, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8845, Reg Loss = 387.4739, Reconstruct Loss = 0.0085, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8833, Reg Loss = 379.5459, Reconstruct Loss = 0.0082, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8838, Reg Loss = 382.1157, Reconstruct Loss = 0.0079, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8887, Reg Loss = 436.5282, Reconstruct Loss = 0.0076, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8942, Reg Loss = 491.3759, Reconstruct Loss = 0.0074, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Epoch [27/30], Training Loss: 1.9019, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Validation Loss: 1.8037, Validation Accuracy: 79.91%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 2.0755, Reg Loss = 2207.8027, Reconstruct Loss = 0.0000, Cls Loss = 1.8547, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.1792, Reg Loss = 1882.6182, Reconstruct Loss = 0.1564, Cls Loss = 1.8346, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.1576, Reg Loss = 1768.3564, Reconstruct Loss = 0.1443, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.1360, Reg Loss = 1683.4258, Reconstruct Loss = 0.1329, Cls Loss = 1.8348, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.1006, Reg Loss = 1613.6654, Reconstruct Loss = 0.1000, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.0913, Reg Loss = 1556.7168, Reconstruct Loss = 0.0974, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.1067, Reg Loss = 1508.1529, Reconstruct Loss = 0.1187, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.1094, Reg Loss = 1445.7347, Reconstruct Loss = 0.1283, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.0924, Reg Loss = 1382.2521, Reconstruct Loss = 0.1180, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.0747, Reg Loss = 1326.3538, Reconstruct Loss = 0.1049, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.0638, Reg Loss = 1278.7641, Reconstruct Loss = 0.0982, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.0569, Reg Loss = 1231.7310, Reconstruct Loss = 0.0953, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.0479, Reg Loss = 1184.5865, Reconstruct Loss = 0.0913, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.0366, Reg Loss = 1137.5819, Reconstruct Loss = 0.0843, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.0265, Reg Loss = 1094.2494, Reconstruct Loss = 0.0783, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.0170, Reg Loss = 1053.8993, Reconstruct Loss = 0.0731, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.0098, Reg Loss = 1015.2917, Reconstruct Loss = 0.0698, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.0019, Reg Loss = 975.8420, Reconstruct Loss = 0.0657, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9952, Reg Loss = 938.5673, Reconstruct Loss = 0.0624, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9883, Reg Loss = 901.3197, Reconstruct Loss = 0.0591, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9819, Reg Loss = 866.0817, Reconstruct Loss = 0.0561, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9759, Reg Loss = 835.0945, Reconstruct Loss = 0.0535, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9701, Reg Loss = 805.8105, Reconstruct Loss = 0.0510, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9644, Reg Loss = 775.4704, Reconstruct Loss = 0.0488, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9595, Reg Loss = 745.3680, Reconstruct Loss = 0.0468, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9668, Reg Loss = 766.3026, Reconstruct Loss = 0.0517, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9725, Reg Loss = 844.4679, Reconstruct Loss = 0.0497, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9874, Reg Loss = 913.0068, Reconstruct Loss = 0.0578, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0095, Reg Loss = 962.7148, Reconstruct Loss = 0.0748, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0098, Reg Loss = 994.0709, Reconstruct Loss = 0.0722, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0091, Reg Loss = 1011.0289, Reconstruct Loss = 0.0698, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0063, Reg Loss = 1008.2785, Reconstruct Loss = 0.0676, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Epoch [28/30], Training Loss: 2.0053, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Validation Loss: 1.8037, Validation Accuracy: 79.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8724, Reg Loss = 424.4771, Reconstruct Loss = 0.0000, Cls Loss = 1.8299, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8628, Reg Loss = 291.8823, Reconstruct Loss = 0.0000, Cls Loss = 1.8337, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8579, Reg Loss = 247.7952, Reconstruct Loss = 0.0000, Cls Loss = 1.8331, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8596, Reg Loss = 228.9425, Reconstruct Loss = 0.0009, Cls Loss = 1.8358, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8559, Reg Loss = 188.0921, Reconstruct Loss = 0.0007, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8566, Reg Loss = 181.6676, Reconstruct Loss = 0.0008, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8577, Reg Loss = 204.8613, Reconstruct Loss = 0.0007, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8565, Reg Loss = 206.1864, Reconstruct Loss = 0.0006, Cls Loss = 1.8354, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8547, Reg Loss = 193.8201, Reconstruct Loss = 0.0005, Cls Loss = 1.8348, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8541, Reg Loss = 181.1735, Reconstruct Loss = 0.0004, Cls Loss = 1.8356, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8541, Reg Loss = 173.3703, Reconstruct Loss = 0.0004, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8646, Reg Loss = 247.5090, Reconstruct Loss = 0.0031, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8730, Reg Loss = 306.1986, Reconstruct Loss = 0.0052, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8798, Reg Loss = 338.2554, Reconstruct Loss = 0.0084, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8825, Reg Loss = 358.3080, Reconstruct Loss = 0.0092, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8834, Reg Loss = 370.1198, Reconstruct Loss = 0.0086, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8862, Reg Loss = 379.2317, Reconstruct Loss = 0.0106, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8863, Reg Loss = 381.6577, Reconstruct Loss = 0.0105, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8859, Reg Loss = 379.6335, Reconstruct Loss = 0.0103, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8851, Reg Loss = 373.0230, Reconstruct Loss = 0.0098, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8836, Reg Loss = 360.5901, Reconstruct Loss = 0.0094, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8868, Reg Loss = 381.9567, Reconstruct Loss = 0.0097, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8877, Reg Loss = 400.0939, Reconstruct Loss = 0.0093, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.5591, Reg Loss = 469.8251, Reconstruct Loss = 0.0089, Cls Loss = 2.5031, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.5762, Reg Loss = 591.1143, Reconstruct Loss = 0.0412, Cls Loss = 2.4758, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.5736, Reg Loss = 692.7622, Reconstruct Loss = 0.0538, Cls Loss = 2.4505, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.5679, Reg Loss = 779.3261, Reconstruct Loss = 0.0626, Cls Loss = 2.4274, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.5606, Reg Loss = 853.7835, Reconstruct Loss = 0.0698, Cls Loss = 2.4054, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.5743, Reg Loss = 917.2807, Reconstruct Loss = 0.0970, Cls Loss = 2.3856, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.5623, Reg Loss = 963.6023, Reconstruct Loss = 0.0992, Cls Loss = 2.3667, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.5498, Reg Loss = 1002.0702, Reconstruct Loss = 0.1009, Cls Loss = 2.3487, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.5376, Reg Loss = 1034.9280, Reconstruct Loss = 0.1022, Cls Loss = 2.3320, Learning rate = 1.0000e-03\n",
      "Epoch [29/30], Training Loss: 2.5337, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Validation Loss: 1.8035, Validation Accuracy: 80.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 2.0501, Reg Loss = 1932.1584, Reconstruct Loss = 0.0000, Cls Loss = 1.8569, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.1418, Reg Loss = 1821.8340, Reconstruct Loss = 0.1197, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.1310, Reg Loss = 1764.0573, Reconstruct Loss = 0.1159, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.1509, Reg Loss = 1677.0222, Reconstruct Loss = 0.1428, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.1079, Reg Loss = 1595.9718, Reconstruct Loss = 0.1075, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.0935, Reg Loss = 1524.3610, Reconstruct Loss = 0.1021, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.0692, Reg Loss = 1469.2794, Reconstruct Loss = 0.0852, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.0526, Reg Loss = 1423.0632, Reconstruct Loss = 0.0731, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.0402, Reg Loss = 1382.6994, Reconstruct Loss = 0.0640, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.0291, Reg Loss = 1348.9261, Reconstruct Loss = 0.0569, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.0210, Reg Loss = 1313.5725, Reconstruct Loss = 0.0513, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.0130, Reg Loss = 1280.0495, Reconstruct Loss = 0.0466, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.0109, Reg Loss = 1243.8637, Reconstruct Loss = 0.0491, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.0023, Reg Loss = 1199.6330, Reconstruct Loss = 0.0454, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9943, Reg Loss = 1148.5864, Reconstruct Loss = 0.0429, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9853, Reg Loss = 1084.7686, Reconstruct Loss = 0.0400, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9775, Reg Loss = 1031.2436, Reconstruct Loss = 0.0375, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9707, Reg Loss = 980.7000, Reconstruct Loss = 0.0355, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9844, Reg Loss = 1025.2375, Reconstruct Loss = 0.0342, Cls Loss = 1.8476, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.0078, Reg Loss = 1126.8041, Reconstruct Loss = 0.0477, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.0130, Reg Loss = 1212.4524, Reconstruct Loss = 0.0453, Cls Loss = 1.8464, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.0287, Reg Loss = 1282.2791, Reconstruct Loss = 0.0543, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.0499, Reg Loss = 1333.6490, Reconstruct Loss = 0.0705, Cls Loss = 1.8460, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.0511, Reg Loss = 1377.4914, Reconstruct Loss = 0.0674, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.0589, Reg Loss = 1414.9342, Reconstruct Loss = 0.0719, Cls Loss = 1.8455, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.0585, Reg Loss = 1446.7166, Reconstruct Loss = 0.0690, Cls Loss = 1.8449, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.0581, Reg Loss = 1472.7147, Reconstruct Loss = 0.0663, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.0638, Reg Loss = 1497.0450, Reconstruct Loss = 0.0698, Cls Loss = 1.8443, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0632, Reg Loss = 1517.9788, Reconstruct Loss = 0.0673, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0678, Reg Loss = 1537.5769, Reconstruct Loss = 0.0701, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0664, Reg Loss = 1552.9369, Reconstruct Loss = 0.0678, Cls Loss = 1.8433, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0701, Reg Loss = 1567.0110, Reconstruct Loss = 0.0701, Cls Loss = 1.8433, Learning rate = 1.0000e-03\n",
      "Epoch [30/30], Training Loss: 2.0699, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the epochs\n",
    "for epoch in range(start_epoch, args.experiment.num_epochs):\n",
    "    # Train the hypernetwork to generate a model with random dimension for one epoch\n",
    "    train_loss, dim_dict, gt_model_dict = train_one_epoch(hyper_model, train_loader, optimizer, criterion, \n",
    "                                                          dim_dict, gt_model_dict, epoch_idx=epoch, ema=ema, \n",
    "                                                          args=args, device=device)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the training loss and learning rate\n",
    "    print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Training Loss: {train_loss:.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # If it's time to evaluate the model\n",
    "    if (epoch + 1) % args.experiment.eval_interval == 0:\n",
    "        # Apply EMA if it is specified\n",
    "        if ema:\n",
    "            ema.apply()  # Save the weights of original model created before training_loop\n",
    "        \n",
    "        # Sample the merged model (create model of same structure before training loop by using the hypernetwork)\n",
    "        # And then test the performance of the hypernetwork by seeing how good it is in generating the weights\n",
    "        model = sample_merge_model(hyper_model, model, args) \n",
    "        # Validate the merged model\n",
    "        val_loss, acc = validate_single(model, val_loader, val_criterion, args=args)\n",
    "\n",
    "        # If EMA is specified, restore the original weights\n",
    "        if ema:\n",
    "            ema.restore()  # Restore the original weights to the weights of the pretrained networks\n",
    "\n",
    "        # Log the validation loss and accuracy to wandb\n",
    "        wandb.log({\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": acc\n",
    "        })\n",
    "        # Print the validation loss and accuracy\n",
    "        print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Save the checkpoint if the accuracy is better than the previous best\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_checkpoint(f\"{args.training.save_model_path}/cifar10_nerf_best.pth\",hyper_model,optimizer,ema,epoch,best_acc)\n",
    "            print(f\"Checkpoint saved at epoch {epoch} with accuracy: {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15464fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the wandb tracking\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6054a4",
   "metadata": {},
   "source": [
    "### 7 Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43945b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_hypernet_path = args.training.save_model_path + '/cifar10_nerf_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f139172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_MLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-3): 4 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4431caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(saved_hypernet_path, map_location=\"cpu\")  # or \"cuda\" if using GPU\n",
    "hyper_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4eaa63eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 16\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 16, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 17\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 17, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 18\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 18, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 19\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 66.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 19, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 20\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 20, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 21\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 21, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 22\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 22, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 23\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 23, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 24\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 24, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 25\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 25, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 26\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 26, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 27\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 27, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 28\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 65.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 28, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 29\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 29, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 30\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 30, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 31\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 31, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 32, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 33, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 34, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 35, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 36, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 37, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 38, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 39, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 40, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 41, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 42, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 43, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 65.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 44, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 61.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 45, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 65.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 46, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 47, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 67.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 48, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 49, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 50, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 51, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 52, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 53, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 65.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 54, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 65.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 55, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 67.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 56, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 57, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 67.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 58, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 59, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 60, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 61, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 62, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 66.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 63, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 64, Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in range(16, 65):\n",
    "    # Create a model for this given dimension\n",
    "    model = create_model(args.model.type,\n",
    "                         hidden_dim=hidden_dim,\n",
    "                         path=args.model.pretrained_path,\n",
    "                         smooth=args.model.smooth).to(device)\n",
    "    \n",
    "    # If EMA is specified, apply it\n",
    "    if ema:\n",
    "        print('Applying EMA')\n",
    "        ema.apply()\n",
    "\n",
    "    # Sample the merged model\n",
    "    accumulated_model = sample_merge_model(hyper_model, model, args, K=100)\n",
    "\n",
    "    # Validate the merged model\n",
    "    val_loss, acc = validate_single(accumulated_model, val_loader, val_criterion, args=args)\n",
    "\n",
    "    # If EMA is specified, restore the original weights after applying EMA\n",
    "    if ema:\n",
    "        ema.restore()  # Restore the original weights after applying \n",
    "        \n",
    "    # Save the model\n",
    "    save_name = os.path.join(args.training.save_model_path, f\"cifar10_{accumulated_model.__class__.__name__}_dim{hidden_dim}_single.pth\")\n",
    "    torch.save(accumulated_model.state_dict(),save_name)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test using model {args.model}: hidden_dim {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Define the directory and filename structure\n",
    "    filename = f\"cifar10_results_{args.experiment.name}.txt\"\n",
    "    filepath = os.path.join(args.training.save_model_path, filename)\n",
    "\n",
    "    # Write the results. 'a' is used to append the results; a new file will be created if it doesn't exist.\n",
    "    with open(filepath, \"a\") as file:\n",
    "        file.write(f\"Hidden_dim: {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
