{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4faf3c9",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7f334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e39782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe9dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_model_cifar10 as create_model\n",
    "from neumeta.utils import (\n",
    "    parse_args, print_omegaconf,\n",
    "    load_checkpoint, save_checkpoint,\n",
    "    set_seed,\n",
    "    get_cifar10, \n",
    "    sample_coordinates, sample_subset, shuffle_coordinates_all,\n",
    "    get_hypernetwork, get_optimizer, \n",
    "    sample_weights,\n",
    "    weighted_regression_loss, validate_single, AverageMeter, EMA,\n",
    "    sample_single_model, sample_merge_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cea0a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad05e8",
   "metadata": {},
   "source": [
    "### 1 Find maximum dimension of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504abeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dim(model_cls):\n",
    "    \"\"\"Find maximum dimension of the model\"\"\"\n",
    "    # Get the learnable parameters of the model\n",
    "    checkpoint = model_cls.learnable_parameter \n",
    "\n",
    "    # Set the maximum value to the length of the checkpoint\n",
    "    max_value = len(checkpoint)\n",
    "\n",
    "    # Iterate over the new model's weight\n",
    "    for i, (k, tensor) in enumerate(checkpoint.items()):\n",
    "        # Handle 2D tensors (e.g., weight matrices) \n",
    "        if len(tensor.shape) == 4:\n",
    "            coords = [tensor.shape[0], tensor.shape[1]]\n",
    "            max_value = max(max_value, max(coords))\n",
    "        # Handle 1D tensors (e.g., biases)\n",
    "        elif len(tensor.shape) == 1:\n",
    "            max_value = max(max_value, tensor.shape[0])\n",
    "    \n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413443e",
   "metadata": {},
   "source": [
    "### 2 Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f49acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(config):\n",
    "    import time\n",
    "    \"\"\"\n",
    "    Initializes Weights and Biases (wandb) with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        configuration (dict): Configuration parameters for the run.\n",
    "    \"\"\"\n",
    "    # Name the run using current time and configuration name\n",
    "    run_name = f\"{time.strftime('%Y%m%d%H%M%S')}-{config.experiment.name}\"\n",
    "    \n",
    "    wandb.init(project=\"ninr-trial\", name=run_name, config=dict(config), group='cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cc73b",
   "metadata": {},
   "source": [
    "### 3 Initialize model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed520bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(args, device):\n",
    "    \"\"\"\n",
    "    Initializes a dictionary of models for each dimension in the given range, along with ground truth models for the starting dimension.\n",
    "\n",
    "    Args:\n",
    "        args: An object containing the arguments for initializing the models.\n",
    "\n",
    "    Returns:\n",
    "        dim_dict: A dictionary containing the models for each dimension, along with their corresponding coordinates, keys, indices, size, and ground truth models.\n",
    "        gt_model_dict: A dictionary containing the ground truth models for the starting dimension.\n",
    "    \"\"\"\n",
    "    dim_dict = {}\n",
    "    gt_model_dict = {}\n",
    "    \n",
    "    # Create a model for each dimension in dimensions range\n",
    "    for dim in args.dimensions.range:\n",
    "        model_cls = create_model(args.model.type,\n",
    "                                 hidden_dim=dim,\n",
    "                                 path=args.model.pretrained_path,\n",
    "                                 smooth=args.model.smooth).to(device)\n",
    "        # Sample the coordinates, keys, indices, and the size for the model\n",
    "        coords_tensor, keys_list, indices_list, size_list = sample_coordinates(model_cls)\n",
    "        # Add the model, coordinates, keys, indices, size, and key mask to the dictionary\n",
    "        dim_dict[f\"{dim}\"] = (model_cls, coords_tensor, keys_list, indices_list, size_list, None)\n",
    "\n",
    "        # Print to makes line better\n",
    "        print('\\n')\n",
    "\n",
    "        # If the dimension is the starting dimension (the dimension of pretrained_model), add the ground truth model to the dictionary\n",
    "        if dim == args.dimensions.start:\n",
    "            print(f\"Loading model for dim {dim}\")\n",
    "            model_trained = create_model(args.model.type, \n",
    "                                         hidden_dim=dim, \n",
    "                                         path=args.model.pretrained_path, \n",
    "                                         smooth=args.model.smooth).to(device)\n",
    "            model_trained.eval()\n",
    "            gt_model_dict[f'{dim}'] = model_trained\n",
    "    \n",
    "    return dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b8aa0",
   "metadata": {},
   "source": [
    "### 4 Training function for target model of a random dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab93eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, dim_dict, gt_model_dict, epoch_idx, ema=None, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    reconstruct_losses = AverageMeter()\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Preprocess input\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Move the data to the device\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # Choose a random hidden dimension\n",
    "        hidden_dim = random.choice(args.dimensions.range)\n",
    "        # Get the model class, coordinates, keys, indices, size, and key mask for the chosen dimension\n",
    "        model_cls, coords_tensor, keys_list, indices_list, size_list, key_mask = dim_dict[f\"{hidden_dim}\"]\n",
    "        # Sample a subset the input tensor of the coordinates, keys, indices, size, and selected keys\n",
    "        coords_tensor, keys_list, indices_list, size_list, selected_keys = sample_subset(coords_tensor,\n",
    "                                                                                         keys_list,\n",
    "                                                                                         indices_list,\n",
    "                                                                                         size_list,\n",
    "                                                                                         key_mask,\n",
    "                                                                                         ratio=args.ratio)\n",
    "        # Add noise to the coordinates if specified\n",
    "        if args.training.coordinate_noise > 0.0:\n",
    "            coords_tensor = coords_tensor + (torch.rand_like(coords_tensor) - 0.5) * args.training.coordinate_noise\n",
    "\n",
    "\n",
    "        # Main task of hypernetwork and target network\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Sample the weights for the target model using hypernetwork\n",
    "        model_cls, reconstructed_weights = sample_weights(model, model_cls,\n",
    "                                                          coords_tensor, keys_list, indices_list, size_list, key_mask, selected_keys,\n",
    "                                                          device=device, NORM=args.dimensions.norm)\n",
    "        # Forward pass\n",
    "        predict = model_cls(x)\n",
    "\n",
    "\n",
    "        # Compute losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Compute classification loss\n",
    "        cls_loss = criterion(predict, target) \n",
    "        # Compute regularization loss\n",
    "        reg_loss = sum([torch.norm(w, p=2) for w in reconstructed_weights])\n",
    "        # Compute reconstruction loss if ground truth model is available\n",
    "        if f\"{hidden_dim}\" in gt_model_dict:\n",
    "            gt_model = gt_model_dict[f\"{hidden_dim}\"]\n",
    "            gt_selected_weights = [\n",
    "                w for k, w in gt_model.learnable_parameter.items() if k in selected_keys]\n",
    "\n",
    "            reconstruct_loss = weighted_regression_loss(\n",
    "                reconstructed_weights, gt_selected_weights)\n",
    "        else:\n",
    "            reconstruct_loss = torch.tensor(0.0)\n",
    "        # Compute the total loss\n",
    "        loss = args.hyper_model.loss_weight.ce_weight * cls_loss + args.hyper_model.loss_weight.reg_weight * \\\n",
    "            reg_loss + args.hyper_model.loss_weight.recon_weight * reconstruct_loss\n",
    "\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Zero the gradients of the updated weights\n",
    "        for updated_weight in model_cls.parameters():\n",
    "            updated_weight.grad = None\n",
    "\n",
    "        # Compute the gradients of the reconstructed weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.autograd.backward(reconstructed_weights, [\n",
    "                                w.grad for k, w in model_cls.named_parameters() if k in selected_keys])\n",
    "        \n",
    "        # Clip the gradients if specified\n",
    "        if args.training.get('clip_grad', 0.0) > 0:\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), args.training.clip_grad)\n",
    "            \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA if specified\n",
    "        if ema:\n",
    "            ema.update()  # Update the EMA after each training step\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update the AverageMeter objects\n",
    "        losses.update(loss.item())\n",
    "        cls_losses.update(cls_loss.item())\n",
    "        reg_losses.update(reg_loss.item())\n",
    "        reconstruct_losses.update(reconstruct_loss.item())\n",
    "\n",
    "\n",
    "        # Log (or plot) losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Log the losses and learning rate to wandb\n",
    "        if batch_idx % args.experiment.log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"Loss\": losses.avg,\n",
    "                \"Cls Loss\": cls_losses.avg,\n",
    "                \"Reg Loss\": reg_losses.avg,\n",
    "                \"Reconstruct Loss\": reconstruct_losses.avg,\n",
    "                \"Learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }, step=batch_idx + epoch_idx * len(train_loader))\n",
    "            # Print the losses and learning rate\n",
    "            print(\n",
    "                f\"Iteration {batch_idx}: Loss = {losses.avg:.4f}, Reg Loss = {reg_losses.avg:.4f}, Reconstruct Loss = {reconstruct_losses.avg:.4f}, Cls Loss = {cls_losses.avg:.4f}, Learning rate = {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "    \n",
    "    # Returns the training loss, structure of network in each dimension, and the original structure of pretrained network\n",
    "    return losses.avg, dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d8965",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e292aae",
   "metadata": {},
   "source": [
    "### 0 Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670c10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd9af3",
   "metadata": {},
   "source": [
    "### 1 Parsing arguments for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21d5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = 'neumeta/config/base_config_smooth.yaml'\n",
    "RATIO = '1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6fd9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv_train = ['--config', CONFIG_PATH, '--ratio', RATIO]\n",
    "argv_test = ['--config', CONFIG_PATH, '--test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebf601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                 Key                  |                                                                Value                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|           experiment.name            |                                       ninr_resnet20_cifar10_32-64-4layer-5_base_config_smooth                                        |\n",
      "|         experiment.recononly         |                                                                  0                                                                   |\n",
      "|        experiment.num_epochs         |                                                                  30                                                                  |\n",
      "|       experiment.log_interval        |                                                                  25                                                                  |\n",
      "|       experiment.eval_interval       |                                                                  1                                                                   |\n",
      "|           experiment.seed            |                                                                  42                                                                  |\n",
      "|              model.type              |                                                               ResNet20                                                               |\n",
      "|        model.pretrained_path         |                                                         resnet20-12fca82f.th                                                         |\n",
      "|             model.smooth             |                                                                 True                                                                 |\n",
      "|        training.learning_rate        |                                                                0.001                                                                 |\n",
      "|         training.batch_size          |                                                                  64                                                                  |\n",
      "|      training.coordinate_noise       |                                                                 0.0                                                                  |\n",
      "|          training.lr_steps           |                                                              [100, 150]                                                              |\n",
      "|        training.weight_decay         |                                                                 0.01                                                                 |\n",
      "|          training.clip_grad          |                                                                 10.0                                                                 |\n",
      "|       training.save_model_path       |                                  toy/experiments/resnet20_cifar10_32-64-4layer-5_base_config_smooth                                  |\n",
      "|        hyper_model.input_dim         |                                                                  6                                                                   |\n",
      "|        hyper_model.hidden_dim        |                                                                 256                                                                  |\n",
      "|        hyper_model.num_layers        |                                                                  4                                                                   |\n",
      "|        hyper_model.num_freqs         |                                                                  16                                                                  |\n",
      "|        hyper_model.output_dim        |                                                                  9                                                                   |\n",
      "|        hyper_model.ema_decay         |                                                                0.995                                                                 |\n",
      "|  hyper_model.loss_weight.ce_weight   |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.reg_weight  |                                                                0.0001                                                                |\n",
      "| hyper_model.loss_weight.recon_weight |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.kd_weight   |                                                                 0.1                                                                  |\n",
      "|           dimensions.range           | [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64] |\n",
      "|           dimensions.test            |                                                                  32                                                                  |\n",
      "|           dimensions.norm            |                                                                  64                                                                  |\n",
      "|           dimensions.start           |                                                                  64                                                                  |\n",
      "|                config                |                                                neumeta/config/base_config_smooth.yaml                                                |\n",
      "|                ratio                 |                                                                 1.0                                                                  |\n",
      "|             resume_from              |                                                                 None                                                                 |\n",
      "|              load_from               |                                                                 None                                                                 |\n",
      "|           test_result_path           |                                                                 None                                                                 |\n",
      "|                 test                 |                                                                False                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(argv_train)  # Parse arguments\n",
    "print_omegaconf(args)  # Print arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2086b8",
   "metadata": {},
   "source": [
    "### 2 Get training and validation data (in dataloader format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "633b90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10(args.training.batch_size, strong_transform=args.training.get('strong_aug', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685e32a",
   "metadata": {},
   "source": [
    "### 3 Create target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d8f75",
   "metadata": {},
   "source": [
    "#### 3.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47436d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1321.4044189453125\n",
      "Permuted TV original model: 1037.066162109375\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args.model.type,\n",
    "                     hidden_dim=args.dimensions.start,\n",
    "                     path=args.model.pretrained_path,\n",
    "                     smooth=args.model.smooth).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb133f",
   "metadata": {},
   "source": [
    "#### 3.1 Print the structure and shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c09f9614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): Identity()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock_Resize(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b86d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3.2.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv1.bias torch.Size([64])\n",
      "layer3.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, (k, tensor) in enumerate(model.learnable_parameter.items()):\n",
    "    print(k, tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f7b45",
   "metadata": {},
   "source": [
    "#### 3.2 The maximum dimension of the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad8c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum DIM: 64\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum dimension of the model\n",
    "print(f'Maximum DIM: {find_max_dim(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195929e",
   "metadata": {},
   "source": [
    "#### 3.3 Validate the accuracy of pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d75f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.2825, Validation Accuracy: 92.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(model, val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb61dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learnable parameters of the model\n",
    "checkpoint = model.learnable_parameter\n",
    "# Get the number of parameters\n",
    "number_param = len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b2fe99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters keys: ['layer3.2.conv1.weight', 'layer3.2.conv1.bias', 'layer3.2.conv2.weight', 'layer3.2.conv2.bias']\n",
      "Number of parameters to be learned: 4\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the parameters and the number of parameters\n",
    "print(f\"Parameters keys: {model.keys}\")\n",
    "print(f\"Number of parameters to be learned: {number_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5fa6f",
   "metadata": {},
   "source": [
    "### 4 Create the hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa4a2f",
   "metadata": {},
   "source": [
    "#### 4.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a82e9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: mlp\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Get the hypermodel\n",
    "hyper_model = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297bd73",
   "metadata": {},
   "source": [
    "#### 4.1 Print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903829b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_MLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-3): 4 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d592e",
   "metadata": {},
   "source": [
    "#### 4.2 Initialize EMA to track only a smooth version of the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a4812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA\n",
    "ema = EMA(hyper_model, decay=args.hyper_model.ema_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffae0",
   "metadata": {},
   "source": [
    "### 5 Get Loss function, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "079aa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, val_criterion, optimizer, scheduler = get_optimizer(args, hyper_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7561c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Val_criterion: CrossEntropyLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x00000223089B7F90>\n"
     ]
    }
   ],
   "source": [
    "print(f'Criterion: {criterion}\\nVal_criterion: {val_criterion}\\nOptimizer: {optimizer}\\nScheduler: {scheduler}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906454",
   "metadata": {},
   "source": [
    "### 6 Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d1d4f",
   "metadata": {},
   "source": [
    "#### 6.1 Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2cdca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting epoch and best accuracy\n",
    "start_epoch = 0\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373217",
   "metadata": {},
   "source": [
    "#### 6.2 Directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35a2746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the model\n",
    "os.makedirs(args.training.save_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504af23",
   "metadata": {},
   "source": [
    "#### 6.3 Resume training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "714db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_from:\n",
    "        print(f\"Resuming from checkpoint: {args.resume_from}\")\n",
    "        checkpoint_info = load_checkpoint(args.resume_from, hyper_model, optimizer, ema)\n",
    "        start_epoch = checkpoint_info['epoch']\n",
    "        best_acc = checkpoint_info['best_acc']\n",
    "        print(f\"Resuming from epoch: {start_epoch}, best accuracy: {best_acc*100:.2f}%\")\n",
    "        # Note: If there are more elements to retrieve, do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a3248",
   "metadata": {},
   "source": [
    "#### 6.4 Initialize wandb for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d9fd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mefradosuryadi\u001b[0m (\u001b[33mefradosuryadi-universitas-indonesia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\wandb\\run-20250517_231104-1l8yq1fk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/1l8yq1fk' target=\"_blank\">20250517231104-ninr_resnet20_cifar10_32-64-4layer-5_base_config_smooth</a></strong> to <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/1l8yq1fk' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/1l8yq1fk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "initialize_wandb(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46056e65",
   "metadata": {},
   "source": [
    "#### 6.5 Initialize model dictionary for each dimension and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "641149b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2133.03515625\n",
      "Permuted TV original model: 2031.6407470703125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2183.499755859375\n",
      "Permuted TV original model: 2066.947021484375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2239.558837890625\n",
      "Permuted TV original model: 2127.741455078125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2281.36767578125\n",
      "Permuted TV original model: 2174.0205078125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2320.63818359375\n",
      "Permuted TV original model: 2200.421630859375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2365.11083984375\n",
      "Permuted TV original model: 2246.33251953125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2411.065673828125\n",
      "Permuted TV original model: 2292.814208984375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2477.281494140625\n",
      "Permuted TV original model: 2354.703369140625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2505.2666015625\n",
      "Permuted TV original model: 2385.358154296875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2559.251708984375\n",
      "Permuted TV original model: 2433.038330078125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2584.597900390625\n",
      "Permuted TV original model: 2463.6982421875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2652.858154296875\n",
      "Permuted TV original model: 2514.36181640625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2701.496337890625\n",
      "Permuted TV original model: 2570.844970703125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2745.886474609375\n",
      "Permuted TV original model: 2612.671630859375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2794.147705078125\n",
      "Permuted TV original model: 2661.843505859375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2843.777587890625\n",
      "Permuted TV original model: 2705.19580078125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2881.433837890625\n",
      "Permuted TV original model: 2745.91796875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2920.102294921875\n",
      "Permuted TV original model: 2783.86474609375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2971.48046875\n",
      "Permuted TV original model: 2830.65966796875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3025.184326171875\n",
      "Permuted TV original model: 2890.646728515625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3078.677490234375\n",
      "Permuted TV original model: 2933.804443359375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3107.453125\n",
      "Permuted TV original model: 2953.649169921875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3163.338134765625\n",
      "Permuted TV original model: 3014.047119140625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3200.6396484375\n",
      "Permuted TV original model: 3045.364013671875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3231.0712890625\n",
      "Permuted TV original model: 3082.00927734375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3280.92431640625\n",
      "Permuted TV original model: 3134.151611328125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3333.243896484375\n",
      "Permuted TV original model: 3183.572021484375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3379.14599609375\n",
      "Permuted TV original model: 3216.4619140625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3451.649169921875\n",
      "Permuted TV original model: 3279.4365234375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3477.70703125\n",
      "Permuted TV original model: 3324.342041015625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3508.17578125\n",
      "Permuted TV original model: 3353.892333984375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3571.388916015625\n",
      "Permuted TV original model: 3392.38818359375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1321.4044189453125\n",
      "Permuted TV original model: 1039.670166015625\n",
      "Loading model for dim 64\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1321.4044189453125\n",
      "Permuted TV original model: 1037.3778076171875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model dictionary\n",
    "dim_dict, gt_model_dict = init_model_dict(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d01d9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'64': CifarResNet(\n",
       "   (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn1): Identity()\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock_Resize(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26d9c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7476d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])})}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict = shuffle_coordinates_all(dim_dict)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d6ad4",
   "metadata": {},
   "source": [
    "#### 6.6 Hypernetwork training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "332580b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.experiment.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4f486f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 1.8501, Reg Loss = 3.1455, Reconstruct Loss = 0.0000, Cls Loss = 1.8498, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8642, Reg Loss = 9.2296, Reconstruct Loss = 0.0011, Cls Loss = 1.8621, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8521, Reg Loss = 9.6634, Reconstruct Loss = 0.0006, Cls Loss = 1.8506, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8494, Reg Loss = 12.2275, Reconstruct Loss = 0.0004, Cls Loss = 1.8478, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8501, Reg Loss = 12.0175, Reconstruct Loss = 0.0003, Cls Loss = 1.8486, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8488, Reg Loss = 10.3947, Reconstruct Loss = 0.0006, Cls Loss = 1.8472, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8493, Reg Loss = 9.9245, Reconstruct Loss = 0.0011, Cls Loss = 1.8472, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8497, Reg Loss = 10.5473, Reconstruct Loss = 0.0009, Cls Loss = 1.8477, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8500, Reg Loss = 10.5343, Reconstruct Loss = 0.0024, Cls Loss = 1.8465, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8513, Reg Loss = 10.8342, Reconstruct Loss = 0.0021, Cls Loss = 1.8481, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8518, Reg Loss = 10.8400, Reconstruct Loss = 0.0019, Cls Loss = 1.8488, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8524, Reg Loss = 10.5930, Reconstruct Loss = 0.0022, Cls Loss = 1.8492, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8524, Reg Loss = 11.1682, Reconstruct Loss = 0.0025, Cls Loss = 1.8489, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8519, Reg Loss = 11.6016, Reconstruct Loss = 0.0028, Cls Loss = 1.8479, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8518, Reg Loss = 11.7263, Reconstruct Loss = 0.0028, Cls Loss = 1.8478, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8509, Reg Loss = 11.4980, Reconstruct Loss = 0.0026, Cls Loss = 1.8472, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8510, Reg Loss = 11.3104, Reconstruct Loss = 0.0025, Cls Loss = 1.8474, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8498, Reg Loss = 11.4329, Reconstruct Loss = 0.0024, Cls Loss = 1.8463, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8498, Reg Loss = 11.4054, Reconstruct Loss = 0.0023, Cls Loss = 1.8463, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8493, Reg Loss = 11.2750, Reconstruct Loss = 0.0022, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8483, Reg Loss = 11.0262, Reconstruct Loss = 0.0021, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8477, Reg Loss = 11.4736, Reconstruct Loss = 0.0020, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8474, Reg Loss = 11.8483, Reconstruct Loss = 0.0019, Cls Loss = 1.8443, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8475, Reg Loss = 12.0244, Reconstruct Loss = 0.0020, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8471, Reg Loss = 12.0122, Reconstruct Loss = 0.0020, Cls Loss = 1.8440, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8475, Reg Loss = 11.8445, Reconstruct Loss = 0.0019, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8474, Reg Loss = 11.5808, Reconstruct Loss = 0.0018, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8474, Reg Loss = 11.3829, Reconstruct Loss = 0.0017, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8474, Reg Loss = 11.3079, Reconstruct Loss = 0.0017, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8471, Reg Loss = 11.1617, Reconstruct Loss = 0.0017, Cls Loss = 1.8443, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8469, Reg Loss = 10.9410, Reconstruct Loss = 0.0016, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8468, Reg Loss = 10.8059, Reconstruct Loss = 0.0016, Cls Loss = 1.8440, Learning rate = 1.0000e-03\n",
      "Epoch [1/30], Training Loss: 1.8466, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Validation Loss: 1.8070, Validation Accuracy: 76.28%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 0 with accuracy: 76.28%\n",
      "Iteration 0: Loss = 1.8105, Reg Loss = 7.4961, Reconstruct Loss = 0.0000, Cls Loss = 1.8098, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8443, Reg Loss = 7.1957, Reconstruct Loss = 0.0017, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8434, Reg Loss = 6.3756, Reconstruct Loss = 0.0016, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8455, Reg Loss = 5.2927, Reconstruct Loss = 0.0016, Cls Loss = 1.8434, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8433, Reg Loss = 4.5854, Reconstruct Loss = 0.0015, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8434, Reg Loss = 4.5724, Reconstruct Loss = 0.0015, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8435, Reg Loss = 7.5027, Reconstruct Loss = 0.0012, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8436, Reg Loss = 9.3649, Reconstruct Loss = 0.0014, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8424, Reg Loss = 9.8418, Reconstruct Loss = 0.0012, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8437, Reg Loss = 9.7526, Reconstruct Loss = 0.0011, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8439, Reg Loss = 9.3031, Reconstruct Loss = 0.0010, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8442, Reg Loss = 8.9660, Reconstruct Loss = 0.0010, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8450, Reg Loss = 9.9336, Reconstruct Loss = 0.0014, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8449, Reg Loss = 10.4730, Reconstruct Loss = 0.0014, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8453, Reg Loss = 10.6917, Reconstruct Loss = 0.0014, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8440, Reg Loss = 10.6532, Reconstruct Loss = 0.0013, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8436, Reg Loss = 10.4886, Reconstruct Loss = 0.0012, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8430, Reg Loss = 10.2257, Reconstruct Loss = 0.0013, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8428, Reg Loss = 9.8689, Reconstruct Loss = 0.0013, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8426, Reg Loss = 9.4509, Reconstruct Loss = 0.0013, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8429, Reg Loss = 9.7698, Reconstruct Loss = 0.0015, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8430, Reg Loss = 10.1981, Reconstruct Loss = 0.0015, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8433, Reg Loss = 10.4894, Reconstruct Loss = 0.0017, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8437, Reg Loss = 10.6026, Reconstruct Loss = 0.0017, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8436, Reg Loss = 10.5716, Reconstruct Loss = 0.0016, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8436, Reg Loss = 10.4931, Reconstruct Loss = 0.0016, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8437, Reg Loss = 10.3501, Reconstruct Loss = 0.0016, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8435, Reg Loss = 10.1959, Reconstruct Loss = 0.0017, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8436, Reg Loss = 10.3787, Reconstruct Loss = 0.0017, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8435, Reg Loss = 10.4524, Reconstruct Loss = 0.0016, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8435, Reg Loss = 10.4753, Reconstruct Loss = 0.0017, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8434, Reg Loss = 10.5234, Reconstruct Loss = 0.0017, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Epoch [2/30], Training Loss: 1.8433, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 83.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Validation Loss: 1.8078, Validation Accuracy: 75.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7892, Reg Loss = 9.2507, Reconstruct Loss = 0.0000, Cls Loss = 1.7883, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8471, Reg Loss = 6.6154, Reconstruct Loss = 0.0014, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8483, Reg Loss = 6.6521, Reconstruct Loss = 0.0014, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8475, Reg Loss = 6.1846, Reconstruct Loss = 0.0014, Cls Loss = 1.8454, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8469, Reg Loss = 7.4288, Reconstruct Loss = 0.0014, Cls Loss = 1.8447, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8467, Reg Loss = 11.3578, Reconstruct Loss = 0.0018, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8447, Reg Loss = 12.8266, Reconstruct Loss = 0.0015, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8446, Reg Loss = 13.5302, Reconstruct Loss = 0.0018, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8443, Reg Loss = 13.9558, Reconstruct Loss = 0.0016, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8435, Reg Loss = 13.8506, Reconstruct Loss = 0.0016, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8435, Reg Loss = 13.1531, Reconstruct Loss = 0.0016, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8437, Reg Loss = 14.1611, Reconstruct Loss = 0.0014, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8438, Reg Loss = 17.6671, Reconstruct Loss = 0.0013, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8449, Reg Loss = 20.3860, Reconstruct Loss = 0.0022, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8450, Reg Loss = 21.3665, Reconstruct Loss = 0.0021, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8449, Reg Loss = 21.2746, Reconstruct Loss = 0.0020, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8451, Reg Loss = 20.7678, Reconstruct Loss = 0.0019, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8451, Reg Loss = 20.8605, Reconstruct Loss = 0.0019, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8448, Reg Loss = 20.5410, Reconstruct Loss = 0.0018, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8449, Reg Loss = 20.8763, Reconstruct Loss = 0.0017, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8453, Reg Loss = 22.3586, Reconstruct Loss = 0.0018, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8457, Reg Loss = 23.4179, Reconstruct Loss = 0.0020, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8460, Reg Loss = 23.8481, Reconstruct Loss = 0.0019, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8457, Reg Loss = 24.0252, Reconstruct Loss = 0.0019, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8458, Reg Loss = 24.0060, Reconstruct Loss = 0.0019, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8455, Reg Loss = 23.8053, Reconstruct Loss = 0.0018, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8448, Reg Loss = 23.4451, Reconstruct Loss = 0.0018, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8447, Reg Loss = 22.9877, Reconstruct Loss = 0.0018, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8447, Reg Loss = 22.4043, Reconstruct Loss = 0.0017, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8447, Reg Loss = 22.2704, Reconstruct Loss = 0.0017, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8447, Reg Loss = 22.8798, Reconstruct Loss = 0.0017, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8444, Reg Loss = 23.3006, Reconstruct Loss = 0.0017, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Epoch [3/30], Training Loss: 1.8444, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Validation Loss: 1.8076, Validation Accuracy: 75.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7898, Reg Loss = 33.1086, Reconstruct Loss = 0.0000, Cls Loss = 1.7865, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8375, Reg Loss = 30.5041, Reconstruct Loss = 0.0042, Cls Loss = 1.8302, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8393, Reg Loss = 27.8545, Reconstruct Loss = 0.0021, Cls Loss = 1.8343, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8398, Reg Loss = 25.4473, Reconstruct Loss = 0.0014, Cls Loss = 1.8358, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8426, Reg Loss = 23.1004, Reconstruct Loss = 0.0018, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8429, Reg Loss = 20.5404, Reconstruct Loss = 0.0015, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8420, Reg Loss = 19.3872, Reconstruct Loss = 0.0015, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8412, Reg Loss = 21.2615, Reconstruct Loss = 0.0012, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8418, Reg Loss = 22.2279, Reconstruct Loss = 0.0013, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8424, Reg Loss = 22.4366, Reconstruct Loss = 0.0013, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8425, Reg Loss = 22.0508, Reconstruct Loss = 0.0012, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8426, Reg Loss = 21.4244, Reconstruct Loss = 0.0013, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8430, Reg Loss = 20.5831, Reconstruct Loss = 0.0013, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8432, Reg Loss = 19.9823, Reconstruct Loss = 0.0012, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8434, Reg Loss = 19.2248, Reconstruct Loss = 0.0012, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8432, Reg Loss = 18.4461, Reconstruct Loss = 0.0013, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8432, Reg Loss = 17.6481, Reconstruct Loss = 0.0014, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8433, Reg Loss = 17.4179, Reconstruct Loss = 0.0013, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8434, Reg Loss = 17.2753, Reconstruct Loss = 0.0013, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8440, Reg Loss = 18.4225, Reconstruct Loss = 0.0012, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8456, Reg Loss = 22.1529, Reconstruct Loss = 0.0030, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8460, Reg Loss = 24.9677, Reconstruct Loss = 0.0032, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8481, Reg Loss = 27.3318, Reconstruct Loss = 0.0048, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8484, Reg Loss = 28.4744, Reconstruct Loss = 0.0049, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8482, Reg Loss = 28.1172, Reconstruct Loss = 0.0047, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8485, Reg Loss = 27.7256, Reconstruct Loss = 0.0045, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8481, Reg Loss = 27.1226, Reconstruct Loss = 0.0044, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8478, Reg Loss = 26.4037, Reconstruct Loss = 0.0042, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8482, Reg Loss = 26.2822, Reconstruct Loss = 0.0042, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8480, Reg Loss = 27.4392, Reconstruct Loss = 0.0040, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8478, Reg Loss = 28.4775, Reconstruct Loss = 0.0039, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8479, Reg Loss = 29.2096, Reconstruct Loss = 0.0038, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Epoch [4/30], Training Loss: 1.8480, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9121, Reg Loss = 47.4968, Reconstruct Loss = 0.0521, Cls Loss = 1.8552, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8516, Reg Loss = 40.9178, Reconstruct Loss = 0.0050, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8530, Reg Loss = 39.3419, Reconstruct Loss = 0.0041, Cls Loss = 1.8450, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8495, Reg Loss = 37.2122, Reconstruct Loss = 0.0037, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8488, Reg Loss = 35.2064, Reconstruct Loss = 0.0032, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8469, Reg Loss = 33.2905, Reconstruct Loss = 0.0026, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8460, Reg Loss = 31.3653, Reconstruct Loss = 0.0021, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8466, Reg Loss = 29.2805, Reconstruct Loss = 0.0023, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8453, Reg Loss = 27.1753, Reconstruct Loss = 0.0020, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8446, Reg Loss = 24.7949, Reconstruct Loss = 0.0018, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8445, Reg Loss = 23.3224, Reconstruct Loss = 0.0016, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8445, Reg Loss = 21.8456, Reconstruct Loss = 0.0016, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8452, Reg Loss = 22.6971, Reconstruct Loss = 0.0016, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8454, Reg Loss = 27.1689, Reconstruct Loss = 0.0019, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8466, Reg Loss = 30.7403, Reconstruct Loss = 0.0021, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8459, Reg Loss = 32.8989, Reconstruct Loss = 0.0020, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8463, Reg Loss = 34.3509, Reconstruct Loss = 0.0020, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8462, Reg Loss = 35.3215, Reconstruct Loss = 0.0019, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8461, Reg Loss = 36.0243, Reconstruct Loss = 0.0018, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8456, Reg Loss = 36.3721, Reconstruct Loss = 0.0017, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8452, Reg Loss = 36.6427, Reconstruct Loss = 0.0018, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8451, Reg Loss = 36.6270, Reconstruct Loss = 0.0018, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8449, Reg Loss = 36.3587, Reconstruct Loss = 0.0017, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8449, Reg Loss = 35.7196, Reconstruct Loss = 0.0017, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8450, Reg Loss = 34.6269, Reconstruct Loss = 0.0017, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8450, Reg Loss = 33.8650, Reconstruct Loss = 0.0017, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8451, Reg Loss = 32.9612, Reconstruct Loss = 0.0017, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8451, Reg Loss = 32.0530, Reconstruct Loss = 0.0017, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8453, Reg Loss = 31.2586, Reconstruct Loss = 0.0017, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8451, Reg Loss = 30.6260, Reconstruct Loss = 0.0017, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8448, Reg Loss = 29.7875, Reconstruct Loss = 0.0016, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8452, Reg Loss = 30.6875, Reconstruct Loss = 0.0016, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Epoch [5/30], Training Loss: 1.8452, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Validation Loss: 1.8076, Validation Accuracy: 75.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8610, Reg Loss = 84.4781, Reconstruct Loss = 0.0000, Cls Loss = 1.8526, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8472, Reg Loss = 84.8355, Reconstruct Loss = 0.0000, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8444, Reg Loss = 81.1760, Reconstruct Loss = 0.0000, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8473, Reg Loss = 74.8004, Reconstruct Loss = 0.0000, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8467, Reg Loss = 63.8160, Reconstruct Loss = 0.0000, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8481, Reg Loss = 53.9559, Reconstruct Loss = 0.0008, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8489, Reg Loss = 49.7305, Reconstruct Loss = 0.0014, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8481, Reg Loss = 45.9749, Reconstruct Loss = 0.0012, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8474, Reg Loss = 41.8410, Reconstruct Loss = 0.0012, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8467, Reg Loss = 39.1318, Reconstruct Loss = 0.0011, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8460, Reg Loss = 38.0803, Reconstruct Loss = 0.0011, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8552, Reg Loss = 39.4623, Reconstruct Loss = 0.0010, Cls Loss = 1.8503, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8552, Reg Loss = 50.7958, Reconstruct Loss = 0.0009, Cls Loss = 1.8492, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8589, Reg Loss = 61.4645, Reconstruct Loss = 0.0046, Cls Loss = 1.8481, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8595, Reg Loss = 69.5484, Reconstruct Loss = 0.0043, Cls Loss = 1.8483, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8591, Reg Loss = 74.3870, Reconstruct Loss = 0.0040, Cls Loss = 1.8477, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8596, Reg Loss = 74.9990, Reconstruct Loss = 0.0050, Cls Loss = 1.8471, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8599, Reg Loss = 73.3647, Reconstruct Loss = 0.0052, Cls Loss = 1.8474, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8596, Reg Loss = 72.2617, Reconstruct Loss = 0.0049, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8589, Reg Loss = 70.3793, Reconstruct Loss = 0.0046, Cls Loss = 1.8472, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8585, Reg Loss = 67.7311, Reconstruct Loss = 0.0044, Cls Loss = 1.8473, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8573, Reg Loss = 66.4363, Reconstruct Loss = 0.0042, Cls Loss = 1.8465, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8571, Reg Loss = 65.7386, Reconstruct Loss = 0.0043, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8567, Reg Loss = 63.9787, Reconstruct Loss = 0.0042, Cls Loss = 1.8461, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8563, Reg Loss = 62.8777, Reconstruct Loss = 0.0042, Cls Loss = 1.8458, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8555, Reg Loss = 62.4659, Reconstruct Loss = 0.0040, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8549, Reg Loss = 61.6124, Reconstruct Loss = 0.0039, Cls Loss = 1.8448, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8543, Reg Loss = 60.2582, Reconstruct Loss = 0.0038, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8537, Reg Loss = 58.5240, Reconstruct Loss = 0.0037, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8534, Reg Loss = 56.9914, Reconstruct Loss = 0.0036, Cls Loss = 1.8440, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8533, Reg Loss = 56.7758, Reconstruct Loss = 0.0036, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8531, Reg Loss = 56.2940, Reconstruct Loss = 0.0035, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Epoch [6/30], Training Loss: 1.8530, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Validation Loss: 1.8076, Validation Accuracy: 75.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8467, Reg Loss = 24.4092, Reconstruct Loss = 0.0000, Cls Loss = 1.8443, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8474, Reg Loss = 17.4552, Reconstruct Loss = 0.0029, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8504, Reg Loss = 32.8710, Reconstruct Loss = 0.0015, Cls Loss = 1.8456, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8565, Reg Loss = 51.4118, Reconstruct Loss = 0.0078, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8541, Reg Loss = 57.4073, Reconstruct Loss = 0.0070, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8532, Reg Loss = 58.9277, Reconstruct Loss = 0.0061, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8521, Reg Loss = 58.0102, Reconstruct Loss = 0.0051, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8505, Reg Loss = 56.2028, Reconstruct Loss = 0.0044, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8498, Reg Loss = 53.4875, Reconstruct Loss = 0.0038, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8496, Reg Loss = 50.5371, Reconstruct Loss = 0.0036, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8492, Reg Loss = 47.1616, Reconstruct Loss = 0.0039, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8483, Reg Loss = 44.0147, Reconstruct Loss = 0.0036, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8473, Reg Loss = 41.6053, Reconstruct Loss = 0.0033, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8468, Reg Loss = 39.1299, Reconstruct Loss = 0.0034, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8460, Reg Loss = 36.9494, Reconstruct Loss = 0.0032, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8463, Reg Loss = 35.2318, Reconstruct Loss = 0.0031, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8482, Reg Loss = 37.6515, Reconstruct Loss = 0.0034, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8487, Reg Loss = 43.0944, Reconstruct Loss = 0.0032, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8489, Reg Loss = 47.6269, Reconstruct Loss = 0.0034, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8496, Reg Loss = 51.2586, Reconstruct Loss = 0.0032, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8496, Reg Loss = 54.1247, Reconstruct Loss = 0.0033, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8494, Reg Loss = 55.8903, Reconstruct Loss = 0.0031, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8494, Reg Loss = 56.1732, Reconstruct Loss = 0.0032, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8497, Reg Loss = 56.4504, Reconstruct Loss = 0.0032, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8500, Reg Loss = 56.2154, Reconstruct Loss = 0.0031, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8498, Reg Loss = 59.0603, Reconstruct Loss = 0.0029, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8503, Reg Loss = 62.5543, Reconstruct Loss = 0.0028, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8510, Reg Loss = 65.4704, Reconstruct Loss = 0.0031, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8515, Reg Loss = 67.5979, Reconstruct Loss = 0.0029, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8516, Reg Loss = 68.5577, Reconstruct Loss = 0.0029, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8516, Reg Loss = 68.7463, Reconstruct Loss = 0.0028, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8514, Reg Loss = 70.5773, Reconstruct Loss = 0.0029, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Epoch [7/30], Training Loss: 1.8515, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8280, Reg Loss = 129.1657, Reconstruct Loss = 0.0000, Cls Loss = 1.8151, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8471, Reg Loss = 120.1233, Reconstruct Loss = 0.0000, Cls Loss = 1.8351, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8501, Reg Loss = 114.7811, Reconstruct Loss = 0.0000, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8477, Reg Loss = 108.5095, Reconstruct Loss = 0.0000, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8497, Reg Loss = 100.3353, Reconstruct Loss = 0.0006, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8489, Reg Loss = 95.4408, Reconstruct Loss = 0.0009, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8500, Reg Loss = 100.8392, Reconstruct Loss = 0.0007, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8520, Reg Loss = 104.1491, Reconstruct Loss = 0.0014, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8522, Reg Loss = 105.0584, Reconstruct Loss = 0.0017, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8524, Reg Loss = 104.1845, Reconstruct Loss = 0.0017, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8522, Reg Loss = 101.4898, Reconstruct Loss = 0.0015, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8537, Reg Loss = 97.2354, Reconstruct Loss = 0.0015, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8531, Reg Loss = 94.5688, Reconstruct Loss = 0.0015, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8528, Reg Loss = 91.0392, Reconstruct Loss = 0.0015, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8522, Reg Loss = 88.2011, Reconstruct Loss = 0.0014, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8517, Reg Loss = 86.3172, Reconstruct Loss = 0.0014, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8515, Reg Loss = 91.2807, Reconstruct Loss = 0.0013, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8518, Reg Loss = 96.3406, Reconstruct Loss = 0.0012, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8523, Reg Loss = 98.8983, Reconstruct Loss = 0.0012, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8524, Reg Loss = 97.5995, Reconstruct Loss = 0.0013, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8529, Reg Loss = 98.2453, Reconstruct Loss = 0.0017, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8529, Reg Loss = 98.6907, Reconstruct Loss = 0.0018, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8530, Reg Loss = 98.1700, Reconstruct Loss = 0.0018, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8522, Reg Loss = 96.4450, Reconstruct Loss = 0.0017, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8522, Reg Loss = 95.5725, Reconstruct Loss = 0.0017, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8525, Reg Loss = 94.8768, Reconstruct Loss = 0.0018, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8527, Reg Loss = 93.4409, Reconstruct Loss = 0.0019, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8525, Reg Loss = 92.2928, Reconstruct Loss = 0.0018, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8529, Reg Loss = 93.1157, Reconstruct Loss = 0.0018, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8528, Reg Loss = 93.6707, Reconstruct Loss = 0.0018, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8527, Reg Loss = 93.8120, Reconstruct Loss = 0.0018, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8527, Reg Loss = 93.3593, Reconstruct Loss = 0.0018, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Epoch [8/30], Training Loss: 1.8524, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8026, Reg Loss = 67.5658, Reconstruct Loss = 0.0000, Cls Loss = 1.7958, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8517, Reg Loss = 55.5490, Reconstruct Loss = 0.0000, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8516, Reg Loss = 49.9514, Reconstruct Loss = 0.0000, Cls Loss = 1.8466, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8521, Reg Loss = 93.7240, Reconstruct Loss = 0.0000, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8580, Reg Loss = 123.5782, Reconstruct Loss = 0.0019, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8597, Reg Loss = 141.1183, Reconstruct Loss = 0.0029, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8594, Reg Loss = 149.1696, Reconstruct Loss = 0.0034, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8602, Reg Loss = 153.0794, Reconstruct Loss = 0.0034, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8605, Reg Loss = 153.5160, Reconstruct Loss = 0.0030, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8601, Reg Loss = 152.3351, Reconstruct Loss = 0.0026, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8596, Reg Loss = 149.6980, Reconstruct Loss = 0.0024, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8581, Reg Loss = 141.7045, Reconstruct Loss = 0.0025, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8576, Reg Loss = 139.0695, Reconstruct Loss = 0.0023, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8563, Reg Loss = 137.0477, Reconstruct Loss = 0.0022, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8567, Reg Loss = 133.4295, Reconstruct Loss = 0.0022, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8564, Reg Loss = 129.0724, Reconstruct Loss = 0.0021, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8555, Reg Loss = 123.9607, Reconstruct Loss = 0.0020, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8542, Reg Loss = 118.2071, Reconstruct Loss = 0.0020, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8538, Reg Loss = 112.7492, Reconstruct Loss = 0.0019, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8532, Reg Loss = 109.0863, Reconstruct Loss = 0.0019, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8537, Reg Loss = 107.1145, Reconstruct Loss = 0.0019, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8531, Reg Loss = 104.1290, Reconstruct Loss = 0.0018, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8522, Reg Loss = 100.3672, Reconstruct Loss = 0.0018, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8521, Reg Loss = 96.8295, Reconstruct Loss = 0.0018, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8525, Reg Loss = 99.9722, Reconstruct Loss = 0.0018, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8526, Reg Loss = 103.8039, Reconstruct Loss = 0.0018, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8535, Reg Loss = 106.2520, Reconstruct Loss = 0.0021, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8534, Reg Loss = 106.8170, Reconstruct Loss = 0.0022, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8535, Reg Loss = 104.8823, Reconstruct Loss = 0.0023, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8534, Reg Loss = 105.5101, Reconstruct Loss = 0.0022, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8536, Reg Loss = 106.0999, Reconstruct Loss = 0.0021, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8535, Reg Loss = 105.0878, Reconstruct Loss = 0.0021, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Epoch [9/30], Training Loss: 1.8533, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Validation Loss: 1.8076, Validation Accuracy: 75.84%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8308, Reg Loss = 30.7504, Reconstruct Loss = 0.0000, Cls Loss = 1.8277, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8727, Reg Loss = 187.4332, Reconstruct Loss = 0.0043, Cls Loss = 1.8496, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8713, Reg Loss = 214.7057, Reconstruct Loss = 0.0022, Cls Loss = 1.8476, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8693, Reg Loss = 205.6198, Reconstruct Loss = 0.0015, Cls Loss = 1.8473, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8653, Reg Loss = 182.0726, Reconstruct Loss = 0.0011, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8614, Reg Loss = 154.9311, Reconstruct Loss = 0.0018, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8602, Reg Loss = 138.6457, Reconstruct Loss = 0.0018, Cls Loss = 1.8446, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8594, Reg Loss = 132.3740, Reconstruct Loss = 0.0020, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8585, Reg Loss = 123.3531, Reconstruct Loss = 0.0018, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8578, Reg Loss = 122.9350, Reconstruct Loss = 0.0017, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8583, Reg Loss = 137.6440, Reconstruct Loss = 0.0020, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8599, Reg Loss = 145.2548, Reconstruct Loss = 0.0021, Cls Loss = 1.8433, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8602, Reg Loss = 146.2280, Reconstruct Loss = 0.0019, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8597, Reg Loss = 142.6499, Reconstruct Loss = 0.0018, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8584, Reg Loss = 136.1741, Reconstruct Loss = 0.0018, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8565, Reg Loss = 128.2739, Reconstruct Loss = 0.0017, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8561, Reg Loss = 124.0011, Reconstruct Loss = 0.0017, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8564, Reg Loss = 132.7501, Reconstruct Loss = 0.0018, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8574, Reg Loss = 140.4237, Reconstruct Loss = 0.0017, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8581, Reg Loss = 145.2069, Reconstruct Loss = 0.0019, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8586, Reg Loss = 147.9926, Reconstruct Loss = 0.0020, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8583, Reg Loss = 147.9868, Reconstruct Loss = 0.0020, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8579, Reg Loss = 145.8311, Reconstruct Loss = 0.0020, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8576, Reg Loss = 141.5642, Reconstruct Loss = 0.0020, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8570, Reg Loss = 136.6456, Reconstruct Loss = 0.0020, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8563, Reg Loss = 132.9747, Reconstruct Loss = 0.0020, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8559, Reg Loss = 130.9779, Reconstruct Loss = 0.0021, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8553, Reg Loss = 127.5790, Reconstruct Loss = 0.0021, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8554, Reg Loss = 125.7095, Reconstruct Loss = 0.0021, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8561, Reg Loss = 133.5304, Reconstruct Loss = 0.0020, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8573, Reg Loss = 140.7251, Reconstruct Loss = 0.0025, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8579, Reg Loss = 145.5009, Reconstruct Loss = 0.0026, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Epoch [10/30], Training Loss: 1.8581, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8538, Reg Loss = 242.9382, Reconstruct Loss = 0.0000, Cls Loss = 1.8295, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8644, Reg Loss = 213.2205, Reconstruct Loss = 0.0000, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8638, Reg Loss = 196.6839, Reconstruct Loss = 0.0036, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8630, Reg Loss = 173.0835, Reconstruct Loss = 0.0031, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8593, Reg Loss = 147.0557, Reconstruct Loss = 0.0028, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8595, Reg Loss = 138.7957, Reconstruct Loss = 0.0022, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8660, Reg Loss = 221.8350, Reconstruct Loss = 0.0018, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8712, Reg Loss = 285.3577, Reconstruct Loss = 0.0016, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8739, Reg Loss = 315.1838, Reconstruct Loss = 0.0014, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8742, Reg Loss = 319.1534, Reconstruct Loss = 0.0012, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8726, Reg Loss = 300.1263, Reconstruct Loss = 0.0015, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8735, Reg Loss = 298.2037, Reconstruct Loss = 0.0026, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8736, Reg Loss = 299.2365, Reconstruct Loss = 0.0024, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8740, Reg Loss = 297.4406, Reconstruct Loss = 0.0025, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8729, Reg Loss = 291.2240, Reconstruct Loss = 0.0026, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8718, Reg Loss = 281.8865, Reconstruct Loss = 0.0024, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8706, Reg Loss = 269.9310, Reconstruct Loss = 0.0024, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8762, Reg Loss = 277.0498, Reconstruct Loss = 0.0023, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8808, Reg Loss = 327.3825, Reconstruct Loss = 0.0021, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8900, Reg Loss = 372.2618, Reconstruct Loss = 0.0073, Cls Loss = 1.8455, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8966, Reg Loss = 410.3233, Reconstruct Loss = 0.0108, Cls Loss = 1.8447, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8984, Reg Loss = 436.8394, Reconstruct Loss = 0.0103, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8997, Reg Loss = 459.3816, Reconstruct Loss = 0.0099, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9029, Reg Loss = 477.6956, Reconstruct Loss = 0.0114, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9050, Reg Loss = 490.5086, Reconstruct Loss = 0.0124, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9054, Reg Loss = 497.5954, Reconstruct Loss = 0.0119, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9054, Reg Loss = 500.9809, Reconstruct Loss = 0.0114, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9062, Reg Loss = 500.3411, Reconstruct Loss = 0.0122, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9050, Reg Loss = 492.1528, Reconstruct Loss = 0.0118, Cls Loss = 1.8440, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9032, Reg Loss = 478.8907, Reconstruct Loss = 0.0115, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9016, Reg Loss = 466.6245, Reconstruct Loss = 0.0111, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8999, Reg Loss = 454.4220, Reconstruct Loss = 0.0108, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Epoch [11/30], Training Loss: 1.8996, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Validation Loss: 1.8076, Validation Accuracy: 75.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8094, Reg Loss = 62.5894, Reconstruct Loss = 0.0000, Cls Loss = 1.8032, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8610, Reg Loss = 154.6872, Reconstruct Loss = 0.0021, Cls Loss = 1.8434, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8635, Reg Loss = 177.2754, Reconstruct Loss = 0.0068, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8598, Reg Loss = 148.2834, Reconstruct Loss = 0.0046, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8635, Reg Loss = 168.3387, Reconstruct Loss = 0.0051, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8627, Reg Loss = 175.6748, Reconstruct Loss = 0.0040, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8607, Reg Loss = 166.8918, Reconstruct Loss = 0.0034, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8606, Reg Loss = 156.1996, Reconstruct Loss = 0.0034, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8601, Reg Loss = 147.9204, Reconstruct Loss = 0.0038, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8589, Reg Loss = 143.0104, Reconstruct Loss = 0.0037, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8595, Reg Loss = 145.6480, Reconstruct Loss = 0.0040, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8605, Reg Loss = 153.5136, Reconstruct Loss = 0.0041, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8606, Reg Loss = 152.3054, Reconstruct Loss = 0.0041, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8594, Reg Loss = 145.0368, Reconstruct Loss = 0.0039, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8584, Reg Loss = 138.7502, Reconstruct Loss = 0.0038, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8573, Reg Loss = 134.3553, Reconstruct Loss = 0.0036, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8570, Reg Loss = 129.4358, Reconstruct Loss = 0.0033, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8564, Reg Loss = 123.4640, Reconstruct Loss = 0.0033, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8669, Reg Loss = 130.9898, Reconstruct Loss = 0.0051, Cls Loss = 1.8487, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8697, Reg Loss = 161.2520, Reconstruct Loss = 0.0048, Cls Loss = 1.8488, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8717, Reg Loss = 188.7538, Reconstruct Loss = 0.0046, Cls Loss = 1.8482, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8740, Reg Loss = 212.5053, Reconstruct Loss = 0.0044, Cls Loss = 1.8484, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8765, Reg Loss = 232.0200, Reconstruct Loss = 0.0054, Cls Loss = 1.8479, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8787, Reg Loss = 247.4638, Reconstruct Loss = 0.0060, Cls Loss = 1.8479, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8796, Reg Loss = 258.0752, Reconstruct Loss = 0.0064, Cls Loss = 1.8474, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8803, Reg Loss = 265.4125, Reconstruct Loss = 0.0067, Cls Loss = 1.8471, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8801, Reg Loss = 269.9766, Reconstruct Loss = 0.0064, Cls Loss = 1.8467, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8799, Reg Loss = 271.6299, Reconstruct Loss = 0.0064, Cls Loss = 1.8463, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8793, Reg Loss = 268.9926, Reconstruct Loss = 0.0064, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8782, Reg Loss = 262.4200, Reconstruct Loss = 0.0063, Cls Loss = 1.8457, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8774, Reg Loss = 259.0745, Reconstruct Loss = 0.0061, Cls Loss = 1.8454, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8765, Reg Loss = 254.7260, Reconstruct Loss = 0.0059, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Epoch [12/30], Training Loss: 1.8765, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8359, Reg Loss = 71.2413, Reconstruct Loss = 0.0000, Cls Loss = 1.8288, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8633, Reg Loss = 122.0467, Reconstruct Loss = 0.0059, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8658, Reg Loss = 211.5389, Reconstruct Loss = 0.0030, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8649, Reg Loss = 235.6565, Reconstruct Loss = 0.0020, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8667, Reg Loss = 228.3082, Reconstruct Loss = 0.0039, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8646, Reg Loss = 204.9569, Reconstruct Loss = 0.0031, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8620, Reg Loss = 187.5635, Reconstruct Loss = 0.0026, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8634, Reg Loss = 190.1149, Reconstruct Loss = 0.0028, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8641, Reg Loss = 187.2036, Reconstruct Loss = 0.0028, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8626, Reg Loss = 178.7011, Reconstruct Loss = 0.0028, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9467, Reg Loss = 189.0249, Reconstruct Loss = 0.0025, Cls Loss = 1.9253, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9546, Reg Loss = 234.3381, Reconstruct Loss = 0.0135, Cls Loss = 1.9177, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9634, Reg Loss = 268.2089, Reconstruct Loss = 0.0250, Cls Loss = 1.9116, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9572, Reg Loss = 289.5566, Reconstruct Loss = 0.0231, Cls Loss = 1.9051, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9510, Reg Loss = 297.7583, Reconstruct Loss = 0.0214, Cls Loss = 1.8998, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9462, Reg Loss = 289.6515, Reconstruct Loss = 0.0200, Cls Loss = 1.8972, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9417, Reg Loss = 284.9300, Reconstruct Loss = 0.0188, Cls Loss = 1.8945, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9378, Reg Loss = 278.0343, Reconstruct Loss = 0.0185, Cls Loss = 1.8915, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9328, Reg Loss = 270.1140, Reconstruct Loss = 0.0175, Cls Loss = 1.8883, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9289, Reg Loss = 263.6857, Reconstruct Loss = 0.0166, Cls Loss = 1.8860, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9246, Reg Loss = 255.1436, Reconstruct Loss = 0.0157, Cls Loss = 1.8834, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9221, Reg Loss = 247.4441, Reconstruct Loss = 0.0152, Cls Loss = 1.8821, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9206, Reg Loss = 247.8234, Reconstruct Loss = 0.0159, Cls Loss = 1.8800, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9186, Reg Loss = 248.1832, Reconstruct Loss = 0.0152, Cls Loss = 1.8786, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9169, Reg Loss = 246.7933, Reconstruct Loss = 0.0149, Cls Loss = 1.8773, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9144, Reg Loss = 243.6600, Reconstruct Loss = 0.0145, Cls Loss = 1.8756, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9121, Reg Loss = 238.2299, Reconstruct Loss = 0.0140, Cls Loss = 1.8743, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9097, Reg Loss = 231.2339, Reconstruct Loss = 0.0135, Cls Loss = 1.8731, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9080, Reg Loss = 228.2251, Reconstruct Loss = 0.0130, Cls Loss = 1.8721, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9058, Reg Loss = 223.3923, Reconstruct Loss = 0.0127, Cls Loss = 1.8708, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9037, Reg Loss = 218.0417, Reconstruct Loss = 0.0123, Cls Loss = 1.8696, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9020, Reg Loss = 211.9874, Reconstruct Loss = 0.0119, Cls Loss = 1.8689, Learning rate = 1.0000e-03\n",
      "Epoch [13/30], Training Loss: 1.9016, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Validation Loss: 1.8076, Validation Accuracy: 75.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8302, Reg Loss = 35.1600, Reconstruct Loss = 0.0000, Cls Loss = 1.8267, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8434, Reg Loss = 21.8639, Reconstruct Loss = 0.0018, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8448, Reg Loss = 32.1366, Reconstruct Loss = 0.0018, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8458, Reg Loss = 29.1444, Reconstruct Loss = 0.0012, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8630, Reg Loss = 76.4757, Reconstruct Loss = 0.0047, Cls Loss = 1.8507, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8757, Reg Loss = 151.3702, Reconstruct Loss = 0.0104, Cls Loss = 1.8501, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8771, Reg Loss = 198.9899, Reconstruct Loss = 0.0087, Cls Loss = 1.8485, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8825, Reg Loss = 231.3651, Reconstruct Loss = 0.0105, Cls Loss = 1.8488, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8811, Reg Loss = 251.3088, Reconstruct Loss = 0.0092, Cls Loss = 1.8468, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8810, Reg Loss = 264.8188, Reconstruct Loss = 0.0094, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8791, Reg Loss = 271.2249, Reconstruct Loss = 0.0084, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8787, Reg Loss = 273.3985, Reconstruct Loss = 0.0077, Cls Loss = 1.8437, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8784, Reg Loss = 268.6225, Reconstruct Loss = 0.0079, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8761, Reg Loss = 258.3005, Reconstruct Loss = 0.0073, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8742, Reg Loss = 243.6550, Reconstruct Loss = 0.0069, Cls Loss = 1.8429, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8716, Reg Loss = 230.9394, Reconstruct Loss = 0.0064, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8695, Reg Loss = 218.4457, Reconstruct Loss = 0.0060, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8690, Reg Loss = 209.1896, Reconstruct Loss = 0.0058, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8680, Reg Loss = 200.0933, Reconstruct Loss = 0.0056, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8672, Reg Loss = 194.9806, Reconstruct Loss = 0.0054, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8663, Reg Loss = 194.3887, Reconstruct Loss = 0.0052, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8661, Reg Loss = 192.1116, Reconstruct Loss = 0.0051, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8651, Reg Loss = 187.7131, Reconstruct Loss = 0.0050, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8645, Reg Loss = 181.7641, Reconstruct Loss = 0.0049, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8638, Reg Loss = 175.7399, Reconstruct Loss = 0.0048, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8636, Reg Loss = 174.3331, Reconstruct Loss = 0.0046, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8633, Reg Loss = 173.3693, Reconstruct Loss = 0.0045, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8628, Reg Loss = 171.3865, Reconstruct Loss = 0.0044, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8627, Reg Loss = 168.2126, Reconstruct Loss = 0.0045, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8623, Reg Loss = 163.7588, Reconstruct Loss = 0.0044, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8618, Reg Loss = 161.8151, Reconstruct Loss = 0.0044, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8616, Reg Loss = 159.3360, Reconstruct Loss = 0.0043, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Epoch [14/30], Training Loss: 1.8616, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Validation Loss: 1.8076, Validation Accuracy: 75.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8336, Reg Loss = 47.6431, Reconstruct Loss = 0.0000, Cls Loss = 1.8288, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8381, Reg Loss = 55.8745, Reconstruct Loss = 0.0000, Cls Loss = 1.8325, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8430, Reg Loss = 63.4835, Reconstruct Loss = 0.0000, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8438, Reg Loss = 57.4073, Reconstruct Loss = 0.0005, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8441, Reg Loss = 54.0217, Reconstruct Loss = 0.0004, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8455, Reg Loss = 67.1299, Reconstruct Loss = 0.0003, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8467, Reg Loss = 72.1120, Reconstruct Loss = 0.0006, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8455, Reg Loss = 70.1303, Reconstruct Loss = 0.0005, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8461, Reg Loss = 65.2268, Reconstruct Loss = 0.0008, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8472, Reg Loss = 60.3390, Reconstruct Loss = 0.0009, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8466, Reg Loss = 57.5047, Reconstruct Loss = 0.0010, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8469, Reg Loss = 57.6653, Reconstruct Loss = 0.0009, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8469, Reg Loss = 58.6825, Reconstruct Loss = 0.0008, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8471, Reg Loss = 61.7380, Reconstruct Loss = 0.0010, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8473, Reg Loss = 62.4570, Reconstruct Loss = 0.0011, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8476, Reg Loss = 60.9637, Reconstruct Loss = 0.0010, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8470, Reg Loss = 58.1571, Reconstruct Loss = 0.0010, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8537, Reg Loss = 76.9386, Reconstruct Loss = 0.0031, Cls Loss = 1.8429, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8603, Reg Loss = 117.7036, Reconstruct Loss = 0.0060, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8696, Reg Loss = 154.6059, Reconstruct Loss = 0.0119, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8717, Reg Loss = 185.3557, Reconstruct Loss = 0.0113, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8763, Reg Loss = 210.5169, Reconstruct Loss = 0.0130, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8775, Reg Loss = 231.8373, Reconstruct Loss = 0.0124, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8800, Reg Loss = 250.4681, Reconstruct Loss = 0.0127, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8808, Reg Loss = 265.5332, Reconstruct Loss = 0.0122, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8826, Reg Loss = 276.1015, Reconstruct Loss = 0.0129, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8829, Reg Loss = 281.0813, Reconstruct Loss = 0.0127, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8820, Reg Loss = 278.5792, Reconstruct Loss = 0.0123, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8813, Reg Loss = 277.7919, Reconstruct Loss = 0.0119, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8808, Reg Loss = 278.1091, Reconstruct Loss = 0.0115, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8804, Reg Loss = 277.2998, Reconstruct Loss = 0.0112, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8804, Reg Loss = 275.8821, Reconstruct Loss = 0.0110, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Epoch [15/30], Training Loss: 1.8803, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9138, Reg Loss = 193.3102, Reconstruct Loss = 0.0000, Cls Loss = 1.8944, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8666, Reg Loss = 191.0097, Reconstruct Loss = 0.0000, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8652, Reg Loss = 177.8220, Reconstruct Loss = 0.0014, Cls Loss = 1.8461, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8604, Reg Loss = 166.6455, Reconstruct Loss = 0.0025, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8603, Reg Loss = 152.8749, Reconstruct Loss = 0.0024, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8576, Reg Loss = 137.4685, Reconstruct Loss = 0.0019, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8571, Reg Loss = 122.7503, Reconstruct Loss = 0.0019, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8552, Reg Loss = 110.5454, Reconstruct Loss = 0.0021, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8542, Reg Loss = 101.7703, Reconstruct Loss = 0.0020, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8539, Reg Loss = 93.8992, Reconstruct Loss = 0.0018, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8572, Reg Loss = 123.5836, Reconstruct Loss = 0.0016, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8617, Reg Loss = 156.4613, Reconstruct Loss = 0.0038, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8648, Reg Loss = 180.8020, Reconstruct Loss = 0.0044, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8676, Reg Loss = 197.8394, Reconstruct Loss = 0.0055, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8679, Reg Loss = 208.8338, Reconstruct Loss = 0.0051, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8703, Reg Loss = 217.7003, Reconstruct Loss = 0.0063, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8710, Reg Loss = 223.2287, Reconstruct Loss = 0.0063, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8704, Reg Loss = 226.6689, Reconstruct Loss = 0.0059, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8701, Reg Loss = 228.3451, Reconstruct Loss = 0.0058, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8702, Reg Loss = 228.1456, Reconstruct Loss = 0.0055, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8694, Reg Loss = 225.5030, Reconstruct Loss = 0.0053, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8682, Reg Loss = 218.3717, Reconstruct Loss = 0.0050, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8680, Reg Loss = 214.1946, Reconstruct Loss = 0.0048, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8674, Reg Loss = 209.6755, Reconstruct Loss = 0.0047, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8900, Reg Loss = 225.5003, Reconstruct Loss = 0.0045, Cls Loss = 1.8629, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8921, Reg Loss = 258.7451, Reconstruct Loss = 0.0044, Cls Loss = 1.8619, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8982, Reg Loss = 260.1421, Reconstruct Loss = 0.0042, Cls Loss = 1.8680, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8971, Reg Loss = 260.6979, Reconstruct Loss = 0.0040, Cls Loss = 1.8670, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9035, Reg Loss = 267.8311, Reconstruct Loss = 0.0107, Cls Loss = 1.8659, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9026, Reg Loss = 272.4253, Reconstruct Loss = 0.0104, Cls Loss = 1.8650, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9049, Reg Loss = 274.9598, Reconstruct Loss = 0.0135, Cls Loss = 1.8639, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9060, Reg Loss = 274.5914, Reconstruct Loss = 0.0152, Cls Loss = 1.8633, Learning rate = 1.0000e-03\n",
      "Epoch [16/30], Training Loss: 1.9073, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9103, Reg Loss = 162.8299, Reconstruct Loss = 0.0000, Cls Loss = 1.8940, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8438, Reg Loss = 165.7093, Reconstruct Loss = 0.0000, Cls Loss = 1.8272, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8741, Reg Loss = 281.0067, Reconstruct Loss = 0.0149, Cls Loss = 1.8311, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8858, Reg Loss = 322.3347, Reconstruct Loss = 0.0164, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8878, Reg Loss = 327.3870, Reconstruct Loss = 0.0157, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8848, Reg Loss = 323.5765, Reconstruct Loss = 0.0139, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8844, Reg Loss = 313.3157, Reconstruct Loss = 0.0132, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8829, Reg Loss = 297.0945, Reconstruct Loss = 0.0120, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8807, Reg Loss = 274.9881, Reconstruct Loss = 0.0105, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8766, Reg Loss = 250.2572, Reconstruct Loss = 0.0093, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8741, Reg Loss = 237.4575, Reconstruct Loss = 0.0084, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8723, Reg Loss = 224.0458, Reconstruct Loss = 0.0078, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8702, Reg Loss = 208.0955, Reconstruct Loss = 0.0074, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8676, Reg Loss = 194.3977, Reconstruct Loss = 0.0069, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8670, Reg Loss = 195.9154, Reconstruct Loss = 0.0064, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8670, Reg Loss = 202.8557, Reconstruct Loss = 0.0059, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8668, Reg Loss = 205.7511, Reconstruct Loss = 0.0056, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8666, Reg Loss = 205.0624, Reconstruct Loss = 0.0056, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8661, Reg Loss = 199.8898, Reconstruct Loss = 0.0055, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8678, Reg Loss = 205.6496, Reconstruct Loss = 0.0053, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8705, Reg Loss = 238.9523, Reconstruct Loss = 0.0051, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8760, Reg Loss = 269.4798, Reconstruct Loss = 0.0078, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8786, Reg Loss = 295.8252, Reconstruct Loss = 0.0074, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8821, Reg Loss = 319.1200, Reconstruct Loss = 0.0091, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8854, Reg Loss = 339.9620, Reconstruct Loss = 0.0104, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8868, Reg Loss = 357.7079, Reconstruct Loss = 0.0099, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8893, Reg Loss = 372.7618, Reconstruct Loss = 0.0108, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8902, Reg Loss = 385.4461, Reconstruct Loss = 0.0104, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8924, Reg Loss = 396.4611, Reconstruct Loss = 0.0111, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8929, Reg Loss = 406.5648, Reconstruct Loss = 0.0107, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8933, Reg Loss = 415.4863, Reconstruct Loss = 0.0104, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8952, Reg Loss = 422.0745, Reconstruct Loss = 0.0117, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Epoch [17/30], Training Loss: 1.8952, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8964, Reg Loss = 601.0917, Reconstruct Loss = 0.0000, Cls Loss = 1.8363, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9002, Reg Loss = 606.3743, Reconstruct Loss = 0.0000, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9119, Reg Loss = 602.7381, Reconstruct Loss = 0.0109, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9068, Reg Loss = 593.3841, Reconstruct Loss = 0.0073, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9164, Reg Loss = 589.0411, Reconstruct Loss = 0.0156, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9159, Reg Loss = 578.2930, Reconstruct Loss = 0.0163, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9138, Reg Loss = 573.3445, Reconstruct Loss = 0.0136, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9141, Reg Loss = 567.9552, Reconstruct Loss = 0.0142, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9131, Reg Loss = 561.4461, Reconstruct Loss = 0.0145, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9096, Reg Loss = 554.2067, Reconstruct Loss = 0.0129, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9093, Reg Loss = 547.7166, Reconstruct Loss = 0.0132, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9084, Reg Loss = 541.4671, Reconstruct Loss = 0.0133, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9062, Reg Loss = 534.7107, Reconstruct Loss = 0.0122, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9046, Reg Loss = 528.4350, Reconstruct Loss = 0.0113, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9052, Reg Loss = 523.1755, Reconstruct Loss = 0.0124, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9042, Reg Loss = 516.8762, Reconstruct Loss = 0.0116, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9033, Reg Loss = 511.7245, Reconstruct Loss = 0.0108, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9018, Reg Loss = 506.1316, Reconstruct Loss = 0.0102, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9008, Reg Loss = 501.2701, Reconstruct Loss = 0.0096, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9003, Reg Loss = 496.2736, Reconstruct Loss = 0.0097, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8995, Reg Loss = 490.9960, Reconstruct Loss = 0.0098, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8984, Reg Loss = 486.2708, Reconstruct Loss = 0.0093, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8973, Reg Loss = 481.4271, Reconstruct Loss = 0.0089, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8969, Reg Loss = 477.3239, Reconstruct Loss = 0.0089, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8970, Reg Loss = 472.6843, Reconstruct Loss = 0.0094, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8971, Reg Loss = 468.6195, Reconstruct Loss = 0.0097, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8970, Reg Loss = 464.3354, Reconstruct Loss = 0.0097, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8961, Reg Loss = 459.7425, Reconstruct Loss = 0.0093, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8953, Reg Loss = 455.0983, Reconstruct Loss = 0.0093, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8948, Reg Loss = 450.8248, Reconstruct Loss = 0.0092, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8941, Reg Loss = 446.0196, Reconstruct Loss = 0.0089, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8932, Reg Loss = 441.1765, Reconstruct Loss = 0.0088, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Epoch [18/30], Training Loss: 1.8929, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Validation Loss: 1.8076, Validation Accuracy: 75.84%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8474, Reg Loss = 290.2026, Reconstruct Loss = 0.0000, Cls Loss = 1.8184, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8624, Reg Loss = 264.6553, Reconstruct Loss = 0.0000, Cls Loss = 1.8359, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8642, Reg Loss = 254.2696, Reconstruct Loss = 0.0000, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8669, Reg Loss = 249.3475, Reconstruct Loss = 0.0015, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8646, Reg Loss = 239.0634, Reconstruct Loss = 0.0022, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8634, Reg Loss = 225.3042, Reconstruct Loss = 0.0017, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8619, Reg Loss = 206.6421, Reconstruct Loss = 0.0015, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8597, Reg Loss = 183.5817, Reconstruct Loss = 0.0015, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8563, Reg Loss = 164.1114, Reconstruct Loss = 0.0013, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8548, Reg Loss = 149.7592, Reconstruct Loss = 0.0013, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8545, Reg Loss = 136.8361, Reconstruct Loss = 0.0013, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8543, Reg Loss = 133.2867, Reconstruct Loss = 0.0015, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8541, Reg Loss = 129.2034, Reconstruct Loss = 0.0016, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8534, Reg Loss = 122.5671, Reconstruct Loss = 0.0014, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8530, Reg Loss = 115.9668, Reconstruct Loss = 0.0017, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8526, Reg Loss = 110.1136, Reconstruct Loss = 0.0018, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8520, Reg Loss = 106.9576, Reconstruct Loss = 0.0017, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8521, Reg Loss = 105.3266, Reconstruct Loss = 0.0016, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8519, Reg Loss = 101.6754, Reconstruct Loss = 0.0016, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8514, Reg Loss = 97.9857, Reconstruct Loss = 0.0017, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8513, Reg Loss = 94.0210, Reconstruct Loss = 0.0016, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8511, Reg Loss = 91.0036, Reconstruct Loss = 0.0016, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8512, Reg Loss = 91.4177, Reconstruct Loss = 0.0019, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8523, Reg Loss = 98.0625, Reconstruct Loss = 0.0021, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8524, Reg Loss = 100.6012, Reconstruct Loss = 0.0020, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.1384, Reg Loss = 106.3555, Reconstruct Loss = 0.0025, Cls Loss = 2.1252, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.1368, Reg Loss = 135.9009, Reconstruct Loss = 0.0088, Cls Loss = 2.1144, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.1360, Reg Loss = 164.0703, Reconstruct Loss = 0.0152, Cls Loss = 2.1044, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.1280, Reg Loss = 187.2784, Reconstruct Loss = 0.0147, Cls Loss = 2.0946, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.1207, Reg Loss = 205.7320, Reconstruct Loss = 0.0142, Cls Loss = 2.0859, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.1165, Reg Loss = 220.0255, Reconstruct Loss = 0.0165, Cls Loss = 2.0779, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.1115, Reg Loss = 230.5212, Reconstruct Loss = 0.0185, Cls Loss = 2.0699, Learning rate = 1.0000e-03\n",
      "Epoch [19/30], Training Loss: 2.1097, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Validation Loss: 1.8076, Validation Accuracy: 75.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 2.1792, Reg Loss = 509.6405, Reconstruct Loss = 0.3178, Cls Loss = 1.8104, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8889, Reg Loss = 385.6854, Reconstruct Loss = 0.0122, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8821, Reg Loss = 347.4886, Reconstruct Loss = 0.0062, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8796, Reg Loss = 322.6845, Reconstruct Loss = 0.0042, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8784, Reg Loss = 298.4929, Reconstruct Loss = 0.0041, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8750, Reg Loss = 271.7210, Reconstruct Loss = 0.0033, Cls Loss = 1.8446, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8726, Reg Loss = 244.0006, Reconstruct Loss = 0.0038, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9900, Reg Loss = 217.6426, Reconstruct Loss = 0.0032, Cls Loss = 1.9650, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9981, Reg Loss = 281.5935, Reconstruct Loss = 0.0203, Cls Loss = 1.9496, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9898, Reg Loss = 348.7446, Reconstruct Loss = 0.0180, Cls Loss = 1.9369, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9842, Reg Loss = 407.2662, Reconstruct Loss = 0.0162, Cls Loss = 1.9273, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9787, Reg Loss = 453.4291, Reconstruct Loss = 0.0148, Cls Loss = 1.9186, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9912, Reg Loss = 490.0531, Reconstruct Loss = 0.0305, Cls Loss = 1.9117, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9866, Reg Loss = 516.2966, Reconstruct Loss = 0.0281, Cls Loss = 1.9068, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9864, Reg Loss = 536.4060, Reconstruct Loss = 0.0303, Cls Loss = 1.9025, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9822, Reg Loss = 549.6130, Reconstruct Loss = 0.0283, Cls Loss = 1.8989, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9779, Reg Loss = 559.7086, Reconstruct Loss = 0.0265, Cls Loss = 1.8954, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9739, Reg Loss = 567.4621, Reconstruct Loss = 0.0250, Cls Loss = 1.8922, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9701, Reg Loss = 573.6909, Reconstruct Loss = 0.0236, Cls Loss = 1.8891, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9683, Reg Loss = 580.0954, Reconstruct Loss = 0.0239, Cls Loss = 1.8864, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9660, Reg Loss = 585.4383, Reconstruct Loss = 0.0241, Cls Loss = 1.8833, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9627, Reg Loss = 587.9619, Reconstruct Loss = 0.0230, Cls Loss = 1.8809, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9624, Reg Loss = 592.2023, Reconstruct Loss = 0.0244, Cls Loss = 1.8788, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9597, Reg Loss = 594.0363, Reconstruct Loss = 0.0233, Cls Loss = 1.8769, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9585, Reg Loss = 595.4150, Reconstruct Loss = 0.0234, Cls Loss = 1.8755, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9565, Reg Loss = 597.2905, Reconstruct Loss = 0.0225, Cls Loss = 1.8742, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9542, Reg Loss = 597.5047, Reconstruct Loss = 0.0216, Cls Loss = 1.8728, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9523, Reg Loss = 598.2856, Reconstruct Loss = 0.0208, Cls Loss = 1.8717, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9506, Reg Loss = 598.5689, Reconstruct Loss = 0.0201, Cls Loss = 1.8706, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9487, Reg Loss = 599.4850, Reconstruct Loss = 0.0194, Cls Loss = 1.8694, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9482, Reg Loss = 599.6320, Reconstruct Loss = 0.0195, Cls Loss = 1.8687, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9465, Reg Loss = 599.4599, Reconstruct Loss = 0.0189, Cls Loss = 1.8677, Learning rate = 1.0000e-03\n",
      "Epoch [20/30], Training Loss: 1.9461, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Validation Loss: 1.8076, Validation Accuracy: 75.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8730, Reg Loss = 609.2399, Reconstruct Loss = 0.0000, Cls Loss = 1.8121, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9209, Reg Loss = 569.9550, Reconstruct Loss = 0.0203, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9110, Reg Loss = 567.6344, Reconstruct Loss = 0.0104, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9138, Reg Loss = 572.9820, Reconstruct Loss = 0.0135, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9067, Reg Loss = 562.4784, Reconstruct Loss = 0.0102, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9090, Reg Loss = 561.4600, Reconstruct Loss = 0.0118, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9093, Reg Loss = 556.1800, Reconstruct Loss = 0.0128, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9073, Reg Loss = 546.6182, Reconstruct Loss = 0.0110, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9054, Reg Loss = 541.2720, Reconstruct Loss = 0.0096, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9056, Reg Loss = 535.9426, Reconstruct Loss = 0.0103, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9047, Reg Loss = 529.6937, Reconstruct Loss = 0.0107, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9038, Reg Loss = 522.9169, Reconstruct Loss = 0.0109, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9022, Reg Loss = 515.5753, Reconstruct Loss = 0.0100, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9003, Reg Loss = 505.0986, Reconstruct Loss = 0.0092, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9004, Reg Loss = 496.0354, Reconstruct Loss = 0.0100, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8997, Reg Loss = 485.7704, Reconstruct Loss = 0.0099, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8970, Reg Loss = 473.3638, Reconstruct Loss = 0.0097, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8954, Reg Loss = 457.2282, Reconstruct Loss = 0.0093, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8925, Reg Loss = 436.4286, Reconstruct Loss = 0.0088, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8901, Reg Loss = 418.0344, Reconstruct Loss = 0.0083, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8883, Reg Loss = 400.6140, Reconstruct Loss = 0.0080, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8885, Reg Loss = 397.1822, Reconstruct Loss = 0.0082, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8885, Reg Loss = 393.9791, Reconstruct Loss = 0.0088, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8875, Reg Loss = 387.1411, Reconstruct Loss = 0.0084, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8863, Reg Loss = 375.4436, Reconstruct Loss = 0.0081, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8846, Reg Loss = 363.8882, Reconstruct Loss = 0.0079, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8834, Reg Loss = 352.0242, Reconstruct Loss = 0.0077, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8833, Reg Loss = 347.2575, Reconstruct Loss = 0.0074, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8841, Reg Loss = 349.4585, Reconstruct Loss = 0.0075, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8840, Reg Loss = 347.9644, Reconstruct Loss = 0.0075, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8832, Reg Loss = 342.5513, Reconstruct Loss = 0.0073, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8819, Reg Loss = 334.2420, Reconstruct Loss = 0.0070, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Epoch [21/30], Training Loss: 1.8818, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Validation Loss: 1.8076, Validation Accuracy: 75.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8580, Reg Loss = 180.9903, Reconstruct Loss = 0.0000, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8880, Reg Loss = 467.8140, Reconstruct Loss = 0.0000, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8923, Reg Loss = 526.0919, Reconstruct Loss = 0.0000, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9113, Reg Loss = 538.6467, Reconstruct Loss = 0.0184, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9107, Reg Loss = 524.1504, Reconstruct Loss = 0.0202, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9086, Reg Loss = 503.6820, Reconstruct Loss = 0.0206, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9042, Reg Loss = 481.9637, Reconstruct Loss = 0.0172, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9010, Reg Loss = 462.1062, Reconstruct Loss = 0.0159, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8983, Reg Loss = 441.9763, Reconstruct Loss = 0.0147, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8956, Reg Loss = 422.9045, Reconstruct Loss = 0.0138, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8920, Reg Loss = 404.3843, Reconstruct Loss = 0.0124, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8891, Reg Loss = 385.8093, Reconstruct Loss = 0.0116, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8878, Reg Loss = 367.0015, Reconstruct Loss = 0.0111, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8840, Reg Loss = 346.7358, Reconstruct Loss = 0.0102, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8819, Reg Loss = 325.7163, Reconstruct Loss = 0.0099, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8818, Reg Loss = 320.6903, Reconstruct Loss = 0.0092, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8837, Reg Loss = 344.0794, Reconstruct Loss = 0.0086, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8849, Reg Loss = 365.2832, Reconstruct Loss = 0.0081, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8863, Reg Loss = 381.9655, Reconstruct Loss = 0.0077, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8883, Reg Loss = 394.9515, Reconstruct Loss = 0.0084, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8888, Reg Loss = 404.2560, Reconstruct Loss = 0.0079, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8912, Reg Loss = 411.0844, Reconstruct Loss = 0.0098, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8911, Reg Loss = 414.8199, Reconstruct Loss = 0.0093, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8921, Reg Loss = 417.1316, Reconstruct Loss = 0.0099, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8919, Reg Loss = 416.5130, Reconstruct Loss = 0.0095, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8911, Reg Loss = 409.9105, Reconstruct Loss = 0.0093, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8904, Reg Loss = 400.2101, Reconstruct Loss = 0.0093, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8899, Reg Loss = 398.5387, Reconstruct Loss = 0.0089, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8897, Reg Loss = 396.4229, Reconstruct Loss = 0.0092, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8892, Reg Loss = 392.7907, Reconstruct Loss = 0.0091, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8883, Reg Loss = 387.7502, Reconstruct Loss = 0.0088, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8875, Reg Loss = 381.5759, Reconstruct Loss = 0.0085, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Epoch [22/30], Training Loss: 1.8872, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8800, Reg Loss = 119.8028, Reconstruct Loss = 0.0000, Cls Loss = 1.8680, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8549, Reg Loss = 95.1176, Reconstruct Loss = 0.0000, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8608, Reg Loss = 183.5259, Reconstruct Loss = 0.0000, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8634, Reg Loss = 217.7669, Reconstruct Loss = 0.0017, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8630, Reg Loss = 222.0583, Reconstruct Loss = 0.0013, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8643, Reg Loss = 215.5092, Reconstruct Loss = 0.0029, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8620, Reg Loss = 201.5296, Reconstruct Loss = 0.0032, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8596, Reg Loss = 183.6805, Reconstruct Loss = 0.0027, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8577, Reg Loss = 165.5862, Reconstruct Loss = 0.0024, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8579, Reg Loss = 161.5861, Reconstruct Loss = 0.0021, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8592, Reg Loss = 177.6452, Reconstruct Loss = 0.0019, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8611, Reg Loss = 188.3005, Reconstruct Loss = 0.0023, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8612, Reg Loss = 192.4872, Reconstruct Loss = 0.0021, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8608, Reg Loss = 186.4387, Reconstruct Loss = 0.0019, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8595, Reg Loss = 176.5794, Reconstruct Loss = 0.0019, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8585, Reg Loss = 166.7940, Reconstruct Loss = 0.0018, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8585, Reg Loss = 159.0269, Reconstruct Loss = 0.0019, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8578, Reg Loss = 152.0129, Reconstruct Loss = 0.0018, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8661, Reg Loss = 186.4676, Reconstruct Loss = 0.0068, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8734, Reg Loss = 232.7719, Reconstruct Loss = 0.0097, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8766, Reg Loss = 269.0391, Reconstruct Loss = 0.0092, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8793, Reg Loss = 299.3184, Reconstruct Loss = 0.0088, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8815, Reg Loss = 324.3071, Reconstruct Loss = 0.0084, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8881, Reg Loss = 345.6220, Reconstruct Loss = 0.0132, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8907, Reg Loss = 361.7246, Reconstruct Loss = 0.0140, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8914, Reg Loss = 375.5688, Reconstruct Loss = 0.0134, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8918, Reg Loss = 387.5989, Reconstruct Loss = 0.0129, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8924, Reg Loss = 396.7581, Reconstruct Loss = 0.0124, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8929, Reg Loss = 405.6167, Reconstruct Loss = 0.0120, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8931, Reg Loss = 413.5347, Reconstruct Loss = 0.0116, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8942, Reg Loss = 420.2795, Reconstruct Loss = 0.0120, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8950, Reg Loss = 425.8859, Reconstruct Loss = 0.0123, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Epoch [23/30], Training Loss: 1.8952, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9185, Reg Loss = 619.1003, Reconstruct Loss = 0.0000, Cls Loss = 1.8566, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9042, Reg Loss = 582.6850, Reconstruct Loss = 0.0000, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9050, Reg Loss = 566.0286, Reconstruct Loss = 0.0000, Cls Loss = 1.8484, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9093, Reg Loss = 560.0660, Reconstruct Loss = 0.0064, Cls Loss = 1.8469, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9080, Reg Loss = 555.7974, Reconstruct Loss = 0.0092, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9036, Reg Loss = 546.9991, Reconstruct Loss = 0.0074, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9060, Reg Loss = 540.9474, Reconstruct Loss = 0.0090, Cls Loss = 1.8429, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9108, Reg Loss = 535.5931, Reconstruct Loss = 0.0146, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9099, Reg Loss = 530.1914, Reconstruct Loss = 0.0146, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9063, Reg Loss = 522.0027, Reconstruct Loss = 0.0130, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9036, Reg Loss = 517.1173, Reconstruct Loss = 0.0117, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9031, Reg Loss = 511.9014, Reconstruct Loss = 0.0119, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9040, Reg Loss = 505.8139, Reconstruct Loss = 0.0130, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9053, Reg Loss = 500.7780, Reconstruct Loss = 0.0149, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9050, Reg Loss = 495.0028, Reconstruct Loss = 0.0146, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9038, Reg Loss = 488.8513, Reconstruct Loss = 0.0143, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9040, Reg Loss = 482.3479, Reconstruct Loss = 0.0147, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9033, Reg Loss = 474.6828, Reconstruct Loss = 0.0148, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9019, Reg Loss = 467.1028, Reconstruct Loss = 0.0140, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9003, Reg Loss = 456.9397, Reconstruct Loss = 0.0135, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8992, Reg Loss = 445.2991, Reconstruct Loss = 0.0133, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8968, Reg Loss = 430.0992, Reconstruct Loss = 0.0128, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8947, Reg Loss = 414.2990, Reconstruct Loss = 0.0123, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8931, Reg Loss = 399.7422, Reconstruct Loss = 0.0120, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8913, Reg Loss = 388.5145, Reconstruct Loss = 0.0115, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8898, Reg Loss = 376.8203, Reconstruct Loss = 0.0111, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8876, Reg Loss = 363.7327, Reconstruct Loss = 0.0107, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8860, Reg Loss = 351.4861, Reconstruct Loss = 0.0104, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8855, Reg Loss = 339.6640, Reconstruct Loss = 0.0100, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8840, Reg Loss = 328.4411, Reconstruct Loss = 0.0096, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8827, Reg Loss = 318.3658, Reconstruct Loss = 0.0094, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8819, Reg Loss = 313.2340, Reconstruct Loss = 0.0091, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Epoch [24/30], Training Loss: 1.8818, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8503, Reg Loss = 157.3515, Reconstruct Loss = 0.0000, Cls Loss = 1.8346, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8490, Reg Loss = 118.3464, Reconstruct Loss = 0.0016, Cls Loss = 1.8356, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 5.1845, Reg Loss = 241.9252, Reconstruct Loss = 0.0571, Cls Loss = 5.1032, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 4.1222, Reg Loss = 521.4451, Reconstruct Loss = 0.0383, Cls Loss = 4.0318, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 3.5849, Reg Loss = 657.1927, Reconstruct Loss = 0.0288, Cls Loss = 3.4904, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 3.3138, Reg Loss = 704.6429, Reconstruct Loss = 0.0791, Cls Loss = 3.1642, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 3.0899, Reg Loss = 702.4853, Reconstruct Loss = 0.0751, Cls Loss = 2.9445, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.9291, Reg Loss = 689.2681, Reconstruct Loss = 0.0722, Cls Loss = 2.7880, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.8002, Reg Loss = 661.3887, Reconstruct Loss = 0.0655, Cls Loss = 2.6686, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.7002, Reg Loss = 632.6751, Reconstruct Loss = 0.0597, Cls Loss = 2.5773, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.6178, Reg Loss = 602.2872, Reconstruct Loss = 0.0538, Cls Loss = 2.5038, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.5497, Reg Loss = 570.9174, Reconstruct Loss = 0.0489, Cls Loss = 2.4437, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.4930, Reg Loss = 536.7599, Reconstruct Loss = 0.0452, Cls Loss = 2.3940, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.4437, Reg Loss = 500.9041, Reconstruct Loss = 0.0419, Cls Loss = 2.3517, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.4017, Reg Loss = 471.0880, Reconstruct Loss = 0.0391, Cls Loss = 2.3155, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.3647, Reg Loss = 442.7239, Reconstruct Loss = 0.0366, Cls Loss = 2.2839, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.3326, Reg Loss = 417.9106, Reconstruct Loss = 0.0345, Cls Loss = 2.2563, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.3039, Reg Loss = 396.4866, Reconstruct Loss = 0.0326, Cls Loss = 2.2317, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.2785, Reg Loss = 377.4970, Reconstruct Loss = 0.0309, Cls Loss = 2.2098, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.2557, Reg Loss = 359.8533, Reconstruct Loss = 0.0293, Cls Loss = 2.1904, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.2357, Reg Loss = 348.5324, Reconstruct Loss = 0.0279, Cls Loss = 2.1730, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.2177, Reg Loss = 338.1360, Reconstruct Loss = 0.0267, Cls Loss = 2.1572, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.2011, Reg Loss = 325.9720, Reconstruct Loss = 0.0255, Cls Loss = 2.1431, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.1855, Reg Loss = 313.2087, Reconstruct Loss = 0.0244, Cls Loss = 2.1298, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.1744, Reg Loss = 315.3524, Reconstruct Loss = 0.0234, Cls Loss = 2.1195, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.1670, Reg Loss = 333.6352, Reconstruct Loss = 0.0254, Cls Loss = 2.1082, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.1584, Reg Loss = 350.2598, Reconstruct Loss = 0.0258, Cls Loss = 2.0976, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.1494, Reg Loss = 364.4496, Reconstruct Loss = 0.0248, Cls Loss = 2.0881, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.1433, Reg Loss = 376.9241, Reconstruct Loss = 0.0263, Cls Loss = 2.0794, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.1382, Reg Loss = 389.3146, Reconstruct Loss = 0.0284, Cls Loss = 2.0710, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.1317, Reg Loss = 398.7255, Reconstruct Loss = 0.0283, Cls Loss = 2.0636, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.1253, Reg Loss = 407.2718, Reconstruct Loss = 0.0282, Cls Loss = 2.0563, Learning rate = 1.0000e-03\n",
      "Epoch [25/30], Training Loss: 2.1237, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9407, Reg Loss = 659.9818, Reconstruct Loss = 0.0000, Cls Loss = 1.8747, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9360, Reg Loss = 645.4766, Reconstruct Loss = 0.0231, Cls Loss = 1.8483, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9308, Reg Loss = 641.8531, Reconstruct Loss = 0.0231, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9345, Reg Loss = 635.3655, Reconstruct Loss = 0.0305, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9314, Reg Loss = 631.7760, Reconstruct Loss = 0.0284, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9270, Reg Loss = 624.4470, Reconstruct Loss = 0.0271, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9290, Reg Loss = 622.1618, Reconstruct Loss = 0.0295, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9234, Reg Loss = 616.2627, Reconstruct Loss = 0.0253, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9203, Reg Loss = 611.0466, Reconstruct Loss = 0.0222, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9186, Reg Loss = 608.1204, Reconstruct Loss = 0.0197, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9190, Reg Loss = 604.7147, Reconstruct Loss = 0.0197, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9244, Reg Loss = 602.3713, Reconstruct Loss = 0.0246, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9219, Reg Loss = 597.8431, Reconstruct Loss = 0.0226, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9225, Reg Loss = 595.2506, Reconstruct Loss = 0.0234, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9216, Reg Loss = 590.5806, Reconstruct Loss = 0.0229, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9212, Reg Loss = 584.9077, Reconstruct Loss = 0.0224, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9187, Reg Loss = 579.0214, Reconstruct Loss = 0.0210, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9182, Reg Loss = 573.5589, Reconstruct Loss = 0.0206, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9176, Reg Loss = 568.5940, Reconstruct Loss = 0.0202, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9162, Reg Loss = 563.0026, Reconstruct Loss = 0.0198, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9161, Reg Loss = 557.7741, Reconstruct Loss = 0.0207, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9152, Reg Loss = 552.0976, Reconstruct Loss = 0.0202, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9149, Reg Loss = 545.5214, Reconstruct Loss = 0.0198, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9131, Reg Loss = 538.8286, Reconstruct Loss = 0.0189, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9117, Reg Loss = 530.2812, Reconstruct Loss = 0.0181, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9092, Reg Loss = 515.3165, Reconstruct Loss = 0.0174, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9072, Reg Loss = 498.8511, Reconstruct Loss = 0.0167, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9048, Reg Loss = 482.7219, Reconstruct Loss = 0.0162, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9027, Reg Loss = 466.6457, Reconstruct Loss = 0.0157, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9008, Reg Loss = 451.6461, Reconstruct Loss = 0.0152, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9013, Reg Loss = 450.8881, Reconstruct Loss = 0.0150, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9036, Reg Loss = 467.5213, Reconstruct Loss = 0.0156, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Epoch [26/30], Training Loss: 1.9039, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8574, Reg Loss = 939.6350, Reconstruct Loss = 0.0000, Cls Loss = 1.7634, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9283, Reg Loss = 984.1207, Reconstruct Loss = 0.0000, Cls Loss = 1.8299, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9477, Reg Loss = 970.0901, Reconstruct Loss = 0.0153, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9524, Reg Loss = 951.4831, Reconstruct Loss = 0.0204, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9608, Reg Loss = 934.5090, Reconstruct Loss = 0.0294, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9522, Reg Loss = 917.4851, Reconstruct Loss = 0.0235, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9521, Reg Loss = 900.4879, Reconstruct Loss = 0.0239, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9450, Reg Loss = 879.0285, Reconstruct Loss = 0.0205, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9401, Reg Loss = 851.7633, Reconstruct Loss = 0.0180, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9404, Reg Loss = 828.0577, Reconstruct Loss = 0.0186, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9368, Reg Loss = 807.8701, Reconstruct Loss = 0.0167, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9360, Reg Loss = 789.9991, Reconstruct Loss = 0.0172, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9327, Reg Loss = 773.3865, Reconstruct Loss = 0.0158, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9300, Reg Loss = 759.1721, Reconstruct Loss = 0.0145, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9298, Reg Loss = 743.1492, Reconstruct Loss = 0.0161, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9273, Reg Loss = 725.5759, Reconstruct Loss = 0.0159, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9251, Reg Loss = 701.3234, Reconstruct Loss = 0.0159, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9217, Reg Loss = 669.0867, Reconstruct Loss = 0.0153, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9174, Reg Loss = 637.5477, Reconstruct Loss = 0.0145, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9138, Reg Loss = 610.4596, Reconstruct Loss = 0.0138, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9103, Reg Loss = 580.9870, Reconstruct Loss = 0.0132, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9082, Reg Loss = 564.3814, Reconstruct Loss = 0.0126, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9065, Reg Loss = 550.4108, Reconstruct Loss = 0.0122, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9043, Reg Loss = 532.8210, Reconstruct Loss = 0.0117, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9021, Reg Loss = 513.7664, Reconstruct Loss = 0.0112, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9003, Reg Loss = 494.3279, Reconstruct Loss = 0.0107, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8985, Reg Loss = 476.7300, Reconstruct Loss = 0.0104, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8970, Reg Loss = 465.9310, Reconstruct Loss = 0.0100, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8962, Reg Loss = 459.8294, Reconstruct Loss = 0.0096, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8953, Reg Loss = 452.6846, Reconstruct Loss = 0.0095, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8945, Reg Loss = 444.0991, Reconstruct Loss = 0.0095, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8933, Reg Loss = 434.2931, Reconstruct Loss = 0.0093, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Epoch [27/30], Training Loss: 1.8933, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Validation Loss: 1.8076, Validation Accuracy: 75.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8417, Reg Loss = 97.1367, Reconstruct Loss = 0.0000, Cls Loss = 1.8320, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8492, Reg Loss = 73.3950, Reconstruct Loss = 0.0033, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8448, Reg Loss = 51.6043, Reconstruct Loss = 0.0017, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8521, Reg Loss = 68.2463, Reconstruct Loss = 0.0016, Cls Loss = 1.8437, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8568, Reg Loss = 122.1065, Reconstruct Loss = 0.0025, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8586, Reg Loss = 144.2946, Reconstruct Loss = 0.0020, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8599, Reg Loss = 151.4448, Reconstruct Loss = 0.0022, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8591, Reg Loss = 149.9013, Reconstruct Loss = 0.0019, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8599, Reg Loss = 143.0714, Reconstruct Loss = 0.0021, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8592, Reg Loss = 133.5978, Reconstruct Loss = 0.0019, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8651, Reg Loss = 176.3536, Reconstruct Loss = 0.0036, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8689, Reg Loss = 220.6810, Reconstruct Loss = 0.0033, Cls Loss = 1.8436, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8728, Reg Loss = 252.3982, Reconstruct Loss = 0.0047, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8740, Reg Loss = 274.7618, Reconstruct Loss = 0.0044, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8751, Reg Loss = 291.7013, Reconstruct Loss = 0.0040, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8774, Reg Loss = 304.0152, Reconstruct Loss = 0.0056, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8777, Reg Loss = 311.6439, Reconstruct Loss = 0.0052, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8789, Reg Loss = 315.7391, Reconstruct Loss = 0.0061, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8788, Reg Loss = 315.6755, Reconstruct Loss = 0.0064, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8775, Reg Loss = 309.6557, Reconstruct Loss = 0.0061, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8762, Reg Loss = 297.6199, Reconstruct Loss = 0.0059, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8748, Reg Loss = 285.8994, Reconstruct Loss = 0.0057, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8744, Reg Loss = 279.9574, Reconstruct Loss = 0.0054, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8858, Reg Loss = 319.9333, Reconstruct Loss = 0.0127, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8926, Reg Loss = 358.7165, Reconstruct Loss = 0.0156, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8981, Reg Loss = 391.3383, Reconstruct Loss = 0.0179, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9001, Reg Loss = 417.9880, Reconstruct Loss = 0.0172, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9037, Reg Loss = 439.4741, Reconstruct Loss = 0.0185, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9063, Reg Loss = 457.4574, Reconstruct Loss = 0.0195, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9081, Reg Loss = 470.0400, Reconstruct Loss = 0.0199, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9080, Reg Loss = 477.9877, Reconstruct Loss = 0.0193, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9088, Reg Loss = 482.2016, Reconstruct Loss = 0.0194, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Epoch [28/30], Training Loss: 1.9088, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8648, Reg Loss = 563.9139, Reconstruct Loss = 0.0000, Cls Loss = 1.8084, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9200, Reg Loss = 468.8978, Reconstruct Loss = 0.0314, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8935, Reg Loss = 350.3806, Reconstruct Loss = 0.0177, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8832, Reg Loss = 279.2663, Reconstruct Loss = 0.0135, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8753, Reg Loss = 233.7104, Reconstruct Loss = 0.0101, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8677, Reg Loss = 198.1575, Reconstruct Loss = 0.0084, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9740, Reg Loss = 397.5273, Reconstruct Loss = 0.0157, Cls Loss = 1.9185, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.1411, Reg Loss = 707.1331, Reconstruct Loss = 0.1625, Cls Loss = 1.9079, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.1328, Reg Loss = 911.4061, Reconstruct Loss = 0.1422, Cls Loss = 1.8994, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.1254, Reg Loss = 1057.5497, Reconstruct Loss = 0.1265, Cls Loss = 1.8932, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.1377, Reg Loss = 1154.0680, Reconstruct Loss = 0.1346, Cls Loss = 1.8876, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.1278, Reg Loss = 1219.4430, Reconstruct Loss = 0.1224, Cls Loss = 1.8834, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.1194, Reg Loss = 1273.6041, Reconstruct Loss = 0.1123, Cls Loss = 1.8798, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.1352, Reg Loss = 1309.6807, Reconstruct Loss = 0.1271, Cls Loss = 1.8771, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.1342, Reg Loss = 1328.2221, Reconstruct Loss = 0.1269, Cls Loss = 1.8744, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.1248, Reg Loss = 1342.1712, Reconstruct Loss = 0.1185, Cls Loss = 1.8721, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.1231, Reg Loss = 1351.5066, Reconstruct Loss = 0.1178, Cls Loss = 1.8702, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.1257, Reg Loss = 1354.0827, Reconstruct Loss = 0.1217, Cls Loss = 1.8686, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.1173, Reg Loss = 1352.5547, Reconstruct Loss = 0.1150, Cls Loss = 1.8671, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.1096, Reg Loss = 1349.5682, Reconstruct Loss = 0.1089, Cls Loss = 1.8658, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.1063, Reg Loss = 1345.1652, Reconstruct Loss = 0.1073, Cls Loss = 1.8646, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.1026, Reg Loss = 1338.4443, Reconstruct Loss = 0.1056, Cls Loss = 1.8632, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.0990, Reg Loss = 1330.4614, Reconstruct Loss = 0.1037, Cls Loss = 1.8622, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.0949, Reg Loss = 1320.1596, Reconstruct Loss = 0.1018, Cls Loss = 1.8610, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.0932, Reg Loss = 1311.8566, Reconstruct Loss = 0.1022, Cls Loss = 1.8599, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.0877, Reg Loss = 1301.6930, Reconstruct Loss = 0.0981, Cls Loss = 1.8595, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.0840, Reg Loss = 1290.0545, Reconstruct Loss = 0.0962, Cls Loss = 1.8588, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.0802, Reg Loss = 1278.1679, Reconstruct Loss = 0.0943, Cls Loss = 1.8581, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0781, Reg Loss = 1266.7842, Reconstruct Loss = 0.0940, Cls Loss = 1.8574, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0731, Reg Loss = 1254.8258, Reconstruct Loss = 0.0908, Cls Loss = 1.8569, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0694, Reg Loss = 1243.4630, Reconstruct Loss = 0.0890, Cls Loss = 1.8561, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0650, Reg Loss = 1231.5699, Reconstruct Loss = 0.0862, Cls Loss = 1.8557, Learning rate = 1.0000e-03\n",
      "Epoch [29/30], Training Loss: 2.0642, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9417, Reg Loss = 876.1196, Reconstruct Loss = 0.0000, Cls Loss = 1.8541, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9381, Reg Loss = 903.8365, Reconstruct Loss = 0.0000, Cls Loss = 1.8477, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9498, Reg Loss = 881.3015, Reconstruct Loss = 0.0166, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9608, Reg Loss = 872.7463, Reconstruct Loss = 0.0323, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9513, Reg Loss = 864.1017, Reconstruct Loss = 0.0243, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9517, Reg Loss = 848.8964, Reconstruct Loss = 0.0252, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9454, Reg Loss = 836.9960, Reconstruct Loss = 0.0210, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9480, Reg Loss = 827.0987, Reconstruct Loss = 0.0255, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9442, Reg Loss = 817.7058, Reconstruct Loss = 0.0223, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9412, Reg Loss = 807.0462, Reconstruct Loss = 0.0199, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9408, Reg Loss = 798.2169, Reconstruct Loss = 0.0202, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9396, Reg Loss = 785.5648, Reconstruct Loss = 0.0204, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9378, Reg Loss = 775.1576, Reconstruct Loss = 0.0204, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9363, Reg Loss = 763.9224, Reconstruct Loss = 0.0203, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9345, Reg Loss = 753.6308, Reconstruct Loss = 0.0189, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9328, Reg Loss = 742.1050, Reconstruct Loss = 0.0187, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9319, Reg Loss = 730.2587, Reconstruct Loss = 0.0185, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9301, Reg Loss = 716.4716, Reconstruct Loss = 0.0182, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9290, Reg Loss = 702.5180, Reconstruct Loss = 0.0184, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9262, Reg Loss = 686.5624, Reconstruct Loss = 0.0174, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9237, Reg Loss = 669.2883, Reconstruct Loss = 0.0166, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9215, Reg Loss = 649.9940, Reconstruct Loss = 0.0160, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9186, Reg Loss = 627.0629, Reconstruct Loss = 0.0154, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9426, Reg Loss = 613.9785, Reconstruct Loss = 0.0149, Cls Loss = 1.8663, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9436, Reg Loss = 640.9643, Reconstruct Loss = 0.0143, Cls Loss = 1.8652, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9449, Reg Loss = 670.7610, Reconstruct Loss = 0.0137, Cls Loss = 1.8641, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9459, Reg Loss = 695.6400, Reconstruct Loss = 0.0132, Cls Loss = 1.8632, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9485, Reg Loss = 712.6360, Reconstruct Loss = 0.0148, Cls Loss = 1.8624, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9525, Reg Loss = 725.6020, Reconstruct Loss = 0.0180, Cls Loss = 1.8619, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9522, Reg Loss = 737.8849, Reconstruct Loss = 0.0174, Cls Loss = 1.8610, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9552, Reg Loss = 747.6968, Reconstruct Loss = 0.0200, Cls Loss = 1.8604, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9549, Reg Loss = 756.6659, Reconstruct Loss = 0.0194, Cls Loss = 1.8598, Learning rate = 1.0000e-03\n",
      "Epoch [30/30], Training Loss: 1.9548, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the epochs\n",
    "for epoch in range(start_epoch, args.experiment.num_epochs):\n",
    "    # Train the hypernetwork to generate a model with random dimension for one epoch\n",
    "    train_loss, dim_dict, gt_model_dict = train_one_epoch(hyper_model, train_loader, optimizer, criterion, \n",
    "                                                          dim_dict, gt_model_dict, epoch_idx=epoch, ema=ema, \n",
    "                                                          args=args, device=device)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the training loss and learning rate\n",
    "    print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Training Loss: {train_loss:.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # If it's time to evaluate the model\n",
    "    if (epoch + 1) % args.experiment.eval_interval == 0:\n",
    "        # Apply EMA if it is specified\n",
    "        if ema:\n",
    "            ema.apply()  # Save the weights of original model created before training_loop\n",
    "        \n",
    "        # Sample the merged model (create model of same structure before training loop by using the hypernetwork)\n",
    "        # And then test the performance of the hypernetwork by seeing how good it is in generating the weights\n",
    "        model = sample_merge_model(hyper_model, model, args) \n",
    "        # Validate the merged model\n",
    "        val_loss, acc = validate_single(model, val_loader, val_criterion, args=args)\n",
    "\n",
    "        # If EMA is specified, restore the original weights\n",
    "        if ema:\n",
    "            ema.restore()  # Restore the original weights to the weights of the pretrained networks\n",
    "\n",
    "        # Log the validation loss and accuracy to wandb\n",
    "        wandb.log({\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": acc\n",
    "        })\n",
    "        # Print the validation loss and accuracy\n",
    "        print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Save the checkpoint if the accuracy is better than the previous best\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_checkpoint(f\"{args.training.save_model_path}/cifar10_nerf_best.pth\",hyper_model,optimizer,ema,epoch,best_acc)\n",
    "            print(f\"Checkpoint saved at epoch {epoch} with accuracy: {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15464fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁█▃▁▁▁▁▁</td></tr><tr><td>Learning rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss</td><td>▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▃▂▂▂▃▃▂▂▃▅▃▃▃▃▃█▄▃██▄</td></tr><tr><td>Reconstruct Loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▁▁▂▂▂▂▂▁▂▂▃▃▂▂█</td></tr><tr><td>Reg Loss</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▃▅▂▃▂▁▃▃▃▅▅▅▅▄▂▃▅▄▅▅█▆▄▃▄▇▆▇</td></tr><tr><td>Validation Accuracy</td><td>█▁▄▄▅▄▅▄▄▅▄▄▅▄▄▄▄▄▅▄▄▄▅▄▄▅▄▅▅▅</td></tr><tr><td>Validation Loss</td><td>▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>1.85983</td></tr><tr><td>Learning rate</td><td>0.001</td></tr><tr><td>Loss</td><td>1.95488</td></tr><tr><td>Reconstruct Loss</td><td>0.01939</td></tr><tr><td>Reg Loss</td><td>756.66594</td></tr><tr><td>Validation Accuracy</td><td>0.7587</td></tr><tr><td>Validation Loss</td><td>1.80759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20250517231104-ninr_resnet20_cifar10_32-64-4layer-5_base_config_smooth</strong> at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/1l8yq1fk' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/1l8yq1fk</a><br> View project at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250517_231104-1l8yq1fk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# End the wandb tracking\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6054a4",
   "metadata": {},
   "source": [
    "### 7 Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa63eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 16\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1403.5904541015625\n",
      "Permuted TV original model: 1321.4053955078125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 16, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 17\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1437.966064453125\n",
      "Permuted TV original model: 1355.92138671875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 17, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 18\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1491.4425048828125\n",
      "Permuted TV original model: 1407.7166748046875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 18, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 19\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1533.149169921875\n",
      "Permuted TV original model: 1449.4130859375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 19, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 20\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1571.125\n",
      "Permuted TV original model: 1487.2523193359375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 20, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 21\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1634.4669189453125\n",
      "Permuted TV original model: 1542.9979248046875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 21, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 22\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1683.61279296875\n",
      "Permuted TV original model: 1594.992919921875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 22, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 23\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1734.969482421875\n",
      "Permuted TV original model: 1636.70703125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 23, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 24\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1775.599609375\n",
      "Permuted TV original model: 1686.9532470703125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 24, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 25\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1830.3165283203125\n",
      "Permuted TV original model: 1735.0860595703125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 25, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 26\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1863.4813232421875\n",
      "Permuted TV original model: 1761.3270263671875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 26, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 27\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1929.5203857421875\n",
      "Permuted TV original model: 1824.9422607421875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 27, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 28\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1964.221435546875\n",
      "Permuted TV original model: 1863.82666015625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 28, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 29\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2009.0\n",
      "Permuted TV original model: 1893.9039306640625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 29, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 30\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2035.8050537109375\n",
      "Permuted TV original model: 1933.3792724609375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 30, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 31\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2098.512939453125\n",
      "Permuted TV original model: 1982.5570068359375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 31, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2135.1767578125\n",
      "Permuted TV original model: 2024.0760498046875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 32, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2185.2470703125\n",
      "Permuted TV original model: 2078.019287109375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 33, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2221.3037109375\n",
      "Permuted TV original model: 2111.09033203125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 34, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2273.787353515625\n",
      "Permuted TV original model: 2160.994384765625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 35, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2319.2021484375\n",
      "Permuted TV original model: 2204.53857421875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 36, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2356.9912109375\n",
      "Permuted TV original model: 2249.363037109375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 37, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2417.119384765625\n",
      "Permuted TV original model: 2298.629150390625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 38, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2477.6396484375\n",
      "Permuted TV original model: 2360.841552734375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 39, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2515.3369140625\n",
      "Permuted TV original model: 2395.062744140625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 40, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2582.225341796875\n",
      "Permuted TV original model: 2457.74462890625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 41, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2590.4072265625\n",
      "Permuted TV original model: 2461.732666015625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 42, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2638.572265625\n",
      "Permuted TV original model: 2503.781494140625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 43, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2689.839599609375\n",
      "Permuted TV original model: 2563.989013671875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 44, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2754.7158203125\n",
      "Permuted TV original model: 2619.078857421875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 45, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2769.814208984375\n",
      "Permuted TV original model: 2634.531982421875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 46, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2830.683349609375\n",
      "Permuted TV original model: 2695.168212890625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 47, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2879.109375\n",
      "Permuted TV original model: 2739.24169921875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 48, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2937.005859375\n",
      "Permuted TV original model: 2791.198486328125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 49, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2981.18896484375\n",
      "Permuted TV original model: 2831.489990234375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 50, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3031.9580078125\n",
      "Permuted TV original model: 2883.512939453125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 51, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3041.26416015625\n",
      "Permuted TV original model: 2896.890380859375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 52, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3101.94775390625\n",
      "Permuted TV original model: 2958.65234375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 53, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3159.317138671875\n",
      "Permuted TV original model: 3008.412353515625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': True}: hidden_dim 54, Validation Loss: 1.8076, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3201.5205078125\n",
      "Permuted TV original model: 3057.19140625\n",
      "Applying EMA\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in range(16, 65):\n",
    "    # Create a model for this given dimension\n",
    "    model = create_model(args.model.type,\n",
    "                         hidden_dim=hidden_dim,\n",
    "                         path=args.model.pretrained_path,\n",
    "                         smooth=args.model.smooth).to(device)\n",
    "    \n",
    "    # If EMA is specified, apply it\n",
    "    if ema:\n",
    "        print('Applying EMA')\n",
    "        ema.apply()\n",
    "\n",
    "    # Sample the merged model\n",
    "    accumulated_model = sample_merge_model(hyper_model, model, args, K=100)\n",
    "\n",
    "    # Validate the merged model\n",
    "    val_loss, acc = validate_single(accumulated_model, val_loader, val_criterion, args=args)\n",
    "\n",
    "    # If EMA is specified, restore the original weights after applying EMA\n",
    "    if ema:\n",
    "        ema.restore()  # Restore the original weights after applying \n",
    "        \n",
    "    # Save the model\n",
    "    save_name = os.path.join(args.training.save_model_path, f\"cifar10_{accumulated_model.__class__.__name__}_dim{hidden_dim}_single.pth\")\n",
    "    torch.save(accumulated_model.state_dict(),save_name)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test using model {args.model}: hidden_dim {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Define the directory and filename structure\n",
    "    filename = f\"cifar10_results_{args.experiment.name}.txt\"\n",
    "    filepath = os.path.join(args.training.save_model_path, filename)\n",
    "\n",
    "    # Write the results. 'a' is used to append the results; a new file will be created if it doesn't exist.\n",
    "    with open(filepath, \"a\") as file:\n",
    "        file.write(f\"Hidden_dim: {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
