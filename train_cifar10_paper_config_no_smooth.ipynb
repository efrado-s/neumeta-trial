{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4faf3c9",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7f334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e39782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe9dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_model_cifar10 as create_model\n",
    "from neumeta.utils import (\n",
    "    parse_args, print_omegaconf,\n",
    "    load_checkpoint, save_checkpoint,\n",
    "    set_seed,\n",
    "    get_cifar10, \n",
    "    sample_coordinates, sample_subset, shuffle_coordinates_all,\n",
    "    get_hypernetwork, get_optimizer, \n",
    "    sample_weights,\n",
    "    weighted_regression_loss, validate_single, AverageMeter, EMA,\n",
    "    sample_single_model, sample_merge_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cea0a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad05e8",
   "metadata": {},
   "source": [
    "### 1 Find maximum dimension of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504abeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dim(model_cls):\n",
    "    \"\"\"Find maximum dimension of the model\"\"\"\n",
    "    # Get the learnable parameters of the model\n",
    "    checkpoint = model_cls.learnable_parameter \n",
    "\n",
    "    # Set the maximum value to the length of the checkpoint\n",
    "    max_value = len(checkpoint)\n",
    "\n",
    "    # Iterate over the new model's weight\n",
    "    for i, (k, tensor) in enumerate(checkpoint.items()):\n",
    "        # Handle 2D tensors (e.g., weight matrices) \n",
    "        if len(tensor.shape) == 4:\n",
    "            coords = [tensor.shape[0], tensor.shape[1]]\n",
    "            max_value = max(max_value, max(coords))\n",
    "        # Handle 1D tensors (e.g., biases)\n",
    "        elif len(tensor.shape) == 1:\n",
    "            max_value = max(max_value, tensor.shape[0])\n",
    "    \n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413443e",
   "metadata": {},
   "source": [
    "### 2 Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f49acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(config):\n",
    "    import time\n",
    "    \"\"\"\n",
    "    Initializes Weights and Biases (wandb) with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        configuration (dict): Configuration parameters for the run.\n",
    "    \"\"\"\n",
    "    # Name the run using current time and configuration name\n",
    "    run_name = f\"{time.strftime('%Y%m%d%H%M%S')}-{config.experiment.name}\"\n",
    "    \n",
    "    wandb.init(project=\"ninr-trial\", name=run_name, config=dict(config), group='cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cc73b",
   "metadata": {},
   "source": [
    "### 3 Initialize model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed520bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(args, device):\n",
    "    \"\"\"\n",
    "    Initializes a dictionary of models for each dimension in the given range, along with ground truth models for the starting dimension.\n",
    "\n",
    "    Args:\n",
    "        args: An object containing the arguments for initializing the models.\n",
    "\n",
    "    Returns:\n",
    "        dim_dict: A dictionary containing the models for each dimension, along with their corresponding coordinates, keys, indices, size, and ground truth models.\n",
    "        gt_model_dict: A dictionary containing the ground truth models for the starting dimension.\n",
    "    \"\"\"\n",
    "    dim_dict = {}\n",
    "    gt_model_dict = {}\n",
    "    \n",
    "    # Create a model for each dimension in dimensions range\n",
    "    for dim in args.dimensions.range:\n",
    "        model_cls = create_model(args.model.type,\n",
    "                                 hidden_dim=dim,\n",
    "                                 path=args.model.pretrained_path,\n",
    "                                 smooth=args.model.smooth).to(device)\n",
    "        # Sample the coordinates, keys, indices, and the size for the model\n",
    "        coords_tensor, keys_list, indices_list, size_list = sample_coordinates(model_cls)\n",
    "        # Add the model, coordinates, keys, indices, size, and key mask to the dictionary\n",
    "        dim_dict[f\"{dim}\"] = (model_cls, coords_tensor, keys_list, indices_list, size_list, None)\n",
    "\n",
    "        # Print to makes line better\n",
    "        print('\\n')\n",
    "        \n",
    "        # If the dimension is the starting dimension (the dimension of pretrained_model), add the ground truth model to the dictionary\n",
    "        if dim == args.dimensions.start:\n",
    "            print(f\"Loading model for dim {dim}\")\n",
    "            model_trained = create_model(args.model.type, \n",
    "                                         hidden_dim=dim, \n",
    "                                         path=args.model.pretrained_path, \n",
    "                                         smooth=args.model.smooth).to(device)\n",
    "            model_trained.eval()\n",
    "            gt_model_dict[f'{dim}'] = model_trained\n",
    "\n",
    "    \n",
    "    return dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b8aa0",
   "metadata": {},
   "source": [
    "### 4 Training function for target model of a random dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab93eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, dim_dict, gt_model_dict, epoch_idx, ema=None, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    reconstruct_losses = AverageMeter()\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Preprocess input\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Move the data to the device\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # Choose a random hidden dimension\n",
    "        hidden_dim = random.choice(args.dimensions.range)\n",
    "        # Get the model class, coordinates, keys, indices, size, and key mask for the chosen dimension\n",
    "        model_cls, coords_tensor, keys_list, indices_list, size_list, key_mask = dim_dict[f\"{hidden_dim}\"]\n",
    "        # Sample a subset the input tensor of the coordinates, keys, indices, size, and selected keys\n",
    "        coords_tensor, keys_list, indices_list, size_list, selected_keys = sample_subset(coords_tensor,\n",
    "                                                                                         keys_list,\n",
    "                                                                                         indices_list,\n",
    "                                                                                         size_list,\n",
    "                                                                                         key_mask,\n",
    "                                                                                         ratio=args.ratio)\n",
    "        # Add noise to the coordinates if specified\n",
    "        if args.training.coordinate_noise > 0.0:\n",
    "            coords_tensor = coords_tensor + (torch.rand_like(coords_tensor) - 0.5) * args.training.coordinate_noise\n",
    "\n",
    "\n",
    "        # Main task of hypernetwork and target network\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Sample the weights for the target model using hypernetwork\n",
    "        model_cls, reconstructed_weights = sample_weights(model, model_cls,\n",
    "                                                          coords_tensor, keys_list, indices_list, size_list, key_mask, selected_keys,\n",
    "                                                          device=device, NORM=args.dimensions.norm)\n",
    "        # Forward pass\n",
    "        predict = model_cls(x)\n",
    "\n",
    "\n",
    "        # Compute losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Compute classification loss\n",
    "        cls_loss = criterion(predict, target) \n",
    "        # Compute regularization loss\n",
    "        reg_loss = sum([torch.norm(w, p=2) for w in reconstructed_weights])\n",
    "        # Compute reconstruction loss if ground truth model is available\n",
    "        if f\"{hidden_dim}\" in gt_model_dict:\n",
    "            gt_model = gt_model_dict[f\"{hidden_dim}\"]\n",
    "            gt_selected_weights = [\n",
    "                w for k, w in gt_model.learnable_parameter.items() if k in selected_keys]\n",
    "\n",
    "            reconstruct_loss = weighted_regression_loss(\n",
    "                reconstructed_weights, gt_selected_weights)\n",
    "        else:\n",
    "            reconstruct_loss = torch.tensor(0.0)\n",
    "        # Compute the total loss\n",
    "        loss = args.hyper_model.loss_weight.ce_weight * cls_loss + args.hyper_model.loss_weight.reg_weight * \\\n",
    "            reg_loss + args.hyper_model.loss_weight.recon_weight * reconstruct_loss\n",
    "\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Zero the gradients of the updated weights\n",
    "        for updated_weight in model_cls.parameters():\n",
    "            updated_weight.grad = None\n",
    "\n",
    "        # Compute the gradients of the reconstructed weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.autograd.backward(reconstructed_weights, [\n",
    "                                w.grad for k, w in model_cls.named_parameters() if k in selected_keys])\n",
    "        \n",
    "        # Clip the gradients if specified\n",
    "        if args.training.get('clip_grad', 0.0) > 0:\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), args.training.clip_grad)\n",
    "            \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA if specified\n",
    "        if ema:\n",
    "            ema.update()  # Update the EMA after each training step\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update the AverageMeter objects\n",
    "        losses.update(loss.item())\n",
    "        cls_losses.update(cls_loss.item())\n",
    "        reg_losses.update(reg_loss.item())\n",
    "        reconstruct_losses.update(reconstruct_loss.item())\n",
    "\n",
    "\n",
    "        # Log (or plot) losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Log the losses and learning rate to wandb\n",
    "        if batch_idx % args.experiment.log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"Loss\": losses.avg,\n",
    "                \"Cls Loss\": cls_losses.avg,\n",
    "                \"Reg Loss\": reg_losses.avg,\n",
    "                \"Reconstruct Loss\": reconstruct_losses.avg,\n",
    "                \"Learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }, step=batch_idx + epoch_idx * len(train_loader))\n",
    "            # Print the losses and learning rate\n",
    "            print(\n",
    "                f\"Iteration {batch_idx}: Loss = {losses.avg:.4f}, Reg Loss = {reg_losses.avg:.4f}, Reconstruct Loss = {reconstruct_losses.avg:.4f}, Cls Loss = {cls_losses.avg:.4f}, Learning rate = {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "    \n",
    "    # Returns the training loss, structure of network in each dimension, and the original structure of pretrained network\n",
    "    return losses.avg, dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d8965",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e292aae",
   "metadata": {},
   "source": [
    "### 0 Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670c10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd9af3",
   "metadata": {},
   "source": [
    "### 1 Parsing arguments for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = 'neumeta/config/paper_config/resnet20_cifar10_paper_config_no_smooth.yaml'\n",
    "RATIO = '1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6fd9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv_train = ['--config', CONFIG_PATH, '--ratio', RATIO]\n",
    "argv_test = ['--config', CONFIG_PATH, '--test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebf601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                 Key                  |                                                                Value                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|           experiment.name            |                                                resnet20_cifar10_base_config_layers_5                                                 |\n",
      "|         experiment.recononly         |                                                                  0                                                                   |\n",
      "|        experiment.num_epochs         |                                                                  30                                                                  |\n",
      "|       experiment.log_interval        |                                                                  25                                                                  |\n",
      "|       experiment.eval_interval       |                                                                  1                                                                   |\n",
      "|           experiment.seed            |                                                                  42                                                                  |\n",
      "|              model.type              |                                                               ResNet20                                                               |\n",
      "|        model.pretrained_path         |                                                         resnet20-12fca82f.th                                                         |\n",
      "|             model.smooth             |                                                                False                                                                 |\n",
      "|        training.learning_rate        |                                                                0.001                                                                 |\n",
      "|         training.batch_size          |                                                                  64                                                                  |\n",
      "|      training.coordinate_noise       |                                                                 0.0                                                                  |\n",
      "|          training.lr_steps           |                                                              [100, 150]                                                              |\n",
      "|        training.weight_decay         |                                                                 0.01                                                                 |\n",
      "|          training.clip_grad          |                                                                 10.0                                                                 |\n",
      "|       training.save_model_path       |                                        toy/experiments/resnet20_cifar10_base_config_layers_5                                         |\n",
      "|        hyper_model.input_dim         |                                                                  6                                                                   |\n",
      "|        hyper_model.hidden_dim        |                                                                 256                                                                  |\n",
      "|        hyper_model.num_layers        |                                                                  5                                                                   |\n",
      "|        hyper_model.num_freqs         |                                                                  16                                                                  |\n",
      "|        hyper_model.output_dim        |                                                                  9                                                                   |\n",
      "|        hyper_model.ema_decay         |                                                                0.995                                                                 |\n",
      "|  hyper_model.loss_weight.ce_weight   |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.reg_weight  |                                                                0.0001                                                                |\n",
      "| hyper_model.loss_weight.recon_weight |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.kd_weight   |                                                                 0.1                                                                  |\n",
      "|           dimensions.range           | [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64] |\n",
      "|           dimensions.test            |                                                                  32                                                                  |\n",
      "|           dimensions.norm            |                                                                  64                                                                  |\n",
      "|           dimensions.start           |                                                                  64                                                                  |\n",
      "|                config                |                                               neumeta/config/base_config_layers_5.yaml                                               |\n",
      "|                ratio                 |                                                                 1.0                                                                  |\n",
      "|             resume_from              |                                                                 None                                                                 |\n",
      "|              load_from               |                                                                 None                                                                 |\n",
      "|           test_result_path           |                                                                 None                                                                 |\n",
      "|                 test                 |                                                                False                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(argv_train)  # Parse arguments\n",
    "print_omegaconf(args)  # Print arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84954fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed... 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.experiment.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2086b8",
   "metadata": {},
   "source": [
    "### 2 Get training and validation data (in dataloader format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633b90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10(args.training.batch_size, strong_transform=args.training.get('strong_aug', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685e32a",
   "metadata": {},
   "source": [
    "### 3 Create target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d8f75",
   "metadata": {},
   "source": [
    "#### 3.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47436d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args.model.type,\n",
    "                     hidden_dim=args.dimensions.start,\n",
    "                     path=args.model.pretrained_path,\n",
    "                     smooth=args.model.smooth).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb133f",
   "metadata": {},
   "source": [
    "#### 3.1 Print the structure and shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09f9614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): Identity()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock_Resize(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b86d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3.2.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv1.bias torch.Size([64])\n",
      "layer3.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, (k, tensor) in enumerate(model.learnable_parameter.items()):\n",
    "    print(k, tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f7b45",
   "metadata": {},
   "source": [
    "#### 3.2 The maximum dimension of the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad8c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum DIM: 64\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum dimension of the model\n",
    "print(f'Maximum DIM: {find_max_dim(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195929e",
   "metadata": {},
   "source": [
    "#### 3.3 Validate the accuracy of pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d75f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.2825, Validation Accuracy: 92.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(model, val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb61dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learnable parameters of the model\n",
    "checkpoint = model.learnable_parameter\n",
    "# Get the number of parameters\n",
    "number_param = len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2fe99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters keys: ['layer3.2.conv1.weight', 'layer3.2.conv1.bias', 'layer3.2.conv2.weight', 'layer3.2.conv2.bias']\n",
      "Number of parameters to be learned: 4\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the parameters and the number of parameters\n",
    "print(f\"Parameters keys: {model.keys}\")\n",
    "print(f\"Number of parameters to be learned: {number_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5fa6f",
   "metadata": {},
   "source": [
    "### 4 Create the hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa4a2f",
   "metadata": {},
   "source": [
    "#### 4.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82e9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: mlp\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Get the hypermodel\n",
    "hyper_model = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297bd73",
   "metadata": {},
   "source": [
    "#### 4.1 Print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903829b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_MLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-3): 4 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d592e",
   "metadata": {},
   "source": [
    "#### 4.2 Initialize EMA to track only a smooth version of the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a4812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA\n",
    "ema = EMA(hyper_model, decay=args.hyper_model.ema_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffae0",
   "metadata": {},
   "source": [
    "### 5 Get Loss function, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079aa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, val_criterion, optimizer, scheduler = get_optimizer(args, hyper_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7561c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Val_criterion: CrossEntropyLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001BD398F5B50>\n"
     ]
    }
   ],
   "source": [
    "print(f'Criterion: {criterion}\\nVal_criterion: {val_criterion}\\nOptimizer: {optimizer}\\nScheduler: {scheduler}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906454",
   "metadata": {},
   "source": [
    "### 6 Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d1d4f",
   "metadata": {},
   "source": [
    "#### 6.1 Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2cdca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting epoch and best accuracy\n",
    "start_epoch = 0\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373217",
   "metadata": {},
   "source": [
    "#### 6.2 Directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35a2746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the model\n",
    "os.makedirs(args.training.save_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504af23",
   "metadata": {},
   "source": [
    "#### 6.3 Resume training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "714db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_from:\n",
    "        print(f\"Resuming from checkpoint: {args.resume_from}\")\n",
    "        checkpoint_info = load_checkpoint(args.resume_from, hyper_model, optimizer, ema)\n",
    "        start_epoch = checkpoint_info['epoch']\n",
    "        best_acc = checkpoint_info['best_acc']\n",
    "        print(f\"Resuming from epoch: {start_epoch}, best accuracy: {best_acc*100:.2f}%\")\n",
    "        # Note: If there are more elements to retrieve, do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a3248",
   "metadata": {},
   "source": [
    "#### 6.4 Initialize wandb for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9fd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mefradosuryadi\u001b[0m (\u001b[33mefradosuryadi-universitas-indonesia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\wandb\\run-20250519_015023-rkywguw2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/rkywguw2' target=\"_blank\">20250519015022-resnet20_cifar10_base_config_layers_5</a></strong> to <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/rkywguw2' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/rkywguw2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "initialize_wandb(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46056e65",
   "metadata": {},
   "source": [
    "#### 6.5 Initialize model dictionary for each dimension and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641149b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "\n",
      "\n",
      "Loading model for dim 64\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n"
     ]
    }
   ],
   "source": [
    "# Initialize model dictionary\n",
    "dim_dict, gt_model_dict = init_model_dict(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d01d9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'64': CifarResNet(\n",
       "   (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn1): Identity()\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock_Resize(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26d9c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7476d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict = shuffle_coordinates_all(dim_dict)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d6ad4",
   "metadata": {},
   "source": [
    "#### 6.6 Hypernetwork training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332580b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.experiment.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f486f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 2.0163, Reg Loss = 4.7107, Reconstruct Loss = 0.0000, Cls Loss = 2.0159, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8795, Reg Loss = 12.4346, Reconstruct Loss = 0.0097, Cls Loss = 1.8686, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8603, Reg Loss = 9.1563, Reconstruct Loss = 0.0049, Cls Loss = 1.8544, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8552, Reg Loss = 9.1358, Reconstruct Loss = 0.0033, Cls Loss = 1.8509, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8544, Reg Loss = 10.2045, Reconstruct Loss = 0.0036, Cls Loss = 1.8498, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8520, Reg Loss = 9.5428, Reconstruct Loss = 0.0036, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8504, Reg Loss = 9.9060, Reconstruct Loss = 0.0030, Cls Loss = 1.8464, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8513, Reg Loss = 10.4573, Reconstruct Loss = 0.0029, Cls Loss = 1.8473, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8500, Reg Loss = 10.3219, Reconstruct Loss = 0.0026, Cls Loss = 1.8464, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8484, Reg Loss = 10.0180, Reconstruct Loss = 0.0023, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8485, Reg Loss = 9.5608, Reconstruct Loss = 0.0022, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8480, Reg Loss = 9.2377, Reconstruct Loss = 0.0021, Cls Loss = 1.8449, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8469, Reg Loss = 8.9193, Reconstruct Loss = 0.0020, Cls Loss = 1.8440, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8461, Reg Loss = 8.5059, Reconstruct Loss = 0.0019, Cls Loss = 1.8434, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8456, Reg Loss = 8.1038, Reconstruct Loss = 0.0017, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8457, Reg Loss = 8.8277, Reconstruct Loss = 0.0019, Cls Loss = 1.8429, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8459, Reg Loss = 9.4691, Reconstruct Loss = 0.0019, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8457, Reg Loss = 9.8939, Reconstruct Loss = 0.0019, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8450, Reg Loss = 10.1268, Reconstruct Loss = 0.0018, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8447, Reg Loss = 9.9442, Reconstruct Loss = 0.0017, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8444, Reg Loss = 9.7515, Reconstruct Loss = 0.0016, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8440, Reg Loss = 9.5538, Reconstruct Loss = 0.0016, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8442, Reg Loss = 9.5185, Reconstruct Loss = 0.0015, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8439, Reg Loss = 9.3572, Reconstruct Loss = 0.0015, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8441, Reg Loss = 10.0333, Reconstruct Loss = 0.0014, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8443, Reg Loss = 11.4283, Reconstruct Loss = 0.0014, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8441, Reg Loss = 12.5935, Reconstruct Loss = 0.0013, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8441, Reg Loss = 13.4325, Reconstruct Loss = 0.0013, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8436, Reg Loss = 13.9396, Reconstruct Loss = 0.0012, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8439, Reg Loss = 14.0097, Reconstruct Loss = 0.0012, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8445, Reg Loss = 15.1227, Reconstruct Loss = 0.0018, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8446, Reg Loss = 16.1808, Reconstruct Loss = 0.0018, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Epoch [1/30], Training Loss: 1.8446, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Validation Loss: 1.8041, Validation Accuracy: 79.42%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 0 with accuracy: 79.42%\n",
      "Iteration 0: Loss = 1.8666, Reg Loss = 44.3113, Reconstruct Loss = 0.0000, Cls Loss = 1.8622, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8504, Reg Loss = 36.0703, Reconstruct Loss = 0.0013, Cls Loss = 1.8455, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8449, Reg Loss = 31.6242, Reconstruct Loss = 0.0016, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8534, Reg Loss = 28.0843, Reconstruct Loss = 0.0015, Cls Loss = 1.8491, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8513, Reg Loss = 40.1542, Reconstruct Loss = 0.0011, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8506, Reg Loss = 49.2000, Reconstruct Loss = 0.0009, Cls Loss = 1.8448, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8504, Reg Loss = 54.5608, Reconstruct Loss = 0.0008, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8500, Reg Loss = 57.0793, Reconstruct Loss = 0.0012, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8498, Reg Loss = 57.4402, Reconstruct Loss = 0.0010, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8487, Reg Loss = 57.0038, Reconstruct Loss = 0.0009, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8483, Reg Loss = 55.2161, Reconstruct Loss = 0.0008, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8475, Reg Loss = 51.8583, Reconstruct Loss = 0.0008, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8476, Reg Loss = 52.2670, Reconstruct Loss = 0.0010, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8479, Reg Loss = 53.0386, Reconstruct Loss = 0.0010, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8478, Reg Loss = 53.0981, Reconstruct Loss = 0.0010, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8475, Reg Loss = 52.6762, Reconstruct Loss = 0.0010, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8465, Reg Loss = 52.0317, Reconstruct Loss = 0.0010, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8462, Reg Loss = 51.0858, Reconstruct Loss = 0.0009, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8463, Reg Loss = 49.8568, Reconstruct Loss = 0.0009, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8462, Reg Loss = 48.2924, Reconstruct Loss = 0.0010, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8457, Reg Loss = 46.3859, Reconstruct Loss = 0.0010, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8457, Reg Loss = 44.6175, Reconstruct Loss = 0.0011, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8455, Reg Loss = 43.9095, Reconstruct Loss = 0.0011, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8456, Reg Loss = 45.7863, Reconstruct Loss = 0.0013, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8454, Reg Loss = 47.3880, Reconstruct Loss = 0.0013, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8453, Reg Loss = 48.5268, Reconstruct Loss = 0.0014, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8455, Reg Loss = 49.1575, Reconstruct Loss = 0.0013, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8454, Reg Loss = 49.4441, Reconstruct Loss = 0.0014, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8455, Reg Loss = 49.5264, Reconstruct Loss = 0.0014, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8454, Reg Loss = 49.4030, Reconstruct Loss = 0.0014, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8455, Reg Loss = 49.0933, Reconstruct Loss = 0.0013, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8453, Reg Loss = 48.5809, Reconstruct Loss = 0.0013, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Epoch [2/30], Training Loss: 1.8453, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Validation Loss: 1.8043, Validation Accuracy: 79.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8639, Reg Loss = 29.1370, Reconstruct Loss = 0.0000, Cls Loss = 1.8610, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8391, Reg Loss = 23.6601, Reconstruct Loss = 0.0000, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8406, Reg Loss = 19.0274, Reconstruct Loss = 0.0006, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8427, Reg Loss = 28.2720, Reconstruct Loss = 0.0008, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8439, Reg Loss = 36.0740, Reconstruct Loss = 0.0008, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8443, Reg Loss = 39.6819, Reconstruct Loss = 0.0009, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8442, Reg Loss = 40.7087, Reconstruct Loss = 0.0011, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8443, Reg Loss = 40.1613, Reconstruct Loss = 0.0011, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8445, Reg Loss = 38.5569, Reconstruct Loss = 0.0014, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8440, Reg Loss = 36.0428, Reconstruct Loss = 0.0015, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8433, Reg Loss = 33.7472, Reconstruct Loss = 0.0015, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8433, Reg Loss = 38.5659, Reconstruct Loss = 0.0013, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8444, Reg Loss = 43.1866, Reconstruct Loss = 0.0012, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8448, Reg Loss = 46.3270, Reconstruct Loss = 0.0014, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8448, Reg Loss = 47.6472, Reconstruct Loss = 0.0014, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9016, Reg Loss = 47.2137, Reconstruct Loss = 0.0014, Cls Loss = 1.8955, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9032, Reg Loss = 54.6793, Reconstruct Loss = 0.0056, Cls Loss = 1.8920, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9053, Reg Loss = 61.6670, Reconstruct Loss = 0.0102, Cls Loss = 1.8889, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9023, Reg Loss = 67.3573, Reconstruct Loss = 0.0097, Cls Loss = 1.8859, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8995, Reg Loss = 71.5984, Reconstruct Loss = 0.0091, Cls Loss = 1.8832, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8972, Reg Loss = 75.2364, Reconstruct Loss = 0.0088, Cls Loss = 1.8809, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8948, Reg Loss = 77.4432, Reconstruct Loss = 0.0084, Cls Loss = 1.8786, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8926, Reg Loss = 77.2439, Reconstruct Loss = 0.0080, Cls Loss = 1.8768, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8908, Reg Loss = 75.8648, Reconstruct Loss = 0.0077, Cls Loss = 1.8755, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8893, Reg Loss = 75.6551, Reconstruct Loss = 0.0076, Cls Loss = 1.8741, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8879, Reg Loss = 74.5207, Reconstruct Loss = 0.0074, Cls Loss = 1.8730, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8862, Reg Loss = 72.6796, Reconstruct Loss = 0.0072, Cls Loss = 1.8718, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8841, Reg Loss = 71.1377, Reconstruct Loss = 0.0071, Cls Loss = 1.8700, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8825, Reg Loss = 69.7498, Reconstruct Loss = 0.0068, Cls Loss = 1.8687, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8809, Reg Loss = 67.8483, Reconstruct Loss = 0.0066, Cls Loss = 1.8674, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8796, Reg Loss = 65.9492, Reconstruct Loss = 0.0064, Cls Loss = 1.8665, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8783, Reg Loss = 64.1338, Reconstruct Loss = 0.0062, Cls Loss = 1.8657, Learning rate = 1.0000e-03\n",
      "Epoch [3/30], Training Loss: 1.8779, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Validation Loss: 1.8040, Validation Accuracy: 79.66%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 2 with accuracy: 79.66%\n",
      "Iteration 0: Loss = 1.8051, Reg Loss = 30.7284, Reconstruct Loss = 0.0000, Cls Loss = 1.8020, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8425, Reg Loss = 42.3424, Reconstruct Loss = 0.0014, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8405, Reg Loss = 33.7880, Reconstruct Loss = 0.0019, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8691, Reg Loss = 37.3207, Reconstruct Loss = 0.0013, Cls Loss = 1.8641, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8620, Reg Loss = 56.0606, Reconstruct Loss = 0.0010, Cls Loss = 1.8555, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8598, Reg Loss = 62.3689, Reconstruct Loss = 0.0008, Cls Loss = 1.8528, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8678, Reg Loss = 63.4666, Reconstruct Loss = 0.0111, Cls Loss = 1.8503, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8678, Reg Loss = 69.5507, Reconstruct Loss = 0.0113, Cls Loss = 1.8496, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8661, Reg Loss = 71.6349, Reconstruct Loss = 0.0099, Cls Loss = 1.8491, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8636, Reg Loss = 71.0582, Reconstruct Loss = 0.0093, Cls Loss = 1.8471, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8619, Reg Loss = 68.2344, Reconstruct Loss = 0.0084, Cls Loss = 1.8467, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8595, Reg Loss = 64.0865, Reconstruct Loss = 0.0076, Cls Loss = 1.8455, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8577, Reg Loss = 59.4729, Reconstruct Loss = 0.0070, Cls Loss = 1.8447, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8560, Reg Loss = 55.7354, Reconstruct Loss = 0.0065, Cls Loss = 1.8440, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8554, Reg Loss = 55.0379, Reconstruct Loss = 0.0061, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8549, Reg Loss = 55.8487, Reconstruct Loss = 0.0061, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8548, Reg Loss = 55.4826, Reconstruct Loss = 0.0057, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8536, Reg Loss = 54.3217, Reconstruct Loss = 0.0055, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8528, Reg Loss = 52.8868, Reconstruct Loss = 0.0053, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8521, Reg Loss = 52.7566, Reconstruct Loss = 0.0050, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8516, Reg Loss = 52.1211, Reconstruct Loss = 0.0048, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8511, Reg Loss = 50.7194, Reconstruct Loss = 0.0046, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8506, Reg Loss = 50.4316, Reconstruct Loss = 0.0045, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8505, Reg Loss = 50.6990, Reconstruct Loss = 0.0043, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8503, Reg Loss = 50.5413, Reconstruct Loss = 0.0042, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8502, Reg Loss = 49.5395, Reconstruct Loss = 0.0040, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8498, Reg Loss = 48.5440, Reconstruct Loss = 0.0039, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8494, Reg Loss = 48.3943, Reconstruct Loss = 0.0037, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8491, Reg Loss = 47.9188, Reconstruct Loss = 0.0036, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8489, Reg Loss = 46.9734, Reconstruct Loss = 0.0035, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8508, Reg Loss = 46.1490, Reconstruct Loss = 0.0034, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8511, Reg Loss = 49.8225, Reconstruct Loss = 0.0033, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Epoch [4/30], Training Loss: 1.8511, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Validation Loss: 1.8041, Validation Accuracy: 79.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8678, Reg Loss = 164.2848, Reconstruct Loss = 0.0000, Cls Loss = 1.8513, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8567, Reg Loss = 176.3888, Reconstruct Loss = 0.0000, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8722, Reg Loss = 166.9555, Reconstruct Loss = 0.0188, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8685, Reg Loss = 155.8634, Reconstruct Loss = 0.0126, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8633, Reg Loss = 148.5719, Reconstruct Loss = 0.0095, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8626, Reg Loss = 141.7214, Reconstruct Loss = 0.0089, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8594, Reg Loss = 135.1955, Reconstruct Loss = 0.0086, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8574, Reg Loss = 129.2786, Reconstruct Loss = 0.0077, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8558, Reg Loss = 123.9094, Reconstruct Loss = 0.0070, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8554, Reg Loss = 118.1248, Reconstruct Loss = 0.0064, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8544, Reg Loss = 111.5804, Reconstruct Loss = 0.0059, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8544, Reg Loss = 103.8329, Reconstruct Loss = 0.0054, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8547, Reg Loss = 101.0878, Reconstruct Loss = 0.0056, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8542, Reg Loss = 102.4861, Reconstruct Loss = 0.0054, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8536, Reg Loss = 103.0735, Reconstruct Loss = 0.0052, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8534, Reg Loss = 102.8207, Reconstruct Loss = 0.0048, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8527, Reg Loss = 101.6331, Reconstruct Loss = 0.0046, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8524, Reg Loss = 99.1647, Reconstruct Loss = 0.0043, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8529, Reg Loss = 100.2925, Reconstruct Loss = 0.0041, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8554, Reg Loss = 107.2523, Reconstruct Loss = 0.0056, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8563, Reg Loss = 113.0426, Reconstruct Loss = 0.0056, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8561, Reg Loss = 117.7897, Reconstruct Loss = 0.0053, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8569, Reg Loss = 122.3022, Reconstruct Loss = 0.0055, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8572, Reg Loss = 125.5852, Reconstruct Loss = 0.0055, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8571, Reg Loss = 127.4917, Reconstruct Loss = 0.0054, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8568, Reg Loss = 127.2490, Reconstruct Loss = 0.0052, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8572, Reg Loss = 124.3228, Reconstruct Loss = 0.0051, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8570, Reg Loss = 123.3250, Reconstruct Loss = 0.0050, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8564, Reg Loss = 122.1082, Reconstruct Loss = 0.0049, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8561, Reg Loss = 120.7091, Reconstruct Loss = 0.0048, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8560, Reg Loss = 119.0645, Reconstruct Loss = 0.0046, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8558, Reg Loss = 117.1256, Reconstruct Loss = 0.0045, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Epoch [5/30], Training Loss: 1.8557, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 54.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Validation Loss: 1.8039, Validation Accuracy: 79.76%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 4 with accuracy: 79.76%\n",
      "Iteration 0: Loss = 1.8361, Reg Loss = 50.5389, Reconstruct Loss = 0.0000, Cls Loss = 1.8311, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8365, Reg Loss = 44.7506, Reconstruct Loss = 0.0000, Cls Loss = 1.8320, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8370, Reg Loss = 37.8398, Reconstruct Loss = 0.0025, Cls Loss = 1.8307, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8403, Reg Loss = 30.3021, Reconstruct Loss = 0.0021, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8401, Reg Loss = 29.8514, Reconstruct Loss = 0.0018, Cls Loss = 1.8353, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8398, Reg Loss = 27.6236, Reconstruct Loss = 0.0019, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8434, Reg Loss = 40.2014, Reconstruct Loss = 0.0021, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8462, Reg Loss = 59.8113, Reconstruct Loss = 0.0025, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8476, Reg Loss = 71.6204, Reconstruct Loss = 0.0022, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8488, Reg Loss = 78.5208, Reconstruct Loss = 0.0019, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8492, Reg Loss = 81.7194, Reconstruct Loss = 0.0019, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8492, Reg Loss = 83.1628, Reconstruct Loss = 0.0019, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8497, Reg Loss = 84.0343, Reconstruct Loss = 0.0021, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8489, Reg Loss = 83.3672, Reconstruct Loss = 0.0020, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8486, Reg Loss = 80.5745, Reconstruct Loss = 0.0018, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8490, Reg Loss = 87.5208, Reconstruct Loss = 0.0020, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8490, Reg Loss = 93.7694, Reconstruct Loss = 0.0018, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8491, Reg Loss = 96.4645, Reconstruct Loss = 0.0017, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8486, Reg Loss = 95.2000, Reconstruct Loss = 0.0017, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8483, Reg Loss = 94.0039, Reconstruct Loss = 0.0016, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8481, Reg Loss = 91.6412, Reconstruct Loss = 0.0015, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8475, Reg Loss = 88.1504, Reconstruct Loss = 0.0015, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8478, Reg Loss = 84.7960, Reconstruct Loss = 0.0014, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8477, Reg Loss = 85.0344, Reconstruct Loss = 0.0013, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8481, Reg Loss = 85.7821, Reconstruct Loss = 0.0013, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8952, Reg Loss = 90.0791, Reconstruct Loss = 0.0012, Cls Loss = 1.8850, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8950, Reg Loss = 107.5565, Reconstruct Loss = 0.0012, Cls Loss = 1.8831, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8952, Reg Loss = 124.7155, Reconstruct Loss = 0.0011, Cls Loss = 1.8816, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9009, Reg Loss = 138.3460, Reconstruct Loss = 0.0073, Cls Loss = 1.8798, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9002, Reg Loss = 146.6856, Reconstruct Loss = 0.0071, Cls Loss = 1.8785, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8992, Reg Loss = 150.1956, Reconstruct Loss = 0.0068, Cls Loss = 1.8773, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8992, Reg Loss = 148.3837, Reconstruct Loss = 0.0079, Cls Loss = 1.8765, Learning rate = 1.0000e-03\n",
      "Epoch [6/30], Training Loss: 1.8989, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Validation Loss: 1.8039, Validation Accuracy: 79.80%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 5 with accuracy: 79.80%\n",
      "Iteration 0: Loss = 1.8165, Reg Loss = 101.0949, Reconstruct Loss = 0.0000, Cls Loss = 1.8064, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8537, Reg Loss = 103.4496, Reconstruct Loss = 0.0016, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8456, Reg Loss = 82.0863, Reconstruct Loss = 0.0016, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8481, Reg Loss = 78.0818, Reconstruct Loss = 0.0022, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8469, Reg Loss = 74.8277, Reconstruct Loss = 0.0016, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8491, Reg Loss = 69.7448, Reconstruct Loss = 0.0013, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8535, Reg Loss = 86.0501, Reconstruct Loss = 0.0059, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8553, Reg Loss = 95.1634, Reconstruct Loss = 0.0073, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8547, Reg Loss = 96.5574, Reconstruct Loss = 0.0064, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8546, Reg Loss = 91.5474, Reconstruct Loss = 0.0057, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8543, Reg Loss = 91.6288, Reconstruct Loss = 0.0053, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8546, Reg Loss = 89.6957, Reconstruct Loss = 0.0048, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8535, Reg Loss = 84.7026, Reconstruct Loss = 0.0045, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8533, Reg Loss = 80.2384, Reconstruct Loss = 0.0043, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8535, Reg Loss = 86.3502, Reconstruct Loss = 0.0040, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8535, Reg Loss = 92.6888, Reconstruct Loss = 0.0037, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8533, Reg Loss = 96.9101, Reconstruct Loss = 0.0035, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8529, Reg Loss = 98.1322, Reconstruct Loss = 0.0033, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8535, Reg Loss = 96.6129, Reconstruct Loss = 0.0042, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8535, Reg Loss = 96.3145, Reconstruct Loss = 0.0040, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8528, Reg Loss = 94.2503, Reconstruct Loss = 0.0040, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8539, Reg Loss = 96.5736, Reconstruct Loss = 0.0038, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8543, Reg Loss = 101.8671, Reconstruct Loss = 0.0041, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8543, Reg Loss = 105.9964, Reconstruct Loss = 0.0039, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8545, Reg Loss = 108.3509, Reconstruct Loss = 0.0039, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8552, Reg Loss = 107.0135, Reconstruct Loss = 0.0037, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8551, Reg Loss = 107.7819, Reconstruct Loss = 0.0036, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8554, Reg Loss = 108.8504, Reconstruct Loss = 0.0036, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8549, Reg Loss = 108.3785, Reconstruct Loss = 0.0035, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8545, Reg Loss = 106.2930, Reconstruct Loss = 0.0035, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8549, Reg Loss = 108.9647, Reconstruct Loss = 0.0036, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8550, Reg Loss = 111.7801, Reconstruct Loss = 0.0036, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Epoch [7/30], Training Loss: 1.8551, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Validation Loss: 1.8045, Validation Accuracy: 78.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8235, Reg Loss = 189.4207, Reconstruct Loss = 0.0000, Cls Loss = 1.8045, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8459, Reg Loss = 145.9026, Reconstruct Loss = 0.0000, Cls Loss = 1.8313, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9093, Reg Loss = 193.3457, Reconstruct Loss = 0.0000, Cls Loss = 1.8900, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9145, Reg Loss = 383.0299, Reconstruct Loss = 0.0000, Cls Loss = 1.8762, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9143, Reg Loss = 475.5754, Reconstruct Loss = 0.0000, Cls Loss = 1.8667, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9323, Reg Loss = 503.7115, Reconstruct Loss = 0.0234, Cls Loss = 1.8585, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9242, Reg Loss = 497.6395, Reconstruct Loss = 0.0195, Cls Loss = 1.8549, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9157, Reg Loss = 469.7177, Reconstruct Loss = 0.0168, Cls Loss = 1.8519, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9088, Reg Loss = 430.8620, Reconstruct Loss = 0.0147, Cls Loss = 1.8510, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9043, Reg Loss = 409.6593, Reconstruct Loss = 0.0130, Cls Loss = 1.8503, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9001, Reg Loss = 388.2610, Reconstruct Loss = 0.0117, Cls Loss = 1.8495, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9012, Reg Loss = 363.9298, Reconstruct Loss = 0.0148, Cls Loss = 1.8500, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8995, Reg Loss = 350.3160, Reconstruct Loss = 0.0155, Cls Loss = 1.8490, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8963, Reg Loss = 336.1015, Reconstruct Loss = 0.0143, Cls Loss = 1.8484, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8938, Reg Loss = 319.2416, Reconstruct Loss = 0.0133, Cls Loss = 1.8486, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8905, Reg Loss = 304.2136, Reconstruct Loss = 0.0130, Cls Loss = 1.8471, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8886, Reg Loss = 292.6275, Reconstruct Loss = 0.0122, Cls Loss = 1.8471, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8870, Reg Loss = 283.3056, Reconstruct Loss = 0.0118, Cls Loss = 1.8469, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8845, Reg Loss = 271.0992, Reconstruct Loss = 0.0113, Cls Loss = 1.8461, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8828, Reg Loss = 261.7691, Reconstruct Loss = 0.0107, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8808, Reg Loss = 251.9165, Reconstruct Loss = 0.0102, Cls Loss = 1.8454, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8855, Reg Loss = 261.2203, Reconstruct Loss = 0.0097, Cls Loss = 1.8497, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8912, Reg Loss = 292.3431, Reconstruct Loss = 0.0128, Cls Loss = 1.8492, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8984, Reg Loss = 319.6796, Reconstruct Loss = 0.0175, Cls Loss = 1.8488, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8992, Reg Loss = 339.1416, Reconstruct Loss = 0.0168, Cls Loss = 1.8484, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8997, Reg Loss = 354.0089, Reconstruct Loss = 0.0161, Cls Loss = 1.8482, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9009, Reg Loss = 364.8434, Reconstruct Loss = 0.0164, Cls Loss = 1.8480, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9013, Reg Loss = 372.0962, Reconstruct Loss = 0.0165, Cls Loss = 1.8476, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9011, Reg Loss = 375.7966, Reconstruct Loss = 0.0164, Cls Loss = 1.8471, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9000, Reg Loss = 373.3144, Reconstruct Loss = 0.0160, Cls Loss = 1.8467, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8989, Reg Loss = 364.8762, Reconstruct Loss = 0.0156, Cls Loss = 1.8468, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8976, Reg Loss = 360.7683, Reconstruct Loss = 0.0153, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Epoch [8/30], Training Loss: 1.8972, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Validation Loss: 1.8037, Validation Accuracy: 80.22%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 7 with accuracy: 80.22%\n",
      "Iteration 0: Loss = 1.8841, Reg Loss = 180.1191, Reconstruct Loss = 0.0000, Cls Loss = 1.8661, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8486, Reg Loss = 129.8073, Reconstruct Loss = 0.0000, Cls Loss = 1.8356, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8758, Reg Loss = 223.9834, Reconstruct Loss = 0.0072, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8814, Reg Loss = 326.0399, Reconstruct Loss = 0.0048, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8871, Reg Loss = 369.7862, Reconstruct Loss = 0.0076, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8864, Reg Loss = 381.7565, Reconstruct Loss = 0.0084, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8842, Reg Loss = 374.0110, Reconstruct Loss = 0.0079, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8808, Reg Loss = 344.9664, Reconstruct Loss = 0.0071, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8765, Reg Loss = 314.5255, Reconstruct Loss = 0.0065, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8732, Reg Loss = 289.9003, Reconstruct Loss = 0.0058, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8709, Reg Loss = 270.5901, Reconstruct Loss = 0.0052, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8691, Reg Loss = 263.2924, Reconstruct Loss = 0.0050, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8683, Reg Loss = 259.7493, Reconstruct Loss = 0.0046, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9123, Reg Loss = 248.0251, Reconstruct Loss = 0.0042, Cls Loss = 1.8833, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9399, Reg Loss = 409.5100, Reconstruct Loss = 0.0187, Cls Loss = 1.8803, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9553, Reg Loss = 594.0567, Reconstruct Loss = 0.0174, Cls Loss = 1.8784, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9614, Reg Loss = 689.2957, Reconstruct Loss = 0.0164, Cls Loss = 1.8761, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9599, Reg Loss = 701.5773, Reconstruct Loss = 0.0154, Cls Loss = 1.8744, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9666, Reg Loss = 675.2458, Reconstruct Loss = 0.0245, Cls Loss = 1.8745, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9620, Reg Loss = 659.0769, Reconstruct Loss = 0.0233, Cls Loss = 1.8728, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9584, Reg Loss = 653.1454, Reconstruct Loss = 0.0221, Cls Loss = 1.8710, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9549, Reg Loss = 633.5647, Reconstruct Loss = 0.0222, Cls Loss = 1.8693, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9505, Reg Loss = 612.0737, Reconstruct Loss = 0.0212, Cls Loss = 1.8681, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9514, Reg Loss = 622.2071, Reconstruct Loss = 0.0226, Cls Loss = 1.8666, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9524, Reg Loss = 630.3935, Reconstruct Loss = 0.0235, Cls Loss = 1.8658, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9518, Reg Loss = 621.6035, Reconstruct Loss = 0.0246, Cls Loss = 1.8650, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9506, Reg Loss = 628.2879, Reconstruct Loss = 0.0237, Cls Loss = 1.8641, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9495, Reg Loss = 633.3786, Reconstruct Loss = 0.0228, Cls Loss = 1.8634, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9477, Reg Loss = 631.2291, Reconstruct Loss = 0.0223, Cls Loss = 1.8622, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9443, Reg Loss = 613.8249, Reconstruct Loss = 0.0216, Cls Loss = 1.8613, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9459, Reg Loss = 643.3595, Reconstruct Loss = 0.0209, Cls Loss = 1.8607, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9740, Reg Loss = 702.9102, Reconstruct Loss = 0.0440, Cls Loss = 1.8597, Learning rate = 1.0000e-03\n",
      "Epoch [9/30], Training Loss: 1.9831, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Validation Loss: 1.8038, Validation Accuracy: 80.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 2.0286, Reg Loss = 1856.8530, Reconstruct Loss = 0.0000, Cls Loss = 1.8429, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.3212, Reg Loss = 1728.3425, Reconstruct Loss = 0.3111, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.1422, Reg Loss = 1451.5370, Reconstruct Loss = 0.1586, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.0659, Reg Loss = 1205.6508, Reconstruct Loss = 0.1064, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.0236, Reg Loss = 987.1829, Reconstruct Loss = 0.0857, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9947, Reg Loss = 871.0845, Reconstruct Loss = 0.0687, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9936, Reg Loss = 878.8421, Reconstruct Loss = 0.0687, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9922, Reg Loss = 939.3968, Reconstruct Loss = 0.0589, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.1238, Reg Loss = 1290.6490, Reconstruct Loss = 0.1551, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.1737, Reg Loss = 1471.0440, Reconstruct Loss = 0.1878, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.1613, Reg Loss = 1544.5844, Reconstruct Loss = 0.1691, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.1603, Reg Loss = 1565.2343, Reconstruct Loss = 0.1658, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.1533, Reg Loss = 1516.0837, Reconstruct Loss = 0.1638, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.1343, Reg Loss = 1442.1308, Reconstruct Loss = 0.1523, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.1166, Reg Loss = 1364.8083, Reconstruct Loss = 0.1421, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.1006, Reg Loss = 1296.0633, Reconstruct Loss = 0.1326, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.0884, Reg Loss = 1243.4832, Reconstruct Loss = 0.1250, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.0773, Reg Loss = 1203.2016, Reconstruct Loss = 0.1177, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.0735, Reg Loss = 1231.3485, Reconstruct Loss = 0.1111, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.0694, Reg Loss = 1251.2500, Reconstruct Loss = 0.1053, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.0680, Reg Loss = 1258.7383, Reconstruct Loss = 0.1035, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.0599, Reg Loss = 1222.2047, Reconstruct Loss = 0.0992, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.0508, Reg Loss = 1174.6074, Reconstruct Loss = 0.0948, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.0430, Reg Loss = 1135.2001, Reconstruct Loss = 0.0907, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.0472, Reg Loss = 1215.7170, Reconstruct Loss = 0.0869, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.1249, Reg Loss = 1397.3135, Reconstruct Loss = 0.1461, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.2005, Reg Loss = 1475.9763, Reconstruct Loss = 0.2139, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.1996, Reg Loss = 1490.3479, Reconstruct Loss = 0.2115, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.1964, Reg Loss = 1479.5211, Reconstruct Loss = 0.2093, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.1867, Reg Loss = 1448.8054, Reconstruct Loss = 0.2025, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.1763, Reg Loss = 1408.7066, Reconstruct Loss = 0.1957, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.1683, Reg Loss = 1368.3409, Reconstruct Loss = 0.1894, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Epoch [10/30], Training Loss: 2.1682, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Validation Loss: 1.8037, Validation Accuracy: 79.98%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9022, Reg Loss = 733.6191, Reconstruct Loss = 0.0000, Cls Loss = 1.8288, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.0062, Reg Loss = 1790.0232, Reconstruct Loss = 0.0000, Cls Loss = 1.8272, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.1499, Reg Loss = 1906.5026, Reconstruct Loss = 0.1241, Cls Loss = 1.8351, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.1527, Reg Loss = 1848.6857, Reconstruct Loss = 0.1302, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.1313, Reg Loss = 1677.4210, Reconstruct Loss = 0.1251, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.0888, Reg Loss = 1500.4614, Reconstruct Loss = 0.1003, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.0584, Reg Loss = 1345.6423, Reconstruct Loss = 0.0837, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.0328, Reg Loss = 1192.5423, Reconstruct Loss = 0.0732, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.3740, Reg Loss = 1549.5671, Reconstruct Loss = 0.3663, Cls Loss = 1.8527, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.6164, Reg Loss = 1930.1290, Reconstruct Loss = 0.5716, Cls Loss = 1.8517, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.5785, Reg Loss = 2129.0640, Reconstruct Loss = 0.5147, Cls Loss = 1.8508, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.6041, Reg Loss = 2257.2163, Reconstruct Loss = 0.5285, Cls Loss = 1.8499, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.6026, Reg Loss = 2324.2528, Reconstruct Loss = 0.5214, Cls Loss = 1.8488, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.5853, Reg Loss = 2336.4121, Reconstruct Loss = 0.5040, Cls Loss = 1.8477, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.5617, Reg Loss = 2315.8750, Reconstruct Loss = 0.4833, Cls Loss = 1.8468, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.5336, Reg Loss = 2278.1400, Reconstruct Loss = 0.4602, Cls Loss = 1.8456, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.5043, Reg Loss = 2224.0362, Reconstruct Loss = 0.4366, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.4718, Reg Loss = 2156.5241, Reconstruct Loss = 0.4110, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.4413, Reg Loss = 2088.9427, Reconstruct Loss = 0.3882, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.4142, Reg Loss = 2013.5372, Reconstruct Loss = 0.3690, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.3864, Reg Loss = 1927.1956, Reconstruct Loss = 0.3509, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.3649, Reg Loss = 1885.4809, Reconstruct Loss = 0.3342, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.3468, Reg Loss = 1855.9591, Reconstruct Loss = 0.3190, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.3317, Reg Loss = 1818.9392, Reconstruct Loss = 0.3075, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.3145, Reg Loss = 1774.3432, Reconstruct Loss = 0.2947, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.2971, Reg Loss = 1722.6872, Reconstruct Loss = 0.2833, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.2803, Reg Loss = 1663.6171, Reconstruct Loss = 0.2725, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.2640, Reg Loss = 1605.3162, Reconstruct Loss = 0.2624, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.2842, Reg Loss = 1627.0401, Reconstruct Loss = 0.2801, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.2827, Reg Loss = 1708.8605, Reconstruct Loss = 0.2705, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.3056, Reg Loss = 1769.8226, Reconstruct Loss = 0.2873, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.3005, Reg Loss = 1811.8581, Reconstruct Loss = 0.2781, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Epoch [11/30], Training Loss: 2.3134, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Validation Loss: 1.8036, Validation Accuracy: 80.32%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 10 with accuracy: 80.32%\n",
      "Iteration 0: Loss = 2.1250, Reg Loss = 2798.4502, Reconstruct Loss = 0.0000, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.3901, Reg Loss = 2483.3844, Reconstruct Loss = 0.3075, Cls Loss = 1.8343, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.3963, Reg Loss = 2150.1948, Reconstruct Loss = 0.3455, Cls Loss = 1.8358, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.3024, Reg Loss = 1847.3302, Reconstruct Loss = 0.2814, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.2092, Reg Loss = 1568.3603, Reconstruct Loss = 0.2158, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.1407, Reg Loss = 1308.7477, Reconstruct Loss = 0.1730, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.0937, Reg Loss = 1119.5079, Reconstruct Loss = 0.1448, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.1669, Reg Loss = 1209.3832, Reconstruct Loss = 0.1850, Cls Loss = 1.8609, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.2136, Reg Loss = 1412.2994, Reconstruct Loss = 0.2148, Cls Loss = 1.8575, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.2368, Reg Loss = 1547.0502, Reconstruct Loss = 0.2275, Cls Loss = 1.8547, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.2213, Reg Loss = 1642.7022, Reconstruct Loss = 0.2048, Cls Loss = 1.8523, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.2082, Reg Loss = 1712.3070, Reconstruct Loss = 0.1863, Cls Loss = 1.8508, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.2517, Reg Loss = 1757.2068, Reconstruct Loss = 0.2267, Cls Loss = 1.8493, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.2626, Reg Loss = 1769.1026, Reconstruct Loss = 0.2367, Cls Loss = 1.8490, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.2453, Reg Loss = 1772.7678, Reconstruct Loss = 0.2198, Cls Loss = 1.8482, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.2303, Reg Loss = 1776.8346, Reconstruct Loss = 0.2052, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.2161, Reg Loss = 1768.9131, Reconstruct Loss = 0.1924, Cls Loss = 1.8468, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.2105, Reg Loss = 1763.6716, Reconstruct Loss = 0.1883, Cls Loss = 1.8458, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.1991, Reg Loss = 1756.9569, Reconstruct Loss = 0.1779, Cls Loss = 1.8455, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.1891, Reg Loss = 1749.5592, Reconstruct Loss = 0.1685, Cls Loss = 1.8456, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.1792, Reg Loss = 1740.8644, Reconstruct Loss = 0.1601, Cls Loss = 1.8450, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.1688, Reg Loss = 1717.3639, Reconstruct Loss = 0.1525, Cls Loss = 1.8446, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.1573, Reg Loss = 1675.2857, Reconstruct Loss = 0.1456, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.1453, Reg Loss = 1614.2068, Reconstruct Loss = 0.1396, Cls Loss = 1.8443, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.1339, Reg Loss = 1559.3524, Reconstruct Loss = 0.1338, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.1233, Reg Loss = 1507.1187, Reconstruct Loss = 0.1284, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.1130, Reg Loss = 1455.1724, Reconstruct Loss = 0.1237, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.1029, Reg Loss = 1405.1274, Reconstruct Loss = 0.1192, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0948, Reg Loss = 1366.4609, Reconstruct Loss = 0.1150, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0871, Reg Loss = 1329.5123, Reconstruct Loss = 0.1113, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0799, Reg Loss = 1293.1176, Reconstruct Loss = 0.1076, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0730, Reg Loss = 1256.5074, Reconstruct Loss = 0.1041, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Epoch [12/30], Training Loss: 2.0714, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Validation Loss: 1.8037, Validation Accuracy: 80.34%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 11 with accuracy: 80.34%\n",
      "Iteration 0: Loss = 1.8261, Reg Loss = 120.2749, Reconstruct Loss = 0.0000, Cls Loss = 1.8141, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8650, Reg Loss = 129.8303, Reconstruct Loss = 0.0000, Cls Loss = 1.8520, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9043, Reg Loss = 428.2013, Reconstruct Loss = 0.0153, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9058, Reg Loss = 554.4654, Reconstruct Loss = 0.0103, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9183, Reg Loss = 598.5042, Reconstruct Loss = 0.0189, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9166, Reg Loss = 608.3673, Reconstruct Loss = 0.0152, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9154, Reg Loss = 603.7078, Reconstruct Loss = 0.0155, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9116, Reg Loss = 593.3372, Reconstruct Loss = 0.0133, Cls Loss = 1.8389, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9081, Reg Loss = 580.6008, Reconstruct Loss = 0.0117, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9068, Reg Loss = 563.4624, Reconstruct Loss = 0.0115, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9042, Reg Loss = 541.1129, Reconstruct Loss = 0.0110, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8999, Reg Loss = 504.3994, Reconstruct Loss = 0.0102, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8970, Reg Loss = 479.6503, Reconstruct Loss = 0.0093, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8927, Reg Loss = 453.7485, Reconstruct Loss = 0.0086, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8941, Reg Loss = 469.1353, Reconstruct Loss = 0.0080, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8966, Reg Loss = 503.3430, Reconstruct Loss = 0.0075, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8998, Reg Loss = 535.9079, Reconstruct Loss = 0.0070, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9087, Reg Loss = 560.8331, Reconstruct Loss = 0.0137, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9093, Reg Loss = 574.2058, Reconstruct Loss = 0.0129, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9117, Reg Loss = 582.3538, Reconstruct Loss = 0.0150, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9112, Reg Loss = 583.2231, Reconstruct Loss = 0.0142, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9101, Reg Loss = 575.1610, Reconstruct Loss = 0.0141, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9079, Reg Loss = 560.0909, Reconstruct Loss = 0.0135, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9065, Reg Loss = 554.3503, Reconstruct Loss = 0.0129, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9049, Reg Loss = 543.4912, Reconstruct Loss = 0.0124, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9218, Reg Loss = 537.7236, Reconstruct Loss = 0.0201, Cls Loss = 1.8479, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9311, Reg Loss = 646.9714, Reconstruct Loss = 0.0193, Cls Loss = 1.8471, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9716, Reg Loss = 770.1656, Reconstruct Loss = 0.0478, Cls Loss = 1.8467, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9990, Reg Loss = 857.4501, Reconstruct Loss = 0.0667, Cls Loss = 1.8466, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0178, Reg Loss = 925.2678, Reconstruct Loss = 0.0791, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0417, Reg Loss = 982.5248, Reconstruct Loss = 0.0976, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0431, Reg Loss = 1030.0542, Reconstruct Loss = 0.0944, Cls Loss = 1.8457, Learning rate = 1.0000e-03\n",
      "Epoch [13/30], Training Loss: 2.0433, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Validation Loss: 1.8037, Validation Accuracy: 80.37%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 12 with accuracy: 80.37%\n",
      "Iteration 0: Loss = 1.9957, Reg Loss = 1895.6831, Reconstruct Loss = 0.0000, Cls Loss = 1.8061, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.8849, Reg Loss = 2209.1037, Reconstruct Loss = 0.8324, Cls Loss = 1.8316, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.4673, Reg Loss = 2059.0114, Reconstruct Loss = 0.4244, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.3213, Reg Loss = 1999.1852, Reconstruct Loss = 0.2848, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.2839, Reg Loss = 1957.9096, Reconstruct Loss = 0.2509, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.2568, Reg Loss = 1913.3572, Reconstruct Loss = 0.2277, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.2138, Reg Loss = 1871.8801, Reconstruct Loss = 0.1900, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.1998, Reg Loss = 1837.7021, Reconstruct Loss = 0.1799, Cls Loss = 1.8361, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.1744, Reg Loss = 1797.9478, Reconstruct Loss = 0.1576, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.1633, Reg Loss = 1764.2067, Reconstruct Loss = 0.1497, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.1437, Reg Loss = 1718.7014, Reconstruct Loss = 0.1348, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.1270, Reg Loss = 1676.4845, Reconstruct Loss = 0.1226, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 2.1124, Reg Loss = 1634.8418, Reconstruct Loss = 0.1124, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.0991, Reg Loss = 1592.9919, Reconstruct Loss = 0.1038, Cls Loss = 1.8360, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 2.0911, Reg Loss = 1547.8293, Reconstruct Loss = 0.0999, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 2.0852, Reg Loss = 1503.0596, Reconstruct Loss = 0.0987, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 2.0801, Reg Loss = 1456.6474, Reconstruct Loss = 0.0979, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 2.0704, Reg Loss = 1411.1260, Reconstruct Loss = 0.0934, Cls Loss = 1.8360, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 2.0616, Reg Loss = 1365.3549, Reconstruct Loss = 0.0891, Cls Loss = 1.8360, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 2.0533, Reg Loss = 1320.0894, Reconstruct Loss = 0.0851, Cls Loss = 1.8361, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 2.0465, Reg Loss = 1276.5740, Reconstruct Loss = 0.0823, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 2.0386, Reg Loss = 1232.9315, Reconstruct Loss = 0.0784, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 2.0313, Reg Loss = 1189.1538, Reconstruct Loss = 0.0750, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 2.0234, Reg Loss = 1145.6716, Reconstruct Loss = 0.0720, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 2.0163, Reg Loss = 1101.5389, Reconstruct Loss = 0.0690, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 2.0097, Reg Loss = 1060.9200, Reconstruct Loss = 0.0662, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 2.0045, Reg Loss = 1027.0956, Reconstruct Loss = 0.0638, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9997, Reg Loss = 1000.5775, Reconstruct Loss = 0.0614, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9951, Reg Loss = 974.9077, Reconstruct Loss = 0.0594, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9906, Reg Loss = 949.0807, Reconstruct Loss = 0.0576, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9863, Reg Loss = 923.7781, Reconstruct Loss = 0.0557, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9817, Reg Loss = 898.8559, Reconstruct Loss = 0.0539, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Epoch [14/30], Training Loss: 1.9807, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Validation Loss: 1.8037, Validation Accuracy: 80.27%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8418, Reg Loss = 122.4586, Reconstruct Loss = 0.0000, Cls Loss = 1.8295, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8485, Reg Loss = 101.6647, Reconstruct Loss = 0.0016, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8461, Reg Loss = 81.8364, Reconstruct Loss = 0.0008, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8513, Reg Loss = 88.1322, Reconstruct Loss = 0.0005, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8564, Reg Loss = 140.0972, Reconstruct Loss = 0.0004, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8628, Reg Loss = 170.0258, Reconstruct Loss = 0.0036, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8632, Reg Loss = 184.6111, Reconstruct Loss = 0.0030, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8634, Reg Loss = 187.9430, Reconstruct Loss = 0.0030, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8619, Reg Loss = 186.1573, Reconstruct Loss = 0.0027, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8603, Reg Loss = 180.2924, Reconstruct Loss = 0.0028, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8591, Reg Loss = 171.0553, Reconstruct Loss = 0.0025, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8572, Reg Loss = 159.7538, Reconstruct Loss = 0.0023, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8723, Reg Loss = 206.8063, Reconstruct Loss = 0.0039, Cls Loss = 1.8478, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8839, Reg Loss = 327.5201, Reconstruct Loss = 0.0036, Cls Loss = 1.8475, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9268, Reg Loss = 430.3215, Reconstruct Loss = 0.0371, Cls Loss = 1.8467, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9317, Reg Loss = 507.8992, Reconstruct Loss = 0.0346, Cls Loss = 1.8462, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9353, Reg Loss = 574.1806, Reconstruct Loss = 0.0325, Cls Loss = 1.8454, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9446, Reg Loss = 627.0696, Reconstruct Loss = 0.0368, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9505, Reg Loss = 669.5773, Reconstruct Loss = 0.0397, Cls Loss = 1.8438, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9601, Reg Loss = 704.9224, Reconstruct Loss = 0.0459, Cls Loss = 1.8437, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9600, Reg Loss = 731.6899, Reconstruct Loss = 0.0436, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9633, Reg Loss = 754.4297, Reconstruct Loss = 0.0446, Cls Loss = 1.8433, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9685, Reg Loss = 773.4243, Reconstruct Loss = 0.0481, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9671, Reg Loss = 787.0138, Reconstruct Loss = 0.0460, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9657, Reg Loss = 794.1806, Reconstruct Loss = 0.0441, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9635, Reg Loss = 791.7327, Reconstruct Loss = 0.0423, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9610, Reg Loss = 780.8729, Reconstruct Loss = 0.0411, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9578, Reg Loss = 762.9817, Reconstruct Loss = 0.0398, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9554, Reg Loss = 740.4943, Reconstruct Loss = 0.0385, Cls Loss = 1.8429, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9523, Reg Loss = 722.0693, Reconstruct Loss = 0.0373, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9489, Reg Loss = 704.1661, Reconstruct Loss = 0.0360, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9461, Reg Loss = 686.1800, Reconstruct Loss = 0.0349, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Epoch [15/30], Training Loss: 1.9456, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Validation Loss: 1.8036, Validation Accuracy: 80.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8511, Reg Loss = 118.2872, Reconstruct Loss = 0.0000, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8479, Reg Loss = 94.1510, Reconstruct Loss = 0.0014, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8469, Reg Loss = 72.5194, Reconstruct Loss = 0.0013, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8435, Reg Loss = 60.6556, Reconstruct Loss = 0.0009, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8488, Reg Loss = 93.6025, Reconstruct Loss = 0.0024, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8505, Reg Loss = 112.9499, Reconstruct Loss = 0.0026, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8506, Reg Loss = 115.6691, Reconstruct Loss = 0.0022, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8488, Reg Loss = 111.4520, Reconstruct Loss = 0.0019, Cls Loss = 1.8358, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8490, Reg Loss = 103.3909, Reconstruct Loss = 0.0018, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8499, Reg Loss = 111.6625, Reconstruct Loss = 0.0016, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8536, Reg Loss = 138.6749, Reconstruct Loss = 0.0021, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8557, Reg Loss = 155.6539, Reconstruct Loss = 0.0028, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8564, Reg Loss = 163.6980, Reconstruct Loss = 0.0025, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8565, Reg Loss = 166.1326, Reconstruct Loss = 0.0024, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8563, Reg Loss = 164.7962, Reconstruct Loss = 0.0025, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8554, Reg Loss = 160.7763, Reconstruct Loss = 0.0024, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8544, Reg Loss = 154.3237, Reconstruct Loss = 0.0023, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8546, Reg Loss = 155.4956, Reconstruct Loss = 0.0021, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8556, Reg Loss = 162.7315, Reconstruct Loss = 0.0022, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8555, Reg Loss = 166.1673, Reconstruct Loss = 0.0021, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8560, Reg Loss = 166.8335, Reconstruct Loss = 0.0021, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8561, Reg Loss = 164.4619, Reconstruct Loss = 0.0022, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8554, Reg Loss = 160.0415, Reconstruct Loss = 0.0021, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8557, Reg Loss = 157.5901, Reconstruct Loss = 0.0020, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8569, Reg Loss = 172.2127, Reconstruct Loss = 0.0019, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8586, Reg Loss = 186.1944, Reconstruct Loss = 0.0022, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8597, Reg Loss = 195.8827, Reconstruct Loss = 0.0021, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8601, Reg Loss = 202.4263, Reconstruct Loss = 0.0021, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8602, Reg Loss = 206.2083, Reconstruct Loss = 0.0020, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8604, Reg Loss = 205.4063, Reconstruct Loss = 0.0020, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8602, Reg Loss = 202.1321, Reconstruct Loss = 0.0020, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8600, Reg Loss = 202.0191, Reconstruct Loss = 0.0020, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Epoch [16/30], Training Loss: 1.8602, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Validation Loss: 1.8036, Validation Accuracy: 80.27%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8887, Reg Loss = 132.2303, Reconstruct Loss = 0.0000, Cls Loss = 1.8755, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8473, Reg Loss = 86.3518, Reconstruct Loss = 0.0000, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8551, Reg Loss = 154.1679, Reconstruct Loss = 0.0009, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8610, Reg Loss = 197.9733, Reconstruct Loss = 0.0006, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8614, Reg Loss = 200.2976, Reconstruct Loss = 0.0005, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8610, Reg Loss = 189.3676, Reconstruct Loss = 0.0009, Cls Loss = 1.8412, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8596, Reg Loss = 169.9779, Reconstruct Loss = 0.0007, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8581, Reg Loss = 155.5447, Reconstruct Loss = 0.0006, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8604, Reg Loss = 174.2858, Reconstruct Loss = 0.0009, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8656, Reg Loss = 225.0271, Reconstruct Loss = 0.0008, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8685, Reg Loss = 260.7881, Reconstruct Loss = 0.0007, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8714, Reg Loss = 284.6957, Reconstruct Loss = 0.0007, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8742, Reg Loss = 298.9132, Reconstruct Loss = 0.0027, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8742, Reg Loss = 302.8107, Reconstruct Loss = 0.0025, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8740, Reg Loss = 302.8990, Reconstruct Loss = 0.0023, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8729, Reg Loss = 298.5963, Reconstruct Loss = 0.0022, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8717, Reg Loss = 289.3490, Reconstruct Loss = 0.0020, Cls Loss = 1.8407, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8696, Reg Loss = 276.5410, Reconstruct Loss = 0.0019, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8690, Reg Loss = 263.7412, Reconstruct Loss = 0.0018, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8688, Reg Loss = 265.6011, Reconstruct Loss = 0.0017, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8691, Reg Loss = 269.5579, Reconstruct Loss = 0.0019, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8682, Reg Loss = 268.0005, Reconstruct Loss = 0.0018, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8679, Reg Loss = 261.6867, Reconstruct Loss = 0.0019, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8678, Reg Loss = 261.7365, Reconstruct Loss = 0.0018, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8763, Reg Loss = 307.5389, Reconstruct Loss = 0.0063, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8841, Reg Loss = 349.4916, Reconstruct Loss = 0.0099, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8874, Reg Loss = 384.2125, Reconstruct Loss = 0.0095, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8898, Reg Loss = 413.9405, Reconstruct Loss = 0.0092, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8918, Reg Loss = 438.3527, Reconstruct Loss = 0.0088, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8939, Reg Loss = 459.0311, Reconstruct Loss = 0.0085, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8970, Reg Loss = 476.7429, Reconstruct Loss = 0.0098, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8979, Reg Loss = 490.2106, Reconstruct Loss = 0.0095, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Epoch [17/30], Training Loss: 1.8979, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Validation Loss: 1.8036, Validation Accuracy: 80.18%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9330, Reg Loss = 703.3301, Reconstruct Loss = 0.0000, Cls Loss = 1.8627, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9398, Reg Loss = 779.3121, Reconstruct Loss = 0.0342, Cls Loss = 1.8277, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9264, Reg Loss = 746.9770, Reconstruct Loss = 0.0174, Cls Loss = 1.8343, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9247, Reg Loss = 708.4017, Reconstruct Loss = 0.0198, Cls Loss = 1.8341, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9187, Reg Loss = 672.4779, Reconstruct Loss = 0.0190, Cls Loss = 1.8325, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9166, Reg Loss = 633.3481, Reconstruct Loss = 0.0204, Cls Loss = 1.8329, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9136, Reg Loss = 587.9608, Reconstruct Loss = 0.0195, Cls Loss = 1.8354, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9061, Reg Loss = 538.0046, Reconstruct Loss = 0.0172, Cls Loss = 1.8350, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8993, Reg Loss = 486.8717, Reconstruct Loss = 0.0151, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8944, Reg Loss = 452.5504, Reconstruct Loss = 0.0134, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8926, Reg Loss = 443.4604, Reconstruct Loss = 0.0121, Cls Loss = 1.8361, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8909, Reg Loss = 431.6369, Reconstruct Loss = 0.0110, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8892, Reg Loss = 414.8684, Reconstruct Loss = 0.0103, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8870, Reg Loss = 394.1413, Reconstruct Loss = 0.0099, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8834, Reg Loss = 370.7591, Reconstruct Loss = 0.0092, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8812, Reg Loss = 352.5896, Reconstruct Loss = 0.0086, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8800, Reg Loss = 344.5783, Reconstruct Loss = 0.0082, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8782, Reg Loss = 333.0059, Reconstruct Loss = 0.0078, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8762, Reg Loss = 317.5985, Reconstruct Loss = 0.0074, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8793, Reg Loss = 333.3224, Reconstruct Loss = 0.0087, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8859, Reg Loss = 371.4237, Reconstruct Loss = 0.0112, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8928, Reg Loss = 402.9747, Reconstruct Loss = 0.0152, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8955, Reg Loss = 424.1035, Reconstruct Loss = 0.0160, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8972, Reg Loss = 438.8001, Reconstruct Loss = 0.0165, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8984, Reg Loss = 448.1419, Reconstruct Loss = 0.0168, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8983, Reg Loss = 453.6979, Reconstruct Loss = 0.0162, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8987, Reg Loss = 456.7202, Reconstruct Loss = 0.0162, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8985, Reg Loss = 457.1168, Reconstruct Loss = 0.0156, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8981, Reg Loss = 456.1809, Reconstruct Loss = 0.0150, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8974, Reg Loss = 454.2915, Reconstruct Loss = 0.0148, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8968, Reg Loss = 450.6208, Reconstruct Loss = 0.0143, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8960, Reg Loss = 445.4281, Reconstruct Loss = 0.0138, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Epoch [18/30], Training Loss: 1.8959, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Validation Loss: 1.8037, Validation Accuracy: 80.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8712, Reg Loss = 239.6486, Reconstruct Loss = 0.0000, Cls Loss = 1.8473, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8542, Reg Loss = 225.8851, Reconstruct Loss = 0.0000, Cls Loss = 1.8316, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8582, Reg Loss = 202.0158, Reconstruct Loss = 0.0042, Cls Loss = 1.8338, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8603, Reg Loss = 174.4606, Reconstruct Loss = 0.0033, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8562, Reg Loss = 145.4460, Reconstruct Loss = 0.0025, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8563, Reg Loss = 131.8421, Reconstruct Loss = 0.0020, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8546, Reg Loss = 123.7654, Reconstruct Loss = 0.0023, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8515, Reg Loss = 112.3172, Reconstruct Loss = 0.0023, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8515, Reg Loss = 109.8794, Reconstruct Loss = 0.0020, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8503, Reg Loss = 105.1132, Reconstruct Loss = 0.0019, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8516, Reg Loss = 100.8299, Reconstruct Loss = 0.0018, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8514, Reg Loss = 103.4872, Reconstruct Loss = 0.0017, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8503, Reg Loss = 100.3566, Reconstruct Loss = 0.0015, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8529, Reg Loss = 116.9333, Reconstruct Loss = 0.0025, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8573, Reg Loss = 147.2884, Reconstruct Loss = 0.0034, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8596, Reg Loss = 169.3791, Reconstruct Loss = 0.0032, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8615, Reg Loss = 186.1501, Reconstruct Loss = 0.0036, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8630, Reg Loss = 196.9039, Reconstruct Loss = 0.0042, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8628, Reg Loss = 202.4729, Reconstruct Loss = 0.0040, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8629, Reg Loss = 204.5196, Reconstruct Loss = 0.0040, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8629, Reg Loss = 203.7656, Reconstruct Loss = 0.0038, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8625, Reg Loss = 200.6250, Reconstruct Loss = 0.0038, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8618, Reg Loss = 196.3871, Reconstruct Loss = 0.0037, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8615, Reg Loss = 192.7230, Reconstruct Loss = 0.0036, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8609, Reg Loss = 187.0252, Reconstruct Loss = 0.0034, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8609, Reg Loss = 190.0421, Reconstruct Loss = 0.0033, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8618, Reg Loss = 201.6603, Reconstruct Loss = 0.0032, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8630, Reg Loss = 210.4017, Reconstruct Loss = 0.0034, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8633, Reg Loss = 214.8503, Reconstruct Loss = 0.0033, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8636, Reg Loss = 217.4358, Reconstruct Loss = 0.0032, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8632, Reg Loss = 218.2126, Reconstruct Loss = 0.0031, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8634, Reg Loss = 217.3435, Reconstruct Loss = 0.0031, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Epoch [19/30], Training Loss: 1.8631, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Validation Loss: 1.8037, Validation Accuracy: 80.00%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8306, Reg Loss = 114.8043, Reconstruct Loss = 0.0000, Cls Loss = 1.8192, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8497, Reg Loss = 84.4583, Reconstruct Loss = 0.0000, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8534, Reg Loss = 90.6031, Reconstruct Loss = 0.0000, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8595, Reg Loss = 174.1285, Reconstruct Loss = 0.0000, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8634, Reg Loss = 210.1681, Reconstruct Loss = 0.0016, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8614, Reg Loss = 218.2207, Reconstruct Loss = 0.0013, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8610, Reg Loss = 215.6453, Reconstruct Loss = 0.0011, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8601, Reg Loss = 206.6835, Reconstruct Loss = 0.0009, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8582, Reg Loss = 193.7884, Reconstruct Loss = 0.0010, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8572, Reg Loss = 185.1699, Reconstruct Loss = 0.0009, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8652, Reg Loss = 224.7988, Reconstruct Loss = 0.0052, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8689, Reg Loss = 250.9992, Reconstruct Loss = 0.0057, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8695, Reg Loss = 264.8813, Reconstruct Loss = 0.0052, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8698, Reg Loss = 271.5567, Reconstruct Loss = 0.0048, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8693, Reg Loss = 272.9005, Reconstruct Loss = 0.0045, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8695, Reg Loss = 269.8776, Reconstruct Loss = 0.0049, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8686, Reg Loss = 262.3956, Reconstruct Loss = 0.0046, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8672, Reg Loss = 252.8133, Reconstruct Loss = 0.0044, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8663, Reg Loss = 242.4619, Reconstruct Loss = 0.0042, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8649, Reg Loss = 232.0733, Reconstruct Loss = 0.0040, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8998, Reg Loss = 274.0030, Reconstruct Loss = 0.0038, Cls Loss = 1.8686, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9263, Reg Loss = 380.2636, Reconstruct Loss = 0.0211, Cls Loss = 1.8672, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9327, Reg Loss = 467.4141, Reconstruct Loss = 0.0201, Cls Loss = 1.8659, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9463, Reg Loss = 535.0460, Reconstruct Loss = 0.0280, Cls Loss = 1.8648, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9559, Reg Loss = 586.8225, Reconstruct Loss = 0.0331, Cls Loss = 1.8642, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9579, Reg Loss = 628.8130, Reconstruct Loss = 0.0317, Cls Loss = 1.8633, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9592, Reg Loss = 664.5182, Reconstruct Loss = 0.0305, Cls Loss = 1.8622, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9701, Reg Loss = 693.1354, Reconstruct Loss = 0.0395, Cls Loss = 1.8613, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9696, Reg Loss = 712.3993, Reconstruct Loss = 0.0381, Cls Loss = 1.8603, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9693, Reg Loss = 728.9472, Reconstruct Loss = 0.0368, Cls Loss = 1.8596, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9686, Reg Loss = 742.0270, Reconstruct Loss = 0.0356, Cls Loss = 1.8589, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9694, Reg Loss = 752.5465, Reconstruct Loss = 0.0362, Cls Loss = 1.8580, Learning rate = 1.0000e-03\n",
      "Epoch [20/30], Training Loss: 1.9691, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Validation Loss: 1.8039, Validation Accuracy: 80.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 3.1673, Reg Loss = 1109.1499, Reconstruct Loss = 1.2154, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 2.0172, Reg Loss = 950.6782, Reconstruct Loss = 0.0880, Cls Loss = 1.8342, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9933, Reg Loss = 920.8012, Reconstruct Loss = 0.0630, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9678, Reg Loss = 883.1831, Reconstruct Loss = 0.0423, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9538, Reg Loss = 847.9914, Reconstruct Loss = 0.0318, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9599, Reg Loss = 823.0715, Reconstruct Loss = 0.0406, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9531, Reg Loss = 791.4185, Reconstruct Loss = 0.0371, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9433, Reg Loss = 760.1035, Reconstruct Loss = 0.0318, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9368, Reg Loss = 732.3456, Reconstruct Loss = 0.0279, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9323, Reg Loss = 706.2757, Reconstruct Loss = 0.0262, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9291, Reg Loss = 678.2321, Reconstruct Loss = 0.0246, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9239, Reg Loss = 650.8193, Reconstruct Loss = 0.0224, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9203, Reg Loss = 624.7869, Reconstruct Loss = 0.0215, Cls Loss = 1.8363, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9167, Reg Loss = 597.1374, Reconstruct Loss = 0.0205, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9122, Reg Loss = 566.8482, Reconstruct Loss = 0.0191, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9076, Reg Loss = 534.8177, Reconstruct Loss = 0.0179, Cls Loss = 1.8363, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9121, Reg Loss = 551.2183, Reconstruct Loss = 0.0168, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9205, Reg Loss = 598.6844, Reconstruct Loss = 0.0206, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9233, Reg Loss = 635.7066, Reconstruct Loss = 0.0195, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9252, Reg Loss = 667.5412, Reconstruct Loss = 0.0184, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9266, Reg Loss = 692.0672, Reconstruct Loss = 0.0175, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9350, Reg Loss = 711.6603, Reconstruct Loss = 0.0245, Cls Loss = 1.8394, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9351, Reg Loss = 723.0165, Reconstruct Loss = 0.0234, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9372, Reg Loss = 731.7743, Reconstruct Loss = 0.0243, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9371, Reg Loss = 738.1734, Reconstruct Loss = 0.0233, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9369, Reg Loss = 743.3356, Reconstruct Loss = 0.0223, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9364, Reg Loss = 747.7367, Reconstruct Loss = 0.0215, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.9360, Reg Loss = 750.8809, Reconstruct Loss = 0.0207, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9353, Reg Loss = 752.9516, Reconstruct Loss = 0.0199, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9348, Reg Loss = 755.0557, Reconstruct Loss = 0.0193, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9352, Reg Loss = 755.3148, Reconstruct Loss = 0.0196, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9350, Reg Loss = 755.2827, Reconstruct Loss = 0.0199, Cls Loss = 1.8395, Learning rate = 1.0000e-03\n",
      "Epoch [21/30], Training Loss: 1.9347, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Validation Loss: 1.8036, Validation Accuracy: 80.17%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8957, Reg Loss = 789.1674, Reconstruct Loss = 0.0000, Cls Loss = 1.8168, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9090, Reg Loss = 736.3091, Reconstruct Loss = 0.0000, Cls Loss = 1.8354, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9056, Reg Loss = 713.5842, Reconstruct Loss = 0.0000, Cls Loss = 1.8343, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9126, Reg Loss = 707.1431, Reconstruct Loss = 0.0078, Cls Loss = 1.8340, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9144, Reg Loss = 699.2725, Reconstruct Loss = 0.0113, Cls Loss = 1.8332, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9247, Reg Loss = 686.1615, Reconstruct Loss = 0.0208, Cls Loss = 1.8352, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.9322, Reg Loss = 672.2359, Reconstruct Loss = 0.0291, Cls Loss = 1.8359, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.9317, Reg Loss = 656.2378, Reconstruct Loss = 0.0291, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.9274, Reg Loss = 640.8097, Reconstruct Loss = 0.0255, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.9247, Reg Loss = 625.1852, Reconstruct Loss = 0.0240, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.9232, Reg Loss = 610.2307, Reconstruct Loss = 0.0237, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.9204, Reg Loss = 593.7237, Reconstruct Loss = 0.0224, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9172, Reg Loss = 578.7859, Reconstruct Loss = 0.0205, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.9142, Reg Loss = 564.5109, Reconstruct Loss = 0.0190, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9114, Reg Loss = 550.3259, Reconstruct Loss = 0.0182, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9089, Reg Loss = 536.7120, Reconstruct Loss = 0.0174, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9071, Reg Loss = 524.0709, Reconstruct Loss = 0.0163, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9050, Reg Loss = 511.1933, Reconstruct Loss = 0.0157, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9029, Reg Loss = 498.2056, Reconstruct Loss = 0.0148, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9009, Reg Loss = 485.3727, Reconstruct Loss = 0.0142, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8990, Reg Loss = 472.9359, Reconstruct Loss = 0.0137, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8971, Reg Loss = 460.1875, Reconstruct Loss = 0.0132, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8950, Reg Loss = 447.2316, Reconstruct Loss = 0.0126, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8936, Reg Loss = 434.1324, Reconstruct Loss = 0.0123, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8916, Reg Loss = 420.5992, Reconstruct Loss = 0.0118, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8900, Reg Loss = 406.5730, Reconstruct Loss = 0.0115, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8882, Reg Loss = 392.8842, Reconstruct Loss = 0.0111, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8868, Reg Loss = 383.6170, Reconstruct Loss = 0.0108, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8859, Reg Loss = 373.3769, Reconstruct Loss = 0.0104, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8858, Reg Loss = 374.2842, Reconstruct Loss = 0.0101, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8855, Reg Loss = 376.4147, Reconstruct Loss = 0.0097, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8850, Reg Loss = 377.4213, Reconstruct Loss = 0.0094, Cls Loss = 1.8378, Learning rate = 1.0000e-03\n",
      "Epoch [22/30], Training Loss: 1.8850, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Validation Loss: 1.8037, Validation Accuracy: 80.19%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8842, Reg Loss = 363.2585, Reconstruct Loss = 0.0000, Cls Loss = 1.8479, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8809, Reg Loss = 382.9967, Reconstruct Loss = 0.0055, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8814, Reg Loss = 370.1152, Reconstruct Loss = 0.0076, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8760, Reg Loss = 356.8496, Reconstruct Loss = 0.0066, Cls Loss = 1.8337, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8735, Reg Loss = 342.8076, Reconstruct Loss = 0.0050, Cls Loss = 1.8342, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8727, Reg Loss = 329.2125, Reconstruct Loss = 0.0040, Cls Loss = 1.8358, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8729, Reg Loss = 317.9702, Reconstruct Loss = 0.0045, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8703, Reg Loss = 306.1845, Reconstruct Loss = 0.0039, Cls Loss = 1.8358, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8690, Reg Loss = 295.4132, Reconstruct Loss = 0.0038, Cls Loss = 1.8357, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8683, Reg Loss = 284.1746, Reconstruct Loss = 0.0034, Cls Loss = 1.8366, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8666, Reg Loss = 273.0243, Reconstruct Loss = 0.0033, Cls Loss = 1.8360, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8661, Reg Loss = 262.1643, Reconstruct Loss = 0.0030, Cls Loss = 1.8369, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8638, Reg Loss = 250.3912, Reconstruct Loss = 0.0027, Cls Loss = 1.8360, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8628, Reg Loss = 237.6996, Reconstruct Loss = 0.0026, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8617, Reg Loss = 223.7888, Reconstruct Loss = 0.0025, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8606, Reg Loss = 214.7843, Reconstruct Loss = 0.0024, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8596, Reg Loss = 205.7006, Reconstruct Loss = 0.0023, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8589, Reg Loss = 196.1379, Reconstruct Loss = 0.0022, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8592, Reg Loss = 188.6774, Reconstruct Loss = 0.0021, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8609, Reg Loss = 199.7889, Reconstruct Loss = 0.0022, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8624, Reg Loss = 208.3893, Reconstruct Loss = 0.0028, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8626, Reg Loss = 212.1343, Reconstruct Loss = 0.0027, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8629, Reg Loss = 214.0056, Reconstruct Loss = 0.0027, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8631, Reg Loss = 214.9965, Reconstruct Loss = 0.0026, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8628, Reg Loss = 215.3842, Reconstruct Loss = 0.0026, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8626, Reg Loss = 214.7300, Reconstruct Loss = 0.0026, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8623, Reg Loss = 211.6838, Reconstruct Loss = 0.0027, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8616, Reg Loss = 205.4598, Reconstruct Loss = 0.0026, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8611, Reg Loss = 200.1827, Reconstruct Loss = 0.0025, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8606, Reg Loss = 194.3470, Reconstruct Loss = 0.0025, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8608, Reg Loss = 195.3478, Reconstruct Loss = 0.0024, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8616, Reg Loss = 206.9410, Reconstruct Loss = 0.0023, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Epoch [23/30], Training Loss: 1.8618, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Validation Loss: 1.8036, Validation Accuracy: 80.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8883, Reg Loss = 528.6055, Reconstruct Loss = 0.0000, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8967, Reg Loss = 506.6016, Reconstruct Loss = 0.0090, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8876, Reg Loss = 465.1070, Reconstruct Loss = 0.0046, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8796, Reg Loss = 440.8979, Reconstruct Loss = 0.0031, Cls Loss = 1.8324, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8797, Reg Loss = 426.6183, Reconstruct Loss = 0.0023, Cls Loss = 1.8347, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8823, Reg Loss = 413.7511, Reconstruct Loss = 0.0063, Cls Loss = 1.8347, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8801, Reg Loss = 403.4098, Reconstruct Loss = 0.0063, Cls Loss = 1.8334, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8788, Reg Loss = 392.7736, Reconstruct Loss = 0.0054, Cls Loss = 1.8341, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8776, Reg Loss = 383.9944, Reconstruct Loss = 0.0055, Cls Loss = 1.8337, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8771, Reg Loss = 375.8430, Reconstruct Loss = 0.0049, Cls Loss = 1.8347, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8767, Reg Loss = 367.6809, Reconstruct Loss = 0.0044, Cls Loss = 1.8355, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8772, Reg Loss = 361.2736, Reconstruct Loss = 0.0040, Cls Loss = 1.8370, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8766, Reg Loss = 354.5108, Reconstruct Loss = 0.0041, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8761, Reg Loss = 348.8813, Reconstruct Loss = 0.0038, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8750, Reg Loss = 342.4800, Reconstruct Loss = 0.0035, Cls Loss = 1.8372, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8743, Reg Loss = 334.1330, Reconstruct Loss = 0.0033, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8729, Reg Loss = 324.0933, Reconstruct Loss = 0.0031, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8717, Reg Loss = 310.2766, Reconstruct Loss = 0.0030, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8713, Reg Loss = 304.5564, Reconstruct Loss = 0.0028, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8712, Reg Loss = 306.0225, Reconstruct Loss = 0.0027, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8706, Reg Loss = 303.6721, Reconstruct Loss = 0.0025, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8704, Reg Loss = 298.2921, Reconstruct Loss = 0.0025, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8697, Reg Loss = 291.3424, Reconstruct Loss = 0.0024, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8691, Reg Loss = 283.1623, Reconstruct Loss = 0.0023, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8680, Reg Loss = 274.1727, Reconstruct Loss = 0.0022, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8666, Reg Loss = 264.5935, Reconstruct Loss = 0.0021, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8656, Reg Loss = 255.5561, Reconstruct Loss = 0.0021, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8652, Reg Loss = 251.1556, Reconstruct Loss = 0.0021, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8643, Reg Loss = 246.3991, Reconstruct Loss = 0.0021, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8636, Reg Loss = 240.0832, Reconstruct Loss = 0.0020, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8630, Reg Loss = 233.0530, Reconstruct Loss = 0.0021, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8628, Reg Loss = 228.9982, Reconstruct Loss = 0.0020, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Epoch [24/30], Training Loss: 1.8628, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Validation Loss: 1.8037, Validation Accuracy: 80.04%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8457, Reg Loss = 160.9082, Reconstruct Loss = 0.0000, Cls Loss = 1.8296, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8555, Reg Loss = 134.5604, Reconstruct Loss = 0.0015, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8468, Reg Loss = 105.1458, Reconstruct Loss = 0.0015, Cls Loss = 1.8348, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8456, Reg Loss = 80.7475, Reconstruct Loss = 0.0014, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8469, Reg Loss = 88.0499, Reconstruct Loss = 0.0014, Cls Loss = 1.8367, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8502, Reg Loss = 110.4512, Reconstruct Loss = 0.0015, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8528, Reg Loss = 116.8650, Reconstruct Loss = 0.0012, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8526, Reg Loss = 113.7122, Reconstruct Loss = 0.0014, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8512, Reg Loss = 105.3524, Reconstruct Loss = 0.0016, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8506, Reg Loss = 100.5422, Reconstruct Loss = 0.0015, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8502, Reg Loss = 99.5366, Reconstruct Loss = 0.0015, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8508, Reg Loss = 98.5765, Reconstruct Loss = 0.0024, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8602, Reg Loss = 159.2394, Reconstruct Loss = 0.0055, Cls Loss = 1.8387, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8649, Reg Loss = 216.7631, Reconstruct Loss = 0.0051, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8689, Reg Loss = 261.2846, Reconstruct Loss = 0.0048, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8743, Reg Loss = 296.3302, Reconstruct Loss = 0.0064, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8765, Reg Loss = 323.5950, Reconstruct Loss = 0.0060, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8779, Reg Loss = 343.6226, Reconstruct Loss = 0.0057, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8785, Reg Loss = 357.7339, Reconstruct Loss = 0.0054, Cls Loss = 1.8374, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8800, Reg Loss = 369.8773, Reconstruct Loss = 0.0060, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8805, Reg Loss = 377.2002, Reconstruct Loss = 0.0057, Cls Loss = 1.8371, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8813, Reg Loss = 380.8500, Reconstruct Loss = 0.0059, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8822, Reg Loss = 380.5729, Reconstruct Loss = 0.0066, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8833, Reg Loss = 374.2027, Reconstruct Loss = 0.0067, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8840, Reg Loss = 383.9262, Reconstruct Loss = 0.0064, Cls Loss = 1.8392, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8847, Reg Loss = 388.7052, Reconstruct Loss = 0.0068, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8895, Reg Loss = 381.9868, Reconstruct Loss = 0.0067, Cls Loss = 1.8446, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8894, Reg Loss = 383.0526, Reconstruct Loss = 0.0066, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8889, Reg Loss = 383.5118, Reconstruct Loss = 0.0064, Cls Loss = 1.8442, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8922, Reg Loss = 396.5066, Reconstruct Loss = 0.0082, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8946, Reg Loss = 393.9605, Reconstruct Loss = 0.0079, Cls Loss = 1.8473, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8964, Reg Loss = 390.4989, Reconstruct Loss = 0.0078, Cls Loss = 1.8495, Learning rate = 1.0000e-03\n",
      "Epoch [25/30], Training Loss: 1.8961, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Validation Loss: 1.8037, Validation Accuracy: 80.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8745, Reg Loss = 343.6938, Reconstruct Loss = 0.0000, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8702, Reg Loss = 275.6547, Reconstruct Loss = 0.0018, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 2.1138, Reg Loss = 706.2907, Reconstruct Loss = 0.1057, Cls Loss = 1.9375, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 2.1216, Reg Loss = 966.2404, Reconstruct Loss = 0.1183, Cls Loss = 1.9067, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 2.1080, Reg Loss = 1039.4451, Reconstruct Loss = 0.1154, Cls Loss = 1.8886, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 2.0753, Reg Loss = 1046.8281, Reconstruct Loss = 0.0925, Cls Loss = 1.8781, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 2.0526, Reg Loss = 1038.7310, Reconstruct Loss = 0.0772, Cls Loss = 1.8716, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 2.0350, Reg Loss = 1015.1846, Reconstruct Loss = 0.0662, Cls Loss = 1.8673, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 2.0193, Reg Loss = 976.8046, Reconstruct Loss = 0.0580, Cls Loss = 1.8636, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 2.0101, Reg Loss = 912.8241, Reconstruct Loss = 0.0518, Cls Loss = 1.8670, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 2.0161, Reg Loss = 847.8111, Reconstruct Loss = 0.0467, Cls Loss = 1.8846, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 2.0044, Reg Loss = 803.5604, Reconstruct Loss = 0.0424, Cls Loss = 1.8816, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.9935, Reg Loss = 767.8369, Reconstruct Loss = 0.0389, Cls Loss = 1.8778, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 2.0028, Reg Loss = 726.3836, Reconstruct Loss = 0.0363, Cls Loss = 1.8939, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.9938, Reg Loss = 695.3082, Reconstruct Loss = 0.0339, Cls Loss = 1.8904, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.9863, Reg Loss = 663.9381, Reconstruct Loss = 0.0318, Cls Loss = 1.8881, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.9793, Reg Loss = 638.0864, Reconstruct Loss = 0.0298, Cls Loss = 1.8857, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.9726, Reg Loss = 621.9556, Reconstruct Loss = 0.0283, Cls Loss = 1.8821, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.9673, Reg Loss = 599.2700, Reconstruct Loss = 0.0269, Cls Loss = 1.8806, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.9648, Reg Loss = 594.9041, Reconstruct Loss = 0.0271, Cls Loss = 1.8782, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.9612, Reg Loss = 590.2385, Reconstruct Loss = 0.0264, Cls Loss = 1.8757, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.9571, Reg Loss = 579.2757, Reconstruct Loss = 0.0252, Cls Loss = 1.8739, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.9523, Reg Loss = 559.4333, Reconstruct Loss = 0.0240, Cls Loss = 1.8723, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.9483, Reg Loss = 543.4806, Reconstruct Loss = 0.0230, Cls Loss = 1.8710, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.9464, Reg Loss = 540.1063, Reconstruct Loss = 0.0225, Cls Loss = 1.8699, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.9440, Reg Loss = 530.8618, Reconstruct Loss = 0.0221, Cls Loss = 1.8688, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.9913, Reg Loss = 555.6138, Reconstruct Loss = 0.0212, Cls Loss = 1.9144, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 2.0142, Reg Loss = 623.2270, Reconstruct Loss = 0.0402, Cls Loss = 1.9117, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 2.0144, Reg Loss = 666.3451, Reconstruct Loss = 0.0388, Cls Loss = 1.9090, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 2.0170, Reg Loss = 695.0224, Reconstruct Loss = 0.0413, Cls Loss = 1.9063, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 2.0178, Reg Loss = 715.5493, Reconstruct Loss = 0.0422, Cls Loss = 1.9040, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 2.0167, Reg Loss = 727.6551, Reconstruct Loss = 0.0423, Cls Loss = 1.9017, Learning rate = 1.0000e-03\n",
      "Epoch [26/30], Training Loss: 2.0160, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Validation Loss: 1.8035, Validation Accuracy: 80.39%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 25 with accuracy: 80.39%\n",
      "Iteration 0: Loss = 1.9259, Reg Loss = 908.0374, Reconstruct Loss = 0.0000, Cls Loss = 1.8351, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9522, Reg Loss = 789.3172, Reconstruct Loss = 0.0267, Cls Loss = 1.8465, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9288, Reg Loss = 681.3930, Reconstruct Loss = 0.0136, Cls Loss = 1.8470, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9131, Reg Loss = 580.0907, Reconstruct Loss = 0.0110, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8983, Reg Loss = 475.4175, Reconstruct Loss = 0.0083, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8944, Reg Loss = 427.0834, Reconstruct Loss = 0.0072, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8912, Reg Loss = 413.7473, Reconstruct Loss = 0.0067, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8880, Reg Loss = 399.4941, Reconstruct Loss = 0.0062, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8853, Reg Loss = 382.9710, Reconstruct Loss = 0.0056, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8823, Reg Loss = 363.7964, Reconstruct Loss = 0.0052, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8794, Reg Loss = 341.7180, Reconstruct Loss = 0.0047, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8756, Reg Loss = 316.2227, Reconstruct Loss = 0.0043, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8727, Reg Loss = 291.7804, Reconstruct Loss = 0.0040, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8833, Reg Loss = 270.8021, Reconstruct Loss = 0.0037, Cls Loss = 1.8526, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8847, Reg Loss = 287.6620, Reconstruct Loss = 0.0034, Cls Loss = 1.8526, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8851, Reg Loss = 312.4860, Reconstruct Loss = 0.0032, Cls Loss = 1.8506, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8864, Reg Loss = 334.3046, Reconstruct Loss = 0.0030, Cls Loss = 1.8499, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8885, Reg Loss = 352.1936, Reconstruct Loss = 0.0039, Cls Loss = 1.8493, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8892, Reg Loss = 367.4330, Reconstruct Loss = 0.0037, Cls Loss = 1.8487, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8901, Reg Loss = 380.0370, Reconstruct Loss = 0.0041, Cls Loss = 1.8480, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8899, Reg Loss = 390.1155, Reconstruct Loss = 0.0039, Cls Loss = 1.8470, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8904, Reg Loss = 397.8071, Reconstruct Loss = 0.0037, Cls Loss = 1.8469, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8905, Reg Loss = 403.9382, Reconstruct Loss = 0.0039, Cls Loss = 1.8463, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8904, Reg Loss = 408.7835, Reconstruct Loss = 0.0037, Cls Loss = 1.8459, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8903, Reg Loss = 412.2670, Reconstruct Loss = 0.0038, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8905, Reg Loss = 413.9100, Reconstruct Loss = 0.0040, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8903, Reg Loss = 413.6471, Reconstruct Loss = 0.0038, Cls Loss = 1.8451, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8898, Reg Loss = 411.8116, Reconstruct Loss = 0.0037, Cls Loss = 1.8449, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8889, Reg Loss = 408.1896, Reconstruct Loss = 0.0036, Cls Loss = 1.8445, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8879, Reg Loss = 403.4229, Reconstruct Loss = 0.0034, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8880, Reg Loss = 402.8356, Reconstruct Loss = 0.0033, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8877, Reg Loss = 404.0595, Reconstruct Loss = 0.0032, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Epoch [27/30], Training Loss: 1.8879, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Validation Loss: 1.8036, Validation Accuracy: 80.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8159, Reg Loss = 373.7431, Reconstruct Loss = 0.0000, Cls Loss = 1.7785, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8743, Reg Loss = 334.2999, Reconstruct Loss = 0.0033, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8753, Reg Loss = 307.2549, Reconstruct Loss = 0.0031, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8698, Reg Loss = 289.7977, Reconstruct Loss = 0.0028, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8667, Reg Loss = 262.4479, Reconstruct Loss = 0.0021, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8639, Reg Loss = 243.9080, Reconstruct Loss = 0.0020, Cls Loss = 1.8375, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8619, Reg Loss = 219.7562, Reconstruct Loss = 0.0023, Cls Loss = 1.8377, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8609, Reg Loss = 195.7001, Reconstruct Loss = 0.0024, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8717, Reg Loss = 184.4395, Reconstruct Loss = 0.0022, Cls Loss = 1.8511, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8776, Reg Loss = 260.2859, Reconstruct Loss = 0.0019, Cls Loss = 1.8496, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8865, Reg Loss = 318.8077, Reconstruct Loss = 0.0061, Cls Loss = 1.8485, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8925, Reg Loss = 346.8772, Reconstruct Loss = 0.0096, Cls Loss = 1.8483, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8926, Reg Loss = 354.5879, Reconstruct Loss = 0.0099, Cls Loss = 1.8473, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8898, Reg Loss = 344.1181, Reconstruct Loss = 0.0092, Cls Loss = 1.8463, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8871, Reg Loss = 334.0084, Reconstruct Loss = 0.0085, Cls Loss = 1.8452, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8848, Reg Loss = 319.8338, Reconstruct Loss = 0.0079, Cls Loss = 1.8449, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8828, Reg Loss = 306.4653, Reconstruct Loss = 0.0077, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8812, Reg Loss = 300.8070, Reconstruct Loss = 0.0073, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8793, Reg Loss = 293.1663, Reconstruct Loss = 0.0070, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8778, Reg Loss = 282.3320, Reconstruct Loss = 0.0066, Cls Loss = 1.8430, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8766, Reg Loss = 270.3670, Reconstruct Loss = 0.0063, Cls Loss = 1.8433, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8769, Reg Loss = 278.6211, Reconstruct Loss = 0.0060, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8774, Reg Loss = 293.0813, Reconstruct Loss = 0.0057, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8781, Reg Loss = 304.4807, Reconstruct Loss = 0.0055, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8787, Reg Loss = 313.2191, Reconstruct Loss = 0.0052, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8791, Reg Loss = 319.2364, Reconstruct Loss = 0.0054, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8790, Reg Loss = 322.3737, Reconstruct Loss = 0.0052, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8789, Reg Loss = 323.5063, Reconstruct Loss = 0.0052, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8795, Reg Loss = 323.0415, Reconstruct Loss = 0.0055, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8794, Reg Loss = 321.1591, Reconstruct Loss = 0.0054, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.8787, Reg Loss = 318.3944, Reconstruct Loss = 0.0052, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.8781, Reg Loss = 314.6899, Reconstruct Loss = 0.0050, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Epoch [28/30], Training Loss: 1.8780, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Validation Loss: 1.8036, Validation Accuracy: 80.36%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8517, Reg Loss = 155.1371, Reconstruct Loss = 0.0000, Cls Loss = 1.8362, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.8477, Reg Loss = 92.7639, Reconstruct Loss = 0.0000, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.8468, Reg Loss = 118.2925, Reconstruct Loss = 0.0000, Cls Loss = 1.8350, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.8500, Reg Loss = 121.0140, Reconstruct Loss = 0.0006, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8603, Reg Loss = 108.4696, Reconstruct Loss = 0.0005, Cls Loss = 1.8490, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.8715, Reg Loss = 231.8115, Reconstruct Loss = 0.0022, Cls Loss = 1.8461, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8808, Reg Loss = 337.7528, Reconstruct Loss = 0.0019, Cls Loss = 1.8452, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8856, Reg Loss = 395.7609, Reconstruct Loss = 0.0016, Cls Loss = 1.8444, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8861, Reg Loss = 410.3400, Reconstruct Loss = 0.0014, Cls Loss = 1.8437, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8871, Reg Loss = 398.8141, Reconstruct Loss = 0.0012, Cls Loss = 1.8460, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8858, Reg Loss = 394.7802, Reconstruct Loss = 0.0011, Cls Loss = 1.8452, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8841, Reg Loss = 386.2474, Reconstruct Loss = 0.0016, Cls Loss = 1.8439, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8827, Reg Loss = 374.8777, Reconstruct Loss = 0.0018, Cls Loss = 1.8434, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8809, Reg Loss = 361.4329, Reconstruct Loss = 0.0020, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8793, Reg Loss = 343.7989, Reconstruct Loss = 0.0020, Cls Loss = 1.8429, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8788, Reg Loss = 328.9042, Reconstruct Loss = 0.0019, Cls Loss = 1.8441, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8769, Reg Loss = 313.9081, Reconstruct Loss = 0.0020, Cls Loss = 1.8435, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8751, Reg Loss = 302.8039, Reconstruct Loss = 0.0020, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8745, Reg Loss = 298.8848, Reconstruct Loss = 0.0020, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8735, Reg Loss = 290.4463, Reconstruct Loss = 0.0019, Cls Loss = 1.8426, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8724, Reg Loss = 279.9737, Reconstruct Loss = 0.0019, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8738, Reg Loss = 290.3919, Reconstruct Loss = 0.0021, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8745, Reg Loss = 301.4173, Reconstruct Loss = 0.0023, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8746, Reg Loss = 306.3994, Reconstruct Loss = 0.0022, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8748, Reg Loss = 306.6539, Reconstruct Loss = 0.0024, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8744, Reg Loss = 303.0282, Reconstruct Loss = 0.0024, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8736, Reg Loss = 294.6806, Reconstruct Loss = 0.0024, Cls Loss = 1.8417, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8725, Reg Loss = 285.7372, Reconstruct Loss = 0.0023, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8718, Reg Loss = 278.8691, Reconstruct Loss = 0.0024, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.8712, Reg Loss = 270.6883, Reconstruct Loss = 0.0024, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9905, Reg Loss = 277.9074, Reconstruct Loss = 0.0029, Cls Loss = 1.9598, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9918, Reg Loss = 314.6678, Reconstruct Loss = 0.0043, Cls Loss = 1.9560, Learning rate = 1.0000e-03\n",
      "Epoch [29/30], Training Loss: 1.9917, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Validation Loss: 1.8036, Validation Accuracy: 80.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.9362, Reg Loss = 1251.3687, Reconstruct Loss = 0.0000, Cls Loss = 1.8111, Learning rate = 1.0000e-03\n",
      "Iteration 25: Loss = 1.9848, Reg Loss = 1039.1440, Reconstruct Loss = 0.0357, Cls Loss = 1.8452, Learning rate = 1.0000e-03\n",
      "Iteration 50: Loss = 1.9553, Reg Loss = 877.9171, Reconstruct Loss = 0.0284, Cls Loss = 1.8391, Learning rate = 1.0000e-03\n",
      "Iteration 75: Loss = 1.9281, Reg Loss = 684.3744, Reconstruct Loss = 0.0216, Cls Loss = 1.8380, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9138, Reg Loss = 590.6674, Reconstruct Loss = 0.0163, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 125: Loss = 1.9069, Reg Loss = 539.2747, Reconstruct Loss = 0.0140, Cls Loss = 1.8390, Learning rate = 1.0000e-03\n",
      "Iteration 150: Loss = 1.8992, Reg Loss = 498.6787, Reconstruct Loss = 0.0117, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 175: Loss = 1.8931, Reg Loss = 463.6442, Reconstruct Loss = 0.0100, Cls Loss = 1.8368, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8894, Reg Loss = 432.8794, Reconstruct Loss = 0.0088, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 225: Loss = 1.8859, Reg Loss = 404.8673, Reconstruct Loss = 0.0078, Cls Loss = 1.8376, Learning rate = 1.0000e-03\n",
      "Iteration 250: Loss = 1.8825, Reg Loss = 376.5554, Reconstruct Loss = 0.0070, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 275: Loss = 1.8801, Reg Loss = 355.3794, Reconstruct Loss = 0.0064, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8780, Reg Loss = 334.3488, Reconstruct Loss = 0.0060, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 325: Loss = 1.8797, Reg Loss = 345.2557, Reconstruct Loss = 0.0056, Cls Loss = 1.8396, Learning rate = 1.0000e-03\n",
      "Iteration 350: Loss = 1.8808, Reg Loss = 356.2046, Reconstruct Loss = 0.0059, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 375: Loss = 1.8804, Reg Loss = 361.5711, Reconstruct Loss = 0.0055, Cls Loss = 1.8388, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8808, Reg Loss = 363.7324, Reconstruct Loss = 0.0052, Cls Loss = 1.8393, Learning rate = 1.0000e-03\n",
      "Iteration 425: Loss = 1.8801, Reg Loss = 365.2277, Reconstruct Loss = 0.0053, Cls Loss = 1.8383, Learning rate = 1.0000e-03\n",
      "Iteration 450: Loss = 1.8798, Reg Loss = 364.2865, Reconstruct Loss = 0.0053, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 475: Loss = 1.8796, Reg Loss = 361.5251, Reconstruct Loss = 0.0053, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8793, Reg Loss = 357.1399, Reconstruct Loss = 0.0050, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 525: Loss = 1.8784, Reg Loss = 351.0262, Reconstruct Loss = 0.0049, Cls Loss = 1.8384, Learning rate = 1.0000e-03\n",
      "Iteration 550: Loss = 1.8772, Reg Loss = 341.3034, Reconstruct Loss = 0.0048, Cls Loss = 1.8382, Learning rate = 1.0000e-03\n",
      "Iteration 575: Loss = 1.8830, Reg Loss = 352.5701, Reconstruct Loss = 0.0046, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8897, Reg Loss = 395.6521, Reconstruct Loss = 0.0073, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 625: Loss = 1.8930, Reg Loss = 432.3363, Reconstruct Loss = 0.0070, Cls Loss = 1.8427, Learning rate = 1.0000e-03\n",
      "Iteration 650: Loss = 1.8957, Reg Loss = 461.2269, Reconstruct Loss = 0.0068, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 675: Loss = 1.8989, Reg Loss = 484.5765, Reconstruct Loss = 0.0080, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.9003, Reg Loss = 501.2269, Reconstruct Loss = 0.0077, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 725: Loss = 1.9019, Reg Loss = 513.3475, Reconstruct Loss = 0.0082, Cls Loss = 1.8423, Learning rate = 1.0000e-03\n",
      "Iteration 750: Loss = 1.9019, Reg Loss = 520.0139, Reconstruct Loss = 0.0079, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Iteration 775: Loss = 1.9022, Reg Loss = 522.7088, Reconstruct Loss = 0.0080, Cls Loss = 1.8419, Learning rate = 1.0000e-03\n",
      "Epoch [30/30], Training Loss: 1.9022, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Validation Loss: 1.8037, Validation Accuracy: 79.97%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the epochs\n",
    "for epoch in range(start_epoch, args.experiment.num_epochs):\n",
    "    # Train the hypernetwork to generate a model with random dimension for one epoch\n",
    "    train_loss, dim_dict, gt_model_dict = train_one_epoch(hyper_model, train_loader, optimizer, criterion, \n",
    "                                                          dim_dict, gt_model_dict, epoch_idx=epoch, ema=ema, \n",
    "                                                          args=args, device=device)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the training loss and learning rate\n",
    "    print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Training Loss: {train_loss:.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # If it's time to evaluate the model\n",
    "    if (epoch + 1) % args.experiment.eval_interval == 0:\n",
    "        # Apply EMA if it is specified\n",
    "        if ema:\n",
    "            ema.apply()  # Save the weights of original model created before training_loop\n",
    "        \n",
    "        # Sample the merged model (create model of same structure before training loop by using the hypernetwork)\n",
    "        # And then test the performance of the hypernetwork by seeing how good it is in generating the weights\n",
    "        model = sample_merge_model(hyper_model, model, args) \n",
    "        # Validate the merged model\n",
    "        val_loss, acc = validate_single(model, val_loader, val_criterion, args=args)\n",
    "\n",
    "        # If EMA is specified, restore the original weights\n",
    "        if ema:\n",
    "            ema.restore()  # Restore the original weights to the weights of the pretrained networks\n",
    "\n",
    "        # Log the validation loss and accuracy to wandb\n",
    "        wandb.log({\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": acc\n",
    "        })\n",
    "        # Print the validation loss and accuracy\n",
    "        print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Save the checkpoint if the accuracy is better than the previous best\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_checkpoint(f\"{args.training.save_model_path}/cifar10_nerf_best.pth\",hyper_model,optimizer,ema,epoch,best_acc)\n",
    "            print(f\"Checkpoint saved at epoch {epoch} with accuracy: {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15464fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>▄▄▄█▅▄▄▄▄▄▁▄▅▅▄▄▃▅▅▄▅▁▄▄▄▄▄▄▃▄▄▄▄▄▅▄▅▄▄▄</td></tr><tr><td>Learning rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss</td><td>▁▁▁▂▁▁▁▁▁▃▁▄▄▇▆▇▆▆▁▁▂▂▂▂▁▄▃▃▂▁▁▂▂█▄▂▂▂▂▄</td></tr><tr><td>Reconstruct Loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁█▃▃▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Reg Loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▅▆█▇█▅▂▄▄▂▂▃▂▂▄▄▂▂▅▃▄▃▂▂▂▃▂▂</td></tr><tr><td>Validation Accuracy</td><td>▄▃▅▄▅▆▁▇▆▆███▇█▇▇▇▆▆▇▇█▇▇████▆</td></tr><tr><td>Validation Loss</td><td>▅▆▄▅▄▄█▂▃▃▂▂▂▂▂▂▂▂▃▃▁▂▂▂▂▁▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>1.84193</td></tr><tr><td>Learning rate</td><td>0.001</td></tr><tr><td>Loss</td><td>1.90219</td></tr><tr><td>Reconstruct Loss</td><td>0.008</td></tr><tr><td>Reg Loss</td><td>522.70884</td></tr><tr><td>Validation Accuracy</td><td>0.7997</td></tr><tr><td>Validation Loss</td><td>1.80365</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20250519015022-resnet20_cifar10_base_config_layers_5</strong> at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/rkywguw2' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/rkywguw2</a><br> View project at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250519_015023-rkywguw2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# End the wandb tracking\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6054a4",
   "metadata": {},
   "source": [
    "### 7 Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43945b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy/experiments/resnet20_cifar10_base_config_layers_5/cifar10_nerf_best.pth'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_hypernet_path = args.training.save_model_path + '/cifar10_nerf_best.pth'\n",
    "saved_hypernet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f139172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_MLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-3): 4 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4431caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(saved_hypernet_path, map_location=\"cpu\")  # or \"cuda\" if using GPU\n",
    "hyper_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4eaa63eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 16\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 16, Validation Loss: 1.8037, Validation Accuracy: 79.96%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 17\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'resnet20-12fca82f.th', 'smooth': False}: hidden_dim 17, Validation Loss: 1.8037, Validation Accuracy: 79.96%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 18\n",
      "Loading pretrained weights for resnet20\n",
      "Applying EMA\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     ema\u001b[38;5;241m.\u001b[39mapply()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Sample the merged model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m accumulated_model \u001b[38;5;241m=\u001b[39m \u001b[43msample_merge_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyper_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Validate the merged model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m val_loss, acc \u001b[38;5;241m=\u001b[39m validate_single(accumulated_model, val_loader, val_criterion, args\u001b[38;5;241m=\u001b[39margs)\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\neumeta\\utils\\hypernet_utils.py:403\u001b[0m, in \u001b[0;36msample_merge_model\u001b[1;34m(hyper_model, model, args, K, device)\u001b[0m\n\u001b[0;32m    400\u001b[0m models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[1;32m--> 403\u001b[0m     model_cls_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     model_cls_temp\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Sampling and merging weights\u001b[39;00m\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "    \u001b[1;31m[... skipping similar frames: _deepcopy_dict at line 231 (4 times), deepcopy at line 146 (4 times), _reconstruct at line 271 (1 times), deepcopy at line 172 (1 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "    \u001b[1;31m[... skipping similar frames: _deepcopy_dict at line 231 (1 times), deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32md:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\skripsi_env\\Lib\\site-packages\\torch\\nn\\parameter.py:68\u001b[0m, in \u001b[0;36mParameter.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\n\u001b[1;32m---> 68\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad\n\u001b[0;32m     69\u001b[0m     )\n\u001b[0;32m     70\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for hidden_dim in range(16, 65):\n",
    "    # Create a model for this given dimension\n",
    "    model = create_model(args.model.type,\n",
    "                         hidden_dim=hidden_dim,\n",
    "                         path=args.model.pretrained_path,\n",
    "                         smooth=args.model.smooth).to(device)\n",
    "    \n",
    "    # If EMA is specified, apply it\n",
    "    if ema:\n",
    "        print('Applying EMA')\n",
    "        ema.apply()\n",
    "\n",
    "    # Sample the merged model\n",
    "    accumulated_model = sample_merge_model(hyper_model, model, args, K=100)\n",
    "\n",
    "    # Validate the merged model\n",
    "    val_loss, acc = validate_single(accumulated_model, val_loader, val_criterion, args=args)\n",
    "\n",
    "    # If EMA is specified, restore the original weights after applying EMA\n",
    "    if ema:\n",
    "        ema.restore()  # Restore the original weights after applying \n",
    "        \n",
    "    # Save the model\n",
    "    save_name = os.path.join(args.training.save_model_path, f\"cifar10_{accumulated_model.__class__.__name__}_dim{hidden_dim}_single.pth\")\n",
    "    torch.save(accumulated_model.state_dict(),save_name)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test using model {args.model}: hidden_dim {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Define the directory and filename structure\n",
    "    filename = f\"cifar10_results_{args.experiment.name}.txt\"\n",
    "    filepath = os.path.join(args.training.save_model_path, filename)\n",
    "\n",
    "    # Write the results. 'a' is used to append the results; a new file will be created if it doesn't exist.\n",
    "    with open(filepath, \"a\") as file:\n",
    "        file.write(f\"Hidden_dim: {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
