{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93dc2c6f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6360918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df94f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9add1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_densenet_model as create_model\n",
    "from neumeta.utils import (\n",
    "    parse_args, print_omegaconf,\n",
    "    load_checkpoint, save_checkpoint,\n",
    "    set_seed,\n",
    "    get_dataset,\n",
    "    sample_coordinates, sample_subset, shuffle_coordinates_all,\n",
    "    get_hypernetwork, get_optimizer,\n",
    "    sample_weights,\n",
    "    weighted_regression_loss, validate_single, AverageMeter, EMA,\n",
    "    sample_merge_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3531f8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df3637",
   "metadata": {},
   "source": [
    "### Find max dimension of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dim(model_cls):\n",
    "    \"\"\"Find maximum dimension of the model\"\"\"\n",
    "    # Get the learnable parameters of the model\n",
    "    checkpoint = model_cls.learnable_parameter \n",
    "\n",
    "    # Set the maximum value to the length of the checkpoint\n",
    "    max_value = len(checkpoint)\n",
    "\n",
    "    # Iterate over the new model's weight\n",
    "    for i, (k, tensor) in enumerate(checkpoint.items()):\n",
    "        # Handle 2D tensors (e.g., weight matrices) \n",
    "        if len(tensor.shape) == 4:\n",
    "            coords = [tensor.shape[0], tensor.shape[1]]\n",
    "            max_value = max(max_value, max(coords))\n",
    "        # Handle 1D tensors (e.g., biases)\n",
    "        elif len(tensor.shape) == 1:\n",
    "            max_value = max(max_value, tensor.shape[0])\n",
    "    \n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c098c",
   "metadata": {},
   "source": [
    "### Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e70c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(config):\n",
    "    import time\n",
    "    \"\"\"\n",
    "    Initializes Weights and Biases (wandb) with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        configuration (dict): Configuration parameters for the run.\n",
    "    \"\"\"\n",
    "    # Name the run using current time and configuration name\n",
    "    run_name = f\"{time.strftime('%Y%m%d%H%M%S')}-{config.experiment.name}\"\n",
    "    \n",
    "    wandb.init(project=\"dense-inr-trial\", name=run_name, config=dict(config), group='cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0bc703",
   "metadata": {},
   "source": [
    "### Init model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319a2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(args, device):\n",
    "    \"\"\"\n",
    "    Initializes a dictionary of models for each dimension in the given range, along with ground truth models for the starting dimension.\n",
    "\n",
    "    Args:\n",
    "        args: An object containing the arguments for initializing the models.\n",
    "\n",
    "    Returns:\n",
    "        dim_dict: A dictionary containing the models for each dimension, along with their corresponding coordinates, keys, indices, size, and ground truth models.\n",
    "        gt_model_dict: A dictionary containing the ground truth models for the starting dimension.\n",
    "    \"\"\"\n",
    "    dim_dict = {}\n",
    "    gt_model_dict = {}\n",
    "    \n",
    "    # Create a model for each dimension in dimensions range\n",
    "    for dim in args.dimensions.range:\n",
    "        model_cls = create_model(args.model.type,\n",
    "                                 layers=args.model.layers,\n",
    "                                 growth=args.model.growth,\n",
    "                                 compression=args.model.compression,\n",
    "                                 bottleneck=args.model.bottleneck,\n",
    "                                 drop_rate=args.model.drop_rate,\n",
    "                                 hidden_dim=dim,\n",
    "                                 path=args.model.pretrained_path).to(device)\n",
    "        # Sample the coordinates, keys, indices, and the size for the model\n",
    "        coords_tensor, keys_list, indices_list, size_list = sample_coordinates(model_cls)\n",
    "        # Add the model, coordinates, keys, indices, size, and key mask to the dictionary\n",
    "        dim_dict[f\"{dim}\"] = (model_cls, coords_tensor, keys_list, indices_list, size_list, None)\n",
    "\n",
    "        # Print to makes line better\n",
    "        print('\\n')\n",
    "        \n",
    "        # If the dimension is the starting dimension (the dimension of pretrained_model), add the ground truth model to the dictionary\n",
    "        if dim == args.dimensions.start:\n",
    "            print(f\"Loading model for dim {dim}\")\n",
    "            model_trained = create_model(args.model.type,\n",
    "                                         layers=args.model.layers,\n",
    "                                         growth=args.model.growth,\n",
    "                                         compression=args.model.compression,\n",
    "                                         bottleneck=args.model.bottleneck,\n",
    "                                         drop_rate=args.model.drop_rate,\n",
    "                                         path=args.model.pretrained_path,\n",
    "                                         smooth=True,\n",
    "                                         hidden_dim=dim).to(device)\n",
    "            model_trained.eval()\n",
    "            gt_model_dict[f'{dim}'] = model_trained\n",
    "\n",
    "    \n",
    "    return dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93b863",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde4cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, dim_dict, gt_model_dict, epoch_idx, ema=None, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    reconstruct_losses = AverageMeter()\n",
    "\n",
    "    # Training accuracy\n",
    "    preds = []\n",
    "    gt = []\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Preprocess input\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Move the data to the device\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # Choose a random hidden dimension\n",
    "        hidden_dim = random.choice(args.dimensions.range)\n",
    "        # Get the model class, coordinates, keys, indices, size, and key mask for the chosen dimension\n",
    "        model_cls, coords_tensor, keys_list, indices_list, size_list, key_mask = dim_dict[f\"{hidden_dim}\"]\n",
    "        # Sample a subset the input tensor of the coordinates, keys, indices, size, and selected keys\n",
    "        coords_tensor, keys_list, indices_list, size_list, selected_keys = sample_subset(coords_tensor,\n",
    "                                                                                         keys_list,\n",
    "                                                                                         indices_list,\n",
    "                                                                                         size_list,\n",
    "                                                                                         key_mask,\n",
    "                                                                                         ratio=args.ratio)\n",
    "        # Add noise to the coordinates if specified\n",
    "        if args.training.coordinate_noise > 0.0:\n",
    "            coords_tensor = coords_tensor + (torch.rand_like(coords_tensor) - 0.5) * args.training.coordinate_noise\n",
    "\n",
    "\n",
    "        # Main task of hypernetwork and target network\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Sample the weights for the target model using hypernetwork\n",
    "        model_cls, reconstructed_weights = sample_weights(model, model_cls,\n",
    "                                                          coords_tensor, keys_list, indices_list, size_list, key_mask, selected_keys,\n",
    "                                                          device=device, NORM=args.dimensions.norm)\n",
    "        # Forward pass\n",
    "        predict = model_cls(x)\n",
    "        \n",
    "        # Sample test model to see training accuracy\n",
    "\n",
    "        pred = torch.argmax(predict, dim=-1)\n",
    "\n",
    "        preds.append(pred)\n",
    "        gt.append(target)\n",
    "\n",
    "        # Compute losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Compute classification loss\n",
    "        cls_loss = criterion(predict, target) \n",
    "        # Compute regularization loss\n",
    "        reg_loss = sum([torch.norm(w, p=2) for w in reconstructed_weights])\n",
    "        # Compute reconstruction loss if ground truth model is available\n",
    "        if f\"{hidden_dim}\" in gt_model_dict:\n",
    "            gt_model = gt_model_dict[f\"{hidden_dim}\"]\n",
    "            gt_selected_weights = [\n",
    "                w for k, w in gt_model.learnable_parameter.items() if k in selected_keys]\n",
    "\n",
    "            reconstruct_loss = weighted_regression_loss(\n",
    "                reconstructed_weights, gt_selected_weights)\n",
    "        else:\n",
    "            reconstruct_loss = torch.tensor(0.0)\n",
    "        # Compute the total loss\n",
    "        loss = args.hyper_model.loss_weight.ce_weight * cls_loss + args.hyper_model.loss_weight.reg_weight * \\\n",
    "            reg_loss + args.hyper_model.loss_weight.recon_weight * reconstruct_loss\n",
    "\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Zero the gradients of the updated weights\n",
    "        for updated_weight in model_cls.parameters():\n",
    "            updated_weight.grad = None\n",
    "\n",
    "        # Compute the gradients of the reconstructed weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.autograd.backward(reconstructed_weights, [\n",
    "                                w.grad for k, w in model_cls.named_parameters() if k in selected_keys])\n",
    "        \n",
    "        # Clip the gradients if specified\n",
    "        if args.training.get('clip_grad', 0.0) > 0:\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), args.training.clip_grad)\n",
    "            \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA if specified\n",
    "        if ema:\n",
    "            ema.update()  # Update the EMA after each training step\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update the AverageMeter objects\n",
    "        losses.update(loss.item())\n",
    "        cls_losses.update(cls_loss.item())\n",
    "        reg_losses.update(reg_loss.item())\n",
    "        reconstruct_losses.update(reconstruct_loss.item())\n",
    "\n",
    "        # Log (or plot) losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Log the losses and learning rate to wandb\n",
    "        if batch_idx % args.experiment.log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"Loss\": losses.avg,\n",
    "                \"Cls Loss\": cls_losses.avg,\n",
    "                \"Reg Loss\": reg_losses.avg,\n",
    "                \"Reconstruct Loss\": reconstruct_losses.avg,\n",
    "                \"Learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }, step=batch_idx + epoch_idx * len(train_loader))\n",
    "            # Print the losses and learning rate\n",
    "            print(\n",
    "                f\"Iteration {batch_idx}: Loss = {losses.avg:.4f}, Reg Loss = {reg_losses.avg:.4f}, Reconstruct Loss = {reconstruct_losses.avg:.4f}, Cls Loss = {cls_losses.avg:.4f}, Learning rate = {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "    \n",
    "    train_acc = accuracy_score(torch.cat(gt).cpu().numpy(), torch.cat(preds).cpu().numpy())\n",
    "\n",
    "    wandb.log({\n",
    "        \"Training accuracy\": train_acc\n",
    "    })\n",
    "\n",
    "    # Returns the training loss, structure of network in each dimension, and the original structure of pretrained network\n",
    "    return losses.avg, dim_dict, gt_model_dict, train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb560cd",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041282c",
   "metadata": {},
   "source": [
    "### 0 Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bcf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6df804",
   "metadata": {},
   "source": [
    "### 1 Parsing arguments for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5570d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = 'neumeta/config/densenet_inr_train/dense_19th_experiment.yaml'\n",
    "RATIO = '1.0'\n",
    "CHECKPOINT_PATH = 'toy/experiments_densenet/dense_19th_experiment/cifar10_nerf_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92954510",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv_train = ['--config', CONFIG_PATH, '--ratio', RATIO, '--resume_from', CHECKPOINT_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1867bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------------------------------------------------------------------------------------------------------+\n",
      "|                 Key                  |                                                Value                                                 |\n",
      "+--------------------------------------+------------------------------------------------------------------------------------------------------+\n",
      "|           experiment.name            |                                        dense_19th_experiment                                         |\n",
      "|        experiment.num_epochs         |                                                 200                                                  |\n",
      "|       experiment.log_interval        |                                                 100                                                  |\n",
      "|       experiment.eval_interval       |                                                  1                                                   |\n",
      "|           experiment.seed            |                                                  42                                                  |\n",
      "|              model.type              |                                               DenseNet                                               |\n",
      "|        model.pretrained_path         |        toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth        |\n",
      "|             model.layers             |                                                  40                                                  |\n",
      "|             model.growth             |                                                  12                                                  |\n",
      "|          model.compression           |                                                 0.5                                                  |\n",
      "|           model.bottleneck           |                                                 True                                                 |\n",
      "|           model.drop_rate            |                                                 0.0                                                  |\n",
      "|           training.dataset           |                                               cifar10                                                |\n",
      "|         training.batch_size          |                                                  64                                                  |\n",
      "|      training.coordinate_noise       |                                                 0.0                                                  |\n",
      "|        training.learning_rate        |                                                0.001                                                 |\n",
      "|          training.lr_steps           |                                              [100, 150]                                              |\n",
      "|          training.optimizer          |                                                adamw                                                 |\n",
      "|        training.weight_decay         |                                                 0.01                                                 |\n",
      "|          training.clip_grad          |                                                 10.0                                                 |\n",
      "|       training.save_model_path       |                            toy/experiments_densenet/dense_19th_experiment                            |\n",
      "|           hyper_model.type           |                                                resmlp                                                |\n",
      "|        hyper_model.input_dim         |                                                  6                                                   |\n",
      "|        hyper_model.hidden_dim        |                                                 256                                                  |\n",
      "|        hyper_model.num_layers        |                                                  5                                                   |\n",
      "|        hyper_model.num_freqs         |                                                  16                                                  |\n",
      "|        hyper_model.output_dim        |                                                  9                                                   |\n",
      "|        hyper_model.ema_decay         |                                                0.995                                                 |\n",
      "|  hyper_model.loss_weight.ce_weight   |                                                 1.0                                                  |\n",
      "|  hyper_model.loss_weight.reg_weight  |                                                0.0001                                                |\n",
      "| hyper_model.loss_weight.recon_weight |                                                 1.0                                                  |\n",
      "|  hyper_model.loss_weight.kd_weight   |                                                 0.1                                                  |\n",
      "|           dimensions.range           | [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] |\n",
      "|           dimensions.test            |                                                  24                                                  |\n",
      "|           dimensions.norm            |                                                 120                                                  |\n",
      "|           dimensions.start           |                                                  48                                                  |\n",
      "|                config                |                     neumeta/config/densenet_inr_train/dense_19th_experiment.yaml                     |\n",
      "|                ratio                 |                                                 1.0                                                  |\n",
      "|             resume_from              |                 toy/experiments_densenet/dense_19th_experiment/cifar10_nerf_best.pth                 |\n",
      "|              load_from               |                                                 None                                                 |\n",
      "|           test_result_path           |                                                 None                                                 |\n",
      "|                 test                 |                                                False                                                 |\n",
      "+--------------------------------------+------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(argv_train)  # Parse arguments\n",
    "print_omegaconf(args)  # Print arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d63002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed... 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.experiment.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1941f5",
   "metadata": {},
   "source": [
    "### 2 Get training and validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1732d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: cifar10 with batch size: 64 and strong transform: None\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_dataset('cifar10', args.training.batch_size, strong_transform=args.training.get('strong_aug', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1754c36",
   "metadata": {},
   "source": [
    "### 3 Create target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f26b5",
   "metadata": {},
   "source": [
    "#### 3.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bde19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args.model.type,\n",
    "                     layers=args.model.layers,\n",
    "                     growth=args.model.growth,\n",
    "                     compression=args.model.compression,\n",
    "                     bottleneck=args.model.bottleneck,\n",
    "                     drop_rate=args.model.drop_rate,\n",
    "                     hidden_dim=args.dimensions.start,\n",
    "                     path=args.model.pretrained_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f2944",
   "metadata": {},
   "source": [
    "#### 3.1 Print the structure and shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2d72666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet3(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block2): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block3): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68fc0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block3.layer.5.conv1.weight torch.Size([48, 120, 1, 1])\n",
      "block3.layer.5.conv1.bias torch.Size([48])\n",
      "block3.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for i, (k, tensor) in enumerate(model.learnable_parameter.items()):\n",
    "    print(k, tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a708ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum DIM: 120\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum dimension of the model\n",
    "print(f'Maximum DIM: {find_max_dim(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9451adb",
   "metadata": {},
   "source": [
    "#### 3.2 Validate the accuracy of pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cca4d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.3239, Validation Accuracy: 91.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(model, val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d526b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = model.learnable_parameter\n",
    "number_param = len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1a8b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters keys: ['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.bias', 'block3.layer.5.conv2.weight']\n",
      "Number of parameters to be learned: 3\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the parameters and the number of parameters\n",
    "print(f\"Parameters keys: {model.keys}\")\n",
    "print(f\"Number of parameters to be learned: {number_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a522bbe",
   "metadata": {},
   "source": [
    "### 4 Create hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17279a4b",
   "metadata": {},
   "source": [
    "#### 4.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6041a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Get the hypermodel\n",
    "hyper_model = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9ba74",
   "metadata": {},
   "source": [
    "#### 4.1 Print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cd60865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_ResMLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-2): 3 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e2cdf",
   "metadata": {},
   "source": [
    "#### 4.2 Initialize EMA to track only a smooth version of the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afb25ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA\n",
    "ema = EMA(hyper_model, decay=args.hyper_model.ema_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccb913",
   "metadata": {},
   "source": [
    "### 5 Get loss function, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "308f44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, val_criterion, optimizer, scheduler = get_optimizer(args, hyper_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45181795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Val_criterion: CrossEntropyLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001DBCFED3B50>\n"
     ]
    }
   ],
   "source": [
    "print(f'Criterion: {criterion}\\nVal_criterion: {val_criterion}\\nOptimizer: {optimizer}\\nScheduler: {scheduler}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991ee56",
   "metadata": {},
   "source": [
    "### 6 Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81099a8",
   "metadata": {},
   "source": [
    "#### 6.1 Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "731bcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting epoch and best accuracy\n",
    "start_epoch = 0\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b1a8f",
   "metadata": {},
   "source": [
    "#### 6.2 Directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91995285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the model\n",
    "os.makedirs(args.training.save_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1632f",
   "metadata": {},
   "source": [
    "#### 6.3 Resume training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cae570b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy/experiments_densenet/dense_19th_experiment/cifar10_nerf_best.pth'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.resume_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf17e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume_from = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55b68075",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_from:\n",
    "        print(f\"Resuming from checkpoint: {args.resume_from}\")\n",
    "        checkpoint_info = load_checkpoint(args.resume_from, hyper_model, optimizer, ema)\n",
    "        start_epoch = checkpoint_info['epoch']\n",
    "        best_acc = checkpoint_info['best_acc']\n",
    "        print(f\"Resuming from epoch: {start_epoch}, best accuracy: {best_acc*100:.2f}%\")\n",
    "        # Note: If there are more elements to retrieve, do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024e53f",
   "metadata": {},
   "source": [
    "#### 6.4 Initialize model dictionary for each dimension and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3558b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model for dim 48\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 428.7051086425781\n",
      "Permuted TV original model: 394.97320556640625\n"
     ]
    }
   ],
   "source": [
    "# Initialize model dictionary\n",
    "dim_dict, gt_model_dict = init_model_dict(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4566bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet3(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block2): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block3): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_model_dict['48']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c64f7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.3239, Validation Accuracy: 91.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(gt_model_dict['48'], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8981361b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'24': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  24., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  21.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  22.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  24.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 21,  3,  3],\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '25': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 25, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(25, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  25., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  22.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  25.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '26': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 26, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(26, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  26., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  23.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  26.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '27': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 27, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(27, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  27., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  24.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  27.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '28': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(28, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  28., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  25.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  28.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '29': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 29, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(29, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  29., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  26.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  29.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '30': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  30., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  27.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  30.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '31': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 31, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(31, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  31., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  28.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  31.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '32': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  32., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  29.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  32.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '33': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 33, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(33, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  33., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  30.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  33.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '34': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(34, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  34., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  31.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  34.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '35': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 35, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(35, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  35., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  32.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  35.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '36': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  36., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  33.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  36.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '37': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 37, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(37, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  37., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  34.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  37.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '38': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(38, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  38., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  35.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  38.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '39': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 39, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(39, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  39., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  36.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  39.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '40': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(40, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  40., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  37.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  40.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '41': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(41, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  41., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  38.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  41.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '42': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(42, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  42., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  39.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  42.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '43': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 43, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(43, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  43., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  40.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  43.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '44': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(44, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  44., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  41.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  44.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '45': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 45, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(45, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  45., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  42.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  45.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '46': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 46, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(46, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  46., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  43.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  46.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '47': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 47, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(47, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  47., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  44.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  47.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '48': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  48., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  45.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  47.,   3.,  12.,  48.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3],\n",
       "          [11, 47,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b93cb60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'24': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  24., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  21.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  22.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  24.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 21,  3,  3],\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '25': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 25, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(25, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  25., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  22.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  25.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '26': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 26, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(26, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  26., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  23.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  26.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '27': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 27, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(27, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  27., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  24.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  27.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '28': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(28, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  28., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  25.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  28.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '29': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 29, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(29, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  29., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  26.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  29.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '30': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  30., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  27.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  30.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '31': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 31, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(31, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  31., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  28.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  31.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '32': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  32., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  29.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  32.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '33': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 33, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(33, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  33., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  30.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  33.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '34': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(34, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  34., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  31.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  34.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '35': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 35, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(35, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  35., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  32.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  35.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '36': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  36., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  33.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  36.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '37': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 37, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(37, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  37., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  34.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  37.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '38': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(38, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  38., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  35.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  38.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '39': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 39, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(39, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  39., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  36.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  39.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '40': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(40, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  40., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  37.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  40.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '41': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(41, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  41., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  38.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  41.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '42': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(42, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  42., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  39.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  42.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '43': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 43, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(43, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  43., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  40.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  43.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '44': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(44, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  44., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  41.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  44.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '45': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 45, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(45, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  45., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  42.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  45.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '46': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 46, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(46, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  46., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  43.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  46.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '47': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 47, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(47, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  47., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  44.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  47.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '48': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  48., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  45.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  47.,   3.,  12.,  48.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3],\n",
       "          [11, 47,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])})}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict = shuffle_coordinates_all(dim_dict)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a20088d",
   "metadata": {},
   "source": [
    "#### 6.5 Initialize wandb for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "044696ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mefradosuryadi\u001b[0m (\u001b[33mefradosuryadi-universitas-indonesia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\wandb\\run-20250530_033435-hmzl3cee</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/hmzl3cee' target=\"_blank\">20250530033434-dense_19th_experiment</a></strong> to <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/hmzl3cee' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/hmzl3cee</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialize_wandb(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f2004",
   "metadata": {},
   "source": [
    "#### 6.6 Hypernetwork training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b78a21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.experiment.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0b94e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.2358, Reg Loss = 0.8331, Reconstruct Loss = 0.0000, Cls Loss = 0.2357, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2281, Reg Loss = 10.1287, Reconstruct Loss = 0.0036, Cls Loss = 0.2234, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2230, Reg Loss = 10.4359, Reconstruct Loss = 0.0043, Cls Loss = 0.2176, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2201, Reg Loss = 9.8539, Reconstruct Loss = 0.0032, Cls Loss = 0.2160, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2162, Reg Loss = 9.7283, Reconstruct Loss = 0.0024, Cls Loss = 0.2128, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2134, Reg Loss = 9.6454, Reconstruct Loss = 0.0021, Cls Loss = 0.2104, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2120, Reg Loss = 9.5445, Reconstruct Loss = 0.0018, Cls Loss = 0.2092, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2106, Reg Loss = 9.4299, Reconstruct Loss = 0.0017, Cls Loss = 0.2080, Learning rate = 1.0000e-03\n",
      "Epoch [1/200], Training Loss: 0.2099, Training Accuracy: 93.51, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Validation Loss: 11.0620, Validation Accuracy: 29.04%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 0 with accuracy: 29.04%\n",
      "Iteration 0: Loss = 0.2293, Reg Loss = 9.0578, Reconstruct Loss = 0.0000, Cls Loss = 0.2284, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1844, Reg Loss = 8.5999, Reconstruct Loss = 0.0014, Cls Loss = 0.1822, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1940, Reg Loss = 8.5660, Reconstruct Loss = 0.0011, Cls Loss = 0.1921, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1942, Reg Loss = 8.6554, Reconstruct Loss = 0.0011, Cls Loss = 0.1922, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1926, Reg Loss = 8.6853, Reconstruct Loss = 0.0010, Cls Loss = 0.1907, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1942, Reg Loss = 8.7552, Reconstruct Loss = 0.0010, Cls Loss = 0.1923, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1919, Reg Loss = 8.7216, Reconstruct Loss = 0.0009, Cls Loss = 0.1901, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1918, Reg Loss = 8.6541, Reconstruct Loss = 0.0009, Cls Loss = 0.1900, Learning rate = 1.0000e-03\n",
      "Epoch [2/200], Training Loss: 0.1917, Training Accuracy: 93.87, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Validation Loss: 5.3093, Validation Accuracy: 38.49%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 1 with accuracy: 38.49%\n",
      "Iteration 0: Loss = 0.1666, Reg Loss = 7.4902, Reconstruct Loss = 0.0000, Cls Loss = 0.1659, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1910, Reg Loss = 7.0223, Reconstruct Loss = 0.0007, Cls Loss = 0.1896, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1836, Reg Loss = 7.0138, Reconstruct Loss = 0.0008, Cls Loss = 0.1821, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1853, Reg Loss = 6.9553, Reconstruct Loss = 0.0009, Cls Loss = 0.1838, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1836, Reg Loss = 6.9088, Reconstruct Loss = 0.0010, Cls Loss = 0.1819, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1837, Reg Loss = 6.9176, Reconstruct Loss = 0.0008, Cls Loss = 0.1822, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1840, Reg Loss = 6.9172, Reconstruct Loss = 0.0009, Cls Loss = 0.1824, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1840, Reg Loss = 6.9235, Reconstruct Loss = 0.0009, Cls Loss = 0.1824, Learning rate = 1.0000e-03\n",
      "Epoch [3/200], Training Loss: 0.1836, Training Accuracy: 94.02, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Validation Loss: 2.0115, Validation Accuracy: 64.72%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 2 with accuracy: 64.72%\n",
      "Iteration 0: Loss = 0.1494, Reg Loss = 6.3089, Reconstruct Loss = 0.0000, Cls Loss = 0.1487, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1889, Reg Loss = 7.2496, Reconstruct Loss = 0.0005, Cls Loss = 0.1877, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1818, Reg Loss = 7.2457, Reconstruct Loss = 0.0007, Cls Loss = 0.1804, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1798, Reg Loss = 7.4211, Reconstruct Loss = 0.0006, Cls Loss = 0.1784, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1772, Reg Loss = 7.3999, Reconstruct Loss = 0.0006, Cls Loss = 0.1758, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1757, Reg Loss = 7.3616, Reconstruct Loss = 0.0007, Cls Loss = 0.1743, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1744, Reg Loss = 7.3109, Reconstruct Loss = 0.0007, Cls Loss = 0.1730, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1721, Reg Loss = 7.3696, Reconstruct Loss = 0.0007, Cls Loss = 0.1707, Learning rate = 1.0000e-03\n",
      "Epoch [4/200], Training Loss: 0.1705, Training Accuracy: 94.58, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Validation Loss: 4.2543, Validation Accuracy: 49.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1167, Reg Loss = 6.2901, Reconstruct Loss = 0.0000, Cls Loss = 0.1161, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1492, Reg Loss = 7.2966, Reconstruct Loss = 0.0008, Cls Loss = 0.1476, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1457, Reg Loss = 7.0676, Reconstruct Loss = 0.0008, Cls Loss = 0.1442, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1427, Reg Loss = 6.8764, Reconstruct Loss = 0.0007, Cls Loss = 0.1413, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1399, Reg Loss = 6.8316, Reconstruct Loss = 0.0008, Cls Loss = 0.1384, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1370, Reg Loss = 6.8534, Reconstruct Loss = 0.0007, Cls Loss = 0.1356, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1337, Reg Loss = 6.8538, Reconstruct Loss = 0.0006, Cls Loss = 0.1323, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1307, Reg Loss = 6.7628, Reconstruct Loss = 0.0006, Cls Loss = 0.1294, Learning rate = 1.0000e-03\n",
      "Epoch [5/200], Training Loss: 0.1301, Training Accuracy: 95.86, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Validation Loss: 3.2850, Validation Accuracy: 57.11%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0693, Reg Loss = 5.6853, Reconstruct Loss = 0.0000, Cls Loss = 0.0688, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1096, Reg Loss = 6.4838, Reconstruct Loss = 0.0008, Cls Loss = 0.1081, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1119, Reg Loss = 6.2427, Reconstruct Loss = 0.0007, Cls Loss = 0.1106, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1089, Reg Loss = 6.3362, Reconstruct Loss = 0.0008, Cls Loss = 0.1075, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1093, Reg Loss = 6.4353, Reconstruct Loss = 0.0007, Cls Loss = 0.1079, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1079, Reg Loss = 6.4044, Reconstruct Loss = 0.0008, Cls Loss = 0.1064, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1059, Reg Loss = 6.3774, Reconstruct Loss = 0.0008, Cls Loss = 0.1045, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1053, Reg Loss = 6.3633, Reconstruct Loss = 0.0007, Cls Loss = 0.1039, Learning rate = 1.0000e-03\n",
      "Epoch [6/200], Training Loss: 0.1050, Training Accuracy: 96.75, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Validation Loss: 4.6296, Validation Accuracy: 53.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0834, Reg Loss = 6.3786, Reconstruct Loss = 0.0000, Cls Loss = 0.0828, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0968, Reg Loss = 6.0962, Reconstruct Loss = 0.0002, Cls Loss = 0.0960, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0929, Reg Loss = 6.1650, Reconstruct Loss = 0.0005, Cls Loss = 0.0917, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0929, Reg Loss = 6.2281, Reconstruct Loss = 0.0006, Cls Loss = 0.0917, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0940, Reg Loss = 6.4302, Reconstruct Loss = 0.0006, Cls Loss = 0.0927, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0935, Reg Loss = 6.5233, Reconstruct Loss = 0.0006, Cls Loss = 0.0922, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0931, Reg Loss = 6.6471, Reconstruct Loss = 0.0007, Cls Loss = 0.0917, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0925, Reg Loss = 6.6556, Reconstruct Loss = 0.0007, Cls Loss = 0.0911, Learning rate = 1.0000e-03\n",
      "Epoch [7/200], Training Loss: 0.0922, Training Accuracy: 97.18, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Validation Loss: 6.3619, Validation Accuracy: 44.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0658, Reg Loss = 7.8215, Reconstruct Loss = 0.0000, Cls Loss = 0.0650, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0884, Reg Loss = 7.3830, Reconstruct Loss = 0.0005, Cls Loss = 0.0871, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0845, Reg Loss = 7.6074, Reconstruct Loss = 0.0008, Cls Loss = 0.0830, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0844, Reg Loss = 7.7054, Reconstruct Loss = 0.0008, Cls Loss = 0.0828, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0828, Reg Loss = 7.6363, Reconstruct Loss = 0.0009, Cls Loss = 0.0811, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0817, Reg Loss = 7.6132, Reconstruct Loss = 0.0009, Cls Loss = 0.0801, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0823, Reg Loss = 7.6167, Reconstruct Loss = 0.0009, Cls Loss = 0.0807, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0805, Reg Loss = 7.6185, Reconstruct Loss = 0.0009, Cls Loss = 0.0789, Learning rate = 1.0000e-03\n",
      "Epoch [8/200], Training Loss: 0.0797, Training Accuracy: 97.54, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Validation Loss: 3.4655, Validation Accuracy: 58.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1166, Reg Loss = 7.0457, Reconstruct Loss = 0.0000, Cls Loss = 0.1159, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0756, Reg Loss = 7.4008, Reconstruct Loss = 0.0011, Cls Loss = 0.0738, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0721, Reg Loss = 7.3956, Reconstruct Loss = 0.0008, Cls Loss = 0.0706, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0747, Reg Loss = 7.3517, Reconstruct Loss = 0.0007, Cls Loss = 0.0732, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0739, Reg Loss = 7.4112, Reconstruct Loss = 0.0009, Cls Loss = 0.0723, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0733, Reg Loss = 7.3873, Reconstruct Loss = 0.0008, Cls Loss = 0.0717, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0727, Reg Loss = 7.5859, Reconstruct Loss = 0.0008, Cls Loss = 0.0711, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0729, Reg Loss = 7.5943, Reconstruct Loss = 0.0008, Cls Loss = 0.0713, Learning rate = 1.0000e-03\n",
      "Epoch [9/200], Training Loss: 0.0723, Training Accuracy: 97.78, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Validation Loss: 2.8052, Validation Accuracy: 62.83%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1438, Reg Loss = 9.6655, Reconstruct Loss = 0.0142, Cls Loss = 0.1286, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0714, Reg Loss = 7.3885, Reconstruct Loss = 0.0007, Cls Loss = 0.0699, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0692, Reg Loss = 7.2258, Reconstruct Loss = 0.0006, Cls Loss = 0.0679, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0658, Reg Loss = 7.2411, Reconstruct Loss = 0.0008, Cls Loss = 0.0643, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0662, Reg Loss = 7.3383, Reconstruct Loss = 0.0008, Cls Loss = 0.0646, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0658, Reg Loss = 7.3238, Reconstruct Loss = 0.0007, Cls Loss = 0.0644, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0662, Reg Loss = 7.3250, Reconstruct Loss = 0.0008, Cls Loss = 0.0647, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0670, Reg Loss = 7.3913, Reconstruct Loss = 0.0007, Cls Loss = 0.0655, Learning rate = 1.0000e-03\n",
      "Epoch [10/200], Training Loss: 0.0671, Training Accuracy: 97.96, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Validation Loss: 3.1232, Validation Accuracy: 59.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1164, Reg Loss = 7.1060, Reconstruct Loss = 0.0000, Cls Loss = 0.1157, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0701, Reg Loss = 7.0040, Reconstruct Loss = 0.0003, Cls Loss = 0.0691, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0643, Reg Loss = 7.1884, Reconstruct Loss = 0.0005, Cls Loss = 0.0631, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0647, Reg Loss = 7.3027, Reconstruct Loss = 0.0006, Cls Loss = 0.0634, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0668, Reg Loss = 7.3120, Reconstruct Loss = 0.0006, Cls Loss = 0.0654, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0659, Reg Loss = 7.3691, Reconstruct Loss = 0.0007, Cls Loss = 0.0646, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0657, Reg Loss = 7.3265, Reconstruct Loss = 0.0006, Cls Loss = 0.0643, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0649, Reg Loss = 7.3226, Reconstruct Loss = 0.0007, Cls Loss = 0.0635, Learning rate = 1.0000e-03\n",
      "Epoch [11/200], Training Loss: 0.0651, Training Accuracy: 97.98, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Validation Loss: 2.7309, Validation Accuracy: 63.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0626, Reg Loss = 6.7956, Reconstruct Loss = 0.0000, Cls Loss = 0.0619, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0655, Reg Loss = 7.8734, Reconstruct Loss = 0.0018, Cls Loss = 0.0629, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0625, Reg Loss = 7.8141, Reconstruct Loss = 0.0010, Cls Loss = 0.0607, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0631, Reg Loss = 7.8032, Reconstruct Loss = 0.0012, Cls Loss = 0.0611, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0622, Reg Loss = 7.7586, Reconstruct Loss = 0.0011, Cls Loss = 0.0603, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0612, Reg Loss = 7.7180, Reconstruct Loss = 0.0010, Cls Loss = 0.0594, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0612, Reg Loss = 7.6760, Reconstruct Loss = 0.0010, Cls Loss = 0.0594, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0607, Reg Loss = 7.7239, Reconstruct Loss = 0.0009, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Epoch [12/200], Training Loss: 0.0609, Training Accuracy: 98.17, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Validation Loss: 1.6173, Validation Accuracy: 71.82%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 11 with accuracy: 71.82%\n",
      "Iteration 0: Loss = 0.0333, Reg Loss = 8.3794, Reconstruct Loss = 0.0000, Cls Loss = 0.0324, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0593, Reg Loss = 8.4215, Reconstruct Loss = 0.0008, Cls Loss = 0.0576, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0624, Reg Loss = 8.4576, Reconstruct Loss = 0.0011, Cls Loss = 0.0604, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0604, Reg Loss = 8.4125, Reconstruct Loss = 0.0011, Cls Loss = 0.0585, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0609, Reg Loss = 8.1988, Reconstruct Loss = 0.0011, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0621, Reg Loss = 8.1825, Reconstruct Loss = 0.0010, Cls Loss = 0.0602, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0614, Reg Loss = 8.0476, Reconstruct Loss = 0.0010, Cls Loss = 0.0596, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0612, Reg Loss = 7.9057, Reconstruct Loss = 0.0009, Cls Loss = 0.0595, Learning rate = 1.0000e-03\n",
      "Epoch [13/200], Training Loss: 0.0610, Training Accuracy: 98.07, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Validation Loss: 1.0182, Validation Accuracy: 79.05%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 12 with accuracy: 79.05%\n",
      "Iteration 0: Loss = 0.1294, Reg Loss = 7.8360, Reconstruct Loss = 0.0000, Cls Loss = 0.1286, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0578, Reg Loss = 7.5604, Reconstruct Loss = 0.0008, Cls Loss = 0.0563, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0595, Reg Loss = 7.4539, Reconstruct Loss = 0.0005, Cls Loss = 0.0582, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0571, Reg Loss = 7.4063, Reconstruct Loss = 0.0005, Cls Loss = 0.0558, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0572, Reg Loss = 7.4463, Reconstruct Loss = 0.0006, Cls Loss = 0.0559, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0585, Reg Loss = 7.4561, Reconstruct Loss = 0.0006, Cls Loss = 0.0572, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0573, Reg Loss = 7.4396, Reconstruct Loss = 0.0005, Cls Loss = 0.0561, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0570, Reg Loss = 7.4636, Reconstruct Loss = 0.0006, Cls Loss = 0.0557, Learning rate = 1.0000e-03\n",
      "Epoch [14/200], Training Loss: 0.0575, Training Accuracy: 98.29, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Validation Loss: 1.5705, Validation Accuracy: 71.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0627, Reg Loss = 6.9297, Reconstruct Loss = 0.0000, Cls Loss = 0.0620, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0574, Reg Loss = 7.1813, Reconstruct Loss = 0.0010, Cls Loss = 0.0557, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0583, Reg Loss = 7.2594, Reconstruct Loss = 0.0009, Cls Loss = 0.0567, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0582, Reg Loss = 7.2878, Reconstruct Loss = 0.0009, Cls Loss = 0.0565, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0583, Reg Loss = 7.3756, Reconstruct Loss = 0.0008, Cls Loss = 0.0567, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0581, Reg Loss = 7.4336, Reconstruct Loss = 0.0008, Cls Loss = 0.0566, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0587, Reg Loss = 7.4215, Reconstruct Loss = 0.0008, Cls Loss = 0.0573, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0582, Reg Loss = 7.3789, Reconstruct Loss = 0.0007, Cls Loss = 0.0568, Learning rate = 1.0000e-03\n",
      "Epoch [15/200], Training Loss: 0.0580, Training Accuracy: 98.22, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Validation Loss: 1.4245, Validation Accuracy: 75.84%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0561, Reg Loss = 6.6399, Reconstruct Loss = 0.0000, Cls Loss = 0.0555, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0569, Reg Loss = 6.7594, Reconstruct Loss = 0.0005, Cls Loss = 0.0557, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0557, Reg Loss = 7.0722, Reconstruct Loss = 0.0008, Cls Loss = 0.0542, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0539, Reg Loss = 6.9751, Reconstruct Loss = 0.0008, Cls Loss = 0.0524, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0538, Reg Loss = 6.9871, Reconstruct Loss = 0.0008, Cls Loss = 0.0522, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0550, Reg Loss = 7.1178, Reconstruct Loss = 0.0008, Cls Loss = 0.0535, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0547, Reg Loss = 7.1354, Reconstruct Loss = 0.0008, Cls Loss = 0.0532, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0548, Reg Loss = 7.1081, Reconstruct Loss = 0.0007, Cls Loss = 0.0533, Learning rate = 1.0000e-03\n",
      "Epoch [16/200], Training Loss: 0.0548, Training Accuracy: 98.31, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Validation Loss: 1.2831, Validation Accuracy: 77.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0244, Reg Loss = 6.4876, Reconstruct Loss = 0.0000, Cls Loss = 0.0238, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0538, Reg Loss = 6.6866, Reconstruct Loss = 0.0008, Cls Loss = 0.0523, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0545, Reg Loss = 6.9824, Reconstruct Loss = 0.0010, Cls Loss = 0.0529, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0555, Reg Loss = 7.3552, Reconstruct Loss = 0.0008, Cls Loss = 0.0539, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0567, Reg Loss = 7.4023, Reconstruct Loss = 0.0007, Cls Loss = 0.0553, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0566, Reg Loss = 7.4457, Reconstruct Loss = 0.0007, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0555, Reg Loss = 7.4544, Reconstruct Loss = 0.0007, Cls Loss = 0.0541, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0553, Reg Loss = 7.4531, Reconstruct Loss = 0.0006, Cls Loss = 0.0539, Learning rate = 1.0000e-03\n",
      "Epoch [17/200], Training Loss: 0.0554, Training Accuracy: 98.25, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200], Validation Loss: 1.5259, Validation Accuracy: 74.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0466, Reg Loss = 6.9563, Reconstruct Loss = 0.0000, Cls Loss = 0.0459, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0494, Reg Loss = 7.4527, Reconstruct Loss = 0.0006, Cls Loss = 0.0481, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0536, Reg Loss = 7.3480, Reconstruct Loss = 0.0009, Cls Loss = 0.0520, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0551, Reg Loss = 7.1795, Reconstruct Loss = 0.0007, Cls Loss = 0.0537, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0560, Reg Loss = 7.2093, Reconstruct Loss = 0.0007, Cls Loss = 0.0546, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0549, Reg Loss = 7.1849, Reconstruct Loss = 0.0007, Cls Loss = 0.0535, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0545, Reg Loss = 7.1593, Reconstruct Loss = 0.0007, Cls Loss = 0.0532, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0544, Reg Loss = 7.2102, Reconstruct Loss = 0.0007, Cls Loss = 0.0530, Learning rate = 1.0000e-03\n",
      "Epoch [18/200], Training Loss: 0.0543, Training Accuracy: 98.31, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200], Validation Loss: 1.0511, Validation Accuracy: 79.18%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 17 with accuracy: 79.18%\n",
      "Iteration 0: Loss = 0.0344, Reg Loss = 6.0349, Reconstruct Loss = 0.0000, Cls Loss = 0.0338, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0526, Reg Loss = 7.4223, Reconstruct Loss = 0.0008, Cls Loss = 0.0510, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0530, Reg Loss = 7.5616, Reconstruct Loss = 0.0009, Cls Loss = 0.0514, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0537, Reg Loss = 7.8254, Reconstruct Loss = 0.0008, Cls Loss = 0.0521, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0547, Reg Loss = 7.8908, Reconstruct Loss = 0.0007, Cls Loss = 0.0533, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0556, Reg Loss = 7.8113, Reconstruct Loss = 0.0006, Cls Loss = 0.0542, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0542, Reg Loss = 7.7989, Reconstruct Loss = 0.0007, Cls Loss = 0.0528, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0533, Reg Loss = 7.7301, Reconstruct Loss = 0.0006, Cls Loss = 0.0519, Learning rate = 1.0000e-03\n",
      "Epoch [19/200], Training Loss: 0.0523, Training Accuracy: 98.42, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Validation Loss: 0.6411, Validation Accuracy: 83.55%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 18 with accuracy: 83.55%\n",
      "Iteration 0: Loss = 0.0077, Reg Loss = 6.9496, Reconstruct Loss = 0.0000, Cls Loss = 0.0071, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0521, Reg Loss = 7.5475, Reconstruct Loss = 0.0008, Cls Loss = 0.0505, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0532, Reg Loss = 7.5290, Reconstruct Loss = 0.0007, Cls Loss = 0.0518, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0520, Reg Loss = 7.5306, Reconstruct Loss = 0.0006, Cls Loss = 0.0506, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0511, Reg Loss = 7.5194, Reconstruct Loss = 0.0005, Cls Loss = 0.0498, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0517, Reg Loss = 7.5983, Reconstruct Loss = 0.0005, Cls Loss = 0.0504, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0515, Reg Loss = 7.6259, Reconstruct Loss = 0.0005, Cls Loss = 0.0502, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0514, Reg Loss = 7.6350, Reconstruct Loss = 0.0005, Cls Loss = 0.0502, Learning rate = 1.0000e-03\n",
      "Epoch [20/200], Training Loss: 0.0514, Training Accuracy: 98.40, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Validation Loss: 0.8224, Validation Accuracy: 80.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0642, Reg Loss = 7.4702, Reconstruct Loss = 0.0000, Cls Loss = 0.0635, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0539, Reg Loss = 7.4274, Reconstruct Loss = 0.0005, Cls Loss = 0.0526, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0524, Reg Loss = 7.6262, Reconstruct Loss = 0.0007, Cls Loss = 0.0510, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0510, Reg Loss = 7.6867, Reconstruct Loss = 0.0009, Cls Loss = 0.0494, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0516, Reg Loss = 7.6624, Reconstruct Loss = 0.0008, Cls Loss = 0.0500, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0515, Reg Loss = 7.6835, Reconstruct Loss = 0.0007, Cls Loss = 0.0500, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0521, Reg Loss = 7.6223, Reconstruct Loss = 0.0008, Cls Loss = 0.0506, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0530, Reg Loss = 7.5773, Reconstruct Loss = 0.0008, Cls Loss = 0.0515, Learning rate = 1.0000e-03\n",
      "Epoch [21/200], Training Loss: 0.0529, Training Accuracy: 98.32, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Validation Loss: 0.9649, Validation Accuracy: 78.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0633, Reg Loss = 7.3685, Reconstruct Loss = 0.0000, Cls Loss = 0.0626, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0518, Reg Loss = 7.4011, Reconstruct Loss = 0.0008, Cls Loss = 0.0502, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0512, Reg Loss = 7.3173, Reconstruct Loss = 0.0010, Cls Loss = 0.0495, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0512, Reg Loss = 7.4126, Reconstruct Loss = 0.0010, Cls Loss = 0.0495, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0504, Reg Loss = 7.3664, Reconstruct Loss = 0.0008, Cls Loss = 0.0489, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0504, Reg Loss = 7.3306, Reconstruct Loss = 0.0008, Cls Loss = 0.0488, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0503, Reg Loss = 7.3446, Reconstruct Loss = 0.0007, Cls Loss = 0.0489, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0507, Reg Loss = 7.4491, Reconstruct Loss = 0.0007, Cls Loss = 0.0493, Learning rate = 1.0000e-03\n",
      "Epoch [22/200], Training Loss: 0.0510, Training Accuracy: 98.47, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200], Validation Loss: 0.9363, Validation Accuracy: 80.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0464, Reg Loss = 7.3564, Reconstruct Loss = 0.0000, Cls Loss = 0.0456, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0544, Reg Loss = 8.0431, Reconstruct Loss = 0.0013, Cls Loss = 0.0523, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0493, Reg Loss = 7.8091, Reconstruct Loss = 0.0011, Cls Loss = 0.0474, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0488, Reg Loss = 7.8150, Reconstruct Loss = 0.0008, Cls Loss = 0.0473, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0490, Reg Loss = 7.7170, Reconstruct Loss = 0.0007, Cls Loss = 0.0476, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0496, Reg Loss = 7.8027, Reconstruct Loss = 0.0009, Cls Loss = 0.0479, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0483, Reg Loss = 7.7044, Reconstruct Loss = 0.0008, Cls Loss = 0.0468, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0495, Reg Loss = 7.6792, Reconstruct Loss = 0.0008, Cls Loss = 0.0479, Learning rate = 1.0000e-03\n",
      "Epoch [23/200], Training Loss: 0.0498, Training Accuracy: 98.47, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 37.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200], Validation Loss: 0.5683, Validation Accuracy: 84.94%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 22 with accuracy: 84.94%\n",
      "Iteration 0: Loss = 0.0237, Reg Loss = 6.8434, Reconstruct Loss = 0.0000, Cls Loss = 0.0231, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0456, Reg Loss = 7.7491, Reconstruct Loss = 0.0017, Cls Loss = 0.0431, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0483, Reg Loss = 7.8424, Reconstruct Loss = 0.0014, Cls Loss = 0.0461, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0476, Reg Loss = 7.7873, Reconstruct Loss = 0.0013, Cls Loss = 0.0455, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0489, Reg Loss = 7.6835, Reconstruct Loss = 0.0013, Cls Loss = 0.0468, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0497, Reg Loss = 7.6415, Reconstruct Loss = 0.0011, Cls Loss = 0.0477, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0485, Reg Loss = 7.6160, Reconstruct Loss = 0.0010, Cls Loss = 0.0468, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0483, Reg Loss = 7.6537, Reconstruct Loss = 0.0010, Cls Loss = 0.0465, Learning rate = 1.0000e-03\n",
      "Epoch [24/200], Training Loss: 0.0484, Training Accuracy: 98.57, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Validation Loss: 0.5896, Validation Accuracy: 84.68%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0884, Reg Loss = 7.7561, Reconstruct Loss = 0.0000, Cls Loss = 0.0876, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0492, Reg Loss = 7.9229, Reconstruct Loss = 0.0009, Cls Loss = 0.0475, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0483, Reg Loss = 7.8001, Reconstruct Loss = 0.0010, Cls Loss = 0.0465, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0494, Reg Loss = 7.6519, Reconstruct Loss = 0.0008, Cls Loss = 0.0478, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0473, Reg Loss = 7.5172, Reconstruct Loss = 0.0007, Cls Loss = 0.0458, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0469, Reg Loss = 7.5326, Reconstruct Loss = 0.0007, Cls Loss = 0.0454, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0465, Reg Loss = 7.5059, Reconstruct Loss = 0.0007, Cls Loss = 0.0450, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0465, Reg Loss = 7.4687, Reconstruct Loss = 0.0007, Cls Loss = 0.0451, Learning rate = 1.0000e-03\n",
      "Epoch [25/200], Training Loss: 0.0470, Training Accuracy: 98.57, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200], Validation Loss: 0.6831, Validation Accuracy: 81.49%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0709, Reg Loss = 8.1461, Reconstruct Loss = 0.0000, Cls Loss = 0.0701, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0470, Reg Loss = 7.7199, Reconstruct Loss = 0.0004, Cls Loss = 0.0458, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0474, Reg Loss = 7.6256, Reconstruct Loss = 0.0007, Cls Loss = 0.0459, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0466, Reg Loss = 7.5045, Reconstruct Loss = 0.0006, Cls Loss = 0.0453, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0464, Reg Loss = 7.4861, Reconstruct Loss = 0.0005, Cls Loss = 0.0451, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0469, Reg Loss = 7.4597, Reconstruct Loss = 0.0006, Cls Loss = 0.0456, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0475, Reg Loss = 7.3813, Reconstruct Loss = 0.0005, Cls Loss = 0.0462, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0468, Reg Loss = 7.3727, Reconstruct Loss = 0.0005, Cls Loss = 0.0455, Learning rate = 1.0000e-03\n",
      "Epoch [26/200], Training Loss: 0.0475, Training Accuracy: 98.56, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200], Validation Loss: 0.6705, Validation Accuracy: 82.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0927, Reg Loss = 6.9801, Reconstruct Loss = 0.0000, Cls Loss = 0.0920, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0578, Reg Loss = 7.5050, Reconstruct Loss = 0.0011, Cls Loss = 0.0559, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0523, Reg Loss = 7.5263, Reconstruct Loss = 0.0009, Cls Loss = 0.0507, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0512, Reg Loss = 7.4728, Reconstruct Loss = 0.0007, Cls Loss = 0.0498, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0501, Reg Loss = 7.4475, Reconstruct Loss = 0.0006, Cls Loss = 0.0487, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0489, Reg Loss = 7.5759, Reconstruct Loss = 0.0007, Cls Loss = 0.0475, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0488, Reg Loss = 7.5946, Reconstruct Loss = 0.0007, Cls Loss = 0.0474, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0489, Reg Loss = 7.6081, Reconstruct Loss = 0.0006, Cls Loss = 0.0476, Learning rate = 1.0000e-03\n",
      "Epoch [27/200], Training Loss: 0.0487, Training Accuracy: 98.52, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200], Validation Loss: 0.7736, Validation Accuracy: 82.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0835, Reg Loss = 7.3428, Reconstruct Loss = 0.0000, Cls Loss = 0.0828, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0464, Reg Loss = 7.9353, Reconstruct Loss = 0.0005, Cls Loss = 0.0451, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0460, Reg Loss = 7.8811, Reconstruct Loss = 0.0005, Cls Loss = 0.0447, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0445, Reg Loss = 7.8413, Reconstruct Loss = 0.0004, Cls Loss = 0.0433, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0454, Reg Loss = 7.8152, Reconstruct Loss = 0.0005, Cls Loss = 0.0442, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0448, Reg Loss = 7.8054, Reconstruct Loss = 0.0006, Cls Loss = 0.0435, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0462, Reg Loss = 7.7930, Reconstruct Loss = 0.0006, Cls Loss = 0.0449, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0458, Reg Loss = 7.7615, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-03\n",
      "Epoch [28/200], Training Loss: 0.0461, Training Accuracy: 98.57, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200], Validation Loss: 0.8357, Validation Accuracy: 79.62%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0438, Reg Loss = 6.9070, Reconstruct Loss = 0.0000, Cls Loss = 0.0431, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0440, Reg Loss = 7.3435, Reconstruct Loss = 0.0003, Cls Loss = 0.0430, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0451, Reg Loss = 7.2838, Reconstruct Loss = 0.0004, Cls Loss = 0.0439, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0452, Reg Loss = 7.5892, Reconstruct Loss = 0.0008, Cls Loss = 0.0436, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0450, Reg Loss = 7.6014, Reconstruct Loss = 0.0010, Cls Loss = 0.0432, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0460, Reg Loss = 7.5480, Reconstruct Loss = 0.0009, Cls Loss = 0.0444, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0459, Reg Loss = 7.5853, Reconstruct Loss = 0.0008, Cls Loss = 0.0443, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0463, Reg Loss = 7.6067, Reconstruct Loss = 0.0007, Cls Loss = 0.0448, Learning rate = 1.0000e-03\n",
      "Epoch [29/200], Training Loss: 0.0459, Training Accuracy: 98.58, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200], Validation Loss: 0.7467, Validation Accuracy: 81.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0506, Reg Loss = 7.9038, Reconstruct Loss = 0.0000, Cls Loss = 0.0498, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0480, Reg Loss = 7.7663, Reconstruct Loss = 0.0007, Cls Loss = 0.0466, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0472, Reg Loss = 7.7292, Reconstruct Loss = 0.0007, Cls Loss = 0.0458, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0481, Reg Loss = 7.9233, Reconstruct Loss = 0.0008, Cls Loss = 0.0465, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0491, Reg Loss = 8.0264, Reconstruct Loss = 0.0007, Cls Loss = 0.0476, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0483, Reg Loss = 7.9531, Reconstruct Loss = 0.0007, Cls Loss = 0.0468, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0480, Reg Loss = 7.8249, Reconstruct Loss = 0.0008, Cls Loss = 0.0464, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0484, Reg Loss = 7.7132, Reconstruct Loss = 0.0007, Cls Loss = 0.0469, Learning rate = 1.0000e-03\n",
      "Epoch [30/200], Training Loss: 0.0500, Training Accuracy: 98.46, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Validation Loss: 0.8309, Validation Accuracy: 78.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0510, Reg Loss = 6.8825, Reconstruct Loss = 0.0000, Cls Loss = 0.0503, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0573, Reg Loss = 8.4034, Reconstruct Loss = 0.0017, Cls Loss = 0.0547, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0536, Reg Loss = 8.2684, Reconstruct Loss = 0.0014, Cls Loss = 0.0514, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0523, Reg Loss = 8.2799, Reconstruct Loss = 0.0012, Cls Loss = 0.0502, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0502, Reg Loss = 8.2486, Reconstruct Loss = 0.0009, Cls Loss = 0.0484, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0498, Reg Loss = 8.2681, Reconstruct Loss = 0.0009, Cls Loss = 0.0481, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0489, Reg Loss = 8.2593, Reconstruct Loss = 0.0009, Cls Loss = 0.0472, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0491, Reg Loss = 8.2799, Reconstruct Loss = 0.0008, Cls Loss = 0.0475, Learning rate = 1.0000e-03\n",
      "Epoch [31/200], Training Loss: 0.0483, Training Accuracy: 98.45, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200], Validation Loss: 0.8148, Validation Accuracy: 81.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0386, Reg Loss = 8.2245, Reconstruct Loss = 0.0000, Cls Loss = 0.0377, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0504, Reg Loss = 8.1648, Reconstruct Loss = 0.0010, Cls Loss = 0.0486, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0480, Reg Loss = 7.9608, Reconstruct Loss = 0.0005, Cls Loss = 0.0467, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0465, Reg Loss = 7.9428, Reconstruct Loss = 0.0004, Cls Loss = 0.0452, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0468, Reg Loss = 7.8280, Reconstruct Loss = 0.0005, Cls Loss = 0.0455, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0454, Reg Loss = 7.8031, Reconstruct Loss = 0.0005, Cls Loss = 0.0441, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0453, Reg Loss = 7.8185, Reconstruct Loss = 0.0006, Cls Loss = 0.0440, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0451, Reg Loss = 7.8927, Reconstruct Loss = 0.0006, Cls Loss = 0.0437, Learning rate = 1.0000e-03\n",
      "Epoch [32/200], Training Loss: 0.0458, Training Accuracy: 98.63, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200], Validation Loss: 0.6115, Validation Accuracy: 85.31%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 31 with accuracy: 85.31%\n",
      "Iteration 0: Loss = 0.0250, Reg Loss = 7.1084, Reconstruct Loss = 0.0000, Cls Loss = 0.0243, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0426, Reg Loss = 7.6555, Reconstruct Loss = 0.0005, Cls Loss = 0.0413, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0439, Reg Loss = 7.6997, Reconstruct Loss = 0.0003, Cls Loss = 0.0428, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0459, Reg Loss = 7.7355, Reconstruct Loss = 0.0005, Cls Loss = 0.0446, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0455, Reg Loss = 7.8202, Reconstruct Loss = 0.0005, Cls Loss = 0.0441, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0464, Reg Loss = 7.9351, Reconstruct Loss = 0.0006, Cls Loss = 0.0449, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0471, Reg Loss = 7.9100, Reconstruct Loss = 0.0006, Cls Loss = 0.0457, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0468, Reg Loss = 7.8686, Reconstruct Loss = 0.0006, Cls Loss = 0.0454, Learning rate = 1.0000e-03\n",
      "Epoch [33/200], Training Loss: 0.0465, Training Accuracy: 98.54, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200], Validation Loss: 0.9690, Validation Accuracy: 80.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0246, Reg Loss = 8.3589, Reconstruct Loss = 0.0000, Cls Loss = 0.0237, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0457, Reg Loss = 8.3711, Reconstruct Loss = 0.0009, Cls Loss = 0.0440, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0434, Reg Loss = 8.1918, Reconstruct Loss = 0.0007, Cls Loss = 0.0419, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0449, Reg Loss = 8.1945, Reconstruct Loss = 0.0006, Cls Loss = 0.0435, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0448, Reg Loss = 8.1539, Reconstruct Loss = 0.0006, Cls Loss = 0.0434, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0453, Reg Loss = 8.1307, Reconstruct Loss = 0.0005, Cls Loss = 0.0440, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0460, Reg Loss = 8.1454, Reconstruct Loss = 0.0005, Cls Loss = 0.0447, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0459, Reg Loss = 8.1509, Reconstruct Loss = 0.0006, Cls Loss = 0.0445, Learning rate = 1.0000e-03\n",
      "Epoch [34/200], Training Loss: 0.0460, Training Accuracy: 98.56, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/200], Validation Loss: 0.6753, Validation Accuracy: 83.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1270, Reg Loss = 8.6792, Reconstruct Loss = 0.0000, Cls Loss = 0.1262, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0491, Reg Loss = 8.2116, Reconstruct Loss = 0.0006, Cls Loss = 0.0477, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0457, Reg Loss = 8.1583, Reconstruct Loss = 0.0006, Cls Loss = 0.0443, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0458, Reg Loss = 8.1545, Reconstruct Loss = 0.0007, Cls Loss = 0.0443, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0454, Reg Loss = 8.2159, Reconstruct Loss = 0.0007, Cls Loss = 0.0438, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0449, Reg Loss = 8.2575, Reconstruct Loss = 0.0007, Cls Loss = 0.0434, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0449, Reg Loss = 8.2344, Reconstruct Loss = 0.0006, Cls Loss = 0.0434, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0446, Reg Loss = 8.1557, Reconstruct Loss = 0.0006, Cls Loss = 0.0432, Learning rate = 1.0000e-03\n",
      "Epoch [35/200], Training Loss: 0.0444, Training Accuracy: 98.62, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/200], Validation Loss: 0.5980, Validation Accuracy: 85.65%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 34 with accuracy: 85.65%\n",
      "Iteration 0: Loss = 0.0442, Reg Loss = 7.7561, Reconstruct Loss = 0.0000, Cls Loss = 0.0435, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0464, Reg Loss = 8.2517, Reconstruct Loss = 0.0003, Cls Loss = 0.0453, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0465, Reg Loss = 8.3025, Reconstruct Loss = 0.0004, Cls Loss = 0.0452, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0466, Reg Loss = 8.4255, Reconstruct Loss = 0.0006, Cls Loss = 0.0451, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0450, Reg Loss = 8.3731, Reconstruct Loss = 0.0006, Cls Loss = 0.0436, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 8.2193, Reconstruct Loss = 0.0006, Cls Loss = 0.0439, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0457, Reg Loss = 8.1334, Reconstruct Loss = 0.0005, Cls Loss = 0.0444, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0457, Reg Loss = 8.1265, Reconstruct Loss = 0.0006, Cls Loss = 0.0443, Learning rate = 1.0000e-03\n",
      "Epoch [36/200], Training Loss: 0.0452, Training Accuracy: 98.60, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200], Validation Loss: 0.6055, Validation Accuracy: 85.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0134, Reg Loss = 7.3984, Reconstruct Loss = 0.0000, Cls Loss = 0.0126, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0456, Reg Loss = 8.4257, Reconstruct Loss = 0.0006, Cls Loss = 0.0442, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0458, Reg Loss = 8.4448, Reconstruct Loss = 0.0006, Cls Loss = 0.0443, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0459, Reg Loss = 8.3315, Reconstruct Loss = 0.0005, Cls Loss = 0.0446, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0448, Reg Loss = 8.3013, Reconstruct Loss = 0.0005, Cls Loss = 0.0435, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0448, Reg Loss = 8.2356, Reconstruct Loss = 0.0005, Cls Loss = 0.0435, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0455, Reg Loss = 8.2936, Reconstruct Loss = 0.0005, Cls Loss = 0.0442, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0452, Reg Loss = 8.2648, Reconstruct Loss = 0.0005, Cls Loss = 0.0438, Learning rate = 1.0000e-03\n",
      "Epoch [37/200], Training Loss: 0.0453, Training Accuracy: 98.60, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/200], Validation Loss: 0.7169, Validation Accuracy: 84.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0051, Reg Loss = 8.1826, Reconstruct Loss = 0.0000, Cls Loss = 0.0043, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0439, Reg Loss = 8.2107, Reconstruct Loss = 0.0008, Cls Loss = 0.0423, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0414, Reg Loss = 8.1720, Reconstruct Loss = 0.0007, Cls Loss = 0.0398, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0424, Reg Loss = 8.2081, Reconstruct Loss = 0.0007, Cls Loss = 0.0409, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0432, Reg Loss = 8.3440, Reconstruct Loss = 0.0006, Cls Loss = 0.0417, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0431, Reg Loss = 8.3054, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0437, Reg Loss = 8.3117, Reconstruct Loss = 0.0006, Cls Loss = 0.0423, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0427, Reg Loss = 8.3025, Reconstruct Loss = 0.0005, Cls Loss = 0.0413, Learning rate = 1.0000e-03\n",
      "Epoch [38/200], Training Loss: 0.0432, Training Accuracy: 98.70, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200], Validation Loss: 0.9632, Validation Accuracy: 81.04%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0278, Reg Loss = 8.3735, Reconstruct Loss = 0.0000, Cls Loss = 0.0270, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0438, Reg Loss = 7.9495, Reconstruct Loss = 0.0003, Cls Loss = 0.0427, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0446, Reg Loss = 8.1360, Reconstruct Loss = 0.0008, Cls Loss = 0.0430, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0428, Reg Loss = 8.2830, Reconstruct Loss = 0.0007, Cls Loss = 0.0412, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0432, Reg Loss = 8.3098, Reconstruct Loss = 0.0007, Cls Loss = 0.0417, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0428, Reg Loss = 8.2966, Reconstruct Loss = 0.0007, Cls Loss = 0.0413, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0426, Reg Loss = 8.2471, Reconstruct Loss = 0.0007, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0438, Reg Loss = 8.3027, Reconstruct Loss = 0.0007, Cls Loss = 0.0423, Learning rate = 1.0000e-03\n",
      "Epoch [39/200], Training Loss: 0.0438, Training Accuracy: 98.67, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200], Validation Loss: 0.6998, Validation Accuracy: 83.71%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1159, Reg Loss = 8.4192, Reconstruct Loss = 0.0000, Cls Loss = 0.1150, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0473, Reg Loss = 8.4263, Reconstruct Loss = 0.0003, Cls Loss = 0.0461, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0475, Reg Loss = 8.2852, Reconstruct Loss = 0.0004, Cls Loss = 0.0462, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0445, Reg Loss = 8.3416, Reconstruct Loss = 0.0005, Cls Loss = 0.0432, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0439, Reg Loss = 8.2810, Reconstruct Loss = 0.0006, Cls Loss = 0.0425, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0436, Reg Loss = 8.3732, Reconstruct Loss = 0.0007, Cls Loss = 0.0421, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0434, Reg Loss = 8.3534, Reconstruct Loss = 0.0006, Cls Loss = 0.0420, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0436, Reg Loss = 8.3728, Reconstruct Loss = 0.0007, Cls Loss = 0.0420, Learning rate = 1.0000e-03\n",
      "Epoch [40/200], Training Loss: 0.0434, Training Accuracy: 98.70, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/200], Validation Loss: 0.7493, Validation Accuracy: 83.77%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0255, Reg Loss = 7.2559, Reconstruct Loss = 0.0000, Cls Loss = 0.0247, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0492, Reg Loss = 8.3561, Reconstruct Loss = 0.0007, Cls Loss = 0.0477, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0441, Reg Loss = 8.2863, Reconstruct Loss = 0.0006, Cls Loss = 0.0427, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0429, Reg Loss = 8.3339, Reconstruct Loss = 0.0006, Cls Loss = 0.0415, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0434, Reg Loss = 8.3508, Reconstruct Loss = 0.0007, Cls Loss = 0.0419, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0430, Reg Loss = 8.3594, Reconstruct Loss = 0.0006, Cls Loss = 0.0416, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0436, Reg Loss = 8.3144, Reconstruct Loss = 0.0006, Cls Loss = 0.0422, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0444, Reg Loss = 8.3462, Reconstruct Loss = 0.0006, Cls Loss = 0.0429, Learning rate = 1.0000e-03\n",
      "Epoch [41/200], Training Loss: 0.0436, Training Accuracy: 98.67, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/200], Validation Loss: 0.6749, Validation Accuracy: 84.00%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0275, Reg Loss = 8.2019, Reconstruct Loss = 0.0000, Cls Loss = 0.0267, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0420, Reg Loss = 7.9757, Reconstruct Loss = 0.0010, Cls Loss = 0.0402, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0426, Reg Loss = 7.8488, Reconstruct Loss = 0.0008, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0425, Reg Loss = 7.9658, Reconstruct Loss = 0.0010, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0429, Reg Loss = 7.9686, Reconstruct Loss = 0.0010, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0441, Reg Loss = 8.0280, Reconstruct Loss = 0.0010, Cls Loss = 0.0424, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0440, Reg Loss = 8.0560, Reconstruct Loss = 0.0009, Cls Loss = 0.0423, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0438, Reg Loss = 8.0420, Reconstruct Loss = 0.0008, Cls Loss = 0.0421, Learning rate = 1.0000e-03\n",
      "Epoch [42/200], Training Loss: 0.0436, Training Accuracy: 98.70, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/200], Validation Loss: 0.5053, Validation Accuracy: 86.19%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 41 with accuracy: 86.19%\n",
      "Iteration 0: Loss = 0.0470, Reg Loss = 7.9873, Reconstruct Loss = 0.0000, Cls Loss = 0.0462, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0413, Reg Loss = 8.1547, Reconstruct Loss = 0.0006, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0438, Reg Loss = 8.1512, Reconstruct Loss = 0.0007, Cls Loss = 0.0423, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 8.2394, Reconstruct Loss = 0.0006, Cls Loss = 0.0428, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0443, Reg Loss = 8.2353, Reconstruct Loss = 0.0006, Cls Loss = 0.0428, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0438, Reg Loss = 8.2194, Reconstruct Loss = 0.0006, Cls Loss = 0.0425, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0441, Reg Loss = 8.1375, Reconstruct Loss = 0.0005, Cls Loss = 0.0428, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0442, Reg Loss = 8.1002, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-03\n",
      "Epoch [43/200], Training Loss: 0.0438, Training Accuracy: 98.60, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/200], Validation Loss: 0.4549, Validation Accuracy: 87.18%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 42 with accuracy: 87.18%\n",
      "Iteration 0: Loss = 0.0822, Reg Loss = 8.3305, Reconstruct Loss = 0.0000, Cls Loss = 0.0814, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0452, Reg Loss = 8.2354, Reconstruct Loss = 0.0005, Cls Loss = 0.0439, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0447, Reg Loss = 8.2635, Reconstruct Loss = 0.0005, Cls Loss = 0.0434, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0424, Reg Loss = 8.2379, Reconstruct Loss = 0.0004, Cls Loss = 0.0412, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0433, Reg Loss = 8.1793, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0439, Reg Loss = 8.1605, Reconstruct Loss = 0.0007, Cls Loss = 0.0425, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0437, Reg Loss = 8.1350, Reconstruct Loss = 0.0006, Cls Loss = 0.0422, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0432, Reg Loss = 8.1266, Reconstruct Loss = 0.0006, Cls Loss = 0.0418, Learning rate = 1.0000e-03\n",
      "Epoch [44/200], Training Loss: 0.0427, Training Accuracy: 98.66, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/200], Validation Loss: 0.5803, Validation Accuracy: 84.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0827, Reg Loss = 8.3625, Reconstruct Loss = 0.0000, Cls Loss = 0.0819, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0384, Reg Loss = 8.0648, Reconstruct Loss = 0.0006, Cls Loss = 0.0370, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0414, Reg Loss = 8.2731, Reconstruct Loss = 0.0007, Cls Loss = 0.0398, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0406, Reg Loss = 8.3428, Reconstruct Loss = 0.0006, Cls Loss = 0.0392, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0410, Reg Loss = 8.2743, Reconstruct Loss = 0.0005, Cls Loss = 0.0397, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0418, Reg Loss = 8.2150, Reconstruct Loss = 0.0005, Cls Loss = 0.0405, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0419, Reg Loss = 8.0273, Reconstruct Loss = 0.0004, Cls Loss = 0.0407, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0422, Reg Loss = 8.0162, Reconstruct Loss = 0.0004, Cls Loss = 0.0409, Learning rate = 1.0000e-03\n",
      "Epoch [45/200], Training Loss: 0.0430, Training Accuracy: 98.69, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/200], Validation Loss: 0.7389, Validation Accuracy: 83.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0169, Reg Loss = 7.9349, Reconstruct Loss = 0.0000, Cls Loss = 0.0161, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0396, Reg Loss = 8.1962, Reconstruct Loss = 0.0009, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0385, Reg Loss = 8.1526, Reconstruct Loss = 0.0007, Cls Loss = 0.0369, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0397, Reg Loss = 8.1397, Reconstruct Loss = 0.0007, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0402, Reg Loss = 8.0835, Reconstruct Loss = 0.0005, Cls Loss = 0.0389, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0400, Reg Loss = 8.0208, Reconstruct Loss = 0.0005, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0413, Reg Loss = 8.0610, Reconstruct Loss = 0.0006, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0420, Reg Loss = 8.0776, Reconstruct Loss = 0.0007, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Epoch [46/200], Training Loss: 0.0420, Training Accuracy: 98.72, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/200], Validation Loss: 0.7423, Validation Accuracy: 83.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0399, Reg Loss = 7.8474, Reconstruct Loss = 0.0000, Cls Loss = 0.0391, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0433, Reg Loss = 8.2150, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0423, Reg Loss = 8.1666, Reconstruct Loss = 0.0004, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0422, Reg Loss = 8.2513, Reconstruct Loss = 0.0004, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0421, Reg Loss = 8.2421, Reconstruct Loss = 0.0005, Cls Loss = 0.0408, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 8.1517, Reconstruct Loss = 0.0004, Cls Loss = 0.0432, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0442, Reg Loss = 8.0716, Reconstruct Loss = 0.0005, Cls Loss = 0.0430, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0440, Reg Loss = 7.9996, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-03\n",
      "Epoch [47/200], Training Loss: 0.0440, Training Accuracy: 98.57, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/200], Validation Loss: 0.6166, Validation Accuracy: 84.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0278, Reg Loss = 7.4248, Reconstruct Loss = 0.0000, Cls Loss = 0.0271, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0428, Reg Loss = 7.8134, Reconstruct Loss = 0.0009, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0407, Reg Loss = 7.9610, Reconstruct Loss = 0.0009, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0422, Reg Loss = 8.0254, Reconstruct Loss = 0.0007, Cls Loss = 0.0408, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0422, Reg Loss = 8.0839, Reconstruct Loss = 0.0006, Cls Loss = 0.0408, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0426, Reg Loss = 8.1872, Reconstruct Loss = 0.0007, Cls Loss = 0.0412, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0439, Reg Loss = 8.1596, Reconstruct Loss = 0.0006, Cls Loss = 0.0425, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0440, Reg Loss = 8.1739, Reconstruct Loss = 0.0006, Cls Loss = 0.0426, Learning rate = 1.0000e-03\n",
      "Epoch [48/200], Training Loss: 0.0438, Training Accuracy: 98.62, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/200], Validation Loss: 0.6757, Validation Accuracy: 83.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0791, Reg Loss = 7.8316, Reconstruct Loss = 0.0000, Cls Loss = 0.0784, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0430, Reg Loss = 8.3625, Reconstruct Loss = 0.0008, Cls Loss = 0.0414, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0453, Reg Loss = 8.6077, Reconstruct Loss = 0.0008, Cls Loss = 0.0437, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0464, Reg Loss = 8.7131, Reconstruct Loss = 0.0009, Cls Loss = 0.0446, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0454, Reg Loss = 8.8185, Reconstruct Loss = 0.0008, Cls Loss = 0.0438, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0443, Reg Loss = 8.7628, Reconstruct Loss = 0.0007, Cls Loss = 0.0427, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0446, Reg Loss = 8.7268, Reconstruct Loss = 0.0008, Cls Loss = 0.0429, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0449, Reg Loss = 8.7346, Reconstruct Loss = 0.0008, Cls Loss = 0.0432, Learning rate = 1.0000e-03\n",
      "Epoch [49/200], Training Loss: 0.0445, Training Accuracy: 98.62, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/200], Validation Loss: 0.6407, Validation Accuracy: 84.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0478, Reg Loss = 7.9738, Reconstruct Loss = 0.0000, Cls Loss = 0.0471, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0364, Reg Loss = 8.4204, Reconstruct Loss = 0.0003, Cls Loss = 0.0353, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0404, Reg Loss = 8.5109, Reconstruct Loss = 0.0005, Cls Loss = 0.0391, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0435, Reg Loss = 8.4429, Reconstruct Loss = 0.0006, Cls Loss = 0.0421, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0442, Reg Loss = 8.3744, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0429, Reg Loss = 8.3734, Reconstruct Loss = 0.0005, Cls Loss = 0.0416, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0427, Reg Loss = 8.3475, Reconstruct Loss = 0.0005, Cls Loss = 0.0414, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0428, Reg Loss = 8.3138, Reconstruct Loss = 0.0005, Cls Loss = 0.0415, Learning rate = 1.0000e-03\n",
      "Epoch [50/200], Training Loss: 0.0432, Training Accuracy: 98.68, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Validation Loss: 0.8267, Validation Accuracy: 80.82%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0140, Reg Loss = 8.5825, Reconstruct Loss = 0.0000, Cls Loss = 0.0131, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0393, Reg Loss = 8.2663, Reconstruct Loss = 0.0006, Cls Loss = 0.0378, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0410, Reg Loss = 8.0536, Reconstruct Loss = 0.0006, Cls Loss = 0.0396, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0416, Reg Loss = 8.0641, Reconstruct Loss = 0.0004, Cls Loss = 0.0404, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0423, Reg Loss = 8.1204, Reconstruct Loss = 0.0005, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0437, Reg Loss = 8.1287, Reconstruct Loss = 0.0004, Cls Loss = 0.0424, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0429, Reg Loss = 8.1755, Reconstruct Loss = 0.0004, Cls Loss = 0.0417, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0420, Reg Loss = 8.1963, Reconstruct Loss = 0.0004, Cls Loss = 0.0409, Learning rate = 1.0000e-03\n",
      "Epoch [51/200], Training Loss: 0.0420, Training Accuracy: 98.68, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/200], Validation Loss: 0.6815, Validation Accuracy: 83.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0690, Reg Loss = 8.4850, Reconstruct Loss = 0.0000, Cls Loss = 0.0682, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0420, Reg Loss = 8.4031, Reconstruct Loss = 0.0005, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0445, Reg Loss = 8.5031, Reconstruct Loss = 0.0007, Cls Loss = 0.0430, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0437, Reg Loss = 8.4190, Reconstruct Loss = 0.0005, Cls Loss = 0.0424, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0437, Reg Loss = 8.4576, Reconstruct Loss = 0.0006, Cls Loss = 0.0422, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0424, Reg Loss = 8.4066, Reconstruct Loss = 0.0006, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0417, Reg Loss = 8.3799, Reconstruct Loss = 0.0006, Cls Loss = 0.0403, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0421, Reg Loss = 8.4975, Reconstruct Loss = 0.0007, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Epoch [52/200], Training Loss: 0.0429, Training Accuracy: 98.72, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/200], Validation Loss: 0.8292, Validation Accuracy: 80.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0170, Reg Loss = 7.8787, Reconstruct Loss = 0.0000, Cls Loss = 0.0162, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0465, Reg Loss = 8.5242, Reconstruct Loss = 0.0006, Cls Loss = 0.0451, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0440, Reg Loss = 8.7407, Reconstruct Loss = 0.0007, Cls Loss = 0.0425, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0428, Reg Loss = 8.6295, Reconstruct Loss = 0.0007, Cls Loss = 0.0413, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0421, Reg Loss = 8.5672, Reconstruct Loss = 0.0007, Cls Loss = 0.0405, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0430, Reg Loss = 8.5878, Reconstruct Loss = 0.0007, Cls Loss = 0.0415, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0446, Reg Loss = 8.6388, Reconstruct Loss = 0.0007, Cls Loss = 0.0430, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0433, Reg Loss = 8.6527, Reconstruct Loss = 0.0007, Cls Loss = 0.0417, Learning rate = 1.0000e-03\n",
      "Epoch [53/200], Training Loss: 0.0435, Training Accuracy: 98.63, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/200], Validation Loss: 0.4626, Validation Accuracy: 87.51%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 52 with accuracy: 87.51%\n",
      "Iteration 0: Loss = 0.1396, Reg Loss = 8.3487, Reconstruct Loss = 0.0000, Cls Loss = 0.1387, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0397, Reg Loss = 8.5613, Reconstruct Loss = 0.0004, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0399, Reg Loss = 8.6062, Reconstruct Loss = 0.0006, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0389, Reg Loss = 8.3734, Reconstruct Loss = 0.0005, Cls Loss = 0.0375, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0396, Reg Loss = 8.2641, Reconstruct Loss = 0.0005, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0401, Reg Loss = 8.3512, Reconstruct Loss = 0.0005, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0406, Reg Loss = 8.4141, Reconstruct Loss = 0.0005, Cls Loss = 0.0393, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0407, Reg Loss = 8.4327, Reconstruct Loss = 0.0005, Cls Loss = 0.0394, Learning rate = 1.0000e-03\n",
      "Epoch [54/200], Training Loss: 0.0408, Training Accuracy: 98.73, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/200], Validation Loss: 0.6011, Validation Accuracy: 84.67%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0268, Reg Loss = 9.0834, Reconstruct Loss = 0.0000, Cls Loss = 0.0259, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0418, Reg Loss = 8.5212, Reconstruct Loss = 0.0006, Cls Loss = 0.0404, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0405, Reg Loss = 8.4640, Reconstruct Loss = 0.0004, Cls Loss = 0.0393, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0418, Reg Loss = 8.3575, Reconstruct Loss = 0.0004, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0403, Reg Loss = 8.3439, Reconstruct Loss = 0.0004, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0399, Reg Loss = 8.3569, Reconstruct Loss = 0.0004, Cls Loss = 0.0386, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0405, Reg Loss = 8.2775, Reconstruct Loss = 0.0004, Cls Loss = 0.0393, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0397, Reg Loss = 8.2537, Reconstruct Loss = 0.0004, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Epoch [55/200], Training Loss: 0.0400, Training Accuracy: 98.80, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/200], Validation Loss: 0.5769, Validation Accuracy: 85.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0468, Reg Loss = 8.1240, Reconstruct Loss = 0.0000, Cls Loss = 0.0460, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0401, Reg Loss = 8.5462, Reconstruct Loss = 0.0005, Cls Loss = 0.0388, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0402, Reg Loss = 8.4468, Reconstruct Loss = 0.0004, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0413, Reg Loss = 8.2501, Reconstruct Loss = 0.0004, Cls Loss = 0.0401, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0422, Reg Loss = 8.3328, Reconstruct Loss = 0.0004, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0415, Reg Loss = 8.3373, Reconstruct Loss = 0.0005, Cls Loss = 0.0402, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0424, Reg Loss = 8.3684, Reconstruct Loss = 0.0005, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0434, Reg Loss = 8.3382, Reconstruct Loss = 0.0005, Cls Loss = 0.0421, Learning rate = 1.0000e-03\n",
      "Epoch [56/200], Training Loss: 0.0427, Training Accuracy: 98.66, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/200], Validation Loss: 0.5506, Validation Accuracy: 85.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0376, Reg Loss = 7.8635, Reconstruct Loss = 0.0000, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0417, Reg Loss = 7.9746, Reconstruct Loss = 0.0004, Cls Loss = 0.0405, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0393, Reg Loss = 8.0606, Reconstruct Loss = 0.0004, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0417, Reg Loss = 8.1361, Reconstruct Loss = 0.0003, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0411, Reg Loss = 8.1003, Reconstruct Loss = 0.0004, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0411, Reg Loss = 8.1488, Reconstruct Loss = 0.0003, Cls Loss = 0.0400, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0420, Reg Loss = 8.2182, Reconstruct Loss = 0.0005, Cls Loss = 0.0407, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0413, Reg Loss = 8.2024, Reconstruct Loss = 0.0004, Cls Loss = 0.0400, Learning rate = 1.0000e-03\n",
      "Epoch [57/200], Training Loss: 0.0412, Training Accuracy: 98.73, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/200], Validation Loss: 0.4599, Validation Accuracy: 87.83%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 56 with accuracy: 87.83%\n",
      "Iteration 0: Loss = 0.0120, Reg Loss = 7.5702, Reconstruct Loss = 0.0000, Cls Loss = 0.0113, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0454, Reg Loss = 7.9410, Reconstruct Loss = 0.0003, Cls Loss = 0.0443, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0422, Reg Loss = 7.8901, Reconstruct Loss = 0.0003, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0416, Reg Loss = 7.8607, Reconstruct Loss = 0.0005, Cls Loss = 0.0404, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0415, Reg Loss = 8.0124, Reconstruct Loss = 0.0004, Cls Loss = 0.0403, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0414, Reg Loss = 8.0149, Reconstruct Loss = 0.0004, Cls Loss = 0.0402, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0417, Reg Loss = 7.9766, Reconstruct Loss = 0.0004, Cls Loss = 0.0405, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0409, Reg Loss = 7.9447, Reconstruct Loss = 0.0004, Cls Loss = 0.0396, Learning rate = 1.0000e-03\n",
      "Epoch [58/200], Training Loss: 0.0405, Training Accuracy: 98.76, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/200], Validation Loss: 0.6333, Validation Accuracy: 84.51%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0994, Reg Loss = 7.2747, Reconstruct Loss = 0.0000, Cls Loss = 0.0987, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0375, Reg Loss = 7.5972, Reconstruct Loss = 0.0005, Cls Loss = 0.0362, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0398, Reg Loss = 7.8445, Reconstruct Loss = 0.0006, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0424, Reg Loss = 8.1326, Reconstruct Loss = 0.0006, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0410, Reg Loss = 8.1057, Reconstruct Loss = 0.0006, Cls Loss = 0.0396, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0410, Reg Loss = 8.0645, Reconstruct Loss = 0.0005, Cls Loss = 0.0397, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0410, Reg Loss = 8.1567, Reconstruct Loss = 0.0006, Cls Loss = 0.0397, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0413, Reg Loss = 8.1925, Reconstruct Loss = 0.0006, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Epoch [59/200], Training Loss: 0.0417, Training Accuracy: 98.72, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/200], Validation Loss: 0.4773, Validation Accuracy: 86.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0634, Reg Loss = 7.8782, Reconstruct Loss = 0.0000, Cls Loss = 0.0626, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0417, Reg Loss = 8.4779, Reconstruct Loss = 0.0009, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0410, Reg Loss = 8.4938, Reconstruct Loss = 0.0006, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0413, Reg Loss = 8.4618, Reconstruct Loss = 0.0005, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0405, Reg Loss = 8.3696, Reconstruct Loss = 0.0006, Cls Loss = 0.0391, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0399, Reg Loss = 8.3297, Reconstruct Loss = 0.0006, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0398, Reg Loss = 8.3264, Reconstruct Loss = 0.0006, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0401, Reg Loss = 8.3148, Reconstruct Loss = 0.0005, Cls Loss = 0.0388, Learning rate = 1.0000e-03\n",
      "Epoch [60/200], Training Loss: 0.0409, Training Accuracy: 98.70, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/200], Validation Loss: 0.5860, Validation Accuracy: 84.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0299, Reg Loss = 8.2085, Reconstruct Loss = 0.0000, Cls Loss = 0.0291, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0386, Reg Loss = 8.4465, Reconstruct Loss = 0.0007, Cls Loss = 0.0370, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0394, Reg Loss = 8.2391, Reconstruct Loss = 0.0005, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0399, Reg Loss = 8.2742, Reconstruct Loss = 0.0006, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0394, Reg Loss = 8.3225, Reconstruct Loss = 0.0006, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0397, Reg Loss = 8.3249, Reconstruct Loss = 0.0006, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0400, Reg Loss = 8.3291, Reconstruct Loss = 0.0005, Cls Loss = 0.0386, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0404, Reg Loss = 8.3580, Reconstruct Loss = 0.0005, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Epoch [61/200], Training Loss: 0.0405, Training Accuracy: 98.73, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/200], Validation Loss: 0.5161, Validation Accuracy: 85.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0461, Reg Loss = 7.6464, Reconstruct Loss = 0.0000, Cls Loss = 0.0453, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 8.1549, Reconstruct Loss = 0.0005, Cls Loss = 0.0470, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0435, Reg Loss = 8.2015, Reconstruct Loss = 0.0005, Cls Loss = 0.0421, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0424, Reg Loss = 8.2434, Reconstruct Loss = 0.0005, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0420, Reg Loss = 8.2209, Reconstruct Loss = 0.0005, Cls Loss = 0.0407, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0411, Reg Loss = 8.1800, Reconstruct Loss = 0.0005, Cls Loss = 0.0398, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0413, Reg Loss = 8.1320, Reconstruct Loss = 0.0005, Cls Loss = 0.0401, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0411, Reg Loss = 8.1584, Reconstruct Loss = 0.0005, Cls Loss = 0.0398, Learning rate = 1.0000e-03\n",
      "Epoch [62/200], Training Loss: 0.0413, Training Accuracy: 98.69, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/200], Validation Loss: 0.5521, Validation Accuracy: 85.62%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0186, Reg Loss = 7.8015, Reconstruct Loss = 0.0000, Cls Loss = 0.0178, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0423, Reg Loss = 8.2647, Reconstruct Loss = 0.0007, Cls Loss = 0.0408, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0414, Reg Loss = 8.4284, Reconstruct Loss = 0.0007, Cls Loss = 0.0398, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0411, Reg Loss = 8.5571, Reconstruct Loss = 0.0008, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0414, Reg Loss = 8.4830, Reconstruct Loss = 0.0007, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0403, Reg Loss = 8.3294, Reconstruct Loss = 0.0006, Cls Loss = 0.0389, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0399, Reg Loss = 8.2173, Reconstruct Loss = 0.0005, Cls Loss = 0.0386, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0395, Reg Loss = 8.1572, Reconstruct Loss = 0.0005, Cls Loss = 0.0382, Learning rate = 1.0000e-03\n",
      "Epoch [63/200], Training Loss: 0.0396, Training Accuracy: 98.77, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/200], Validation Loss: 0.5170, Validation Accuracy: 85.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0121, Reg Loss = 7.9306, Reconstruct Loss = 0.0000, Cls Loss = 0.0113, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0382, Reg Loss = 7.9295, Reconstruct Loss = 0.0006, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0396, Reg Loss = 7.8637, Reconstruct Loss = 0.0004, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0407, Reg Loss = 8.0005, Reconstruct Loss = 0.0004, Cls Loss = 0.0396, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0395, Reg Loss = 8.0586, Reconstruct Loss = 0.0004, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0406, Reg Loss = 8.0747, Reconstruct Loss = 0.0004, Cls Loss = 0.0394, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0403, Reg Loss = 8.1540, Reconstruct Loss = 0.0004, Cls Loss = 0.0391, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0398, Reg Loss = 8.1258, Reconstruct Loss = 0.0004, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Epoch [64/200], Training Loss: 0.0399, Training Accuracy: 98.72, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/200], Validation Loss: 0.4907, Validation Accuracy: 86.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0093, Reg Loss = 7.8222, Reconstruct Loss = 0.0000, Cls Loss = 0.0085, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0420, Reg Loss = 8.0815, Reconstruct Loss = 0.0007, Cls Loss = 0.0405, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0419, Reg Loss = 8.1800, Reconstruct Loss = 0.0007, Cls Loss = 0.0404, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0415, Reg Loss = 8.1977, Reconstruct Loss = 0.0006, Cls Loss = 0.0401, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0423, Reg Loss = 8.2601, Reconstruct Loss = 0.0005, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0421, Reg Loss = 8.3102, Reconstruct Loss = 0.0005, Cls Loss = 0.0407, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0418, Reg Loss = 8.2819, Reconstruct Loss = 0.0006, Cls Loss = 0.0404, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0417, Reg Loss = 8.2984, Reconstruct Loss = 0.0007, Cls Loss = 0.0402, Learning rate = 1.0000e-03\n",
      "Epoch [65/200], Training Loss: 0.0422, Training Accuracy: 98.68, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/200], Validation Loss: 0.7028, Validation Accuracy: 83.07%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0293, Reg Loss = 7.9373, Reconstruct Loss = 0.0000, Cls Loss = 0.0285, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0395, Reg Loss = 8.6814, Reconstruct Loss = 0.0007, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0412, Reg Loss = 8.7438, Reconstruct Loss = 0.0004, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0401, Reg Loss = 8.5728, Reconstruct Loss = 0.0004, Cls Loss = 0.0388, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0390, Reg Loss = 8.4967, Reconstruct Loss = 0.0004, Cls Loss = 0.0377, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0397, Reg Loss = 8.5038, Reconstruct Loss = 0.0004, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0393, Reg Loss = 8.4019, Reconstruct Loss = 0.0004, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0391, Reg Loss = 8.3793, Reconstruct Loss = 0.0005, Cls Loss = 0.0378, Learning rate = 1.0000e-03\n",
      "Epoch [66/200], Training Loss: 0.0391, Training Accuracy: 98.82, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/200], Validation Loss: 0.6223, Validation Accuracy: 85.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0557, Reg Loss = 8.3868, Reconstruct Loss = 0.0000, Cls Loss = 0.0548, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0328, Reg Loss = 8.4345, Reconstruct Loss = 0.0001, Cls Loss = 0.0318, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0379, Reg Loss = 8.5885, Reconstruct Loss = 0.0002, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0381, Reg Loss = 8.5365, Reconstruct Loss = 0.0002, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0382, Reg Loss = 8.3662, Reconstruct Loss = 0.0002, Cls Loss = 0.0372, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0388, Reg Loss = 8.2728, Reconstruct Loss = 0.0002, Cls Loss = 0.0378, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0388, Reg Loss = 8.2075, Reconstruct Loss = 0.0002, Cls Loss = 0.0378, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0391, Reg Loss = 8.1783, Reconstruct Loss = 0.0002, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Epoch [67/200], Training Loss: 0.0385, Training Accuracy: 98.82, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/200], Validation Loss: 0.5447, Validation Accuracy: 85.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0611, Reg Loss = 8.1603, Reconstruct Loss = 0.0000, Cls Loss = 0.0603, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0414, Reg Loss = 8.8086, Reconstruct Loss = 0.0004, Cls Loss = 0.0401, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0431, Reg Loss = 8.6758, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0423, Reg Loss = 8.5993, Reconstruct Loss = 0.0006, Cls Loss = 0.0408, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0422, Reg Loss = 8.5438, Reconstruct Loss = 0.0006, Cls Loss = 0.0407, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0421, Reg Loss = 8.5179, Reconstruct Loss = 0.0006, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0415, Reg Loss = 8.5382, Reconstruct Loss = 0.0007, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0415, Reg Loss = 8.5615, Reconstruct Loss = 0.0006, Cls Loss = 0.0400, Learning rate = 1.0000e-03\n",
      "Epoch [68/200], Training Loss: 0.0413, Training Accuracy: 98.70, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/200], Validation Loss: 1.3905, Validation Accuracy: 76.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0051, Reg Loss = 8.2071, Reconstruct Loss = 0.0000, Cls Loss = 0.0043, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0367, Reg Loss = 7.8816, Reconstruct Loss = 0.0005, Cls Loss = 0.0354, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0383, Reg Loss = 7.8597, Reconstruct Loss = 0.0007, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0393, Reg Loss = 8.0118, Reconstruct Loss = 0.0005, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0390, Reg Loss = 8.1336, Reconstruct Loss = 0.0006, Cls Loss = 0.0375, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0386, Reg Loss = 8.1499, Reconstruct Loss = 0.0007, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0388, Reg Loss = 8.1264, Reconstruct Loss = 0.0008, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0390, Reg Loss = 8.1428, Reconstruct Loss = 0.0007, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Epoch [69/200], Training Loss: 0.0395, Training Accuracy: 98.81, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/200], Validation Loss: 0.6529, Validation Accuracy: 84.69%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0316, Reg Loss = 8.1334, Reconstruct Loss = 0.0000, Cls Loss = 0.0308, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0378, Reg Loss = 8.0935, Reconstruct Loss = 0.0007, Cls Loss = 0.0364, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0375, Reg Loss = 7.9893, Reconstruct Loss = 0.0009, Cls Loss = 0.0358, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0379, Reg Loss = 8.1092, Reconstruct Loss = 0.0007, Cls Loss = 0.0364, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0400, Reg Loss = 8.1592, Reconstruct Loss = 0.0008, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0405, Reg Loss = 8.1830, Reconstruct Loss = 0.0009, Cls Loss = 0.0388, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0410, Reg Loss = 8.1658, Reconstruct Loss = 0.0008, Cls Loss = 0.0394, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0402, Reg Loss = 8.1195, Reconstruct Loss = 0.0009, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Epoch [70/200], Training Loss: 0.0409, Training Accuracy: 98.74, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/200], Validation Loss: 0.7197, Validation Accuracy: 83.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0239, Reg Loss = 8.5635, Reconstruct Loss = 0.0000, Cls Loss = 0.0231, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0412, Reg Loss = 8.6187, Reconstruct Loss = 0.0013, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0409, Reg Loss = 8.4967, Reconstruct Loss = 0.0011, Cls Loss = 0.0389, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0426, Reg Loss = 8.4687, Reconstruct Loss = 0.0012, Cls Loss = 0.0405, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0426, Reg Loss = 8.4335, Reconstruct Loss = 0.0012, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0413, Reg Loss = 8.3938, Reconstruct Loss = 0.0013, Cls Loss = 0.0392, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0411, Reg Loss = 8.3618, Reconstruct Loss = 0.0012, Cls Loss = 0.0391, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0414, Reg Loss = 8.3803, Reconstruct Loss = 0.0012, Cls Loss = 0.0394, Learning rate = 1.0000e-03\n",
      "Epoch [71/200], Training Loss: 0.0416, Training Accuracy: 98.71, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/200], Validation Loss: 0.7013, Validation Accuracy: 83.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0055, Reg Loss = 8.2105, Reconstruct Loss = 0.0000, Cls Loss = 0.0047, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0391, Reg Loss = 8.5483, Reconstruct Loss = 0.0020, Cls Loss = 0.0363, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0421, Reg Loss = 8.5796, Reconstruct Loss = 0.0013, Cls Loss = 0.0399, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0401, Reg Loss = 8.4268, Reconstruct Loss = 0.0013, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0402, Reg Loss = 8.3147, Reconstruct Loss = 0.0012, Cls Loss = 0.0382, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0403, Reg Loss = 8.2902, Reconstruct Loss = 0.0011, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0406, Reg Loss = 8.2362, Reconstruct Loss = 0.0011, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0406, Reg Loss = 8.2753, Reconstruct Loss = 0.0010, Cls Loss = 0.0388, Learning rate = 1.0000e-03\n",
      "Epoch [72/200], Training Loss: 0.0408, Training Accuracy: 98.71, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/200], Validation Loss: 0.7180, Validation Accuracy: 82.50%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0179, Reg Loss = 7.5368, Reconstruct Loss = 0.0000, Cls Loss = 0.0172, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0384, Reg Loss = 8.1106, Reconstruct Loss = 0.0011, Cls Loss = 0.0365, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0394, Reg Loss = 8.2486, Reconstruct Loss = 0.0014, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0392, Reg Loss = 8.3641, Reconstruct Loss = 0.0012, Cls Loss = 0.0372, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0393, Reg Loss = 8.3938, Reconstruct Loss = 0.0011, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0385, Reg Loss = 8.3577, Reconstruct Loss = 0.0011, Cls Loss = 0.0366, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0393, Reg Loss = 8.3644, Reconstruct Loss = 0.0011, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0390, Reg Loss = 8.3284, Reconstruct Loss = 0.0011, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Epoch [73/200], Training Loss: 0.0399, Training Accuracy: 98.80, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/200], Validation Loss: 0.6080, Validation Accuracy: 84.90%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0242, Reg Loss = 8.1632, Reconstruct Loss = 0.0000, Cls Loss = 0.0234, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0467, Reg Loss = 8.5537, Reconstruct Loss = 0.0007, Cls Loss = 0.0452, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0403, Reg Loss = 8.5794, Reconstruct Loss = 0.0010, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0396, Reg Loss = 8.4751, Reconstruct Loss = 0.0011, Cls Loss = 0.0377, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0392, Reg Loss = 8.4956, Reconstruct Loss = 0.0010, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0398, Reg Loss = 8.5030, Reconstruct Loss = 0.0010, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0401, Reg Loss = 8.5038, Reconstruct Loss = 0.0009, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0397, Reg Loss = 8.4594, Reconstruct Loss = 0.0010, Cls Loss = 0.0379, Learning rate = 1.0000e-03\n",
      "Epoch [74/200], Training Loss: 0.0400, Training Accuracy: 98.81, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/200], Validation Loss: 0.5792, Validation Accuracy: 85.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0358, Reg Loss = 8.7967, Reconstruct Loss = 0.0000, Cls Loss = 0.0349, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0426, Reg Loss = 8.4886, Reconstruct Loss = 0.0011, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0432, Reg Loss = 8.5609, Reconstruct Loss = 0.0013, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0407, Reg Loss = 8.4357, Reconstruct Loss = 0.0012, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0398, Reg Loss = 8.4189, Reconstruct Loss = 0.0012, Cls Loss = 0.0377, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0392, Reg Loss = 8.4985, Reconstruct Loss = 0.0013, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0389, Reg Loss = 8.5507, Reconstruct Loss = 0.0012, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0397, Reg Loss = 8.5381, Reconstruct Loss = 0.0012, Cls Loss = 0.0376, Learning rate = 1.0000e-03\n",
      "Epoch [75/200], Training Loss: 0.0395, Training Accuracy: 98.77, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/200], Validation Loss: 0.7094, Validation Accuracy: 83.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0629, Reg Loss = 7.7578, Reconstruct Loss = 0.0000, Cls Loss = 0.0622, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0360, Reg Loss = 8.5076, Reconstruct Loss = 0.0008, Cls Loss = 0.0343, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0413, Reg Loss = 8.7336, Reconstruct Loss = 0.0008, Cls Loss = 0.0396, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0412, Reg Loss = 8.6443, Reconstruct Loss = 0.0009, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0422, Reg Loss = 8.6183, Reconstruct Loss = 0.0010, Cls Loss = 0.0403, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0412, Reg Loss = 8.5634, Reconstruct Loss = 0.0009, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0421, Reg Loss = 8.4918, Reconstruct Loss = 0.0010, Cls Loss = 0.0402, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0414, Reg Loss = 8.5110, Reconstruct Loss = 0.0011, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Epoch [76/200], Training Loss: 0.0415, Training Accuracy: 98.72, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/200], Validation Loss: 0.6154, Validation Accuracy: 84.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0449, Reg Loss = 8.6098, Reconstruct Loss = 0.0000, Cls Loss = 0.0441, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0392, Reg Loss = 8.4760, Reconstruct Loss = 0.0006, Cls Loss = 0.0378, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0404, Reg Loss = 8.5006, Reconstruct Loss = 0.0011, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0395, Reg Loss = 8.5906, Reconstruct Loss = 0.0010, Cls Loss = 0.0376, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0400, Reg Loss = 8.5245, Reconstruct Loss = 0.0011, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0398, Reg Loss = 8.5279, Reconstruct Loss = 0.0010, Cls Loss = 0.0379, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0403, Reg Loss = 8.4916, Reconstruct Loss = 0.0009, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0404, Reg Loss = 8.5037, Reconstruct Loss = 0.0011, Cls Loss = 0.0385, Learning rate = 1.0000e-03\n",
      "Epoch [77/200], Training Loss: 0.0403, Training Accuracy: 98.76, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/200], Validation Loss: 0.7955, Validation Accuracy: 81.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0297, Reg Loss = 9.1024, Reconstruct Loss = 0.0000, Cls Loss = 0.0288, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0421, Reg Loss = 9.0054, Reconstruct Loss = 0.0005, Cls Loss = 0.0406, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0407, Reg Loss = 8.8170, Reconstruct Loss = 0.0008, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0407, Reg Loss = 8.6211, Reconstruct Loss = 0.0009, Cls Loss = 0.0389, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0392, Reg Loss = 8.5671, Reconstruct Loss = 0.0009, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0399, Reg Loss = 8.4389, Reconstruct Loss = 0.0008, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0392, Reg Loss = 8.3620, Reconstruct Loss = 0.0008, Cls Loss = 0.0375, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0391, Reg Loss = 8.3706, Reconstruct Loss = 0.0009, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Epoch [78/200], Training Loss: 0.0392, Training Accuracy: 98.80, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/200], Validation Loss: 0.7207, Validation Accuracy: 82.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0254, Reg Loss = 8.4517, Reconstruct Loss = 0.0000, Cls Loss = 0.0245, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0365, Reg Loss = 8.5591, Reconstruct Loss = 0.0014, Cls Loss = 0.0343, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0374, Reg Loss = 8.5109, Reconstruct Loss = 0.0014, Cls Loss = 0.0352, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0391, Reg Loss = 8.4747, Reconstruct Loss = 0.0013, Cls Loss = 0.0370, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0385, Reg Loss = 8.3926, Reconstruct Loss = 0.0011, Cls Loss = 0.0365, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0387, Reg Loss = 8.3178, Reconstruct Loss = 0.0013, Cls Loss = 0.0366, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0391, Reg Loss = 8.2864, Reconstruct Loss = 0.0012, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0385, Reg Loss = 8.2528, Reconstruct Loss = 0.0011, Cls Loss = 0.0366, Learning rate = 1.0000e-03\n",
      "Epoch [79/200], Training Loss: 0.0384, Training Accuracy: 98.85, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/200], Validation Loss: 0.6694, Validation Accuracy: 84.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0462, Reg Loss = 8.6603, Reconstruct Loss = 0.0000, Cls Loss = 0.0454, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0363, Reg Loss = 8.6856, Reconstruct Loss = 0.0008, Cls Loss = 0.0346, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0391, Reg Loss = 8.4404, Reconstruct Loss = 0.0009, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0392, Reg Loss = 8.4116, Reconstruct Loss = 0.0010, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0392, Reg Loss = 8.4852, Reconstruct Loss = 0.0011, Cls Loss = 0.0372, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0401, Reg Loss = 8.5071, Reconstruct Loss = 0.0011, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0391, Reg Loss = 8.4872, Reconstruct Loss = 0.0010, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0395, Reg Loss = 8.4546, Reconstruct Loss = 0.0010, Cls Loss = 0.0377, Learning rate = 1.0000e-03\n",
      "Epoch [80/200], Training Loss: 0.0393, Training Accuracy: 98.79, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/200], Validation Loss: 0.7081, Validation Accuracy: 82.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0121, Reg Loss = 8.1748, Reconstruct Loss = 0.0000, Cls Loss = 0.0113, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0366, Reg Loss = 8.5456, Reconstruct Loss = 0.0012, Cls Loss = 0.0346, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0366, Reg Loss = 8.5047, Reconstruct Loss = 0.0011, Cls Loss = 0.0347, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0364, Reg Loss = 8.5057, Reconstruct Loss = 0.0010, Cls Loss = 0.0345, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0371, Reg Loss = 8.4793, Reconstruct Loss = 0.0009, Cls Loss = 0.0354, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0377, Reg Loss = 8.4837, Reconstruct Loss = 0.0010, Cls Loss = 0.0359, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0379, Reg Loss = 8.4909, Reconstruct Loss = 0.0011, Cls Loss = 0.0359, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0387, Reg Loss = 8.4759, Reconstruct Loss = 0.0010, Cls Loss = 0.0369, Learning rate = 1.0000e-03\n",
      "Epoch [81/200], Training Loss: 0.0389, Training Accuracy: 98.83, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/200], Validation Loss: 0.7398, Validation Accuracy: 82.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0502, Reg Loss = 8.2905, Reconstruct Loss = 0.0000, Cls Loss = 0.0493, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0406, Reg Loss = 8.2251, Reconstruct Loss = 0.0017, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0378, Reg Loss = 8.1551, Reconstruct Loss = 0.0012, Cls Loss = 0.0358, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0373, Reg Loss = 8.1587, Reconstruct Loss = 0.0008, Cls Loss = 0.0356, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0377, Reg Loss = 8.1563, Reconstruct Loss = 0.0008, Cls Loss = 0.0361, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0380, Reg Loss = 8.1551, Reconstruct Loss = 0.0007, Cls Loss = 0.0365, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0378, Reg Loss = 8.1412, Reconstruct Loss = 0.0007, Cls Loss = 0.0363, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0385, Reg Loss = 8.2121, Reconstruct Loss = 0.0008, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Epoch [82/200], Training Loss: 0.0386, Training Accuracy: 98.83, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/200], Validation Loss: 0.5754, Validation Accuracy: 85.03%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0195, Reg Loss = 8.2289, Reconstruct Loss = 0.0000, Cls Loss = 0.0187, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0422, Reg Loss = 8.2053, Reconstruct Loss = 0.0004, Cls Loss = 0.0410, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0421, Reg Loss = 8.2197, Reconstruct Loss = 0.0007, Cls Loss = 0.0407, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0407, Reg Loss = 8.0564, Reconstruct Loss = 0.0007, Cls Loss = 0.0392, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0408, Reg Loss = 8.1407, Reconstruct Loss = 0.0009, Cls Loss = 0.0391, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0401, Reg Loss = 8.2009, Reconstruct Loss = 0.0009, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0402, Reg Loss = 8.2694, Reconstruct Loss = 0.0009, Cls Loss = 0.0384, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0393, Reg Loss = 8.3465, Reconstruct Loss = 0.0009, Cls Loss = 0.0376, Learning rate = 1.0000e-03\n",
      "Epoch [83/200], Training Loss: 0.0391, Training Accuracy: 98.81, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/200], Validation Loss: 0.5770, Validation Accuracy: 84.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0123, Reg Loss = 8.3656, Reconstruct Loss = 0.0000, Cls Loss = 0.0115, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0370, Reg Loss = 8.5850, Reconstruct Loss = 0.0006, Cls Loss = 0.0355, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0378, Reg Loss = 8.4596, Reconstruct Loss = 0.0009, Cls Loss = 0.0360, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0380, Reg Loss = 8.4709, Reconstruct Loss = 0.0007, Cls Loss = 0.0364, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0376, Reg Loss = 8.3813, Reconstruct Loss = 0.0008, Cls Loss = 0.0360, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0380, Reg Loss = 8.4189, Reconstruct Loss = 0.0010, Cls Loss = 0.0362, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0384, Reg Loss = 8.4278, Reconstruct Loss = 0.0011, Cls Loss = 0.0365, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0383, Reg Loss = 8.4324, Reconstruct Loss = 0.0010, Cls Loss = 0.0365, Learning rate = 1.0000e-03\n",
      "Epoch [84/200], Training Loss: 0.0384, Training Accuracy: 98.78, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/200], Validation Loss: 0.4746, Validation Accuracy: 86.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0614, Reg Loss = 8.6056, Reconstruct Loss = 0.0000, Cls Loss = 0.0606, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0397, Reg Loss = 8.3540, Reconstruct Loss = 0.0008, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0410, Reg Loss = 8.2603, Reconstruct Loss = 0.0012, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0406, Reg Loss = 8.2488, Reconstruct Loss = 0.0010, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0394, Reg Loss = 8.2919, Reconstruct Loss = 0.0011, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0389, Reg Loss = 8.3336, Reconstruct Loss = 0.0010, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0393, Reg Loss = 8.3474, Reconstruct Loss = 0.0010, Cls Loss = 0.0375, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0390, Reg Loss = 8.3191, Reconstruct Loss = 0.0009, Cls Loss = 0.0372, Learning rate = 1.0000e-03\n",
      "Epoch [85/200], Training Loss: 0.0390, Training Accuracy: 98.77, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/200], Validation Loss: 0.4962, Validation Accuracy: 86.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0542, Reg Loss = 8.7720, Reconstruct Loss = 0.0000, Cls Loss = 0.0533, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0395, Reg Loss = 8.9824, Reconstruct Loss = 0.0014, Cls Loss = 0.0372, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0400, Reg Loss = 8.9606, Reconstruct Loss = 0.0011, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0409, Reg Loss = 8.8732, Reconstruct Loss = 0.0011, Cls Loss = 0.0389, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0400, Reg Loss = 8.9021, Reconstruct Loss = 0.0011, Cls Loss = 0.0379, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0408, Reg Loss = 8.8848, Reconstruct Loss = 0.0010, Cls Loss = 0.0389, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0406, Reg Loss = 8.8912, Reconstruct Loss = 0.0010, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0405, Reg Loss = 8.8350, Reconstruct Loss = 0.0009, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Epoch [86/200], Training Loss: 0.0404, Training Accuracy: 98.74, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/200], Validation Loss: 0.5798, Validation Accuracy: 85.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0517, Reg Loss = 8.7733, Reconstruct Loss = 0.0000, Cls Loss = 0.0508, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0410, Reg Loss = 8.9402, Reconstruct Loss = 0.0011, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0394, Reg Loss = 9.0232, Reconstruct Loss = 0.0010, Cls Loss = 0.0375, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0399, Reg Loss = 8.8996, Reconstruct Loss = 0.0008, Cls Loss = 0.0382, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0396, Reg Loss = 8.8347, Reconstruct Loss = 0.0007, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0380, Reg Loss = 8.7635, Reconstruct Loss = 0.0008, Cls Loss = 0.0364, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0375, Reg Loss = 8.7721, Reconstruct Loss = 0.0007, Cls Loss = 0.0359, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0381, Reg Loss = 8.7146, Reconstruct Loss = 0.0007, Cls Loss = 0.0365, Learning rate = 1.0000e-03\n",
      "Epoch [87/200], Training Loss: 0.0376, Training Accuracy: 98.90, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/200], Validation Loss: 0.5538, Validation Accuracy: 85.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0140, Reg Loss = 8.5890, Reconstruct Loss = 0.0000, Cls Loss = 0.0131, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0399, Reg Loss = 8.5905, Reconstruct Loss = 0.0004, Cls Loss = 0.0386, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0396, Reg Loss = 8.5618, Reconstruct Loss = 0.0007, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0372, Reg Loss = 8.6176, Reconstruct Loss = 0.0007, Cls Loss = 0.0356, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0373, Reg Loss = 8.6443, Reconstruct Loss = 0.0007, Cls Loss = 0.0358, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0397, Reg Loss = 8.7470, Reconstruct Loss = 0.0007, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0394, Reg Loss = 8.7689, Reconstruct Loss = 0.0007, Cls Loss = 0.0379, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0395, Reg Loss = 8.8109, Reconstruct Loss = 0.0008, Cls Loss = 0.0378, Learning rate = 1.0000e-03\n",
      "Epoch [88/200], Training Loss: 0.0398, Training Accuracy: 98.76, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/200], Validation Loss: 0.5549, Validation Accuracy: 85.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0388, Reg Loss = 11.3168, Reconstruct Loss = 0.0199, Cls Loss = 0.0177, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0376, Reg Loss = 9.2388, Reconstruct Loss = 0.0016, Cls Loss = 0.0351, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0389, Reg Loss = 9.0457, Reconstruct Loss = 0.0012, Cls Loss = 0.0369, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0379, Reg Loss = 8.9182, Reconstruct Loss = 0.0010, Cls Loss = 0.0360, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0385, Reg Loss = 8.8066, Reconstruct Loss = 0.0009, Cls Loss = 0.0367, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0385, Reg Loss = 8.7897, Reconstruct Loss = 0.0011, Cls Loss = 0.0366, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0391, Reg Loss = 8.8167, Reconstruct Loss = 0.0010, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0386, Reg Loss = 8.8186, Reconstruct Loss = 0.0010, Cls Loss = 0.0367, Learning rate = 1.0000e-03\n",
      "Epoch [89/200], Training Loss: 0.0385, Training Accuracy: 98.75, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/200], Validation Loss: 0.6236, Validation Accuracy: 84.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0496, Reg Loss = 9.2777, Reconstruct Loss = 0.0000, Cls Loss = 0.0487, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0363, Reg Loss = 8.8677, Reconstruct Loss = 0.0009, Cls Loss = 0.0345, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0364, Reg Loss = 8.6476, Reconstruct Loss = 0.0007, Cls Loss = 0.0349, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0357, Reg Loss = 8.5902, Reconstruct Loss = 0.0007, Cls Loss = 0.0342, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0375, Reg Loss = 8.6008, Reconstruct Loss = 0.0006, Cls Loss = 0.0360, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0378, Reg Loss = 8.5996, Reconstruct Loss = 0.0005, Cls Loss = 0.0364, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0377, Reg Loss = 8.5469, Reconstruct Loss = 0.0005, Cls Loss = 0.0363, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0375, Reg Loss = 8.5639, Reconstruct Loss = 0.0005, Cls Loss = 0.0362, Learning rate = 1.0000e-03\n",
      "Epoch [90/200], Training Loss: 0.0376, Training Accuracy: 98.86, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/200], Validation Loss: 0.5762, Validation Accuracy: 84.77%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0146, Reg Loss = 8.7366, Reconstruct Loss = 0.0000, Cls Loss = 0.0137, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0388, Reg Loss = 8.7318, Reconstruct Loss = 0.0004, Cls Loss = 0.0376, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0385, Reg Loss = 8.6564, Reconstruct Loss = 0.0011, Cls Loss = 0.0366, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0384, Reg Loss = 8.6518, Reconstruct Loss = 0.0008, Cls Loss = 0.0367, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0391, Reg Loss = 8.6643, Reconstruct Loss = 0.0008, Cls Loss = 0.0375, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0400, Reg Loss = 8.7309, Reconstruct Loss = 0.0008, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0392, Reg Loss = 8.6582, Reconstruct Loss = 0.0007, Cls Loss = 0.0376, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0388, Reg Loss = 8.6781, Reconstruct Loss = 0.0007, Cls Loss = 0.0372, Learning rate = 1.0000e-03\n",
      "Epoch [91/200], Training Loss: 0.0384, Training Accuracy: 98.85, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200], Validation Loss: 0.5723, Validation Accuracy: 85.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0164, Reg Loss = 8.4463, Reconstruct Loss = 0.0000, Cls Loss = 0.0155, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0364, Reg Loss = 8.3298, Reconstruct Loss = 0.0008, Cls Loss = 0.0349, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0395, Reg Loss = 8.3548, Reconstruct Loss = 0.0008, Cls Loss = 0.0379, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0393, Reg Loss = 8.4078, Reconstruct Loss = 0.0007, Cls Loss = 0.0377, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0402, Reg Loss = 8.3793, Reconstruct Loss = 0.0007, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0390, Reg Loss = 8.4078, Reconstruct Loss = 0.0007, Cls Loss = 0.0375, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0388, Reg Loss = 8.3852, Reconstruct Loss = 0.0007, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0389, Reg Loss = 8.4062, Reconstruct Loss = 0.0007, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Epoch [92/200], Training Loss: 0.0392, Training Accuracy: 98.81, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/200], Validation Loss: 0.5130, Validation Accuracy: 86.11%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0188, Reg Loss = 8.4381, Reconstruct Loss = 0.0000, Cls Loss = 0.0180, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0432, Reg Loss = 8.4687, Reconstruct Loss = 0.0009, Cls Loss = 0.0414, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0415, Reg Loss = 8.6073, Reconstruct Loss = 0.0011, Cls Loss = 0.0396, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0413, Reg Loss = 8.5606, Reconstruct Loss = 0.0009, Cls Loss = 0.0395, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0406, Reg Loss = 8.5467, Reconstruct Loss = 0.0011, Cls Loss = 0.0387, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0400, Reg Loss = 8.5196, Reconstruct Loss = 0.0011, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0401, Reg Loss = 8.5013, Reconstruct Loss = 0.0010, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0392, Reg Loss = 8.4807, Reconstruct Loss = 0.0010, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Epoch [93/200], Training Loss: 0.0400, Training Accuracy: 98.78, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/200], Validation Loss: 0.6210, Validation Accuracy: 84.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0816, Reg Loss = 8.8918, Reconstruct Loss = 0.0000, Cls Loss = 0.0807, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0409, Reg Loss = 8.7810, Reconstruct Loss = 0.0011, Cls Loss = 0.0389, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0395, Reg Loss = 8.6682, Reconstruct Loss = 0.0010, Cls Loss = 0.0376, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0401, Reg Loss = 8.6941, Reconstruct Loss = 0.0009, Cls Loss = 0.0383, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0399, Reg Loss = 8.6321, Reconstruct Loss = 0.0009, Cls Loss = 0.0381, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0403, Reg Loss = 8.6084, Reconstruct Loss = 0.0009, Cls Loss = 0.0386, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0403, Reg Loss = 8.6100, Reconstruct Loss = 0.0009, Cls Loss = 0.0386, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0407, Reg Loss = 8.5531, Reconstruct Loss = 0.0008, Cls Loss = 0.0390, Learning rate = 1.0000e-03\n",
      "Epoch [94/200], Training Loss: 0.0408, Training Accuracy: 98.70, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/200], Validation Loss: 0.5682, Validation Accuracy: 84.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0544, Reg Loss = 8.8021, Reconstruct Loss = 0.0000, Cls Loss = 0.0535, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0428, Reg Loss = 8.5409, Reconstruct Loss = 0.0008, Cls Loss = 0.0411, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0400, Reg Loss = 8.5538, Reconstruct Loss = 0.0011, Cls Loss = 0.0380, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0404, Reg Loss = 8.4432, Reconstruct Loss = 0.0010, Cls Loss = 0.0386, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0398, Reg Loss = 8.3950, Reconstruct Loss = 0.0008, Cls Loss = 0.0382, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0392, Reg Loss = 8.3865, Reconstruct Loss = 0.0006, Cls Loss = 0.0378, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0385, Reg Loss = 8.3417, Reconstruct Loss = 0.0007, Cls Loss = 0.0370, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0382, Reg Loss = 8.3688, Reconstruct Loss = 0.0006, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Epoch [95/200], Training Loss: 0.0386, Training Accuracy: 98.83, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/200], Validation Loss: 0.6248, Validation Accuracy: 83.42%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0591, Reg Loss = 8.6550, Reconstruct Loss = 0.0000, Cls Loss = 0.0582, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0329, Reg Loss = 8.5021, Reconstruct Loss = 0.0002, Cls Loss = 0.0319, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0356, Reg Loss = 8.6041, Reconstruct Loss = 0.0007, Cls Loss = 0.0340, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0371, Reg Loss = 8.6759, Reconstruct Loss = 0.0009, Cls Loss = 0.0353, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0369, Reg Loss = 8.6203, Reconstruct Loss = 0.0008, Cls Loss = 0.0353, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0373, Reg Loss = 8.6866, Reconstruct Loss = 0.0008, Cls Loss = 0.0355, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0376, Reg Loss = 8.6776, Reconstruct Loss = 0.0008, Cls Loss = 0.0359, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0376, Reg Loss = 8.6504, Reconstruct Loss = 0.0009, Cls Loss = 0.0359, Learning rate = 1.0000e-03\n",
      "Epoch [96/200], Training Loss: 0.0376, Training Accuracy: 98.82, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/200], Validation Loss: 0.4799, Validation Accuracy: 86.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0576, Reg Loss = 8.6540, Reconstruct Loss = 0.0000, Cls Loss = 0.0567, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0380, Reg Loss = 8.5636, Reconstruct Loss = 0.0008, Cls Loss = 0.0364, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0381, Reg Loss = 8.5809, Reconstruct Loss = 0.0006, Cls Loss = 0.0367, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0384, Reg Loss = 8.5557, Reconstruct Loss = 0.0007, Cls Loss = 0.0369, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0369, Reg Loss = 8.4797, Reconstruct Loss = 0.0007, Cls Loss = 0.0354, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0376, Reg Loss = 8.4864, Reconstruct Loss = 0.0007, Cls Loss = 0.0360, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0376, Reg Loss = 8.4482, Reconstruct Loss = 0.0007, Cls Loss = 0.0360, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0369, Reg Loss = 8.4157, Reconstruct Loss = 0.0007, Cls Loss = 0.0353, Learning rate = 1.0000e-03\n",
      "Epoch [97/200], Training Loss: 0.0365, Training Accuracy: 98.90, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/200], Validation Loss: 0.5227, Validation Accuracy: 85.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0176, Reg Loss = 8.6811, Reconstruct Loss = 0.0000, Cls Loss = 0.0167, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0358, Reg Loss = 8.8874, Reconstruct Loss = 0.0007, Cls Loss = 0.0343, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0373, Reg Loss = 8.7589, Reconstruct Loss = 0.0006, Cls Loss = 0.0359, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0388, Reg Loss = 8.7058, Reconstruct Loss = 0.0004, Cls Loss = 0.0374, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0374, Reg Loss = 8.6383, Reconstruct Loss = 0.0005, Cls Loss = 0.0361, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0382, Reg Loss = 8.5980, Reconstruct Loss = 0.0004, Cls Loss = 0.0369, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0386, Reg Loss = 8.6085, Reconstruct Loss = 0.0006, Cls Loss = 0.0372, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0383, Reg Loss = 8.5701, Reconstruct Loss = 0.0005, Cls Loss = 0.0369, Learning rate = 1.0000e-03\n",
      "Epoch [98/200], Training Loss: 0.0389, Training Accuracy: 98.86, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/200], Validation Loss: 0.6226, Validation Accuracy: 83.58%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0176, Reg Loss = 8.9043, Reconstruct Loss = 0.0000, Cls Loss = 0.0167, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0453, Reg Loss = 8.7826, Reconstruct Loss = 0.0007, Cls Loss = 0.0437, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0429, Reg Loss = 8.8929, Reconstruct Loss = 0.0008, Cls Loss = 0.0412, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0410, Reg Loss = 8.9273, Reconstruct Loss = 0.0008, Cls Loss = 0.0393, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0408, Reg Loss = 9.0016, Reconstruct Loss = 0.0008, Cls Loss = 0.0391, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0393, Reg Loss = 8.9208, Reconstruct Loss = 0.0007, Cls Loss = 0.0377, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0387, Reg Loss = 8.8948, Reconstruct Loss = 0.0007, Cls Loss = 0.0371, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0384, Reg Loss = 8.8994, Reconstruct Loss = 0.0007, Cls Loss = 0.0368, Learning rate = 1.0000e-03\n",
      "Epoch [99/200], Training Loss: 0.0383, Training Accuracy: 98.85, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/200], Validation Loss: 0.6584, Validation Accuracy: 84.42%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0157, Reg Loss = 8.1751, Reconstruct Loss = 0.0000, Cls Loss = 0.0149, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0373, Reg Loss = 8.5417, Reconstruct Loss = 0.0007, Cls Loss = 0.0358, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0381, Reg Loss = 8.5330, Reconstruct Loss = 0.0007, Cls Loss = 0.0366, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0365, Reg Loss = 8.5501, Reconstruct Loss = 0.0007, Cls Loss = 0.0350, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0354, Reg Loss = 8.6491, Reconstruct Loss = 0.0008, Cls Loss = 0.0338, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0359, Reg Loss = 8.6366, Reconstruct Loss = 0.0008, Cls Loss = 0.0342, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0363, Reg Loss = 8.6672, Reconstruct Loss = 0.0008, Cls Loss = 0.0346, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0362, Reg Loss = 8.6156, Reconstruct Loss = 0.0007, Cls Loss = 0.0346, Learning rate = 1.0000e-03\n",
      "Epoch [100/200], Training Loss: 0.0367, Training Accuracy: 98.89, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/200], Validation Loss: 0.7201, Validation Accuracy: 84.00%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0111, Reg Loss = 8.8295, Reconstruct Loss = 0.0000, Cls Loss = 0.0102, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0389, Reg Loss = 8.8604, Reconstruct Loss = 0.0006, Cls Loss = 0.0374, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0360, Reg Loss = 8.8935, Reconstruct Loss = 0.0005, Cls Loss = 0.0345, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0370, Reg Loss = 8.9081, Reconstruct Loss = 0.0006, Cls Loss = 0.0355, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0363, Reg Loss = 8.8965, Reconstruct Loss = 0.0005, Cls Loss = 0.0349, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0354, Reg Loss = 8.8861, Reconstruct Loss = 0.0005, Cls Loss = 0.0340, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0343, Reg Loss = 8.8754, Reconstruct Loss = 0.0005, Cls Loss = 0.0329, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0338, Reg Loss = 8.8625, Reconstruct Loss = 0.0005, Cls Loss = 0.0324, Learning rate = 1.0000e-04\n",
      "Epoch [101/200], Training Loss: 0.0340, Training Accuracy: 98.94, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200], Validation Loss: 0.6833, Validation Accuracy: 84.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0702, Reg Loss = 8.7382, Reconstruct Loss = 0.0000, Cls Loss = 0.0693, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0328, Reg Loss = 8.6397, Reconstruct Loss = 0.0008, Cls Loss = 0.0312, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0345, Reg Loss = 8.5972, Reconstruct Loss = 0.0008, Cls Loss = 0.0328, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0336, Reg Loss = 8.5312, Reconstruct Loss = 0.0007, Cls Loss = 0.0321, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0328, Reg Loss = 8.4934, Reconstruct Loss = 0.0005, Cls Loss = 0.0315, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0332, Reg Loss = 8.4809, Reconstruct Loss = 0.0006, Cls Loss = 0.0317, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0327, Reg Loss = 8.4664, Reconstruct Loss = 0.0006, Cls Loss = 0.0312, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0319, Reg Loss = 8.4493, Reconstruct Loss = 0.0006, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Epoch [102/200], Training Loss: 0.0319, Training Accuracy: 99.01, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/200], Validation Loss: 0.6335, Validation Accuracy: 83.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0143, Reg Loss = 7.7438, Reconstruct Loss = 0.0000, Cls Loss = 0.0135, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0302, Reg Loss = 8.1968, Reconstruct Loss = 0.0008, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0309, Reg Loss = 8.0940, Reconstruct Loss = 0.0005, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0300, Reg Loss = 8.0796, Reconstruct Loss = 0.0007, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0317, Reg Loss = 8.0357, Reconstruct Loss = 0.0008, Cls Loss = 0.0301, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0313, Reg Loss = 7.9614, Reconstruct Loss = 0.0007, Cls Loss = 0.0299, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0318, Reg Loss = 7.9174, Reconstruct Loss = 0.0007, Cls Loss = 0.0303, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0311, Reg Loss = 7.8843, Reconstruct Loss = 0.0007, Cls Loss = 0.0297, Learning rate = 1.0000e-04\n",
      "Epoch [103/200], Training Loss: 0.0313, Training Accuracy: 99.04, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/200], Validation Loss: 0.6546, Validation Accuracy: 82.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0523, Reg Loss = 7.5578, Reconstruct Loss = 0.0000, Cls Loss = 0.0516, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0291, Reg Loss = 7.6441, Reconstruct Loss = 0.0003, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0290, Reg Loss = 7.6367, Reconstruct Loss = 0.0004, Cls Loss = 0.0278, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0288, Reg Loss = 7.5859, Reconstruct Loss = 0.0004, Cls Loss = 0.0276, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0287, Reg Loss = 7.5775, Reconstruct Loss = 0.0003, Cls Loss = 0.0276, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0300, Reg Loss = 7.5896, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0316, Reg Loss = 7.5852, Reconstruct Loss = 0.0005, Cls Loss = 0.0303, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0314, Reg Loss = 7.5684, Reconstruct Loss = 0.0005, Cls Loss = 0.0301, Learning rate = 1.0000e-04\n",
      "Epoch [104/200], Training Loss: 0.0311, Training Accuracy: 99.05, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/200], Validation Loss: 0.6454, Validation Accuracy: 81.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0135, Reg Loss = 7.5076, Reconstruct Loss = 0.0000, Cls Loss = 0.0127, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0310, Reg Loss = 7.4788, Reconstruct Loss = 0.0006, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0336, Reg Loss = 7.4523, Reconstruct Loss = 0.0006, Cls Loss = 0.0323, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0322, Reg Loss = 7.4205, Reconstruct Loss = 0.0005, Cls Loss = 0.0310, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0318, Reg Loss = 7.3782, Reconstruct Loss = 0.0004, Cls Loss = 0.0307, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0318, Reg Loss = 7.3814, Reconstruct Loss = 0.0004, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0315, Reg Loss = 7.4029, Reconstruct Loss = 0.0006, Cls Loss = 0.0301, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0312, Reg Loss = 7.3824, Reconstruct Loss = 0.0006, Cls Loss = 0.0299, Learning rate = 1.0000e-04\n",
      "Epoch [105/200], Training Loss: 0.0315, Training Accuracy: 99.01, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/200], Validation Loss: 0.6415, Validation Accuracy: 81.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0246, Reg Loss = 6.9409, Reconstruct Loss = 0.0000, Cls Loss = 0.0239, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0285, Reg Loss = 7.2729, Reconstruct Loss = 0.0005, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0292, Reg Loss = 7.3487, Reconstruct Loss = 0.0008, Cls Loss = 0.0277, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0298, Reg Loss = 7.3375, Reconstruct Loss = 0.0007, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0299, Reg Loss = 7.3248, Reconstruct Loss = 0.0007, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0293, Reg Loss = 7.3584, Reconstruct Loss = 0.0007, Cls Loss = 0.0278, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0293, Reg Loss = 7.3505, Reconstruct Loss = 0.0007, Cls Loss = 0.0279, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0298, Reg Loss = 7.3625, Reconstruct Loss = 0.0008, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Epoch [106/200], Training Loss: 0.0303, Training Accuracy: 99.11, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/200], Validation Loss: 0.6449, Validation Accuracy: 81.55%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0195, Reg Loss = 7.2630, Reconstruct Loss = 0.0000, Cls Loss = 0.0188, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0292, Reg Loss = 7.2681, Reconstruct Loss = 0.0004, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0305, Reg Loss = 7.2720, Reconstruct Loss = 0.0004, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0302, Reg Loss = 7.2780, Reconstruct Loss = 0.0004, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0298, Reg Loss = 7.2791, Reconstruct Loss = 0.0005, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0305, Reg Loss = 7.2802, Reconstruct Loss = 0.0006, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0307, Reg Loss = 7.2724, Reconstruct Loss = 0.0006, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0312, Reg Loss = 7.2720, Reconstruct Loss = 0.0007, Cls Loss = 0.0298, Learning rate = 1.0000e-04\n",
      "Epoch [107/200], Training Loss: 0.0319, Training Accuracy: 99.07, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/200], Validation Loss: 0.6782, Validation Accuracy: 80.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0301, Reg Loss = 7.0307, Reconstruct Loss = 0.0000, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0305, Reg Loss = 7.2653, Reconstruct Loss = 0.0007, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0322, Reg Loss = 7.2167, Reconstruct Loss = 0.0007, Cls Loss = 0.0308, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0306, Reg Loss = 7.2181, Reconstruct Loss = 0.0006, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0305, Reg Loss = 7.2257, Reconstruct Loss = 0.0006, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0306, Reg Loss = 7.2359, Reconstruct Loss = 0.0008, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0299, Reg Loss = 7.2170, Reconstruct Loss = 0.0008, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0302, Reg Loss = 7.1910, Reconstruct Loss = 0.0008, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Epoch [108/200], Training Loss: 0.0303, Training Accuracy: 99.09, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/200], Validation Loss: 0.6917, Validation Accuracy: 80.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0502, Reg Loss = 6.8125, Reconstruct Loss = 0.0000, Cls Loss = 0.0495, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0300, Reg Loss = 6.9490, Reconstruct Loss = 0.0002, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0297, Reg Loss = 7.0292, Reconstruct Loss = 0.0005, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0308, Reg Loss = 7.0345, Reconstruct Loss = 0.0006, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0303, Reg Loss = 7.0592, Reconstruct Loss = 0.0007, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0310, Reg Loss = 7.0567, Reconstruct Loss = 0.0006, Cls Loss = 0.0297, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0313, Reg Loss = 7.0760, Reconstruct Loss = 0.0006, Cls Loss = 0.0300, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0313, Reg Loss = 7.0740, Reconstruct Loss = 0.0006, Cls Loss = 0.0300, Learning rate = 1.0000e-04\n",
      "Epoch [109/200], Training Loss: 0.0308, Training Accuracy: 99.08, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/200], Validation Loss: 0.6775, Validation Accuracy: 80.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0315, Reg Loss = 6.8325, Reconstruct Loss = 0.0000, Cls Loss = 0.0309, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0301, Reg Loss = 7.0851, Reconstruct Loss = 0.0004, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0294, Reg Loss = 7.0239, Reconstruct Loss = 0.0003, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0294, Reg Loss = 7.0297, Reconstruct Loss = 0.0004, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0298, Reg Loss = 7.0598, Reconstruct Loss = 0.0005, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0295, Reg Loss = 7.0531, Reconstruct Loss = 0.0004, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0304, Reg Loss = 7.0444, Reconstruct Loss = 0.0003, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0303, Reg Loss = 7.0500, Reconstruct Loss = 0.0004, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Epoch [110/200], Training Loss: 0.0308, Training Accuracy: 99.07, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/200], Validation Loss: 0.6687, Validation Accuracy: 80.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0295, Reg Loss = 6.9942, Reconstruct Loss = 0.0000, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0308, Reg Loss = 7.0733, Reconstruct Loss = 0.0010, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0321, Reg Loss = 7.0683, Reconstruct Loss = 0.0009, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0327, Reg Loss = 7.0623, Reconstruct Loss = 0.0009, Cls Loss = 0.0311, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0327, Reg Loss = 6.9889, Reconstruct Loss = 0.0007, Cls Loss = 0.0312, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0325, Reg Loss = 6.9574, Reconstruct Loss = 0.0007, Cls Loss = 0.0311, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0317, Reg Loss = 6.9297, Reconstruct Loss = 0.0006, Cls Loss = 0.0303, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0323, Reg Loss = 6.9190, Reconstruct Loss = 0.0006, Cls Loss = 0.0310, Learning rate = 1.0000e-04\n",
      "Epoch [111/200], Training Loss: 0.0319, Training Accuracy: 98.98, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/200], Validation Loss: 0.7456, Validation Accuracy: 78.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0059, Reg Loss = 6.8247, Reconstruct Loss = 0.0000, Cls Loss = 0.0052, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0333, Reg Loss = 6.9428, Reconstruct Loss = 0.0007, Cls Loss = 0.0319, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0319, Reg Loss = 6.9371, Reconstruct Loss = 0.0007, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0309, Reg Loss = 6.9469, Reconstruct Loss = 0.0007, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0315, Reg Loss = 6.9568, Reconstruct Loss = 0.0008, Cls Loss = 0.0300, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0315, Reg Loss = 6.9591, Reconstruct Loss = 0.0008, Cls Loss = 0.0299, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0310, Reg Loss = 6.9438, Reconstruct Loss = 0.0008, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0307, Reg Loss = 6.9270, Reconstruct Loss = 0.0008, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Epoch [112/200], Training Loss: 0.0308, Training Accuracy: 99.03, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/200], Validation Loss: 0.7457, Validation Accuracy: 78.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0042, Reg Loss = 6.8383, Reconstruct Loss = 0.0000, Cls Loss = 0.0035, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0310, Reg Loss = 6.7018, Reconstruct Loss = 0.0003, Cls Loss = 0.0301, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0322, Reg Loss = 6.7708, Reconstruct Loss = 0.0007, Cls Loss = 0.0308, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0315, Reg Loss = 6.7531, Reconstruct Loss = 0.0006, Cls Loss = 0.0302, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0323, Reg Loss = 6.7404, Reconstruct Loss = 0.0006, Cls Loss = 0.0310, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0319, Reg Loss = 6.7305, Reconstruct Loss = 0.0006, Cls Loss = 0.0307, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0316, Reg Loss = 6.7307, Reconstruct Loss = 0.0006, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0311, Reg Loss = 6.7369, Reconstruct Loss = 0.0006, Cls Loss = 0.0298, Learning rate = 1.0000e-04\n",
      "Epoch [113/200], Training Loss: 0.0309, Training Accuracy: 99.10, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/200], Validation Loss: 0.7148, Validation Accuracy: 79.03%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0109, Reg Loss = 6.8377, Reconstruct Loss = 0.0000, Cls Loss = 0.0103, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0349, Reg Loss = 6.6982, Reconstruct Loss = 0.0004, Cls Loss = 0.0337, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0330, Reg Loss = 6.6249, Reconstruct Loss = 0.0003, Cls Loss = 0.0321, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0326, Reg Loss = 6.6209, Reconstruct Loss = 0.0003, Cls Loss = 0.0316, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0335, Reg Loss = 6.5968, Reconstruct Loss = 0.0003, Cls Loss = 0.0325, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0322, Reg Loss = 6.5836, Reconstruct Loss = 0.0003, Cls Loss = 0.0313, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0319, Reg Loss = 6.5770, Reconstruct Loss = 0.0003, Cls Loss = 0.0309, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0315, Reg Loss = 6.5617, Reconstruct Loss = 0.0003, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Epoch [114/200], Training Loss: 0.0315, Training Accuracy: 98.98, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/200], Validation Loss: 0.7404, Validation Accuracy: 78.11%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0153, Reg Loss = 6.2033, Reconstruct Loss = 0.0000, Cls Loss = 0.0147, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0316, Reg Loss = 6.4846, Reconstruct Loss = 0.0004, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0284, Reg Loss = 6.4602, Reconstruct Loss = 0.0004, Cls Loss = 0.0274, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0305, Reg Loss = 6.4407, Reconstruct Loss = 0.0003, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0297, Reg Loss = 6.4230, Reconstruct Loss = 0.0003, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0293, Reg Loss = 6.4176, Reconstruct Loss = 0.0004, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0299, Reg Loss = 6.4335, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0299, Reg Loss = 6.4363, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Epoch [115/200], Training Loss: 0.0302, Training Accuracy: 99.09, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/200], Validation Loss: 0.7362, Validation Accuracy: 78.20%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0096, Reg Loss = 6.6791, Reconstruct Loss = 0.0000, Cls Loss = 0.0090, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0318, Reg Loss = 6.4796, Reconstruct Loss = 0.0006, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0304, Reg Loss = 6.4441, Reconstruct Loss = 0.0005, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0310, Reg Loss = 6.4332, Reconstruct Loss = 0.0005, Cls Loss = 0.0298, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0309, Reg Loss = 6.4459, Reconstruct Loss = 0.0006, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0301, Reg Loss = 6.4130, Reconstruct Loss = 0.0005, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0304, Reg Loss = 6.3893, Reconstruct Loss = 0.0005, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0304, Reg Loss = 6.3773, Reconstruct Loss = 0.0005, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Epoch [116/200], Training Loss: 0.0307, Training Accuracy: 99.06, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200], Validation Loss: 0.7912, Validation Accuracy: 76.67%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0213, Reg Loss = 5.8404, Reconstruct Loss = 0.0000, Cls Loss = 0.0207, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0288, Reg Loss = 6.3929, Reconstruct Loss = 0.0009, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0313, Reg Loss = 6.3419, Reconstruct Loss = 0.0007, Cls Loss = 0.0300, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0318, Reg Loss = 6.3283, Reconstruct Loss = 0.0005, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0314, Reg Loss = 6.3403, Reconstruct Loss = 0.0006, Cls Loss = 0.0302, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0311, Reg Loss = 6.3321, Reconstruct Loss = 0.0005, Cls Loss = 0.0299, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0316, Reg Loss = 6.3442, Reconstruct Loss = 0.0006, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0317, Reg Loss = 6.3522, Reconstruct Loss = 0.0006, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Epoch [117/200], Training Loss: 0.0309, Training Accuracy: 99.09, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/200], Validation Loss: 0.7919, Validation Accuracy: 76.78%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0175, Reg Loss = 6.1125, Reconstruct Loss = 0.0000, Cls Loss = 0.0169, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0297, Reg Loss = 6.2101, Reconstruct Loss = 0.0006, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0307, Reg Loss = 6.1984, Reconstruct Loss = 0.0005, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0307, Reg Loss = 6.1909, Reconstruct Loss = 0.0005, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0316, Reg Loss = 6.1824, Reconstruct Loss = 0.0005, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0319, Reg Loss = 6.2108, Reconstruct Loss = 0.0006, Cls Loss = 0.0307, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0317, Reg Loss = 6.2122, Reconstruct Loss = 0.0006, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0311, Reg Loss = 6.2411, Reconstruct Loss = 0.0007, Cls Loss = 0.0298, Learning rate = 1.0000e-04\n",
      "Epoch [118/200], Training Loss: 0.0309, Training Accuracy: 99.09, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/200], Validation Loss: 0.8718, Validation Accuracy: 75.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0258, Reg Loss = 6.1447, Reconstruct Loss = 0.0000, Cls Loss = 0.0252, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0325, Reg Loss = 6.1288, Reconstruct Loss = 0.0004, Cls Loss = 0.0315, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0335, Reg Loss = 6.0960, Reconstruct Loss = 0.0004, Cls Loss = 0.0325, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0315, Reg Loss = 6.0862, Reconstruct Loss = 0.0003, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0314, Reg Loss = 6.1208, Reconstruct Loss = 0.0005, Cls Loss = 0.0303, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0311, Reg Loss = 6.1099, Reconstruct Loss = 0.0005, Cls Loss = 0.0300, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0308, Reg Loss = 6.1249, Reconstruct Loss = 0.0005, Cls Loss = 0.0297, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0303, Reg Loss = 6.1310, Reconstruct Loss = 0.0005, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Epoch [119/200], Training Loss: 0.0304, Training Accuracy: 99.07, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/200], Validation Loss: 0.8496, Validation Accuracy: 75.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0568, Reg Loss = 6.0164, Reconstruct Loss = 0.0000, Cls Loss = 0.0562, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0286, Reg Loss = 6.1461, Reconstruct Loss = 0.0004, Cls Loss = 0.0276, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0281, Reg Loss = 6.1215, Reconstruct Loss = 0.0004, Cls Loss = 0.0271, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0296, Reg Loss = 6.1046, Reconstruct Loss = 0.0004, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0296, Reg Loss = 6.0978, Reconstruct Loss = 0.0004, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0295, Reg Loss = 6.0977, Reconstruct Loss = 0.0004, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0301, Reg Loss = 6.0936, Reconstruct Loss = 0.0004, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0303, Reg Loss = 6.1068, Reconstruct Loss = 0.0005, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Epoch [120/200], Training Loss: 0.0306, Training Accuracy: 99.06, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/200], Validation Loss: 0.8472, Validation Accuracy: 75.60%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0356, Reg Loss = 6.0410, Reconstruct Loss = 0.0000, Cls Loss = 0.0350, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0254, Reg Loss = 6.1080, Reconstruct Loss = 0.0006, Cls Loss = 0.0242, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0292, Reg Loss = 6.0958, Reconstruct Loss = 0.0006, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0293, Reg Loss = 6.0913, Reconstruct Loss = 0.0006, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0302, Reg Loss = 6.1003, Reconstruct Loss = 0.0006, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0299, Reg Loss = 6.1044, Reconstruct Loss = 0.0006, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0306, Reg Loss = 6.1125, Reconstruct Loss = 0.0007, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0301, Reg Loss = 6.0948, Reconstruct Loss = 0.0006, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Epoch [121/200], Training Loss: 0.0303, Training Accuracy: 99.10, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/200], Validation Loss: 0.8204, Validation Accuracy: 76.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0575, Reg Loss = 9.2057, Reconstruct Loss = 0.0144, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0304, Reg Loss = 6.2144, Reconstruct Loss = 0.0011, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0290, Reg Loss = 6.1525, Reconstruct Loss = 0.0009, Cls Loss = 0.0274, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0284, Reg Loss = 6.1271, Reconstruct Loss = 0.0009, Cls Loss = 0.0269, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0299, Reg Loss = 6.1196, Reconstruct Loss = 0.0009, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0299, Reg Loss = 6.0993, Reconstruct Loss = 0.0008, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0299, Reg Loss = 6.0695, Reconstruct Loss = 0.0008, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0296, Reg Loss = 6.0536, Reconstruct Loss = 0.0007, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Epoch [122/200], Training Loss: 0.0299, Training Accuracy: 99.10, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/200], Validation Loss: 0.8224, Validation Accuracy: 75.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0548, Reg Loss = 5.7533, Reconstruct Loss = 0.0000, Cls Loss = 0.0543, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0300, Reg Loss = 5.9782, Reconstruct Loss = 0.0004, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0299, Reg Loss = 6.0140, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0304, Reg Loss = 6.0352, Reconstruct Loss = 0.0005, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0306, Reg Loss = 6.0465, Reconstruct Loss = 0.0005, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0307, Reg Loss = 6.0574, Reconstruct Loss = 0.0005, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0307, Reg Loss = 6.0635, Reconstruct Loss = 0.0005, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0305, Reg Loss = 6.0610, Reconstruct Loss = 0.0005, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Epoch [123/200], Training Loss: 0.0311, Training Accuracy: 99.06, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/200], Validation Loss: 0.8217, Validation Accuracy: 75.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0087, Reg Loss = 5.9773, Reconstruct Loss = 0.0000, Cls Loss = 0.0081, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0310, Reg Loss = 6.0704, Reconstruct Loss = 0.0004, Cls Loss = 0.0300, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0301, Reg Loss = 6.0262, Reconstruct Loss = 0.0003, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0299, Reg Loss = 6.0364, Reconstruct Loss = 0.0003, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0298, Reg Loss = 6.0332, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0301, Reg Loss = 6.0341, Reconstruct Loss = 0.0004, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0305, Reg Loss = 6.0406, Reconstruct Loss = 0.0004, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0306, Reg Loss = 6.0437, Reconstruct Loss = 0.0004, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Epoch [124/200], Training Loss: 0.0307, Training Accuracy: 99.07, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/200], Validation Loss: 0.7881, Validation Accuracy: 76.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0686, Reg Loss = 5.9657, Reconstruct Loss = 0.0000, Cls Loss = 0.0680, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0320, Reg Loss = 6.1605, Reconstruct Loss = 0.0009, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0305, Reg Loss = 6.1968, Reconstruct Loss = 0.0009, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0305, Reg Loss = 6.1552, Reconstruct Loss = 0.0008, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0307, Reg Loss = 6.1236, Reconstruct Loss = 0.0007, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0302, Reg Loss = 6.1043, Reconstruct Loss = 0.0007, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0300, Reg Loss = 6.0833, Reconstruct Loss = 0.0006, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0295, Reg Loss = 6.0557, Reconstruct Loss = 0.0005, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Epoch [125/200], Training Loss: 0.0307, Training Accuracy: 99.08, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/200], Validation Loss: 0.8272, Validation Accuracy: 75.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0193, Reg Loss = 6.0224, Reconstruct Loss = 0.0000, Cls Loss = 0.0187, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0280, Reg Loss = 6.0215, Reconstruct Loss = 0.0006, Cls Loss = 0.0268, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0297, Reg Loss = 6.0438, Reconstruct Loss = 0.0006, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0300, Reg Loss = 6.0333, Reconstruct Loss = 0.0005, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0304, Reg Loss = 6.0244, Reconstruct Loss = 0.0005, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0306, Reg Loss = 6.0163, Reconstruct Loss = 0.0005, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0310, Reg Loss = 5.9945, Reconstruct Loss = 0.0005, Cls Loss = 0.0299, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0304, Reg Loss = 5.9718, Reconstruct Loss = 0.0005, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Epoch [126/200], Training Loss: 0.0311, Training Accuracy: 99.08, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/200], Validation Loss: 0.8335, Validation Accuracy: 75.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0266, Reg Loss = 5.8055, Reconstruct Loss = 0.0000, Cls Loss = 0.0260, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0333, Reg Loss = 5.8839, Reconstruct Loss = 0.0003, Cls Loss = 0.0324, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0314, Reg Loss = 5.8454, Reconstruct Loss = 0.0003, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0328, Reg Loss = 5.8691, Reconstruct Loss = 0.0005, Cls Loss = 0.0317, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0323, Reg Loss = 5.8536, Reconstruct Loss = 0.0005, Cls Loss = 0.0313, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0316, Reg Loss = 5.8377, Reconstruct Loss = 0.0005, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0315, Reg Loss = 5.8197, Reconstruct Loss = 0.0004, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0310, Reg Loss = 5.8122, Reconstruct Loss = 0.0004, Cls Loss = 0.0300, Learning rate = 1.0000e-04\n",
      "Epoch [127/200], Training Loss: 0.0308, Training Accuracy: 99.06, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/200], Validation Loss: 0.9158, Validation Accuracy: 74.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0186, Reg Loss = 5.6266, Reconstruct Loss = 0.0000, Cls Loss = 0.0181, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0306, Reg Loss = 5.7872, Reconstruct Loss = 0.0004, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0328, Reg Loss = 5.8125, Reconstruct Loss = 0.0005, Cls Loss = 0.0317, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0305, Reg Loss = 5.8310, Reconstruct Loss = 0.0005, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0296, Reg Loss = 5.8182, Reconstruct Loss = 0.0004, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0297, Reg Loss = 5.8296, Reconstruct Loss = 0.0005, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0306, Reg Loss = 5.8369, Reconstruct Loss = 0.0005, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0303, Reg Loss = 5.8417, Reconstruct Loss = 0.0005, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Epoch [128/200], Training Loss: 0.0300, Training Accuracy: 99.11, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/200], Validation Loss: 0.9011, Validation Accuracy: 74.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0321, Reg Loss = 5.8476, Reconstruct Loss = 0.0000, Cls Loss = 0.0315, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0286, Reg Loss = 5.8383, Reconstruct Loss = 0.0006, Cls Loss = 0.0275, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0311, Reg Loss = 5.7904, Reconstruct Loss = 0.0004, Cls Loss = 0.0301, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0305, Reg Loss = 5.8057, Reconstruct Loss = 0.0005, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0305, Reg Loss = 5.8008, Reconstruct Loss = 0.0005, Cls Loss = 0.0295, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0303, Reg Loss = 5.7866, Reconstruct Loss = 0.0004, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0300, Reg Loss = 5.7814, Reconstruct Loss = 0.0004, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0304, Reg Loss = 5.7734, Reconstruct Loss = 0.0004, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Epoch [129/200], Training Loss: 0.0310, Training Accuracy: 99.01, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/200], Validation Loss: 0.9203, Validation Accuracy: 74.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0257, Reg Loss = 5.6289, Reconstruct Loss = 0.0000, Cls Loss = 0.0251, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0328, Reg Loss = 5.7061, Reconstruct Loss = 0.0003, Cls Loss = 0.0320, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0315, Reg Loss = 5.7748, Reconstruct Loss = 0.0006, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0310, Reg Loss = 5.7838, Reconstruct Loss = 0.0006, Cls Loss = 0.0298, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0306, Reg Loss = 5.7846, Reconstruct Loss = 0.0006, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0312, Reg Loss = 5.7657, Reconstruct Loss = 0.0005, Cls Loss = 0.0301, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0308, Reg Loss = 5.7600, Reconstruct Loss = 0.0005, Cls Loss = 0.0297, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0306, Reg Loss = 5.7625, Reconstruct Loss = 0.0005, Cls Loss = 0.0296, Learning rate = 1.0000e-04\n",
      "Epoch [130/200], Training Loss: 0.0307, Training Accuracy: 99.06, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/200], Validation Loss: 0.8996, Validation Accuracy: 74.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0050, Reg Loss = 5.5780, Reconstruct Loss = 0.0000, Cls Loss = 0.0044, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0287, Reg Loss = 5.6845, Reconstruct Loss = 0.0001, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0302, Reg Loss = 5.7330, Reconstruct Loss = 0.0002, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0303, Reg Loss = 5.7735, Reconstruct Loss = 0.0004, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0304, Reg Loss = 5.7903, Reconstruct Loss = 0.0005, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0302, Reg Loss = 5.7917, Reconstruct Loss = 0.0005, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0299, Reg Loss = 5.7974, Reconstruct Loss = 0.0006, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0299, Reg Loss = 5.7868, Reconstruct Loss = 0.0005, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Epoch [131/200], Training Loss: 0.0298, Training Accuracy: 99.08, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/200], Validation Loss: 0.9144, Validation Accuracy: 74.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0096, Reg Loss = 5.5800, Reconstruct Loss = 0.0000, Cls Loss = 0.0090, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0295, Reg Loss = 5.7473, Reconstruct Loss = 0.0007, Cls Loss = 0.0282, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0290, Reg Loss = 5.7398, Reconstruct Loss = 0.0006, Cls Loss = 0.0278, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0295, Reg Loss = 5.7389, Reconstruct Loss = 0.0005, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0293, Reg Loss = 5.7161, Reconstruct Loss = 0.0004, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0291, Reg Loss = 5.7319, Reconstruct Loss = 0.0005, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0296, Reg Loss = 5.7368, Reconstruct Loss = 0.0005, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0294, Reg Loss = 5.7446, Reconstruct Loss = 0.0005, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Epoch [132/200], Training Loss: 0.0295, Training Accuracy: 99.10, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/200], Validation Loss: 0.9374, Validation Accuracy: 74.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0275, Reg Loss = 5.4717, Reconstruct Loss = 0.0000, Cls Loss = 0.0269, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0323, Reg Loss = 5.7401, Reconstruct Loss = 0.0006, Cls Loss = 0.0311, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0303, Reg Loss = 5.7485, Reconstruct Loss = 0.0006, Cls Loss = 0.0291, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0301, Reg Loss = 5.7334, Reconstruct Loss = 0.0007, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0298, Reg Loss = 5.7496, Reconstruct Loss = 0.0007, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0303, Reg Loss = 5.7233, Reconstruct Loss = 0.0006, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0303, Reg Loss = 5.7525, Reconstruct Loss = 0.0007, Cls Loss = 0.0290, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0306, Reg Loss = 5.7313, Reconstruct Loss = 0.0007, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Epoch [133/200], Training Loss: 0.0308, Training Accuracy: 99.13, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/200], Validation Loss: 0.8954, Validation Accuracy: 74.67%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0693, Reg Loss = 5.3632, Reconstruct Loss = 0.0000, Cls Loss = 0.0687, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0326, Reg Loss = 5.5947, Reconstruct Loss = 0.0003, Cls Loss = 0.0318, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0314, Reg Loss = 5.5710, Reconstruct Loss = 0.0003, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0315, Reg Loss = 5.5728, Reconstruct Loss = 0.0004, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0318, Reg Loss = 5.5788, Reconstruct Loss = 0.0005, Cls Loss = 0.0307, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0318, Reg Loss = 5.5706, Reconstruct Loss = 0.0004, Cls Loss = 0.0308, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0318, Reg Loss = 5.5620, Reconstruct Loss = 0.0004, Cls Loss = 0.0309, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0317, Reg Loss = 5.5627, Reconstruct Loss = 0.0004, Cls Loss = 0.0307, Learning rate = 1.0000e-04\n",
      "Epoch [134/200], Training Loss: 0.0319, Training Accuracy: 99.01, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/200], Validation Loss: 0.9214, Validation Accuracy: 74.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0248, Reg Loss = 5.2970, Reconstruct Loss = 0.0000, Cls Loss = 0.0243, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0282, Reg Loss = 5.5131, Reconstruct Loss = 0.0004, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0270, Reg Loss = 5.5520, Reconstruct Loss = 0.0006, Cls Loss = 0.0259, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0284, Reg Loss = 5.5538, Reconstruct Loss = 0.0007, Cls Loss = 0.0271, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0289, Reg Loss = 5.5778, Reconstruct Loss = 0.0008, Cls Loss = 0.0275, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0294, Reg Loss = 5.5492, Reconstruct Loss = 0.0007, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0294, Reg Loss = 5.5593, Reconstruct Loss = 0.0007, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0293, Reg Loss = 5.5509, Reconstruct Loss = 0.0007, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Epoch [135/200], Training Loss: 0.0293, Training Accuracy: 99.15, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/200], Validation Loss: 0.9810, Validation Accuracy: 73.31%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0362, Reg Loss = 5.3808, Reconstruct Loss = 0.0000, Cls Loss = 0.0356, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0293, Reg Loss = 5.5971, Reconstruct Loss = 0.0010, Cls Loss = 0.0277, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0301, Reg Loss = 5.5935, Reconstruct Loss = 0.0009, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0301, Reg Loss = 5.6180, Reconstruct Loss = 0.0010, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0303, Reg Loss = 5.5943, Reconstruct Loss = 0.0008, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0301, Reg Loss = 5.5867, Reconstruct Loss = 0.0008, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0301, Reg Loss = 5.5896, Reconstruct Loss = 0.0009, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0300, Reg Loss = 5.5817, Reconstruct Loss = 0.0008, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Epoch [136/200], Training Loss: 0.0301, Training Accuracy: 99.05, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/200], Validation Loss: 0.9050, Validation Accuracy: 74.20%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0542, Reg Loss = 5.3682, Reconstruct Loss = 0.0000, Cls Loss = 0.0537, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0290, Reg Loss = 5.5208, Reconstruct Loss = 0.0004, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0280, Reg Loss = 5.4870, Reconstruct Loss = 0.0003, Cls Loss = 0.0272, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0271, Reg Loss = 5.4979, Reconstruct Loss = 0.0004, Cls Loss = 0.0261, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0273, Reg Loss = 5.4977, Reconstruct Loss = 0.0005, Cls Loss = 0.0262, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0283, Reg Loss = 5.5127, Reconstruct Loss = 0.0005, Cls Loss = 0.0272, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0285, Reg Loss = 5.5179, Reconstruct Loss = 0.0006, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0283, Reg Loss = 5.4895, Reconstruct Loss = 0.0005, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Epoch [137/200], Training Loss: 0.0292, Training Accuracy: 99.15, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/200], Validation Loss: 1.0149, Validation Accuracy: 72.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0040, Reg Loss = 5.2754, Reconstruct Loss = 0.0000, Cls Loss = 0.0034, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0299, Reg Loss = 5.4542, Reconstruct Loss = 0.0006, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0303, Reg Loss = 5.4285, Reconstruct Loss = 0.0004, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0289, Reg Loss = 5.4081, Reconstruct Loss = 0.0003, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0295, Reg Loss = 5.4308, Reconstruct Loss = 0.0004, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0291, Reg Loss = 5.4145, Reconstruct Loss = 0.0004, Cls Loss = 0.0282, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0288, Reg Loss = 5.4062, Reconstruct Loss = 0.0004, Cls Loss = 0.0279, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0289, Reg Loss = 5.3838, Reconstruct Loss = 0.0003, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Epoch [138/200], Training Loss: 0.0293, Training Accuracy: 99.11, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/200], Validation Loss: 0.9844, Validation Accuracy: 72.86%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0548, Reg Loss = 5.3806, Reconstruct Loss = 0.0000, Cls Loss = 0.0543, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0316, Reg Loss = 5.2836, Reconstruct Loss = 0.0003, Cls Loss = 0.0308, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0297, Reg Loss = 5.2849, Reconstruct Loss = 0.0002, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0291, Reg Loss = 5.3110, Reconstruct Loss = 0.0004, Cls Loss = 0.0282, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0291, Reg Loss = 5.3217, Reconstruct Loss = 0.0004, Cls Loss = 0.0282, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0294, Reg Loss = 5.3119, Reconstruct Loss = 0.0004, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0296, Reg Loss = 5.3062, Reconstruct Loss = 0.0004, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0291, Reg Loss = 5.3139, Reconstruct Loss = 0.0004, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Epoch [139/200], Training Loss: 0.0296, Training Accuracy: 99.07, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/200], Validation Loss: 0.9830, Validation Accuracy: 72.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0077, Reg Loss = 5.1800, Reconstruct Loss = 0.0000, Cls Loss = 0.0072, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0282, Reg Loss = 5.3008, Reconstruct Loss = 0.0007, Cls Loss = 0.0269, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0258, Reg Loss = 5.2853, Reconstruct Loss = 0.0005, Cls Loss = 0.0248, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0282, Reg Loss = 5.2731, Reconstruct Loss = 0.0004, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0283, Reg Loss = 5.2558, Reconstruct Loss = 0.0003, Cls Loss = 0.0274, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0293, Reg Loss = 5.2768, Reconstruct Loss = 0.0004, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0293, Reg Loss = 5.2887, Reconstruct Loss = 0.0004, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0292, Reg Loss = 5.2753, Reconstruct Loss = 0.0004, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Epoch [140/200], Training Loss: 0.0293, Training Accuracy: 99.12, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/200], Validation Loss: 1.0484, Validation Accuracy: 72.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0642, Reg Loss = 5.2807, Reconstruct Loss = 0.0000, Cls Loss = 0.0636, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0285, Reg Loss = 5.3252, Reconstruct Loss = 0.0006, Cls Loss = 0.0274, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0279, Reg Loss = 5.3155, Reconstruct Loss = 0.0005, Cls Loss = 0.0269, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0277, Reg Loss = 5.3797, Reconstruct Loss = 0.0008, Cls Loss = 0.0264, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0271, Reg Loss = 5.3835, Reconstruct Loss = 0.0007, Cls Loss = 0.0259, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0285, Reg Loss = 5.3801, Reconstruct Loss = 0.0007, Cls Loss = 0.0272, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0293, Reg Loss = 5.3661, Reconstruct Loss = 0.0007, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0292, Reg Loss = 5.3646, Reconstruct Loss = 0.0007, Cls Loss = 0.0280, Learning rate = 1.0000e-04\n",
      "Epoch [141/200], Training Loss: 0.0292, Training Accuracy: 99.11, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/200], Validation Loss: 1.0023, Validation Accuracy: 72.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0063, Reg Loss = 5.4114, Reconstruct Loss = 0.0000, Cls Loss = 0.0057, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0350, Reg Loss = 5.4384, Reconstruct Loss = 0.0009, Cls Loss = 0.0335, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0315, Reg Loss = 5.3652, Reconstruct Loss = 0.0006, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0308, Reg Loss = 5.3436, Reconstruct Loss = 0.0005, Cls Loss = 0.0297, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0318, Reg Loss = 5.3525, Reconstruct Loss = 0.0005, Cls Loss = 0.0308, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0316, Reg Loss = 5.3632, Reconstruct Loss = 0.0006, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0316, Reg Loss = 5.3610, Reconstruct Loss = 0.0005, Cls Loss = 0.0305, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0317, Reg Loss = 5.3606, Reconstruct Loss = 0.0006, Cls Loss = 0.0306, Learning rate = 1.0000e-04\n",
      "Epoch [142/200], Training Loss: 0.0320, Training Accuracy: 98.98, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/200], Validation Loss: 0.9579, Validation Accuracy: 73.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0248, Reg Loss = 8.3134, Reconstruct Loss = 0.0141, Cls Loss = 0.0099, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0286, Reg Loss = 5.3073, Reconstruct Loss = 0.0008, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0285, Reg Loss = 5.2485, Reconstruct Loss = 0.0006, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0283, Reg Loss = 5.2307, Reconstruct Loss = 0.0006, Cls Loss = 0.0272, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0276, Reg Loss = 5.2347, Reconstruct Loss = 0.0005, Cls Loss = 0.0266, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0275, Reg Loss = 5.2211, Reconstruct Loss = 0.0005, Cls Loss = 0.0265, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0278, Reg Loss = 5.2184, Reconstruct Loss = 0.0005, Cls Loss = 0.0268, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0284, Reg Loss = 5.2264, Reconstruct Loss = 0.0005, Cls Loss = 0.0273, Learning rate = 1.0000e-04\n",
      "Epoch [143/200], Training Loss: 0.0285, Training Accuracy: 99.08, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/200], Validation Loss: 1.0247, Validation Accuracy: 72.27%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0788, Reg Loss = 5.2247, Reconstruct Loss = 0.0000, Cls Loss = 0.0783, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0319, Reg Loss = 5.1560, Reconstruct Loss = 0.0004, Cls Loss = 0.0309, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0308, Reg Loss = 5.1706, Reconstruct Loss = 0.0005, Cls Loss = 0.0298, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0293, Reg Loss = 5.1639, Reconstruct Loss = 0.0005, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0299, Reg Loss = 5.1655, Reconstruct Loss = 0.0005, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0290, Reg Loss = 5.1460, Reconstruct Loss = 0.0005, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0298, Reg Loss = 5.1271, Reconstruct Loss = 0.0004, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0292, Reg Loss = 5.1154, Reconstruct Loss = 0.0004, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Epoch [144/200], Training Loss: 0.0297, Training Accuracy: 99.08, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/200], Validation Loss: 1.0034, Validation Accuracy: 72.50%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0254, Reg Loss = 4.8573, Reconstruct Loss = 0.0000, Cls Loss = 0.0249, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0292, Reg Loss = 5.0886, Reconstruct Loss = 0.0004, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0303, Reg Loss = 5.1243, Reconstruct Loss = 0.0006, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0295, Reg Loss = 5.1252, Reconstruct Loss = 0.0006, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0291, Reg Loss = 5.1012, Reconstruct Loss = 0.0005, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0293, Reg Loss = 5.1327, Reconstruct Loss = 0.0006, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0287, Reg Loss = 5.1501, Reconstruct Loss = 0.0007, Cls Loss = 0.0275, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0287, Reg Loss = 5.1339, Reconstruct Loss = 0.0006, Cls Loss = 0.0275, Learning rate = 1.0000e-04\n",
      "Epoch [145/200], Training Loss: 0.0287, Training Accuracy: 99.18, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/200], Validation Loss: 0.9744, Validation Accuracy: 72.77%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0518, Reg Loss = 5.0656, Reconstruct Loss = 0.0000, Cls Loss = 0.0513, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0283, Reg Loss = 5.2708, Reconstruct Loss = 0.0011, Cls Loss = 0.0267, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0286, Reg Loss = 5.2073, Reconstruct Loss = 0.0009, Cls Loss = 0.0272, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0296, Reg Loss = 5.2091, Reconstruct Loss = 0.0009, Cls Loss = 0.0282, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0312, Reg Loss = 5.2232, Reconstruct Loss = 0.0010, Cls Loss = 0.0297, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0308, Reg Loss = 5.1910, Reconstruct Loss = 0.0008, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0306, Reg Loss = 5.1631, Reconstruct Loss = 0.0008, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0305, Reg Loss = 5.1637, Reconstruct Loss = 0.0008, Cls Loss = 0.0292, Learning rate = 1.0000e-04\n",
      "Epoch [146/200], Training Loss: 0.0309, Training Accuracy: 99.11, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/200], Validation Loss: 1.0230, Validation Accuracy: 72.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0049, Reg Loss = 4.8087, Reconstruct Loss = 0.0000, Cls Loss = 0.0044, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0299, Reg Loss = 5.1605, Reconstruct Loss = 0.0009, Cls Loss = 0.0285, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0282, Reg Loss = 5.1101, Reconstruct Loss = 0.0005, Cls Loss = 0.0272, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0301, Reg Loss = 5.1436, Reconstruct Loss = 0.0007, Cls Loss = 0.0289, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0300, Reg Loss = 5.1194, Reconstruct Loss = 0.0006, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0292, Reg Loss = 5.1048, Reconstruct Loss = 0.0006, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0294, Reg Loss = 5.0993, Reconstruct Loss = 0.0006, Cls Loss = 0.0283, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0298, Reg Loss = 5.1025, Reconstruct Loss = 0.0006, Cls Loss = 0.0287, Learning rate = 1.0000e-04\n",
      "Epoch [147/200], Training Loss: 0.0301, Training Accuracy: 99.06, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/200], Validation Loss: 1.0140, Validation Accuracy: 72.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0125, Reg Loss = 5.0408, Reconstruct Loss = 0.0000, Cls Loss = 0.0120, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0263, Reg Loss = 5.1210, Reconstruct Loss = 0.0009, Cls Loss = 0.0249, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0286, Reg Loss = 5.1401, Reconstruct Loss = 0.0009, Cls Loss = 0.0272, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0277, Reg Loss = 5.1022, Reconstruct Loss = 0.0007, Cls Loss = 0.0265, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0279, Reg Loss = 5.1150, Reconstruct Loss = 0.0008, Cls Loss = 0.0267, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0283, Reg Loss = 5.1131, Reconstruct Loss = 0.0008, Cls Loss = 0.0270, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0290, Reg Loss = 5.0898, Reconstruct Loss = 0.0008, Cls Loss = 0.0277, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0294, Reg Loss = 5.0760, Reconstruct Loss = 0.0007, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Epoch [148/200], Training Loss: 0.0292, Training Accuracy: 99.12, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/200], Validation Loss: 1.0611, Validation Accuracy: 71.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0276, Reg Loss = 4.9089, Reconstruct Loss = 0.0000, Cls Loss = 0.0271, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0313, Reg Loss = 4.9672, Reconstruct Loss = 0.0004, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0303, Reg Loss = 4.9417, Reconstruct Loss = 0.0004, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0296, Reg Loss = 4.9518, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0297, Reg Loss = 4.9509, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0298, Reg Loss = 4.9890, Reconstruct Loss = 0.0006, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0297, Reg Loss = 5.0000, Reconstruct Loss = 0.0006, Cls Loss = 0.0286, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0293, Reg Loss = 5.0195, Reconstruct Loss = 0.0007, Cls Loss = 0.0281, Learning rate = 1.0000e-04\n",
      "Epoch [149/200], Training Loss: 0.0294, Training Accuracy: 99.11, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/200], Validation Loss: 1.0752, Validation Accuracy: 71.51%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0057, Reg Loss = 4.8394, Reconstruct Loss = 0.0000, Cls Loss = 0.0053, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0283, Reg Loss = 4.9774, Reconstruct Loss = 0.0007, Cls Loss = 0.0271, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0308, Reg Loss = 4.9692, Reconstruct Loss = 0.0006, Cls Loss = 0.0297, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0298, Reg Loss = 4.9377, Reconstruct Loss = 0.0005, Cls Loss = 0.0288, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0289, Reg Loss = 4.9588, Reconstruct Loss = 0.0006, Cls Loss = 0.0278, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0290, Reg Loss = 4.9567, Reconstruct Loss = 0.0006, Cls Loss = 0.0279, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0288, Reg Loss = 4.9527, Reconstruct Loss = 0.0005, Cls Loss = 0.0277, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0287, Reg Loss = 4.9556, Reconstruct Loss = 0.0005, Cls Loss = 0.0276, Learning rate = 1.0000e-04\n",
      "Epoch [150/200], Training Loss: 0.0289, Training Accuracy: 99.10, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/200], Validation Loss: 1.0926, Validation Accuracy: 71.75%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0070, Reg Loss = 5.0252, Reconstruct Loss = 0.0000, Cls Loss = 0.0064, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0303, Reg Loss = 4.8464, Reconstruct Loss = 0.0001, Cls Loss = 0.0297, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0303, Reg Loss = 4.9069, Reconstruct Loss = 0.0004, Cls Loss = 0.0294, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0291, Reg Loss = 4.9238, Reconstruct Loss = 0.0005, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0294, Reg Loss = 4.9376, Reconstruct Loss = 0.0006, Cls Loss = 0.0283, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0287, Reg Loss = 4.9180, Reconstruct Loss = 0.0005, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0289, Reg Loss = 4.9148, Reconstruct Loss = 0.0005, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0286, Reg Loss = 4.9093, Reconstruct Loss = 0.0004, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Epoch [151/200], Training Loss: 0.0284, Training Accuracy: 99.20, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/200], Validation Loss: 1.0913, Validation Accuracy: 72.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0153, Reg Loss = 4.6715, Reconstruct Loss = 0.0000, Cls Loss = 0.0148, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0277, Reg Loss = 5.0032, Reconstruct Loss = 0.0008, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0288, Reg Loss = 5.0192, Reconstruct Loss = 0.0009, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0293, Reg Loss = 4.9879, Reconstruct Loss = 0.0007, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0298, Reg Loss = 4.9676, Reconstruct Loss = 0.0007, Cls Loss = 0.0287, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0292, Reg Loss = 4.9704, Reconstruct Loss = 0.0007, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0290, Reg Loss = 4.9550, Reconstruct Loss = 0.0006, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0291, Reg Loss = 4.9543, Reconstruct Loss = 0.0006, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Epoch [152/200], Training Loss: 0.0291, Training Accuracy: 99.11, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/200], Validation Loss: 1.0853, Validation Accuracy: 71.92%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0044, Reg Loss = 4.7900, Reconstruct Loss = 0.0000, Cls Loss = 0.0039, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0285, Reg Loss = 4.8777, Reconstruct Loss = 0.0003, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0278, Reg Loss = 4.8952, Reconstruct Loss = 0.0003, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0274, Reg Loss = 4.8857, Reconstruct Loss = 0.0003, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0275, Reg Loss = 4.9033, Reconstruct Loss = 0.0004, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0274, Reg Loss = 4.8952, Reconstruct Loss = 0.0004, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0272, Reg Loss = 4.8976, Reconstruct Loss = 0.0004, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0276, Reg Loss = 4.8926, Reconstruct Loss = 0.0004, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Epoch [153/200], Training Loss: 0.0274, Training Accuracy: 99.18, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/200], Validation Loss: 1.0893, Validation Accuracy: 71.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1877, Reg Loss = 4.6448, Reconstruct Loss = 0.0000, Cls Loss = 0.1873, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0294, Reg Loss = 4.8944, Reconstruct Loss = 0.0006, Cls Loss = 0.0283, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0279, Reg Loss = 4.9045, Reconstruct Loss = 0.0006, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0277, Reg Loss = 4.9128, Reconstruct Loss = 0.0006, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0273, Reg Loss = 4.9142, Reconstruct Loss = 0.0006, Cls Loss = 0.0262, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0270, Reg Loss = 4.9138, Reconstruct Loss = 0.0006, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0278, Reg Loss = 4.9200, Reconstruct Loss = 0.0006, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0277, Reg Loss = 4.9113, Reconstruct Loss = 0.0005, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Epoch [154/200], Training Loss: 0.0275, Training Accuracy: 99.19, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/200], Validation Loss: 1.0915, Validation Accuracy: 71.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0049, Reg Loss = 4.8228, Reconstruct Loss = 0.0000, Cls Loss = 0.0044, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0281, Reg Loss = 4.9026, Reconstruct Loss = 0.0006, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0293, Reg Loss = 4.9191, Reconstruct Loss = 0.0006, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0291, Reg Loss = 4.8963, Reconstruct Loss = 0.0005, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0284, Reg Loss = 4.8917, Reconstruct Loss = 0.0005, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0286, Reg Loss = 4.8972, Reconstruct Loss = 0.0005, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0283, Reg Loss = 4.8840, Reconstruct Loss = 0.0004, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0285, Reg Loss = 4.8764, Reconstruct Loss = 0.0004, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Epoch [155/200], Training Loss: 0.0289, Training Accuracy: 99.14, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [155/200], Validation Loss: 1.0942, Validation Accuracy: 71.55%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0310, Reg Loss = 4.8265, Reconstruct Loss = 0.0000, Cls Loss = 0.0305, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0231, Reg Loss = 4.8795, Reconstruct Loss = 0.0004, Cls Loss = 0.0222, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0267, Reg Loss = 4.9076, Reconstruct Loss = 0.0006, Cls Loss = 0.0257, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0285, Reg Loss = 4.9252, Reconstruct Loss = 0.0006, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0272, Reg Loss = 4.9205, Reconstruct Loss = 0.0006, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0270, Reg Loss = 4.8943, Reconstruct Loss = 0.0005, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0273, Reg Loss = 4.9006, Reconstruct Loss = 0.0005, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0277, Reg Loss = 4.9196, Reconstruct Loss = 0.0006, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Epoch [156/200], Training Loss: 0.0273, Training Accuracy: 99.20, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [156/200], Validation Loss: 1.0921, Validation Accuracy: 71.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0347, Reg Loss = 4.7504, Reconstruct Loss = 0.0000, Cls Loss = 0.0342, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0251, Reg Loss = 4.9171, Reconstruct Loss = 0.0006, Cls Loss = 0.0240, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0257, Reg Loss = 4.8958, Reconstruct Loss = 0.0005, Cls Loss = 0.0247, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0267, Reg Loss = 4.8801, Reconstruct Loss = 0.0004, Cls Loss = 0.0258, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0269, Reg Loss = 4.8670, Reconstruct Loss = 0.0004, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0269, Reg Loss = 4.8741, Reconstruct Loss = 0.0004, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0267, Reg Loss = 4.8737, Reconstruct Loss = 0.0004, Cls Loss = 0.0258, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0270, Reg Loss = 4.8665, Reconstruct Loss = 0.0004, Cls Loss = 0.0262, Learning rate = 1.0000e-05\n",
      "Epoch [157/200], Training Loss: 0.0274, Training Accuracy: 99.15, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/200], Validation Loss: 1.0815, Validation Accuracy: 71.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0579, Reg Loss = 4.7199, Reconstruct Loss = 0.0000, Cls Loss = 0.0575, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0309, Reg Loss = 4.8753, Reconstruct Loss = 0.0006, Cls Loss = 0.0298, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0298, Reg Loss = 4.8605, Reconstruct Loss = 0.0005, Cls Loss = 0.0288, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0290, Reg Loss = 4.8637, Reconstruct Loss = 0.0005, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0278, Reg Loss = 4.8905, Reconstruct Loss = 0.0006, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0287, Reg Loss = 4.8909, Reconstruct Loss = 0.0006, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0287, Reg Loss = 4.8758, Reconstruct Loss = 0.0005, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0285, Reg Loss = 4.8716, Reconstruct Loss = 0.0005, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Epoch [158/200], Training Loss: 0.0289, Training Accuracy: 99.15, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/200], Validation Loss: 1.0700, Validation Accuracy: 71.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0251, Reg Loss = 4.6443, Reconstruct Loss = 0.0000, Cls Loss = 0.0246, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0265, Reg Loss = 4.9212, Reconstruct Loss = 0.0007, Cls Loss = 0.0254, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0268, Reg Loss = 4.9266, Reconstruct Loss = 0.0007, Cls Loss = 0.0256, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0288, Reg Loss = 4.9425, Reconstruct Loss = 0.0008, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0287, Reg Loss = 4.9438, Reconstruct Loss = 0.0008, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0293, Reg Loss = 4.9355, Reconstruct Loss = 0.0008, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0291, Reg Loss = 4.9230, Reconstruct Loss = 0.0007, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0291, Reg Loss = 4.9075, Reconstruct Loss = 0.0007, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Epoch [159/200], Training Loss: 0.0290, Training Accuracy: 99.10, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/200], Validation Loss: 1.0758, Validation Accuracy: 71.75%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0332, Reg Loss = 4.8778, Reconstruct Loss = 0.0000, Cls Loss = 0.0327, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0280, Reg Loss = 4.7885, Reconstruct Loss = 0.0001, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0280, Reg Loss = 4.8555, Reconstruct Loss = 0.0005, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0274, Reg Loss = 4.8534, Reconstruct Loss = 0.0005, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0277, Reg Loss = 4.8665, Reconstruct Loss = 0.0005, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0272, Reg Loss = 4.8605, Reconstruct Loss = 0.0005, Cls Loss = 0.0262, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0273, Reg Loss = 4.8605, Reconstruct Loss = 0.0005, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0272, Reg Loss = 4.8700, Reconstruct Loss = 0.0005, Cls Loss = 0.0262, Learning rate = 1.0000e-05\n",
      "Epoch [160/200], Training Loss: 0.0273, Training Accuracy: 99.19, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/200], Validation Loss: 1.0703, Validation Accuracy: 71.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0113, Reg Loss = 4.8024, Reconstruct Loss = 0.0000, Cls Loss = 0.0108, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0294, Reg Loss = 4.8729, Reconstruct Loss = 0.0006, Cls Loss = 0.0284, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0302, Reg Loss = 4.8307, Reconstruct Loss = 0.0004, Cls Loss = 0.0294, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0293, Reg Loss = 4.8827, Reconstruct Loss = 0.0006, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0290, Reg Loss = 4.8830, Reconstruct Loss = 0.0006, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0287, Reg Loss = 4.8893, Reconstruct Loss = 0.0006, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0283, Reg Loss = 4.8913, Reconstruct Loss = 0.0006, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0281, Reg Loss = 4.8939, Reconstruct Loss = 0.0006, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Epoch [161/200], Training Loss: 0.0278, Training Accuracy: 99.16, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/200], Validation Loss: 1.0838, Validation Accuracy: 71.69%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0555, Reg Loss = 4.8334, Reconstruct Loss = 0.0000, Cls Loss = 0.0550, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0268, Reg Loss = 4.9577, Reconstruct Loss = 0.0010, Cls Loss = 0.0253, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0277, Reg Loss = 4.9441, Reconstruct Loss = 0.0009, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0280, Reg Loss = 4.9059, Reconstruct Loss = 0.0007, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0286, Reg Loss = 4.8741, Reconstruct Loss = 0.0006, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0282, Reg Loss = 4.8825, Reconstruct Loss = 0.0007, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0280, Reg Loss = 4.8946, Reconstruct Loss = 0.0007, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0279, Reg Loss = 4.9122, Reconstruct Loss = 0.0008, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Epoch [162/200], Training Loss: 0.0276, Training Accuracy: 99.19, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/200], Validation Loss: 1.0886, Validation Accuracy: 71.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0109, Reg Loss = 4.6613, Reconstruct Loss = 0.0000, Cls Loss = 0.0105, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0306, Reg Loss = 4.9117, Reconstruct Loss = 0.0008, Cls Loss = 0.0293, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0302, Reg Loss = 4.9091, Reconstruct Loss = 0.0008, Cls Loss = 0.0290, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0303, Reg Loss = 4.9136, Reconstruct Loss = 0.0008, Cls Loss = 0.0290, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0291, Reg Loss = 4.9230, Reconstruct Loss = 0.0008, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0291, Reg Loss = 4.9236, Reconstruct Loss = 0.0008, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0292, Reg Loss = 4.9130, Reconstruct Loss = 0.0008, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0294, Reg Loss = 4.8999, Reconstruct Loss = 0.0007, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Epoch [163/200], Training Loss: 0.0294, Training Accuracy: 99.07, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/200], Validation Loss: 1.0772, Validation Accuracy: 71.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0568, Reg Loss = 4.8643, Reconstruct Loss = 0.0000, Cls Loss = 0.0563, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0268, Reg Loss = 4.8928, Reconstruct Loss = 0.0007, Cls Loss = 0.0256, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0262, Reg Loss = 4.8583, Reconstruct Loss = 0.0006, Cls Loss = 0.0252, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0267, Reg Loss = 4.8374, Reconstruct Loss = 0.0005, Cls Loss = 0.0257, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0272, Reg Loss = 4.8347, Reconstruct Loss = 0.0005, Cls Loss = 0.0262, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0270, Reg Loss = 4.8354, Reconstruct Loss = 0.0004, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0271, Reg Loss = 4.8407, Reconstruct Loss = 0.0005, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0267, Reg Loss = 4.8537, Reconstruct Loss = 0.0006, Cls Loss = 0.0257, Learning rate = 1.0000e-05\n",
      "Epoch [164/200], Training Loss: 0.0272, Training Accuracy: 99.21, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/200], Validation Loss: 1.0761, Validation Accuracy: 71.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0100, Reg Loss = 4.6782, Reconstruct Loss = 0.0000, Cls Loss = 0.0095, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0281, Reg Loss = 4.8057, Reconstruct Loss = 0.0004, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0283, Reg Loss = 4.8260, Reconstruct Loss = 0.0005, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0280, Reg Loss = 4.8368, Reconstruct Loss = 0.0006, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0273, Reg Loss = 4.8373, Reconstruct Loss = 0.0006, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0276, Reg Loss = 4.8468, Reconstruct Loss = 0.0006, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0281, Reg Loss = 4.8267, Reconstruct Loss = 0.0005, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0287, Reg Loss = 4.8239, Reconstruct Loss = 0.0005, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Epoch [165/200], Training Loss: 0.0285, Training Accuracy: 99.12, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/200], Validation Loss: 1.0925, Validation Accuracy: 71.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0436, Reg Loss = 4.6653, Reconstruct Loss = 0.0000, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0271, Reg Loss = 4.8153, Reconstruct Loss = 0.0004, Cls Loss = 0.0262, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0302, Reg Loss = 4.8427, Reconstruct Loss = 0.0006, Cls Loss = 0.0292, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0295, Reg Loss = 4.8500, Reconstruct Loss = 0.0006, Cls Loss = 0.0285, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0283, Reg Loss = 4.8469, Reconstruct Loss = 0.0006, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0284, Reg Loss = 4.8423, Reconstruct Loss = 0.0006, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0289, Reg Loss = 4.8448, Reconstruct Loss = 0.0006, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0286, Reg Loss = 4.8480, Reconstruct Loss = 0.0006, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Epoch [166/200], Training Loss: 0.0288, Training Accuracy: 99.09, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/200], Validation Loss: 1.0930, Validation Accuracy: 71.55%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0082, Reg Loss = 4.6145, Reconstruct Loss = 0.0000, Cls Loss = 0.0078, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0297, Reg Loss = 4.8903, Reconstruct Loss = 0.0008, Cls Loss = 0.0284, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0281, Reg Loss = 4.8590, Reconstruct Loss = 0.0007, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0271, Reg Loss = 4.8167, Reconstruct Loss = 0.0005, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0285, Reg Loss = 4.8096, Reconstruct Loss = 0.0005, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0288, Reg Loss = 4.7877, Reconstruct Loss = 0.0004, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0289, Reg Loss = 4.7819, Reconstruct Loss = 0.0004, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0288, Reg Loss = 4.7886, Reconstruct Loss = 0.0004, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Epoch [167/200], Training Loss: 0.0286, Training Accuracy: 99.12, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/200], Validation Loss: 1.0905, Validation Accuracy: 71.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0048, Reg Loss = 4.5031, Reconstruct Loss = 0.0000, Cls Loss = 0.0044, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0292, Reg Loss = 4.8264, Reconstruct Loss = 0.0007, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0284, Reg Loss = 4.8800, Reconstruct Loss = 0.0009, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0269, Reg Loss = 4.8484, Reconstruct Loss = 0.0007, Cls Loss = 0.0257, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0283, Reg Loss = 4.8676, Reconstruct Loss = 0.0008, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0284, Reg Loss = 4.9023, Reconstruct Loss = 0.0010, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0284, Reg Loss = 4.8836, Reconstruct Loss = 0.0009, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0283, Reg Loss = 4.8707, Reconstruct Loss = 0.0009, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Epoch [168/200], Training Loss: 0.0286, Training Accuracy: 99.16, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [168/200], Validation Loss: 1.0803, Validation Accuracy: 71.62%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1024, Reg Loss = 7.7104, Reconstruct Loss = 0.0140, Cls Loss = 0.0877, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0309, Reg Loss = 4.8884, Reconstruct Loss = 0.0010, Cls Loss = 0.0294, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0287, Reg Loss = 4.8246, Reconstruct Loss = 0.0007, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0289, Reg Loss = 4.8086, Reconstruct Loss = 0.0006, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0286, Reg Loss = 4.8083, Reconstruct Loss = 0.0006, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0287, Reg Loss = 4.7979, Reconstruct Loss = 0.0005, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0286, Reg Loss = 4.8003, Reconstruct Loss = 0.0005, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0291, Reg Loss = 4.7915, Reconstruct Loss = 0.0005, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Epoch [169/200], Training Loss: 0.0291, Training Accuracy: 99.10, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/200], Validation Loss: 1.0778, Validation Accuracy: 71.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0192, Reg Loss = 4.6720, Reconstruct Loss = 0.0000, Cls Loss = 0.0187, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0250, Reg Loss = 4.9420, Reconstruct Loss = 0.0011, Cls Loss = 0.0234, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0258, Reg Loss = 4.8661, Reconstruct Loss = 0.0008, Cls Loss = 0.0246, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0259, Reg Loss = 4.8499, Reconstruct Loss = 0.0007, Cls Loss = 0.0247, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0268, Reg Loss = 4.8625, Reconstruct Loss = 0.0008, Cls Loss = 0.0255, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0279, Reg Loss = 4.8578, Reconstruct Loss = 0.0008, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0274, Reg Loss = 4.8446, Reconstruct Loss = 0.0007, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0275, Reg Loss = 4.8352, Reconstruct Loss = 0.0006, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Epoch [170/200], Training Loss: 0.0278, Training Accuracy: 99.17, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/200], Validation Loss: 1.0779, Validation Accuracy: 71.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0276, Reg Loss = 4.5712, Reconstruct Loss = 0.0000, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0322, Reg Loss = 4.7719, Reconstruct Loss = 0.0003, Cls Loss = 0.0314, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0308, Reg Loss = 4.8271, Reconstruct Loss = 0.0005, Cls Loss = 0.0298, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0301, Reg Loss = 4.8138, Reconstruct Loss = 0.0005, Cls Loss = 0.0292, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0302, Reg Loss = 4.7900, Reconstruct Loss = 0.0004, Cls Loss = 0.0294, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0306, Reg Loss = 4.7979, Reconstruct Loss = 0.0004, Cls Loss = 0.0297, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0303, Reg Loss = 4.8021, Reconstruct Loss = 0.0004, Cls Loss = 0.0294, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0298, Reg Loss = 4.8238, Reconstruct Loss = 0.0005, Cls Loss = 0.0288, Learning rate = 1.0000e-05\n",
      "Epoch [171/200], Training Loss: 0.0299, Training Accuracy: 99.10, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/200], Validation Loss: 1.0746, Validation Accuracy: 71.78%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0315, Reg Loss = 4.8618, Reconstruct Loss = 0.0000, Cls Loss = 0.0310, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0261, Reg Loss = 4.8271, Reconstruct Loss = 0.0006, Cls Loss = 0.0251, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0259, Reg Loss = 4.8151, Reconstruct Loss = 0.0006, Cls Loss = 0.0249, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0265, Reg Loss = 4.8145, Reconstruct Loss = 0.0006, Cls Loss = 0.0255, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0274, Reg Loss = 4.7875, Reconstruct Loss = 0.0004, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0280, Reg Loss = 4.7987, Reconstruct Loss = 0.0005, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0282, Reg Loss = 4.8109, Reconstruct Loss = 0.0005, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0286, Reg Loss = 4.8080, Reconstruct Loss = 0.0005, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Epoch [172/200], Training Loss: 0.0283, Training Accuracy: 99.19, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/200], Validation Loss: 1.0894, Validation Accuracy: 71.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0234, Reg Loss = 4.7537, Reconstruct Loss = 0.0000, Cls Loss = 0.0230, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0283, Reg Loss = 4.9165, Reconstruct Loss = 0.0011, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0267, Reg Loss = 4.9288, Reconstruct Loss = 0.0011, Cls Loss = 0.0250, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0278, Reg Loss = 4.8717, Reconstruct Loss = 0.0008, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0271, Reg Loss = 4.8778, Reconstruct Loss = 0.0008, Cls Loss = 0.0258, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0275, Reg Loss = 4.8839, Reconstruct Loss = 0.0009, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0271, Reg Loss = 4.8719, Reconstruct Loss = 0.0008, Cls Loss = 0.0258, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0270, Reg Loss = 4.8666, Reconstruct Loss = 0.0008, Cls Loss = 0.0257, Learning rate = 1.0000e-05\n",
      "Epoch [173/200], Training Loss: 0.0270, Training Accuracy: 99.20, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/200], Validation Loss: 1.0898, Validation Accuracy: 71.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0210, Reg Loss = 4.8151, Reconstruct Loss = 0.0000, Cls Loss = 0.0205, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0278, Reg Loss = 4.8742, Reconstruct Loss = 0.0008, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0282, Reg Loss = 4.8543, Reconstruct Loss = 0.0007, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0281, Reg Loss = 4.8655, Reconstruct Loss = 0.0007, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0281, Reg Loss = 4.8632, Reconstruct Loss = 0.0007, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0277, Reg Loss = 4.8357, Reconstruct Loss = 0.0006, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0276, Reg Loss = 4.8331, Reconstruct Loss = 0.0006, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0279, Reg Loss = 4.8473, Reconstruct Loss = 0.0007, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Epoch [174/200], Training Loss: 0.0282, Training Accuracy: 99.13, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200], Validation Loss: 1.0888, Validation Accuracy: 71.53%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0243, Reg Loss = 4.5561, Reconstruct Loss = 0.0000, Cls Loss = 0.0239, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0287, Reg Loss = 4.7105, Reconstruct Loss = 0.0001, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0287, Reg Loss = 4.7480, Reconstruct Loss = 0.0003, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0282, Reg Loss = 4.7700, Reconstruct Loss = 0.0004, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0281, Reg Loss = 4.7888, Reconstruct Loss = 0.0005, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0283, Reg Loss = 4.7876, Reconstruct Loss = 0.0004, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0275, Reg Loss = 4.7866, Reconstruct Loss = 0.0004, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0274, Reg Loss = 4.7968, Reconstruct Loss = 0.0005, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Epoch [175/200], Training Loss: 0.0281, Training Accuracy: 99.16, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/200], Validation Loss: 1.0788, Validation Accuracy: 71.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0106, Reg Loss = 4.8234, Reconstruct Loss = 0.0000, Cls Loss = 0.0101, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0249, Reg Loss = 4.7921, Reconstruct Loss = 0.0004, Cls Loss = 0.0240, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0257, Reg Loss = 4.7952, Reconstruct Loss = 0.0005, Cls Loss = 0.0247, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0263, Reg Loss = 4.7851, Reconstruct Loss = 0.0005, Cls Loss = 0.0253, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0267, Reg Loss = 4.7901, Reconstruct Loss = 0.0005, Cls Loss = 0.0258, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0278, Reg Loss = 4.7952, Reconstruct Loss = 0.0005, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0282, Reg Loss = 4.8076, Reconstruct Loss = 0.0006, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0278, Reg Loss = 4.8014, Reconstruct Loss = 0.0005, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Epoch [176/200], Training Loss: 0.0285, Training Accuracy: 99.15, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/200], Validation Loss: 1.0761, Validation Accuracy: 71.56%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0272, Reg Loss = 7.6845, Reconstruct Loss = 0.0140, Cls Loss = 0.0124, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0273, Reg Loss = 4.7777, Reconstruct Loss = 0.0004, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0271, Reg Loss = 4.8397, Reconstruct Loss = 0.0007, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0272, Reg Loss = 4.8345, Reconstruct Loss = 0.0007, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0280, Reg Loss = 4.8138, Reconstruct Loss = 0.0006, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0282, Reg Loss = 4.8064, Reconstruct Loss = 0.0006, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0283, Reg Loss = 4.8090, Reconstruct Loss = 0.0006, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0285, Reg Loss = 4.7986, Reconstruct Loss = 0.0005, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Epoch [177/200], Training Loss: 0.0286, Training Accuracy: 99.15, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/200], Validation Loss: 1.0719, Validation Accuracy: 71.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0263, Reg Loss = 4.5345, Reconstruct Loss = 0.0000, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0267, Reg Loss = 4.9007, Reconstruct Loss = 0.0011, Cls Loss = 0.0251, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0277, Reg Loss = 4.8140, Reconstruct Loss = 0.0007, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0274, Reg Loss = 4.7813, Reconstruct Loss = 0.0006, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0275, Reg Loss = 4.7751, Reconstruct Loss = 0.0005, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0277, Reg Loss = 4.7669, Reconstruct Loss = 0.0005, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0274, Reg Loss = 4.7773, Reconstruct Loss = 0.0005, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0280, Reg Loss = 4.7752, Reconstruct Loss = 0.0005, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Epoch [178/200], Training Loss: 0.0279, Training Accuracy: 99.19, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/200], Validation Loss: 1.0958, Validation Accuracy: 71.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0295, Reg Loss = 4.8602, Reconstruct Loss = 0.0000, Cls Loss = 0.0290, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0264, Reg Loss = 4.7186, Reconstruct Loss = 0.0003, Cls Loss = 0.0256, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0274, Reg Loss = 4.7461, Reconstruct Loss = 0.0004, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0279, Reg Loss = 4.7674, Reconstruct Loss = 0.0005, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0278, Reg Loss = 4.7640, Reconstruct Loss = 0.0005, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0277, Reg Loss = 4.7564, Reconstruct Loss = 0.0004, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0278, Reg Loss = 4.7558, Reconstruct Loss = 0.0004, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0279, Reg Loss = 4.7408, Reconstruct Loss = 0.0004, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Epoch [179/200], Training Loss: 0.0282, Training Accuracy: 99.12, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/200], Validation Loss: 1.0889, Validation Accuracy: 71.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0067, Reg Loss = 4.5931, Reconstruct Loss = 0.0000, Cls Loss = 0.0063, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0280, Reg Loss = 4.6900, Reconstruct Loss = 0.0001, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0290, Reg Loss = 4.6860, Reconstruct Loss = 0.0001, Cls Loss = 0.0284, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0295, Reg Loss = 4.7134, Reconstruct Loss = 0.0002, Cls Loss = 0.0288, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0286, Reg Loss = 4.7427, Reconstruct Loss = 0.0004, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0286, Reg Loss = 4.7280, Reconstruct Loss = 0.0003, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0286, Reg Loss = 4.7406, Reconstruct Loss = 0.0004, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0281, Reg Loss = 4.7372, Reconstruct Loss = 0.0004, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Epoch [180/200], Training Loss: 0.0284, Training Accuracy: 99.15, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/200], Validation Loss: 1.0979, Validation Accuracy: 71.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0506, Reg Loss = 4.6424, Reconstruct Loss = 0.0000, Cls Loss = 0.0502, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0293, Reg Loss = 4.7826, Reconstruct Loss = 0.0006, Cls Loss = 0.0283, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0296, Reg Loss = 4.7489, Reconstruct Loss = 0.0004, Cls Loss = 0.0287, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0299, Reg Loss = 4.7427, Reconstruct Loss = 0.0004, Cls Loss = 0.0290, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0299, Reg Loss = 4.7285, Reconstruct Loss = 0.0004, Cls Loss = 0.0291, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0297, Reg Loss = 4.7353, Reconstruct Loss = 0.0004, Cls Loss = 0.0288, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0295, Reg Loss = 4.7532, Reconstruct Loss = 0.0005, Cls Loss = 0.0286, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0286, Reg Loss = 4.7457, Reconstruct Loss = 0.0005, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Epoch [181/200], Training Loss: 0.0290, Training Accuracy: 99.15, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/200], Validation Loss: 1.1007, Validation Accuracy: 71.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0328, Reg Loss = 4.6436, Reconstruct Loss = 0.0000, Cls Loss = 0.0323, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0270, Reg Loss = 4.7531, Reconstruct Loss = 0.0006, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0265, Reg Loss = 4.7269, Reconstruct Loss = 0.0004, Cls Loss = 0.0256, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0275, Reg Loss = 4.7154, Reconstruct Loss = 0.0004, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0279, Reg Loss = 4.7361, Reconstruct Loss = 0.0005, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0278, Reg Loss = 4.7348, Reconstruct Loss = 0.0004, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0279, Reg Loss = 4.7243, Reconstruct Loss = 0.0004, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0280, Reg Loss = 4.7238, Reconstruct Loss = 0.0004, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Epoch [182/200], Training Loss: 0.0277, Training Accuracy: 99.16, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/200], Validation Loss: 1.1114, Validation Accuracy: 71.24%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0062, Reg Loss = 4.6848, Reconstruct Loss = 0.0000, Cls Loss = 0.0058, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0326, Reg Loss = 4.8451, Reconstruct Loss = 0.0008, Cls Loss = 0.0313, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0296, Reg Loss = 4.8592, Reconstruct Loss = 0.0009, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0296, Reg Loss = 4.8504, Reconstruct Loss = 0.0009, Cls Loss = 0.0283, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0294, Reg Loss = 4.8276, Reconstruct Loss = 0.0008, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0292, Reg Loss = 4.8186, Reconstruct Loss = 0.0007, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0288, Reg Loss = 4.8064, Reconstruct Loss = 0.0007, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0285, Reg Loss = 4.7958, Reconstruct Loss = 0.0007, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Epoch [183/200], Training Loss: 0.0285, Training Accuracy: 99.18, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/200], Validation Loss: 1.1128, Validation Accuracy: 71.22%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0269, Reg Loss = 4.4911, Reconstruct Loss = 0.0000, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0250, Reg Loss = 4.7618, Reconstruct Loss = 0.0005, Cls Loss = 0.0240, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0276, Reg Loss = 4.7574, Reconstruct Loss = 0.0006, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0274, Reg Loss = 4.7340, Reconstruct Loss = 0.0005, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0278, Reg Loss = 4.7171, Reconstruct Loss = 0.0004, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0274, Reg Loss = 4.7118, Reconstruct Loss = 0.0004, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0274, Reg Loss = 4.7152, Reconstruct Loss = 0.0004, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0277, Reg Loss = 4.7197, Reconstruct Loss = 0.0004, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Epoch [184/200], Training Loss: 0.0277, Training Accuracy: 99.17, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/200], Validation Loss: 1.1067, Validation Accuracy: 71.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0325, Reg Loss = 4.7083, Reconstruct Loss = 0.0000, Cls Loss = 0.0321, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0282, Reg Loss = 4.7738, Reconstruct Loss = 0.0007, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0262, Reg Loss = 4.7442, Reconstruct Loss = 0.0006, Cls Loss = 0.0252, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0271, Reg Loss = 4.7326, Reconstruct Loss = 0.0005, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0272, Reg Loss = 4.7578, Reconstruct Loss = 0.0006, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0267, Reg Loss = 4.7792, Reconstruct Loss = 0.0007, Cls Loss = 0.0255, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0271, Reg Loss = 4.7734, Reconstruct Loss = 0.0006, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0269, Reg Loss = 4.7554, Reconstruct Loss = 0.0006, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Epoch [185/200], Training Loss: 0.0271, Training Accuracy: 99.20, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/200], Validation Loss: 1.1094, Validation Accuracy: 71.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0887, Reg Loss = 4.6244, Reconstruct Loss = 0.0000, Cls Loss = 0.0883, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0298, Reg Loss = 4.6798, Reconstruct Loss = 0.0003, Cls Loss = 0.0291, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0287, Reg Loss = 4.6983, Reconstruct Loss = 0.0003, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0297, Reg Loss = 4.7237, Reconstruct Loss = 0.0005, Cls Loss = 0.0287, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0291, Reg Loss = 4.7218, Reconstruct Loss = 0.0005, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0289, Reg Loss = 4.7215, Reconstruct Loss = 0.0004, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0286, Reg Loss = 4.7207, Reconstruct Loss = 0.0004, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0282, Reg Loss = 4.7148, Reconstruct Loss = 0.0004, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Epoch [186/200], Training Loss: 0.0285, Training Accuracy: 99.20, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/200], Validation Loss: 1.1067, Validation Accuracy: 71.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0089, Reg Loss = 4.7838, Reconstruct Loss = 0.0000, Cls Loss = 0.0085, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0266, Reg Loss = 4.7748, Reconstruct Loss = 0.0007, Cls Loss = 0.0254, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0268, Reg Loss = 4.7549, Reconstruct Loss = 0.0006, Cls Loss = 0.0258, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0264, Reg Loss = 4.7309, Reconstruct Loss = 0.0005, Cls Loss = 0.0254, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0269, Reg Loss = 4.7135, Reconstruct Loss = 0.0004, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0273, Reg Loss = 4.7372, Reconstruct Loss = 0.0005, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0277, Reg Loss = 4.7367, Reconstruct Loss = 0.0005, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0277, Reg Loss = 4.7429, Reconstruct Loss = 0.0005, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Epoch [187/200], Training Loss: 0.0277, Training Accuracy: 99.16, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/200], Validation Loss: 1.1086, Validation Accuracy: 71.17%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0625, Reg Loss = 4.7242, Reconstruct Loss = 0.0000, Cls Loss = 0.0620, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0275, Reg Loss = 4.7143, Reconstruct Loss = 0.0004, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0282, Reg Loss = 4.8433, Reconstruct Loss = 0.0010, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0287, Reg Loss = 4.8309, Reconstruct Loss = 0.0010, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0286, Reg Loss = 4.8292, Reconstruct Loss = 0.0010, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0284, Reg Loss = 4.8118, Reconstruct Loss = 0.0009, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0277, Reg Loss = 4.7996, Reconstruct Loss = 0.0008, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0274, Reg Loss = 4.7927, Reconstruct Loss = 0.0008, Cls Loss = 0.0261, Learning rate = 1.0000e-05\n",
      "Epoch [188/200], Training Loss: 0.0272, Training Accuracy: 99.21, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/200], Validation Loss: 1.1137, Validation Accuracy: 71.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0471, Reg Loss = 4.5478, Reconstruct Loss = 0.0000, Cls Loss = 0.0466, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0270, Reg Loss = 4.7483, Reconstruct Loss = 0.0006, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0282, Reg Loss = 4.7387, Reconstruct Loss = 0.0006, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0287, Reg Loss = 4.7399, Reconstruct Loss = 0.0006, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0285, Reg Loss = 4.7166, Reconstruct Loss = 0.0005, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0284, Reg Loss = 4.7314, Reconstruct Loss = 0.0005, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0287, Reg Loss = 4.7299, Reconstruct Loss = 0.0005, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0285, Reg Loss = 4.7430, Reconstruct Loss = 0.0006, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Epoch [189/200], Training Loss: 0.0293, Training Accuracy: 99.14, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/200], Validation Loss: 1.1124, Validation Accuracy: 71.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0558, Reg Loss = 7.6751, Reconstruct Loss = 0.0139, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0303, Reg Loss = 4.7301, Reconstruct Loss = 0.0006, Cls Loss = 0.0292, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0290, Reg Loss = 4.7193, Reconstruct Loss = 0.0005, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0294, Reg Loss = 4.7214, Reconstruct Loss = 0.0005, Cls Loss = 0.0284, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0296, Reg Loss = 4.7404, Reconstruct Loss = 0.0006, Cls Loss = 0.0285, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0288, Reg Loss = 4.7523, Reconstruct Loss = 0.0006, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0290, Reg Loss = 4.7663, Reconstruct Loss = 0.0007, Cls Loss = 0.0279, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0286, Reg Loss = 4.7693, Reconstruct Loss = 0.0007, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Epoch [190/200], Training Loss: 0.0283, Training Accuracy: 99.20, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/200], Validation Loss: 1.1171, Validation Accuracy: 71.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0189, Reg Loss = 4.6073, Reconstruct Loss = 0.0000, Cls Loss = 0.0185, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0290, Reg Loss = 4.7311, Reconstruct Loss = 0.0006, Cls Loss = 0.0280, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0289, Reg Loss = 4.7849, Reconstruct Loss = 0.0008, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0298, Reg Loss = 4.7801, Reconstruct Loss = 0.0007, Cls Loss = 0.0286, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0285, Reg Loss = 4.7582, Reconstruct Loss = 0.0007, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0281, Reg Loss = 4.7474, Reconstruct Loss = 0.0006, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0275, Reg Loss = 4.7378, Reconstruct Loss = 0.0006, Cls Loss = 0.0265, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0275, Reg Loss = 4.7436, Reconstruct Loss = 0.0006, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Epoch [191/200], Training Loss: 0.0274, Training Accuracy: 99.19, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/200], Validation Loss: 1.1168, Validation Accuracy: 71.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0085, Reg Loss = 4.6649, Reconstruct Loss = 0.0000, Cls Loss = 0.0080, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0255, Reg Loss = 4.8230, Reconstruct Loss = 0.0010, Cls Loss = 0.0241, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0254, Reg Loss = 4.8134, Reconstruct Loss = 0.0009, Cls Loss = 0.0240, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0259, Reg Loss = 4.8037, Reconstruct Loss = 0.0009, Cls Loss = 0.0246, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0260, Reg Loss = 4.7665, Reconstruct Loss = 0.0007, Cls Loss = 0.0248, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0261, Reg Loss = 4.7576, Reconstruct Loss = 0.0007, Cls Loss = 0.0249, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0268, Reg Loss = 4.7506, Reconstruct Loss = 0.0006, Cls Loss = 0.0257, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0271, Reg Loss = 4.7543, Reconstruct Loss = 0.0007, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Epoch [192/200], Training Loss: 0.0271, Training Accuracy: 99.20, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/200], Validation Loss: 1.1142, Validation Accuracy: 71.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0379, Reg Loss = 4.7092, Reconstruct Loss = 0.0000, Cls Loss = 0.0374, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0284, Reg Loss = 4.7778, Reconstruct Loss = 0.0008, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0269, Reg Loss = 4.7235, Reconstruct Loss = 0.0006, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0270, Reg Loss = 4.7122, Reconstruct Loss = 0.0005, Cls Loss = 0.0260, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0269, Reg Loss = 4.7085, Reconstruct Loss = 0.0005, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0274, Reg Loss = 4.7049, Reconstruct Loss = 0.0005, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0276, Reg Loss = 4.7053, Reconstruct Loss = 0.0005, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0272, Reg Loss = 4.7040, Reconstruct Loss = 0.0005, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Epoch [193/200], Training Loss: 0.0273, Training Accuracy: 99.21, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/200], Validation Loss: 1.1184, Validation Accuracy: 71.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0048, Reg Loss = 4.7937, Reconstruct Loss = 0.0000, Cls Loss = 0.0043, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0258, Reg Loss = 4.6887, Reconstruct Loss = 0.0004, Cls Loss = 0.0249, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0288, Reg Loss = 4.7178, Reconstruct Loss = 0.0006, Cls Loss = 0.0278, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0276, Reg Loss = 4.7145, Reconstruct Loss = 0.0006, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0274, Reg Loss = 4.7116, Reconstruct Loss = 0.0006, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0279, Reg Loss = 4.7176, Reconstruct Loss = 0.0006, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0281, Reg Loss = 4.7102, Reconstruct Loss = 0.0006, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0285, Reg Loss = 4.7172, Reconstruct Loss = 0.0006, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Epoch [194/200], Training Loss: 0.0288, Training Accuracy: 99.13, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/200], Validation Loss: 1.1181, Validation Accuracy: 71.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0223, Reg Loss = 4.4452, Reconstruct Loss = 0.0000, Cls Loss = 0.0218, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0268, Reg Loss = 4.8255, Reconstruct Loss = 0.0011, Cls Loss = 0.0252, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0275, Reg Loss = 4.7389, Reconstruct Loss = 0.0007, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0275, Reg Loss = 4.7349, Reconstruct Loss = 0.0007, Cls Loss = 0.0263, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0280, Reg Loss = 4.7316, Reconstruct Loss = 0.0007, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0280, Reg Loss = 4.7347, Reconstruct Loss = 0.0007, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0279, Reg Loss = 4.7374, Reconstruct Loss = 0.0007, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0280, Reg Loss = 4.7377, Reconstruct Loss = 0.0008, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Epoch [195/200], Training Loss: 0.0279, Training Accuracy: 99.17, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [195/200], Validation Loss: 1.1168, Validation Accuracy: 71.11%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0133, Reg Loss = 4.6434, Reconstruct Loss = 0.0000, Cls Loss = 0.0128, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0285, Reg Loss = 4.7258, Reconstruct Loss = 0.0007, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0272, Reg Loss = 4.6439, Reconstruct Loss = 0.0003, Cls Loss = 0.0264, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0276, Reg Loss = 4.6607, Reconstruct Loss = 0.0004, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0285, Reg Loss = 4.6553, Reconstruct Loss = 0.0004, Cls Loss = 0.0276, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0283, Reg Loss = 4.6700, Reconstruct Loss = 0.0004, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0279, Reg Loss = 4.6772, Reconstruct Loss = 0.0005, Cls Loss = 0.0270, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0283, Reg Loss = 4.6753, Reconstruct Loss = 0.0005, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Epoch [196/200], Training Loss: 0.0282, Training Accuracy: 99.16, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/200], Validation Loss: 1.1162, Validation Accuracy: 71.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0241, Reg Loss = 4.5232, Reconstruct Loss = 0.0000, Cls Loss = 0.0237, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0280, Reg Loss = 4.5987, Reconstruct Loss = 0.0001, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0265, Reg Loss = 4.6320, Reconstruct Loss = 0.0003, Cls Loss = 0.0258, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0275, Reg Loss = 4.6663, Reconstruct Loss = 0.0004, Cls Loss = 0.0266, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0284, Reg Loss = 4.6659, Reconstruct Loss = 0.0004, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0284, Reg Loss = 4.6804, Reconstruct Loss = 0.0005, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0277, Reg Loss = 4.6876, Reconstruct Loss = 0.0005, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0278, Reg Loss = 4.6918, Reconstruct Loss = 0.0005, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Epoch [197/200], Training Loss: 0.0281, Training Accuracy: 99.18, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [197/200], Validation Loss: 1.1083, Validation Accuracy: 71.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0275, Reg Loss = 4.4506, Reconstruct Loss = 0.0000, Cls Loss = 0.0271, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0267, Reg Loss = 4.6859, Reconstruct Loss = 0.0006, Cls Loss = 0.0257, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0268, Reg Loss = 4.6803, Reconstruct Loss = 0.0005, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0274, Reg Loss = 4.6393, Reconstruct Loss = 0.0003, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0271, Reg Loss = 4.6487, Reconstruct Loss = 0.0003, Cls Loss = 0.0262, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0278, Reg Loss = 4.6723, Reconstruct Loss = 0.0004, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0277, Reg Loss = 4.6971, Reconstruct Loss = 0.0006, Cls Loss = 0.0267, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0279, Reg Loss = 4.6840, Reconstruct Loss = 0.0005, Cls Loss = 0.0269, Learning rate = 1.0000e-05\n",
      "Epoch [198/200], Training Loss: 0.0278, Training Accuracy: 99.11, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [198/200], Validation Loss: 1.1270, Validation Accuracy: 71.03%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0124, Reg Loss = 4.3972, Reconstruct Loss = 0.0000, Cls Loss = 0.0120, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0294, Reg Loss = 4.6039, Reconstruct Loss = 0.0003, Cls Loss = 0.0287, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0293, Reg Loss = 4.6080, Reconstruct Loss = 0.0002, Cls Loss = 0.0286, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0291, Reg Loss = 4.6234, Reconstruct Loss = 0.0003, Cls Loss = 0.0284, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0286, Reg Loss = 4.6647, Reconstruct Loss = 0.0004, Cls Loss = 0.0277, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0278, Reg Loss = 4.6658, Reconstruct Loss = 0.0005, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0278, Reg Loss = 4.6780, Reconstruct Loss = 0.0005, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0278, Reg Loss = 4.6823, Reconstruct Loss = 0.0006, Cls Loss = 0.0268, Learning rate = 1.0000e-05\n",
      "Epoch [199/200], Training Loss: 0.0280, Training Accuracy: 99.16, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/200], Validation Loss: 1.1339, Validation Accuracy: 71.04%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0088, Reg Loss = 4.3829, Reconstruct Loss = 0.0000, Cls Loss = 0.0083, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0262, Reg Loss = 4.6066, Reconstruct Loss = 0.0003, Cls Loss = 0.0254, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0269, Reg Loss = 4.6729, Reconstruct Loss = 0.0006, Cls Loss = 0.0259, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0291, Reg Loss = 4.6431, Reconstruct Loss = 0.0004, Cls Loss = 0.0282, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0284, Reg Loss = 4.6692, Reconstruct Loss = 0.0005, Cls Loss = 0.0274, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0290, Reg Loss = 4.6693, Reconstruct Loss = 0.0005, Cls Loss = 0.0281, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0285, Reg Loss = 4.6732, Reconstruct Loss = 0.0005, Cls Loss = 0.0275, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0283, Reg Loss = 4.6709, Reconstruct Loss = 0.0005, Cls Loss = 0.0273, Learning rate = 1.0000e-05\n",
      "Epoch [200/200], Training Loss: 0.0285, Training Accuracy: 99.19, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/200], Validation Loss: 1.1214, Validation Accuracy: 71.09%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the epochs\n",
    "for epoch in range(start_epoch, args.experiment.num_epochs):\n",
    "    # Train the hypernetwork to generate a model with random dimension for one epoch\n",
    "    train_loss, dim_dict, gt_model_dict, train_acc = train_one_epoch(hyper_model, train_loader, optimizer, criterion, \n",
    "                                                                     dim_dict, gt_model_dict, epoch_idx=epoch, ema=ema, \n",
    "                                                                     args=args, device=device)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the training loss and learning rate\n",
    "    print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc*100:.2f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # If it's time to evaluate the model\n",
    "    if (epoch + 1) % args.experiment.eval_interval == 0:\n",
    "        # Apply EMA if it is specified\n",
    "        if ema:\n",
    "            ema.apply()  # Save the weights of original model created before training_loop\n",
    "        \n",
    "        # Sample the merged model (create model of same structure before training loop by using the hypernetwork)\n",
    "        # And then test the performance of the hypernetwork by seeing how good it is in generating the weights\n",
    "        model = sample_merge_model(hyper_model, model, args) \n",
    "        # Validate the merged model\n",
    "        val_loss, acc = validate_single(model, val_loader, val_criterion, args=args)\n",
    "\n",
    "        # If EMA is specified, restore the original weights\n",
    "        if ema:\n",
    "            ema.restore()  # Restore the original weights to the weights of the pretrained networks\n",
    "\n",
    "        # Log the validation loss and accuracy to wandb\n",
    "        wandb.log({\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": acc\n",
    "        })\n",
    "        # Print the validation loss and accuracy\n",
    "        print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Save the checkpoint if the accuracy is better than the previous best\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_checkpoint(f\"{args.training.save_model_path}/cifar10_nerf_best.pth\",hyper_model,optimizer,ema,epoch,best_acc)\n",
    "            print(f\"Checkpoint saved at epoch {epoch} with accuracy: {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31152508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>█▅▂▃▃▂▃▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Learning rate</td><td>████████████████████▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss</td><td>█▇▇▇▅▅▅▅▅▅▅▅▅▅▄▄▄▄▅▄▄▄▃▄▃▄▄▄▄▁▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Reconstruct Loss</td><td>█▃▅▅█▅▄▅▃▃▅▃▃▂▂▂▂▇▆▇▄▅▅▄▆▄▃▂▂▂▂▄▅▄▂▃▂▇▄▁</td></tr><tr><td>Reg Loss</td><td>▅▄▆▆▇█▇▇▇▇▇▇▇▆▇▇██▇██▇▄▄▄▃▃▃▃▃▂▂▁▂▁▂▁▁▁▁</td></tr><tr><td>Training accuracy</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>Validation Accuracy</td><td>▂▅▅▆▇█▇▇█▇▆██▇▇▇▆▄▄▃▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Loss</td><td>▆█▄▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>0.02726</td></tr><tr><td>Learning rate</td><td>1e-05</td></tr><tr><td>Loss</td><td>0.02826</td></tr><tr><td>Reconstruct Loss</td><td>0.00053</td></tr><tr><td>Reg Loss</td><td>4.67095</td></tr><tr><td>Training accuracy</td><td>0.99186</td></tr><tr><td>Validation Accuracy</td><td>0.7109</td></tr><tr><td>Validation Loss</td><td>1.12144</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20250530033434-dense_19th_experiment</strong> at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/hmzl3cee' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/hmzl3cee</a><br> View project at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250530_033435-hmzl3cee\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e92a8",
   "metadata": {},
   "source": [
    "### 7 Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ac18d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_hypernet_path = args.training.save_model_path + '/cifar10_nerf_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1aa0d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy/experiments_densenet/dense_19th_experiment/cifar10_nerf_best.pth'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_hypernet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d59b8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "hyper_model_test = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4d3b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(saved_hypernet_path, map_location=\"cpu\")  # or \"cuda\" if using GPU\n",
    "hyper_model_test.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a834964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 12, Validation Loss: 4.2957, Validation Accuracy: 53.38%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 13, Validation Loss: 5.5226, Validation Accuracy: 40.51%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 14, Validation Loss: 1.7488, Validation Accuracy: 73.54%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 15, Validation Loss: 1.3791, Validation Accuracy: 78.77%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 16, Validation Loss: 1.8519, Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 17, Validation Loss: 1.3467, Validation Accuracy: 74.52%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 18, Validation Loss: 1.4937, Validation Accuracy: 75.75%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 19, Validation Loss: 1.6343, Validation Accuracy: 72.31%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 20, Validation Loss: 0.9487, Validation Accuracy: 79.32%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 21, Validation Loss: 2.1155, Validation Accuracy: 66.77%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 22, Validation Loss: 0.9420, Validation Accuracy: 78.96%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 23, Validation Loss: 1.1450, Validation Accuracy: 77.04%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 24, Validation Loss: 0.7353, Validation Accuracy: 83.44%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 25, Validation Loss: 1.0181, Validation Accuracy: 79.55%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 26, Validation Loss: 0.7817, Validation Accuracy: 82.54%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 27, Validation Loss: 0.8584, Validation Accuracy: 81.64%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 28, Validation Loss: 0.8285, Validation Accuracy: 81.23%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 29, Validation Loss: 0.5881, Validation Accuracy: 85.68%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 30, Validation Loss: 0.7931, Validation Accuracy: 82.05%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 31, Validation Loss: 0.5385, Validation Accuracy: 86.29%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 32, Validation Loss: 0.6625, Validation Accuracy: 84.65%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 33, Validation Loss: 0.7662, Validation Accuracy: 82.83%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 34, Validation Loss: 0.8084, Validation Accuracy: 81.91%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 35, Validation Loss: 0.8235, Validation Accuracy: 81.86%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 36, Validation Loss: 0.8270, Validation Accuracy: 81.76%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 37, Validation Loss: 0.5866, Validation Accuracy: 85.41%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 38, Validation Loss: 0.8782, Validation Accuracy: 81.02%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 39, Validation Loss: 0.6535, Validation Accuracy: 84.43%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 40, Validation Loss: 0.7520, Validation Accuracy: 83.49%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 41, Validation Loss: 0.5861, Validation Accuracy: 85.55%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 42, Validation Loss: 0.8003, Validation Accuracy: 82.36%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 43, Validation Loss: 0.6174, Validation Accuracy: 84.94%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 44, Validation Loss: 0.4129, Validation Accuracy: 88.92%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 45, Validation Loss: 0.5587, Validation Accuracy: 85.87%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 46, Validation Loss: 0.5434, Validation Accuracy: 86.28%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 47, Validation Loss: 0.6768, Validation Accuracy: 84.26%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 48, Validation Loss: 0.4631, Validation Accuracy: 87.17%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in range(12, 49):\n",
    "    # Create a model for this given dimension\n",
    "    model_trained = create_model(args.model.type,\n",
    "                                 layers=args.model.layers,\n",
    "                                 growth=args.model.growth,\n",
    "                                 compression=args.model.compression,\n",
    "                                 bottleneck=args.model.bottleneck,\n",
    "                                 drop_rate=args.model.drop_rate,\n",
    "                                 path=args.model.pretrained_path,\n",
    "                                 hidden_dim=hidden_dim).to(device)\n",
    "    \n",
    "    # If EMA is specified, apply it\n",
    "    if ema:\n",
    "        print('Applying EMA')\n",
    "        ema.apply()\n",
    "\n",
    "    # Sample the merged model\n",
    "    accumulated_model = sample_merge_model(hyper_model_test, model_trained, args, K=100)\n",
    "\n",
    "    # Validate the merged model\n",
    "    val_loss, acc = validate_single(accumulated_model, val_loader, val_criterion, args=args)\n",
    "\n",
    "    # If EMA is specified, restore the original weights after applying EMA\n",
    "    if ema:\n",
    "        ema.restore()  # Restore the original weights after applying \n",
    "        \n",
    "    # Save the model\n",
    "    save_name = os.path.join(args.training.save_model_path, f\"cifar10_{accumulated_model.__class__.__name__}_dim{hidden_dim}_single.pth\")\n",
    "    torch.save(accumulated_model.state_dict(),save_name)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test using model {args.model}: hidden_dim {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Define the directory and filename structure\n",
    "    filename = f\"cifar10_results_{args.experiment.name}.txt\"\n",
    "    filepath = os.path.join(args.training.save_model_path, filename)\n",
    "\n",
    "    # Write the results. 'a' is used to append the results; a new file will be created if it doesn't exist.\n",
    "    with open(filepath, \"a\") as file:\n",
    "        file.write(f\"Hidden_dim: {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
