{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93dc2c6f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6360918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df94f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9add1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_densenet_model as create_model\n",
    "from neumeta.utils import (\n",
    "    parse_args, print_omegaconf,\n",
    "    load_checkpoint, save_checkpoint,\n",
    "    set_seed,\n",
    "    get_dataset,\n",
    "    sample_coordinates, sample_subset, shuffle_coordinates_all,\n",
    "    get_hypernetwork, get_optimizer,\n",
    "    sample_weights,\n",
    "    weighted_regression_loss, validate_single, AverageMeter, EMA,\n",
    "    sample_merge_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3531f8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df3637",
   "metadata": {},
   "source": [
    "### Find max dimension of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dim(model_cls):\n",
    "    \"\"\"Find maximum dimension of the model\"\"\"\n",
    "    # Get the learnable parameters of the model\n",
    "    checkpoint = model_cls.learnable_parameter \n",
    "\n",
    "    # Set the maximum value to the length of the checkpoint\n",
    "    max_value = len(checkpoint)\n",
    "\n",
    "    # Iterate over the new model's weight\n",
    "    for i, (k, tensor) in enumerate(checkpoint.items()):\n",
    "        # Handle 2D tensors (e.g., weight matrices) \n",
    "        if len(tensor.shape) == 4:\n",
    "            coords = [tensor.shape[0], tensor.shape[1]]\n",
    "            max_value = max(max_value, max(coords))\n",
    "        # Handle 1D tensors (e.g., biases)\n",
    "        elif len(tensor.shape) == 1:\n",
    "            max_value = max(max_value, tensor.shape[0])\n",
    "    \n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c098c",
   "metadata": {},
   "source": [
    "### Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e70c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(config):\n",
    "    import time\n",
    "    \"\"\"\n",
    "    Initializes Weights and Biases (wandb) with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        configuration (dict): Configuration parameters for the run.\n",
    "    \"\"\"\n",
    "    # Name the run using current time and configuration name\n",
    "    run_name = f\"{time.strftime('%Y%m%d%H%M%S')}-{config.experiment.name}\"\n",
    "    \n",
    "    wandb.init(project=\"dense-inr-trial\", name=run_name, config=dict(config), group='cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0bc703",
   "metadata": {},
   "source": [
    "### Init model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319a2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(args, device):\n",
    "    \"\"\"\n",
    "    Initializes a dictionary of models for each dimension in the given range, along with ground truth models for the starting dimension.\n",
    "\n",
    "    Args:\n",
    "        args: An object containing the arguments for initializing the models.\n",
    "\n",
    "    Returns:\n",
    "        dim_dict: A dictionary containing the models for each dimension, along with their corresponding coordinates, keys, indices, size, and ground truth models.\n",
    "        gt_model_dict: A dictionary containing the ground truth models for the starting dimension.\n",
    "    \"\"\"\n",
    "    dim_dict = {}\n",
    "    gt_model_dict = {}\n",
    "    \n",
    "    # Create a model for each dimension in dimensions range\n",
    "    for dim in args.dimensions.range:\n",
    "        model_cls = create_model(args.model.type,\n",
    "                                 layers=args.model.layers,\n",
    "                                 growth=args.model.growth,\n",
    "                                 compression=args.model.compression,\n",
    "                                 bottleneck=args.model.bottleneck,\n",
    "                                 drop_rate=args.model.drop_rate,\n",
    "                                 hidden_dim=dim,\n",
    "                                 path=args.model.pretrained_path).to(device)\n",
    "        # Sample the coordinates, keys, indices, and the size for the model\n",
    "        coords_tensor, keys_list, indices_list, size_list = sample_coordinates(model_cls)\n",
    "        # Add the model, coordinates, keys, indices, size, and key mask to the dictionary\n",
    "        dim_dict[f\"{dim}\"] = (model_cls, coords_tensor, keys_list, indices_list, size_list, None)\n",
    "\n",
    "        # Print to makes line better\n",
    "        print('\\n')\n",
    "        \n",
    "        # If the dimension is the starting dimension (the dimension of pretrained_model), add the ground truth model to the dictionary\n",
    "        if dim == args.dimensions.start:\n",
    "            print(f\"Loading model for dim {dim}\")\n",
    "            model_trained = create_model(args.model.type,\n",
    "                                         layers=args.model.layers,\n",
    "                                         growth=args.model.growth,\n",
    "                                         compression=args.model.compression,\n",
    "                                         bottleneck=args.model.bottleneck,\n",
    "                                         drop_rate=args.model.drop_rate,\n",
    "                                         path=args.model.pretrained_path,\n",
    "                                         smooth=True,\n",
    "                                         hidden_dim=dim).to(device)\n",
    "            model_trained.eval()\n",
    "            gt_model_dict[f'{dim}'] = model_trained\n",
    "\n",
    "    \n",
    "    return dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93b863",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde4cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, dim_dict, gt_model_dict, epoch_idx, ema=None, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    reconstruct_losses = AverageMeter()\n",
    "\n",
    "    # Training accuracy\n",
    "    preds = []\n",
    "    gt = []\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Preprocess input\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Move the data to the device\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # Choose a random hidden dimension\n",
    "        hidden_dim = random.choice(args.dimensions.range)\n",
    "        # Get the model class, coordinates, keys, indices, size, and key mask for the chosen dimension\n",
    "        model_cls, coords_tensor, keys_list, indices_list, size_list, key_mask = dim_dict[f\"{hidden_dim}\"]\n",
    "        # Sample a subset the input tensor of the coordinates, keys, indices, size, and selected keys\n",
    "        coords_tensor, keys_list, indices_list, size_list, selected_keys = sample_subset(coords_tensor,\n",
    "                                                                                         keys_list,\n",
    "                                                                                         indices_list,\n",
    "                                                                                         size_list,\n",
    "                                                                                         key_mask,\n",
    "                                                                                         ratio=args.ratio)\n",
    "        # Add noise to the coordinates if specified\n",
    "        if args.training.coordinate_noise > 0.0:\n",
    "            coords_tensor = coords_tensor + (torch.rand_like(coords_tensor) - 0.5) * args.training.coordinate_noise\n",
    "\n",
    "\n",
    "        # Main task of hypernetwork and target network\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Sample the weights for the target model using hypernetwork\n",
    "        model_cls, reconstructed_weights = sample_weights(model, model_cls,\n",
    "                                                          coords_tensor, keys_list, indices_list, size_list, key_mask, selected_keys,\n",
    "                                                          device=device, NORM=args.dimensions.norm)\n",
    "        # Forward pass\n",
    "        predict = model_cls(x)\n",
    "        \n",
    "        # Sample test model to see training accuracy\n",
    "\n",
    "        pred = torch.argmax(predict, dim=-1)\n",
    "\n",
    "        preds.append(pred)\n",
    "        gt.append(target)\n",
    "\n",
    "        # Compute losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Compute classification loss\n",
    "        cls_loss = criterion(predict, target) \n",
    "        # Compute regularization loss\n",
    "        reg_loss = sum([torch.norm(w, p=2) for w in reconstructed_weights])\n",
    "        # Compute reconstruction loss if ground truth model is available\n",
    "        if f\"{hidden_dim}\" in gt_model_dict:\n",
    "            gt_model = gt_model_dict[f\"{hidden_dim}\"]\n",
    "            gt_selected_weights = [\n",
    "                w for k, w in gt_model.learnable_parameter.items() if k in selected_keys]\n",
    "\n",
    "            reconstruct_loss = weighted_regression_loss(\n",
    "                reconstructed_weights, gt_selected_weights)\n",
    "        else:\n",
    "            reconstruct_loss = torch.tensor(0.0)\n",
    "        # Compute the total loss\n",
    "        loss = args.hyper_model.loss_weight.ce_weight * cls_loss + args.hyper_model.loss_weight.reg_weight * \\\n",
    "            reg_loss + args.hyper_model.loss_weight.recon_weight * reconstruct_loss\n",
    "\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Zero the gradients of the updated weights\n",
    "        for updated_weight in model_cls.parameters():\n",
    "            updated_weight.grad = None\n",
    "\n",
    "        # Compute the gradients of the reconstructed weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.autograd.backward(reconstructed_weights, [\n",
    "                                w.grad for k, w in model_cls.named_parameters() if k in selected_keys])\n",
    "        \n",
    "        # Clip the gradients if specified\n",
    "        if args.training.get('clip_grad', 0.0) > 0:\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), args.training.clip_grad)\n",
    "            \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA if specified\n",
    "        if ema:\n",
    "            ema.update()  # Update the EMA after each training step\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update the AverageMeter objects\n",
    "        losses.update(loss.item())\n",
    "        cls_losses.update(cls_loss.item())\n",
    "        reg_losses.update(reg_loss.item())\n",
    "        reconstruct_losses.update(reconstruct_loss.item())\n",
    "\n",
    "        # Log (or plot) losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Log the losses and learning rate to wandb\n",
    "        if batch_idx % args.experiment.log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"Loss\": losses.avg,\n",
    "                \"Cls Loss\": cls_losses.avg,\n",
    "                \"Reg Loss\": reg_losses.avg,\n",
    "                \"Reconstruct Loss\": reconstruct_losses.avg,\n",
    "                \"Learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }, step=batch_idx + epoch_idx * len(train_loader))\n",
    "            # Print the losses and learning rate\n",
    "            print(\n",
    "                f\"Iteration {batch_idx}: Loss = {losses.avg:.4f}, Reg Loss = {reg_losses.avg:.4f}, Reconstruct Loss = {reconstruct_losses.avg:.4f}, Cls Loss = {cls_losses.avg:.4f}, Learning rate = {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "    \n",
    "    train_acc = accuracy_score(torch.cat(gt).cpu().numpy(), torch.cat(preds).cpu().numpy())\n",
    "\n",
    "    wandb.log({\n",
    "        \"Training accuracy\": train_acc\n",
    "    })\n",
    "\n",
    "    # Returns the training loss, structure of network in each dimension, and the original structure of pretrained network\n",
    "    return losses.avg, dim_dict, gt_model_dict, train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb560cd",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041282c",
   "metadata": {},
   "source": [
    "### 0 Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bcf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6df804",
   "metadata": {},
   "source": [
    "### 1 Parsing arguments for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5570d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = 'neumeta/config/densenet_inr_train/dense_20th_experiment.yaml'\n",
    "RATIO = '1.0'\n",
    "CHECKPOINT_PATH = 'toy/experiments_densenet/dense_20th_experiment/cifar10_nerf_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92954510",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv_train = ['--config', CONFIG_PATH, '--ratio', RATIO, '--resume_from', CHECKPOINT_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1867bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------------------------------------------------------------------------------------------------------+\n",
      "|                 Key                  |                                                Value                                                 |\n",
      "+--------------------------------------+------------------------------------------------------------------------------------------------------+\n",
      "|           experiment.name            |                                        dense_20th_experiment                                         |\n",
      "|        experiment.num_epochs         |                                                 200                                                  |\n",
      "|       experiment.log_interval        |                                                 100                                                  |\n",
      "|       experiment.eval_interval       |                                                  1                                                   |\n",
      "|           experiment.seed            |                                                  42                                                  |\n",
      "|              model.type              |                                               DenseNet                                               |\n",
      "|        model.pretrained_path         |        toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth        |\n",
      "|             model.layers             |                                                  40                                                  |\n",
      "|             model.growth             |                                                  12                                                  |\n",
      "|          model.compression           |                                                 0.5                                                  |\n",
      "|           model.bottleneck           |                                                 True                                                 |\n",
      "|           model.drop_rate            |                                                 0.0                                                  |\n",
      "|           training.dataset           |                                               cifar10                                                |\n",
      "|         training.batch_size          |                                                  64                                                  |\n",
      "|      training.coordinate_noise       |                                                 1.0                                                  |\n",
      "|        training.learning_rate        |                                                0.001                                                 |\n",
      "|          training.lr_steps           |                                              [100, 150]                                              |\n",
      "|          training.optimizer          |                                                adamw                                                 |\n",
      "|        training.weight_decay         |                                                 0.01                                                 |\n",
      "|          training.clip_grad          |                                                 10.0                                                 |\n",
      "|       training.save_model_path       |                            toy/experiments_densenet/dense_20th_experiment                            |\n",
      "|           hyper_model.type           |                                                resmlp                                                |\n",
      "|        hyper_model.input_dim         |                                                  6                                                   |\n",
      "|        hyper_model.hidden_dim        |                                                 256                                                  |\n",
      "|        hyper_model.num_layers        |                                                  5                                                   |\n",
      "|        hyper_model.num_freqs         |                                                  16                                                  |\n",
      "|        hyper_model.output_dim        |                                                  9                                                   |\n",
      "|        hyper_model.ema_decay         |                                                0.995                                                 |\n",
      "|  hyper_model.loss_weight.ce_weight   |                                                 1.0                                                  |\n",
      "|  hyper_model.loss_weight.reg_weight  |                                                0.0001                                                |\n",
      "| hyper_model.loss_weight.recon_weight |                                                 1.0                                                  |\n",
      "|  hyper_model.loss_weight.kd_weight   |                                                 0.1                                                  |\n",
      "|           dimensions.range           | [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] |\n",
      "|           dimensions.test            |                                                  24                                                  |\n",
      "|           dimensions.norm            |                                                 120                                                  |\n",
      "|           dimensions.start           |                                                  48                                                  |\n",
      "|                config                |                     neumeta/config/densenet_inr_train/dense_20th_experiment.yaml                     |\n",
      "|                ratio                 |                                                 1.0                                                  |\n",
      "|             resume_from              |                 toy/experiments_densenet/dense_20th_experiment/cifar10_nerf_best.pth                 |\n",
      "|              load_from               |                                                 None                                                 |\n",
      "|           test_result_path           |                                                 None                                                 |\n",
      "|                 test                 |                                                False                                                 |\n",
      "+--------------------------------------+------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(argv_train)  # Parse arguments\n",
    "print_omegaconf(args)  # Print arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d63002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed... 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.experiment.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1941f5",
   "metadata": {},
   "source": [
    "### 2 Get training and validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1732d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: cifar10 with batch size: 64 and strong transform: None\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_dataset('cifar10', args.training.batch_size, strong_transform=args.training.get('strong_aug', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1754c36",
   "metadata": {},
   "source": [
    "### 3 Create target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f26b5",
   "metadata": {},
   "source": [
    "#### 3.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bde19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args.model.type,\n",
    "                     layers=args.model.layers,\n",
    "                     growth=args.model.growth,\n",
    "                     compression=args.model.compression,\n",
    "                     bottleneck=args.model.bottleneck,\n",
    "                     drop_rate=args.model.drop_rate,\n",
    "                     hidden_dim=args.dimensions.start,\n",
    "                     path=args.model.pretrained_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f2944",
   "metadata": {},
   "source": [
    "#### 3.1 Print the structure and shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2d72666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet3(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block2): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block3): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68fc0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block3.layer.5.conv1.weight torch.Size([48, 120, 1, 1])\n",
      "block3.layer.5.conv1.bias torch.Size([48])\n",
      "block3.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for i, (k, tensor) in enumerate(model.learnable_parameter.items()):\n",
    "    print(k, tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a708ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum DIM: 120\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum dimension of the model\n",
    "print(f'Maximum DIM: {find_max_dim(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9451adb",
   "metadata": {},
   "source": [
    "#### 3.2 Validate the accuracy of pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cca4d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.3239, Validation Accuracy: 91.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(model, val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d526b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = model.learnable_parameter\n",
    "number_param = len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1a8b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters keys: ['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.bias', 'block3.layer.5.conv2.weight']\n",
      "Number of parameters to be learned: 3\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the parameters and the number of parameters\n",
    "print(f\"Parameters keys: {model.keys}\")\n",
    "print(f\"Number of parameters to be learned: {number_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a522bbe",
   "metadata": {},
   "source": [
    "### 4 Create hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17279a4b",
   "metadata": {},
   "source": [
    "#### 4.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6041a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Get the hypermodel\n",
    "hyper_model = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9ba74",
   "metadata": {},
   "source": [
    "#### 4.1 Print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cd60865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_ResMLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-2): 3 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e2cdf",
   "metadata": {},
   "source": [
    "#### 4.2 Initialize EMA to track only a smooth version of the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afb25ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA\n",
    "ema = EMA(hyper_model, decay=args.hyper_model.ema_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccb913",
   "metadata": {},
   "source": [
    "### 5 Get loss function, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "308f44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, val_criterion, optimizer, scheduler = get_optimizer(args, hyper_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45181795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Val_criterion: CrossEntropyLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x00000247CF35DB10>\n"
     ]
    }
   ],
   "source": [
    "print(f'Criterion: {criterion}\\nVal_criterion: {val_criterion}\\nOptimizer: {optimizer}\\nScheduler: {scheduler}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991ee56",
   "metadata": {},
   "source": [
    "### 6 Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81099a8",
   "metadata": {},
   "source": [
    "#### 6.1 Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "731bcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting epoch and best accuracy\n",
    "start_epoch = 0\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b1a8f",
   "metadata": {},
   "source": [
    "#### 6.2 Directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91995285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the model\n",
    "os.makedirs(args.training.save_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1632f",
   "metadata": {},
   "source": [
    "#### 6.3 Resume training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cae570b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy/experiments_densenet/dense_20th_experiment/cifar10_nerf_best.pth'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.resume_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf17e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume_from = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55b68075",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_from:\n",
    "        print(f\"Resuming from checkpoint: {args.resume_from}\")\n",
    "        checkpoint_info = load_checkpoint(args.resume_from, hyper_model, optimizer, ema)\n",
    "        start_epoch = checkpoint_info['epoch']\n",
    "        best_acc = checkpoint_info['best_acc']\n",
    "        print(f\"Resuming from epoch: {start_epoch}, best accuracy: {best_acc*100:.2f}%\")\n",
    "        # Note: If there are more elements to retrieve, do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024e53f",
   "metadata": {},
   "source": [
    "#### 6.4 Initialize model dictionary for each dimension and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3558b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "\n",
      "\n",
      "Loading model for dim 48\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 428.7051086425781\n",
      "Permuted TV original model: 394.97869873046875\n"
     ]
    }
   ],
   "source": [
    "# Initialize model dictionary\n",
    "dim_dict, gt_model_dict = init_model_dict(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4566bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet3(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block2): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block3): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_model_dict['48']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c64f7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.3239, Validation Accuracy: 91.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(gt_model_dict['48'], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8981361b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'24': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  24., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  21.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  22.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  24.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 21,  3,  3],\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '25': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 25, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(25, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  25., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  22.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  25.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '26': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 26, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(26, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  26., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  23.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  26.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '27': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 27, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(27, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  27., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  24.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  27.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '28': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(28, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  28., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  25.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  28.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '29': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 29, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(29, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  29., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  26.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  29.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '30': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  30., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  27.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  30.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '31': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 31, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(31, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  31., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  28.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  31.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '32': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  32., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  29.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  32.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '33': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 33, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(33, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  33., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  30.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  33.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '34': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(34, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  34., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  31.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  34.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '35': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 35, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(35, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  35., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  32.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  35.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '36': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  36., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  33.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  36.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '37': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 37, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(37, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  37., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  34.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  37.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '38': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(38, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  38., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  35.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  38.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '39': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 39, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(39, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  39., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  36.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  39.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '40': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(40, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  40., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  37.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  40.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '41': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(41, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  41., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  38.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  41.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '42': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(42, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  42., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  39.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  42.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '43': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 43, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(43, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  43., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  40.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  43.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '44': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(44, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  44., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  41.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  44.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '45': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 45, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(45, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  45., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  42.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  45.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '46': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 46, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(46, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  46., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  43.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  46.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '47': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 47, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(47, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  47., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  44.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  47.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None),\n",
       " '48': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  48., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  45.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  47.,   3.,  12.,  48.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3],\n",
       "          [11, 47,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  None)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b93cb60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'24': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  24., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  24., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  21.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  22.,   3.,  12.,  24.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  24.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 21,  3,  3],\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '25': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 25, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(25, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  25., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  25., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  22.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  23.,   3.,  12.,  25.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  25.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 22,  3,  3],\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '26': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 26, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(26, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  26., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  26., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  23.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  24.,   3.,  12.,  26.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  26.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 23,  3,  3],\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '27': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 27, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(27, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  27., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  27., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  24.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  25.,   3.,  12.,  27.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  27.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 24,  3,  3],\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '28': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(28, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  28., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  28., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  25.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  26.,   3.,  12.,  28.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  28.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 25,  3,  3],\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '29': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 29, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(29, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  29., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  29., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  26.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  27.,   3.,  12.,  29.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  29.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 26,  3,  3],\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '30': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  30., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  30., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  27.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  28.,   3.,  12.,  30.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  30.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 27,  3,  3],\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '31': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 31, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(31, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  31., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  31., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  28.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  29.,   3.,  12.,  31.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  31.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 28,  3,  3],\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '32': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  32., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  32., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  29.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  30.,   3.,  12.,  32.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  32.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 29,  3,  3],\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '33': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 33, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(33, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  33., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  33., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  30.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  31.,   3.,  12.,  33.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  33.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 30,  3,  3],\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '34': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(34, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  34., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  34., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  31.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  32.,   3.,  12.,  34.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  34.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 31,  3,  3],\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '35': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 35, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(35, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  35., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  35., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  32.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  33.,   3.,  12.,  35.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  35.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 32,  3,  3],\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '36': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  36., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  36., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  33.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  34.,   3.,  12.,  36.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  36.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 33,  3,  3],\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '37': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 37, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(37, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  37., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  37., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  34.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  35.,   3.,  12.,  37.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  37.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 34,  3,  3],\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '38': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(38, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  38., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  38., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  35.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  36.,   3.,  12.,  38.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  38.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 35,  3,  3],\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '39': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 39, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(39, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  39., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  39., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  36.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  37.,   3.,  12.,  39.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  39.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 36,  3,  3],\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '40': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(40, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  40., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  40., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  37.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  38.,   3.,  12.,  40.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  40.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 37,  3,  3],\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '41': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 41, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(41, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  41., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  41., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  38.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  39.,   3.,  12.,  41.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  41.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 38,  3,  3],\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '42': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(42, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  42., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  42., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  39.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  40.,   3.,  12.,  42.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  42.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 39,  3,  3],\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '43': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 43, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(43, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  43., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  43., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  40.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  41.,   3.,  12.,  43.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  43.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 40,  3,  3],\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '44': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(44, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  44., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  44., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  41.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  42.,   3.,  12.,  44.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  44.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 41,  3,  3],\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '45': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 45, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(45, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  45., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  45., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  42.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  43.,   3.,  12.,  45.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  45.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 42,  3,  3],\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '46': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 46, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(46, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  46., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  46., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  43.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  44.,   3.,  12.,  46.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  46.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 43,  3,  3],\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '47': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 47, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(47, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  47., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  47., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  44.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  45.,   3.,  12.,  47.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  47.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 44,  3,  3],\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])}),\n",
       " '48': (DenseNet3(\n",
       "    (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (block1): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans1): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block2): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans2): TransitionBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (block3): DenseBlock(\n",
       "      (layer): Sequential(\n",
       "        (0): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): BottleneckBlock(\n",
       "          (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): Identity()\n",
       "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[  0.,   0.,   0.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   1.,   3.,  48., 120.],\n",
       "          [  0.,   0.,   2.,   3.,  48., 120.],\n",
       "          ...,\n",
       "          [  2.,  11.,  45.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  46.,   3.,  12.,  48.],\n",
       "          [  2.,  11.,  47.,   3.,  12.,  48.]]),\n",
       "  array(['block3.layer.5.conv1.weight', 'block3.layer.5.conv1.weight',\n",
       "         'block3.layer.5.conv1.weight', ..., 'block3.layer.5.conv2.weight',\n",
       "         'block3.layer.5.conv2.weight', 'block3.layer.5.conv2.weight'],\n",
       "        dtype='<U27'),\n",
       "  tensor([[ 0,  0,  1,  1],\n",
       "          [ 0,  1,  1,  1],\n",
       "          [ 0,  2,  1,  1],\n",
       "          ...,\n",
       "          [11, 45,  3,  3],\n",
       "          [11, 46,  3,  3],\n",
       "          [11, 47,  3,  3]]),\n",
       "  tensor([4, 4, 4,  ..., 4, 4, 4]),\n",
       "  {np.str_('block3.layer.5.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('block3.layer.5.conv2.weight'): tensor([0, 0, 0,  ..., 1, 1, 1])})}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict = shuffle_coordinates_all(dim_dict)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a20088d",
   "metadata": {},
   "source": [
    "#### 6.5 Initialize wandb for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "044696ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mefradosuryadi\u001b[0m (\u001b[33mefradosuryadi-universitas-indonesia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\wandb\\run-20250530_111918-m32hvkdp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/m32hvkdp' target=\"_blank\">20250530111917-dense_20th_experiment</a></strong> to <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/m32hvkdp' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/m32hvkdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialize_wandb(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f2004",
   "metadata": {},
   "source": [
    "#### 6.6 Hypernetwork training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b78a21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.experiment.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0b94e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.2212, Reg Loss = 1.8081, Reconstruct Loss = 0.0000, Cls Loss = 0.2210, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2320, Reg Loss = 5.3794, Reconstruct Loss = 0.0025, Cls Loss = 0.2289, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2251, Reg Loss = 5.7428, Reconstruct Loss = 0.0032, Cls Loss = 0.2213, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2251, Reg Loss = 5.7656, Reconstruct Loss = 0.0025, Cls Loss = 0.2220, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2216, Reg Loss = 5.8781, Reconstruct Loss = 0.0019, Cls Loss = 0.2191, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2195, Reg Loss = 6.0365, Reconstruct Loss = 0.0020, Cls Loss = 0.2169, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2189, Reg Loss = 6.1396, Reconstruct Loss = 0.0017, Cls Loss = 0.2165, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2187, Reg Loss = 6.2300, Reconstruct Loss = 0.0018, Cls Loss = 0.2162, Learning rate = 1.0000e-03\n",
      "Epoch [1/200], Training Loss: 0.2176, Training Accuracy: 93.53, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Validation Loss: 1.4051, Validation Accuracy: 64.69%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 0 with accuracy: 64.69%\n",
      "Iteration 0: Loss = 0.1859, Reg Loss = 5.4495, Reconstruct Loss = 0.0000, Cls Loss = 0.1854, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.2188, Reg Loss = 6.1999, Reconstruct Loss = 0.0039, Cls Loss = 0.2143, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.2126, Reg Loss = 5.6175, Reconstruct Loss = 0.0028, Cls Loss = 0.2093, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2122, Reg Loss = 5.4885, Reconstruct Loss = 0.0026, Cls Loss = 0.2091, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.2087, Reg Loss = 5.2801, Reconstruct Loss = 0.0024, Cls Loss = 0.2057, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.2094, Reg Loss = 5.1176, Reconstruct Loss = 0.0023, Cls Loss = 0.2065, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.2085, Reg Loss = 4.9994, Reconstruct Loss = 0.0022, Cls Loss = 0.2058, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.2071, Reg Loss = 4.9201, Reconstruct Loss = 0.0021, Cls Loss = 0.2044, Learning rate = 1.0000e-03\n",
      "Epoch [2/200], Training Loss: 0.2054, Training Accuracy: 93.80, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Validation Loss: 1.1566, Validation Accuracy: 68.61%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 1 with accuracy: 68.61%\n",
      "Iteration 0: Loss = 0.2196, Reg Loss = 4.0030, Reconstruct Loss = 0.0000, Cls Loss = 0.2192, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1999, Reg Loss = 4.7001, Reconstruct Loss = 0.0012, Cls Loss = 0.1983, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1997, Reg Loss = 4.6985, Reconstruct Loss = 0.0015, Cls Loss = 0.1978, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.2005, Reg Loss = 4.7895, Reconstruct Loss = 0.0017, Cls Loss = 0.1983, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1987, Reg Loss = 4.8176, Reconstruct Loss = 0.0020, Cls Loss = 0.1962, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1963, Reg Loss = 4.8210, Reconstruct Loss = 0.0017, Cls Loss = 0.1941, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1956, Reg Loss = 4.8090, Reconstruct Loss = 0.0020, Cls Loss = 0.1932, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1957, Reg Loss = 4.8050, Reconstruct Loss = 0.0019, Cls Loss = 0.1934, Learning rate = 1.0000e-03\n",
      "Epoch [3/200], Training Loss: 0.1961, Training Accuracy: 93.86, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Validation Loss: 0.9362, Validation Accuracy: 74.94%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 2 with accuracy: 74.94%\n",
      "Iteration 0: Loss = 0.2141, Reg Loss = 4.7045, Reconstruct Loss = 0.0000, Cls Loss = 0.2136, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1935, Reg Loss = 4.9780, Reconstruct Loss = 0.0012, Cls Loss = 0.1918, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1931, Reg Loss = 5.0319, Reconstruct Loss = 0.0015, Cls Loss = 0.1911, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1901, Reg Loss = 5.0081, Reconstruct Loss = 0.0014, Cls Loss = 0.1882, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1894, Reg Loss = 5.0325, Reconstruct Loss = 0.0015, Cls Loss = 0.1875, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1893, Reg Loss = 5.0243, Reconstruct Loss = 0.0014, Cls Loss = 0.1873, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1889, Reg Loss = 5.0340, Reconstruct Loss = 0.0015, Cls Loss = 0.1869, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1888, Reg Loss = 5.0789, Reconstruct Loss = 0.0014, Cls Loss = 0.1869, Learning rate = 1.0000e-03\n",
      "Epoch [4/200], Training Loss: 0.1886, Training Accuracy: 94.06, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Validation Loss: 0.9180, Validation Accuracy: 72.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1605, Reg Loss = 5.0190, Reconstruct Loss = 0.0000, Cls Loss = 0.1600, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1794, Reg Loss = 5.4953, Reconstruct Loss = 0.0017, Cls Loss = 0.1772, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1800, Reg Loss = 5.3685, Reconstruct Loss = 0.0017, Cls Loss = 0.1778, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1811, Reg Loss = 5.4108, Reconstruct Loss = 0.0014, Cls Loss = 0.1792, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1834, Reg Loss = 5.4371, Reconstruct Loss = 0.0015, Cls Loss = 0.1813, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1824, Reg Loss = 5.4328, Reconstruct Loss = 0.0013, Cls Loss = 0.1806, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1828, Reg Loss = 5.4248, Reconstruct Loss = 0.0013, Cls Loss = 0.1810, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1817, Reg Loss = 5.4420, Reconstruct Loss = 0.0011, Cls Loss = 0.1800, Learning rate = 1.0000e-03\n",
      "Epoch [5/200], Training Loss: 0.1823, Training Accuracy: 94.38, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Validation Loss: 1.2094, Validation Accuracy: 64.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1820, Reg Loss = 5.4102, Reconstruct Loss = 0.0000, Cls Loss = 0.1815, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1787, Reg Loss = 5.5448, Reconstruct Loss = 0.0015, Cls Loss = 0.1766, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1715, Reg Loss = 5.6507, Reconstruct Loss = 0.0016, Cls Loss = 0.1694, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1764, Reg Loss = 5.6215, Reconstruct Loss = 0.0018, Cls Loss = 0.1740, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1761, Reg Loss = 5.5813, Reconstruct Loss = 0.0017, Cls Loss = 0.1738, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1762, Reg Loss = 5.5927, Reconstruct Loss = 0.0017, Cls Loss = 0.1740, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1749, Reg Loss = 5.6238, Reconstruct Loss = 0.0015, Cls Loss = 0.1728, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1748, Reg Loss = 5.6679, Reconstruct Loss = 0.0014, Cls Loss = 0.1728, Learning rate = 1.0000e-03\n",
      "Epoch [6/200], Training Loss: 0.1748, Training Accuracy: 94.60, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Validation Loss: 4.3123, Validation Accuracy: 45.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2266, Reg Loss = 5.4581, Reconstruct Loss = 0.0000, Cls Loss = 0.2260, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1615, Reg Loss = 6.5408, Reconstruct Loss = 0.0003, Cls Loss = 0.1606, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1612, Reg Loss = 6.6010, Reconstruct Loss = 0.0009, Cls Loss = 0.1596, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1628, Reg Loss = 6.5415, Reconstruct Loss = 0.0011, Cls Loss = 0.1610, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1628, Reg Loss = 6.5749, Reconstruct Loss = 0.0012, Cls Loss = 0.1610, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1610, Reg Loss = 6.5919, Reconstruct Loss = 0.0011, Cls Loss = 0.1592, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1594, Reg Loss = 6.6128, Reconstruct Loss = 0.0013, Cls Loss = 0.1574, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1580, Reg Loss = 6.6702, Reconstruct Loss = 0.0013, Cls Loss = 0.1560, Learning rate = 1.0000e-03\n",
      "Epoch [7/200], Training Loss: 0.1574, Training Accuracy: 95.16, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Validation Loss: 11.9626, Validation Accuracy: 18.57%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1986, Reg Loss = 7.5856, Reconstruct Loss = 0.0000, Cls Loss = 0.1978, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1433, Reg Loss = 7.2119, Reconstruct Loss = 0.0014, Cls Loss = 0.1411, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1416, Reg Loss = 7.2212, Reconstruct Loss = 0.0017, Cls Loss = 0.1392, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1434, Reg Loss = 7.2359, Reconstruct Loss = 0.0017, Cls Loss = 0.1409, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1438, Reg Loss = 7.2240, Reconstruct Loss = 0.0018, Cls Loss = 0.1413, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1430, Reg Loss = 7.1888, Reconstruct Loss = 0.0016, Cls Loss = 0.1407, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1420, Reg Loss = 7.1907, Reconstruct Loss = 0.0015, Cls Loss = 0.1398, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1420, Reg Loss = 7.1848, Reconstruct Loss = 0.0015, Cls Loss = 0.1398, Learning rate = 1.0000e-03\n",
      "Epoch [8/200], Training Loss: 0.1413, Training Accuracy: 95.62, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Validation Loss: 10.1814, Validation Accuracy: 19.98%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0946, Reg Loss = 6.7377, Reconstruct Loss = 0.0000, Cls Loss = 0.0939, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1273, Reg Loss = 7.3280, Reconstruct Loss = 0.0022, Cls Loss = 0.1244, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1328, Reg Loss = 7.3761, Reconstruct Loss = 0.0016, Cls Loss = 0.1305, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1333, Reg Loss = 7.3869, Reconstruct Loss = 0.0015, Cls Loss = 0.1311, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1344, Reg Loss = 7.2924, Reconstruct Loss = 0.0016, Cls Loss = 0.1321, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1335, Reg Loss = 7.2556, Reconstruct Loss = 0.0015, Cls Loss = 0.1313, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1329, Reg Loss = 7.3268, Reconstruct Loss = 0.0016, Cls Loss = 0.1305, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1319, Reg Loss = 7.3463, Reconstruct Loss = 0.0016, Cls Loss = 0.1296, Learning rate = 1.0000e-03\n",
      "Epoch [9/200], Training Loss: 0.1324, Training Accuracy: 95.92, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Validation Loss: 15.3054, Validation Accuracy: 22.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1680, Reg Loss = 7.3035, Reconstruct Loss = 0.0332, Cls Loss = 0.1342, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1277, Reg Loss = 7.5171, Reconstruct Loss = 0.0014, Cls Loss = 0.1256, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1249, Reg Loss = 7.6636, Reconstruct Loss = 0.0012, Cls Loss = 0.1229, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1263, Reg Loss = 7.8008, Reconstruct Loss = 0.0016, Cls Loss = 0.1239, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1287, Reg Loss = 7.7909, Reconstruct Loss = 0.0017, Cls Loss = 0.1262, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1274, Reg Loss = 7.8864, Reconstruct Loss = 0.0014, Cls Loss = 0.1252, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1283, Reg Loss = 7.9392, Reconstruct Loss = 0.0016, Cls Loss = 0.1259, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1282, Reg Loss = 7.9562, Reconstruct Loss = 0.0016, Cls Loss = 0.1257, Learning rate = 1.0000e-03\n",
      "Epoch [10/200], Training Loss: 0.1278, Training Accuracy: 95.92, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Validation Loss: 18.3760, Validation Accuracy: 19.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2063, Reg Loss = 8.1310, Reconstruct Loss = 0.0000, Cls Loss = 0.2055, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1192, Reg Loss = 8.3204, Reconstruct Loss = 0.0008, Cls Loss = 0.1176, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1204, Reg Loss = 8.3272, Reconstruct Loss = 0.0009, Cls Loss = 0.1187, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1195, Reg Loss = 8.2819, Reconstruct Loss = 0.0012, Cls Loss = 0.1175, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1199, Reg Loss = 8.2657, Reconstruct Loss = 0.0014, Cls Loss = 0.1176, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1203, Reg Loss = 8.2566, Reconstruct Loss = 0.0013, Cls Loss = 0.1181, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1204, Reg Loss = 8.2834, Reconstruct Loss = 0.0013, Cls Loss = 0.1183, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1213, Reg Loss = 8.2653, Reconstruct Loss = 0.0013, Cls Loss = 0.1192, Learning rate = 1.0000e-03\n",
      "Epoch [11/200], Training Loss: 0.1212, Training Accuracy: 96.29, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Validation Loss: 10.2589, Validation Accuracy: 27.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0599, Reg Loss = 7.2223, Reconstruct Loss = 0.0000, Cls Loss = 0.0592, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1227, Reg Loss = 8.5199, Reconstruct Loss = 0.0033, Cls Loss = 0.1186, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1181, Reg Loss = 8.4282, Reconstruct Loss = 0.0019, Cls Loss = 0.1154, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1162, Reg Loss = 8.2807, Reconstruct Loss = 0.0019, Cls Loss = 0.1135, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1147, Reg Loss = 8.3458, Reconstruct Loss = 0.0016, Cls Loss = 0.1122, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1144, Reg Loss = 8.4225, Reconstruct Loss = 0.0016, Cls Loss = 0.1120, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1137, Reg Loss = 8.4267, Reconstruct Loss = 0.0016, Cls Loss = 0.1113, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1132, Reg Loss = 8.4250, Reconstruct Loss = 0.0015, Cls Loss = 0.1109, Learning rate = 1.0000e-03\n",
      "Epoch [12/200], Training Loss: 0.1122, Training Accuracy: 96.58, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Validation Loss: 9.0315, Validation Accuracy: 32.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1031, Reg Loss = 8.4004, Reconstruct Loss = 0.0000, Cls Loss = 0.1023, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1095, Reg Loss = 8.8526, Reconstruct Loss = 0.0016, Cls Loss = 0.1070, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1101, Reg Loss = 8.8541, Reconstruct Loss = 0.0020, Cls Loss = 0.1072, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1061, Reg Loss = 8.8502, Reconstruct Loss = 0.0020, Cls Loss = 0.1032, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.1049, Reg Loss = 8.8501, Reconstruct Loss = 0.0020, Cls Loss = 0.1021, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.1037, Reg Loss = 8.8553, Reconstruct Loss = 0.0019, Cls Loss = 0.1009, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.1039, Reg Loss = 8.9423, Reconstruct Loss = 0.0018, Cls Loss = 0.1012, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.1037, Reg Loss = 8.9770, Reconstruct Loss = 0.0017, Cls Loss = 0.1011, Learning rate = 1.0000e-03\n",
      "Epoch [13/200], Training Loss: 0.1035, Training Accuracy: 96.83, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Validation Loss: 29.7474, Validation Accuracy: 13.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0636, Reg Loss = 9.1846, Reconstruct Loss = 0.0000, Cls Loss = 0.0626, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1001, Reg Loss = 8.6669, Reconstruct Loss = 0.0010, Cls Loss = 0.0982, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1010, Reg Loss = 9.1060, Reconstruct Loss = 0.0007, Cls Loss = 0.0994, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0991, Reg Loss = 9.3177, Reconstruct Loss = 0.0007, Cls Loss = 0.0974, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0994, Reg Loss = 9.4065, Reconstruct Loss = 0.0009, Cls Loss = 0.0976, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0981, Reg Loss = 9.3756, Reconstruct Loss = 0.0008, Cls Loss = 0.0964, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0988, Reg Loss = 9.4077, Reconstruct Loss = 0.0007, Cls Loss = 0.0972, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0985, Reg Loss = 9.4552, Reconstruct Loss = 0.0008, Cls Loss = 0.0968, Learning rate = 1.0000e-03\n",
      "Epoch [14/200], Training Loss: 0.0986, Training Accuracy: 96.93, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Validation Loss: 16.4051, Validation Accuracy: 23.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1240, Reg Loss = 9.0090, Reconstruct Loss = 0.0000, Cls Loss = 0.1231, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.1048, Reg Loss = 9.6654, Reconstruct Loss = 0.0016, Cls Loss = 0.1022, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.1018, Reg Loss = 9.5617, Reconstruct Loss = 0.0013, Cls Loss = 0.0996, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.1011, Reg Loss = 9.5504, Reconstruct Loss = 0.0012, Cls Loss = 0.0989, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0977, Reg Loss = 9.6288, Reconstruct Loss = 0.0011, Cls Loss = 0.0956, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0983, Reg Loss = 9.6322, Reconstruct Loss = 0.0012, Cls Loss = 0.0962, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0969, Reg Loss = 9.6164, Reconstruct Loss = 0.0011, Cls Loss = 0.0948, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0970, Reg Loss = 9.5837, Reconstruct Loss = 0.0011, Cls Loss = 0.0950, Learning rate = 1.0000e-03\n",
      "Epoch [15/200], Training Loss: 0.0960, Training Accuracy: 97.15, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Validation Loss: 18.3268, Validation Accuracy: 21.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1084, Reg Loss = 9.2596, Reconstruct Loss = 0.0000, Cls Loss = 0.1074, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0975, Reg Loss = 9.5970, Reconstruct Loss = 0.0007, Cls Loss = 0.0958, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0978, Reg Loss = 9.5092, Reconstruct Loss = 0.0010, Cls Loss = 0.0959, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0970, Reg Loss = 9.5714, Reconstruct Loss = 0.0011, Cls Loss = 0.0950, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0963, Reg Loss = 9.5429, Reconstruct Loss = 0.0011, Cls Loss = 0.0943, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0966, Reg Loss = 9.5769, Reconstruct Loss = 0.0010, Cls Loss = 0.0946, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0968, Reg Loss = 9.5746, Reconstruct Loss = 0.0010, Cls Loss = 0.0948, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0965, Reg Loss = 9.5863, Reconstruct Loss = 0.0010, Cls Loss = 0.0945, Learning rate = 1.0000e-03\n",
      "Epoch [16/200], Training Loss: 0.0960, Training Accuracy: 97.13, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Validation Loss: 18.0691, Validation Accuracy: 21.71%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0574, Reg Loss = 9.5749, Reconstruct Loss = 0.0000, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0975, Reg Loss = 9.7675, Reconstruct Loss = 0.0012, Cls Loss = 0.0953, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0949, Reg Loss = 9.7348, Reconstruct Loss = 0.0014, Cls Loss = 0.0926, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0927, Reg Loss = 9.7691, Reconstruct Loss = 0.0012, Cls Loss = 0.0905, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0925, Reg Loss = 9.7361, Reconstruct Loss = 0.0011, Cls Loss = 0.0904, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0936, Reg Loss = 9.6846, Reconstruct Loss = 0.0011, Cls Loss = 0.0915, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0935, Reg Loss = 9.6431, Reconstruct Loss = 0.0010, Cls Loss = 0.0915, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0939, Reg Loss = 9.6388, Reconstruct Loss = 0.0009, Cls Loss = 0.0919, Learning rate = 1.0000e-03\n",
      "Epoch [17/200], Training Loss: 0.0947, Training Accuracy: 97.08, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200], Validation Loss: 13.6691, Validation Accuracy: 28.18%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0608, Reg Loss = 10.0187, Reconstruct Loss = 0.0000, Cls Loss = 0.0598, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0910, Reg Loss = 10.0533, Reconstruct Loss = 0.0009, Cls Loss = 0.0891, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0973, Reg Loss = 9.8694, Reconstruct Loss = 0.0011, Cls Loss = 0.0952, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0952, Reg Loss = 9.7921, Reconstruct Loss = 0.0009, Cls Loss = 0.0933, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0936, Reg Loss = 9.7909, Reconstruct Loss = 0.0010, Cls Loss = 0.0916, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0922, Reg Loss = 9.8650, Reconstruct Loss = 0.0010, Cls Loss = 0.0902, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0917, Reg Loss = 9.8803, Reconstruct Loss = 0.0010, Cls Loss = 0.0898, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0916, Reg Loss = 9.8673, Reconstruct Loss = 0.0010, Cls Loss = 0.0896, Learning rate = 1.0000e-03\n",
      "Epoch [18/200], Training Loss: 0.0916, Training Accuracy: 97.23, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200], Validation Loss: 12.9640, Validation Accuracy: 29.83%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0531, Reg Loss = 9.7766, Reconstruct Loss = 0.0000, Cls Loss = 0.0521, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0932, Reg Loss = 9.5336, Reconstruct Loss = 0.0012, Cls Loss = 0.0910, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0937, Reg Loss = 9.6629, Reconstruct Loss = 0.0014, Cls Loss = 0.0913, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0923, Reg Loss = 9.7214, Reconstruct Loss = 0.0012, Cls Loss = 0.0901, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0924, Reg Loss = 9.7506, Reconstruct Loss = 0.0011, Cls Loss = 0.0903, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0922, Reg Loss = 9.7311, Reconstruct Loss = 0.0009, Cls Loss = 0.0903, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0933, Reg Loss = 9.7676, Reconstruct Loss = 0.0010, Cls Loss = 0.0913, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0929, Reg Loss = 9.8056, Reconstruct Loss = 0.0010, Cls Loss = 0.0910, Learning rate = 1.0000e-03\n",
      "Epoch [19/200], Training Loss: 0.0931, Training Accuracy: 97.11, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Validation Loss: 22.3980, Validation Accuracy: 22.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0806, Reg Loss = 10.4675, Reconstruct Loss = 0.0000, Cls Loss = 0.0796, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0931, Reg Loss = 9.8943, Reconstruct Loss = 0.0015, Cls Loss = 0.0905, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0941, Reg Loss = 9.8722, Reconstruct Loss = 0.0011, Cls Loss = 0.0919, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0932, Reg Loss = 9.9580, Reconstruct Loss = 0.0011, Cls Loss = 0.0912, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0909, Reg Loss = 10.0242, Reconstruct Loss = 0.0008, Cls Loss = 0.0890, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0911, Reg Loss = 10.0361, Reconstruct Loss = 0.0008, Cls Loss = 0.0893, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0905, Reg Loss = 10.0408, Reconstruct Loss = 0.0008, Cls Loss = 0.0888, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0899, Reg Loss = 10.0132, Reconstruct Loss = 0.0007, Cls Loss = 0.0881, Learning rate = 1.0000e-03\n",
      "Epoch [20/200], Training Loss: 0.0902, Training Accuracy: 97.30, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Validation Loss: 12.8475, Validation Accuracy: 32.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0914, Reg Loss = 10.4205, Reconstruct Loss = 0.0000, Cls Loss = 0.0903, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0836, Reg Loss = 10.0891, Reconstruct Loss = 0.0008, Cls Loss = 0.0818, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0886, Reg Loss = 9.9978, Reconstruct Loss = 0.0009, Cls Loss = 0.0867, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0883, Reg Loss = 10.0074, Reconstruct Loss = 0.0011, Cls Loss = 0.0862, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0888, Reg Loss = 9.9748, Reconstruct Loss = 0.0010, Cls Loss = 0.0868, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0892, Reg Loss = 10.0310, Reconstruct Loss = 0.0010, Cls Loss = 0.0872, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0892, Reg Loss = 10.0580, Reconstruct Loss = 0.0010, Cls Loss = 0.0872, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0896, Reg Loss = 10.1008, Reconstruct Loss = 0.0010, Cls Loss = 0.0875, Learning rate = 1.0000e-03\n",
      "Epoch [21/200], Training Loss: 0.0887, Training Accuracy: 97.29, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Validation Loss: 24.1572, Validation Accuracy: 20.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0576, Reg Loss = 10.2443, Reconstruct Loss = 0.0000, Cls Loss = 0.0566, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0824, Reg Loss = 10.0003, Reconstruct Loss = 0.0014, Cls Loss = 0.0800, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0858, Reg Loss = 10.2100, Reconstruct Loss = 0.0016, Cls Loss = 0.0832, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0864, Reg Loss = 10.1178, Reconstruct Loss = 0.0014, Cls Loss = 0.0840, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0872, Reg Loss = 10.1664, Reconstruct Loss = 0.0012, Cls Loss = 0.0850, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0878, Reg Loss = 10.1834, Reconstruct Loss = 0.0012, Cls Loss = 0.0856, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0878, Reg Loss = 10.2186, Reconstruct Loss = 0.0010, Cls Loss = 0.0858, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0889, Reg Loss = 10.2424, Reconstruct Loss = 0.0010, Cls Loss = 0.0869, Learning rate = 1.0000e-03\n",
      "Epoch [22/200], Training Loss: 0.0883, Training Accuracy: 97.34, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200], Validation Loss: 23.2333, Validation Accuracy: 20.56%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0754, Reg Loss = 10.7219, Reconstruct Loss = 0.0000, Cls Loss = 0.0743, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0874, Reg Loss = 10.7540, Reconstruct Loss = 0.0018, Cls Loss = 0.0845, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0851, Reg Loss = 10.5657, Reconstruct Loss = 0.0015, Cls Loss = 0.0826, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0845, Reg Loss = 10.6208, Reconstruct Loss = 0.0011, Cls Loss = 0.0824, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0846, Reg Loss = 10.5937, Reconstruct Loss = 0.0010, Cls Loss = 0.0826, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0860, Reg Loss = 10.5406, Reconstruct Loss = 0.0012, Cls Loss = 0.0838, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0863, Reg Loss = 10.5361, Reconstruct Loss = 0.0011, Cls Loss = 0.0841, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0856, Reg Loss = 10.5112, Reconstruct Loss = 0.0011, Cls Loss = 0.0834, Learning rate = 1.0000e-03\n",
      "Epoch [23/200], Training Loss: 0.0861, Training Accuracy: 97.47, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200], Validation Loss: 16.1831, Validation Accuracy: 28.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0345, Reg Loss = 10.9792, Reconstruct Loss = 0.0000, Cls Loss = 0.0334, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0871, Reg Loss = 10.3318, Reconstruct Loss = 0.0018, Cls Loss = 0.0842, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0876, Reg Loss = 10.2035, Reconstruct Loss = 0.0016, Cls Loss = 0.0850, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0879, Reg Loss = 10.1633, Reconstruct Loss = 0.0016, Cls Loss = 0.0853, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0887, Reg Loss = 10.1520, Reconstruct Loss = 0.0016, Cls Loss = 0.0861, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0872, Reg Loss = 10.1474, Reconstruct Loss = 0.0014, Cls Loss = 0.0848, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0866, Reg Loss = 10.1648, Reconstruct Loss = 0.0013, Cls Loss = 0.0843, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0872, Reg Loss = 10.1794, Reconstruct Loss = 0.0013, Cls Loss = 0.0848, Learning rate = 1.0000e-03\n",
      "Epoch [24/200], Training Loss: 0.0877, Training Accuracy: 97.33, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Validation Loss: 21.8998, Validation Accuracy: 19.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0765, Reg Loss = 9.6085, Reconstruct Loss = 0.0000, Cls Loss = 0.0756, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0833, Reg Loss = 9.9097, Reconstruct Loss = 0.0014, Cls Loss = 0.0809, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0884, Reg Loss = 9.9286, Reconstruct Loss = 0.0017, Cls Loss = 0.0858, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0890, Reg Loss = 10.0263, Reconstruct Loss = 0.0013, Cls Loss = 0.0867, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0880, Reg Loss = 10.0252, Reconstruct Loss = 0.0012, Cls Loss = 0.0858, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0871, Reg Loss = 10.1070, Reconstruct Loss = 0.0011, Cls Loss = 0.0850, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0870, Reg Loss = 10.1240, Reconstruct Loss = 0.0012, Cls Loss = 0.0848, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0865, Reg Loss = 10.0897, Reconstruct Loss = 0.0011, Cls Loss = 0.0844, Learning rate = 1.0000e-03\n",
      "Epoch [25/200], Training Loss: 0.0864, Training Accuracy: 97.39, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200], Validation Loss: 19.1648, Validation Accuracy: 14.76%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0941, Reg Loss = 10.1018, Reconstruct Loss = 0.0000, Cls Loss = 0.0931, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0842, Reg Loss = 10.0940, Reconstruct Loss = 0.0005, Cls Loss = 0.0828, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0866, Reg Loss = 10.2181, Reconstruct Loss = 0.0008, Cls Loss = 0.0848, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0858, Reg Loss = 10.3144, Reconstruct Loss = 0.0006, Cls Loss = 0.0841, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0855, Reg Loss = 10.3860, Reconstruct Loss = 0.0006, Cls Loss = 0.0838, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0840, Reg Loss = 10.3865, Reconstruct Loss = 0.0007, Cls Loss = 0.0823, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0849, Reg Loss = 10.4612, Reconstruct Loss = 0.0007, Cls Loss = 0.0831, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0841, Reg Loss = 10.4776, Reconstruct Loss = 0.0008, Cls Loss = 0.0823, Learning rate = 1.0000e-03\n",
      "Epoch [26/200], Training Loss: 0.0839, Training Accuracy: 97.37, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200], Validation Loss: 14.0158, Validation Accuracy: 20.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0656, Reg Loss = 10.3892, Reconstruct Loss = 0.0000, Cls Loss = 0.0646, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0868, Reg Loss = 10.6783, Reconstruct Loss = 0.0018, Cls Loss = 0.0839, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0840, Reg Loss = 10.7736, Reconstruct Loss = 0.0013, Cls Loss = 0.0816, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0823, Reg Loss = 10.8094, Reconstruct Loss = 0.0010, Cls Loss = 0.0802, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0800, Reg Loss = 10.7427, Reconstruct Loss = 0.0009, Cls Loss = 0.0780, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0808, Reg Loss = 10.7878, Reconstruct Loss = 0.0011, Cls Loss = 0.0786, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0808, Reg Loss = 10.7536, Reconstruct Loss = 0.0011, Cls Loss = 0.0786, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0811, Reg Loss = 10.7779, Reconstruct Loss = 0.0010, Cls Loss = 0.0791, Learning rate = 1.0000e-03\n",
      "Epoch [27/200], Training Loss: 0.0810, Training Accuracy: 97.61, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200], Validation Loss: 19.8341, Validation Accuracy: 15.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0750, Reg Loss = 10.6856, Reconstruct Loss = 0.0000, Cls Loss = 0.0740, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0750, Reg Loss = 10.8354, Reconstruct Loss = 0.0005, Cls Loss = 0.0735, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0805, Reg Loss = 10.9556, Reconstruct Loss = 0.0005, Cls Loss = 0.0789, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0799, Reg Loss = 10.9883, Reconstruct Loss = 0.0006, Cls Loss = 0.0783, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0790, Reg Loss = 11.0124, Reconstruct Loss = 0.0008, Cls Loss = 0.0771, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0797, Reg Loss = 11.0378, Reconstruct Loss = 0.0009, Cls Loss = 0.0777, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0798, Reg Loss = 11.0687, Reconstruct Loss = 0.0010, Cls Loss = 0.0777, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0793, Reg Loss = 11.1000, Reconstruct Loss = 0.0009, Cls Loss = 0.0773, Learning rate = 1.0000e-03\n",
      "Epoch [28/200], Training Loss: 0.0796, Training Accuracy: 97.58, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200], Validation Loss: 33.6848, Validation Accuracy: 10.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0572, Reg Loss = 11.7686, Reconstruct Loss = 0.0000, Cls Loss = 0.0560, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0804, Reg Loss = 11.2064, Reconstruct Loss = 0.0006, Cls Loss = 0.0787, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0777, Reg Loss = 11.2152, Reconstruct Loss = 0.0008, Cls Loss = 0.0758, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0779, Reg Loss = 11.2233, Reconstruct Loss = 0.0012, Cls Loss = 0.0756, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0785, Reg Loss = 11.1609, Reconstruct Loss = 0.0015, Cls Loss = 0.0759, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0781, Reg Loss = 11.1902, Reconstruct Loss = 0.0014, Cls Loss = 0.0756, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0778, Reg Loss = 11.1788, Reconstruct Loss = 0.0012, Cls Loss = 0.0755, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0779, Reg Loss = 11.1966, Reconstruct Loss = 0.0011, Cls Loss = 0.0756, Learning rate = 1.0000e-03\n",
      "Epoch [29/200], Training Loss: 0.0780, Training Accuracy: 97.62, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200], Validation Loss: 24.4421, Validation Accuracy: 10.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0598, Reg Loss = 11.4611, Reconstruct Loss = 0.0000, Cls Loss = 0.0587, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0752, Reg Loss = 11.3574, Reconstruct Loss = 0.0009, Cls Loss = 0.0732, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0764, Reg Loss = 11.3009, Reconstruct Loss = 0.0009, Cls Loss = 0.0743, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0767, Reg Loss = 11.4133, Reconstruct Loss = 0.0011, Cls Loss = 0.0744, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0767, Reg Loss = 11.4465, Reconstruct Loss = 0.0010, Cls Loss = 0.0745, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0772, Reg Loss = 11.5137, Reconstruct Loss = 0.0011, Cls Loss = 0.0750, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0775, Reg Loss = 11.5516, Reconstruct Loss = 0.0011, Cls Loss = 0.0753, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0769, Reg Loss = 11.6226, Reconstruct Loss = 0.0011, Cls Loss = 0.0746, Learning rate = 1.0000e-03\n",
      "Epoch [30/200], Training Loss: 0.0767, Training Accuracy: 97.66, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Validation Loss: 25.8815, Validation Accuracy: 10.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0690, Reg Loss = 12.2487, Reconstruct Loss = 0.0000, Cls Loss = 0.0677, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0689, Reg Loss = 11.8042, Reconstruct Loss = 0.0023, Cls Loss = 0.0654, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0710, Reg Loss = 11.7418, Reconstruct Loss = 0.0018, Cls Loss = 0.0680, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0735, Reg Loss = 11.8808, Reconstruct Loss = 0.0016, Cls Loss = 0.0707, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0748, Reg Loss = 11.9255, Reconstruct Loss = 0.0013, Cls Loss = 0.0723, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0737, Reg Loss = 11.9375, Reconstruct Loss = 0.0013, Cls Loss = 0.0712, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0736, Reg Loss = 11.8989, Reconstruct Loss = 0.0012, Cls Loss = 0.0712, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0736, Reg Loss = 11.8841, Reconstruct Loss = 0.0011, Cls Loss = 0.0713, Learning rate = 1.0000e-03\n",
      "Epoch [31/200], Training Loss: 0.0737, Training Accuracy: 97.79, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200], Validation Loss: 39.9392, Validation Accuracy: 10.00%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0740, Reg Loss = 12.3588, Reconstruct Loss = 0.0000, Cls Loss = 0.0727, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0756, Reg Loss = 12.0170, Reconstruct Loss = 0.0018, Cls Loss = 0.0726, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0707, Reg Loss = 12.1081, Reconstruct Loss = 0.0009, Cls Loss = 0.0686, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0702, Reg Loss = 12.1025, Reconstruct Loss = 0.0008, Cls Loss = 0.0682, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0711, Reg Loss = 12.1419, Reconstruct Loss = 0.0008, Cls Loss = 0.0691, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0715, Reg Loss = 12.1008, Reconstruct Loss = 0.0009, Cls Loss = 0.0694, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0724, Reg Loss = 12.1118, Reconstruct Loss = 0.0008, Cls Loss = 0.0704, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0713, Reg Loss = 12.0624, Reconstruct Loss = 0.0009, Cls Loss = 0.0692, Learning rate = 1.0000e-03\n",
      "Epoch [32/200], Training Loss: 0.0723, Training Accuracy: 97.81, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200], Validation Loss: 33.0244, Validation Accuracy: 10.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0440, Reg Loss = 12.0037, Reconstruct Loss = 0.0000, Cls Loss = 0.0428, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0684, Reg Loss = 12.3970, Reconstruct Loss = 0.0008, Cls Loss = 0.0663, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0689, Reg Loss = 12.4280, Reconstruct Loss = 0.0005, Cls Loss = 0.0671, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0697, Reg Loss = 12.4085, Reconstruct Loss = 0.0007, Cls Loss = 0.0677, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0700, Reg Loss = 12.3486, Reconstruct Loss = 0.0008, Cls Loss = 0.0680, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0721, Reg Loss = 12.2642, Reconstruct Loss = 0.0009, Cls Loss = 0.0699, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0722, Reg Loss = 12.2188, Reconstruct Loss = 0.0009, Cls Loss = 0.0701, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0718, Reg Loss = 12.2245, Reconstruct Loss = 0.0009, Cls Loss = 0.0696, Learning rate = 1.0000e-03\n",
      "Epoch [33/200], Training Loss: 0.0715, Training Accuracy: 97.82, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200], Validation Loss: 31.6373, Validation Accuracy: 10.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0668, Reg Loss = 11.7896, Reconstruct Loss = 0.0000, Cls Loss = 0.0656, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0732, Reg Loss = 12.5684, Reconstruct Loss = 0.0011, Cls Loss = 0.0708, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0720, Reg Loss = 12.5818, Reconstruct Loss = 0.0009, Cls Loss = 0.0698, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0693, Reg Loss = 12.4237, Reconstruct Loss = 0.0008, Cls Loss = 0.0672, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0701, Reg Loss = 12.4163, Reconstruct Loss = 0.0009, Cls Loss = 0.0680, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0699, Reg Loss = 12.4057, Reconstruct Loss = 0.0008, Cls Loss = 0.0679, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0699, Reg Loss = 12.3591, Reconstruct Loss = 0.0008, Cls Loss = 0.0679, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0695, Reg Loss = 12.3608, Reconstruct Loss = 0.0008, Cls Loss = 0.0675, Learning rate = 1.0000e-03\n",
      "Epoch [34/200], Training Loss: 0.0702, Training Accuracy: 97.92, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/200], Validation Loss: 26.3159, Validation Accuracy: 13.56%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0574, Reg Loss = 12.6331, Reconstruct Loss = 0.0000, Cls Loss = 0.0561, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0673, Reg Loss = 12.4654, Reconstruct Loss = 0.0009, Cls Loss = 0.0652, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0717, Reg Loss = 12.4948, Reconstruct Loss = 0.0010, Cls Loss = 0.0695, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0708, Reg Loss = 12.4739, Reconstruct Loss = 0.0010, Cls Loss = 0.0686, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0706, Reg Loss = 12.3991, Reconstruct Loss = 0.0010, Cls Loss = 0.0684, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0697, Reg Loss = 12.4024, Reconstruct Loss = 0.0010, Cls Loss = 0.0675, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0698, Reg Loss = 12.4830, Reconstruct Loss = 0.0010, Cls Loss = 0.0675, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0693, Reg Loss = 12.5075, Reconstruct Loss = 0.0009, Cls Loss = 0.0672, Learning rate = 1.0000e-03\n",
      "Epoch [35/200], Training Loss: 0.0693, Training Accuracy: 97.96, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/200], Validation Loss: 36.7506, Validation Accuracy: 10.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0577, Reg Loss = 12.2056, Reconstruct Loss = 0.0000, Cls Loss = 0.0565, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0684, Reg Loss = 12.5115, Reconstruct Loss = 0.0004, Cls Loss = 0.0667, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0673, Reg Loss = 12.5652, Reconstruct Loss = 0.0006, Cls Loss = 0.0654, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0671, Reg Loss = 12.6836, Reconstruct Loss = 0.0007, Cls Loss = 0.0652, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0677, Reg Loss = 12.6552, Reconstruct Loss = 0.0007, Cls Loss = 0.0657, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0677, Reg Loss = 12.6161, Reconstruct Loss = 0.0007, Cls Loss = 0.0657, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0681, Reg Loss = 12.6111, Reconstruct Loss = 0.0007, Cls Loss = 0.0661, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0684, Reg Loss = 12.5745, Reconstruct Loss = 0.0008, Cls Loss = 0.0663, Learning rate = 1.0000e-03\n",
      "Epoch [36/200], Training Loss: 0.0682, Training Accuracy: 97.93, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200], Validation Loss: 40.5868, Validation Accuracy: 10.19%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1058, Reg Loss = 12.9371, Reconstruct Loss = 0.0000, Cls Loss = 0.1045, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0661, Reg Loss = 12.5694, Reconstruct Loss = 0.0009, Cls Loss = 0.0640, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0707, Reg Loss = 12.7969, Reconstruct Loss = 0.0009, Cls Loss = 0.0685, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0690, Reg Loss = 12.8738, Reconstruct Loss = 0.0008, Cls Loss = 0.0668, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0687, Reg Loss = 12.9690, Reconstruct Loss = 0.0008, Cls Loss = 0.0667, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0700, Reg Loss = 12.9990, Reconstruct Loss = 0.0008, Cls Loss = 0.0679, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0696, Reg Loss = 13.0301, Reconstruct Loss = 0.0009, Cls Loss = 0.0674, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0698, Reg Loss = 13.0331, Reconstruct Loss = 0.0009, Cls Loss = 0.0676, Learning rate = 1.0000e-03\n",
      "Epoch [37/200], Training Loss: 0.0695, Training Accuracy: 97.86, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/200], Validation Loss: 44.0919, Validation Accuracy: 10.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0708, Reg Loss = 12.9899, Reconstruct Loss = 0.0000, Cls Loss = 0.0695, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0739, Reg Loss = 12.7168, Reconstruct Loss = 0.0008, Cls Loss = 0.0718, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0726, Reg Loss = 12.8316, Reconstruct Loss = 0.0009, Cls Loss = 0.0704, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0705, Reg Loss = 12.8754, Reconstruct Loss = 0.0009, Cls Loss = 0.0683, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0696, Reg Loss = 13.0126, Reconstruct Loss = 0.0008, Cls Loss = 0.0675, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0676, Reg Loss = 13.0804, Reconstruct Loss = 0.0007, Cls Loss = 0.0656, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0674, Reg Loss = 13.1727, Reconstruct Loss = 0.0007, Cls Loss = 0.0653, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0673, Reg Loss = 13.2188, Reconstruct Loss = 0.0007, Cls Loss = 0.0652, Learning rate = 1.0000e-03\n",
      "Epoch [38/200], Training Loss: 0.0675, Training Accuracy: 97.94, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200], Validation Loss: 23.4859, Validation Accuracy: 18.36%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0936, Reg Loss = 14.1212, Reconstruct Loss = 0.0000, Cls Loss = 0.0922, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0686, Reg Loss = 13.6159, Reconstruct Loss = 0.0004, Cls Loss = 0.0669, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0714, Reg Loss = 13.6868, Reconstruct Loss = 0.0012, Cls Loss = 0.0688, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0714, Reg Loss = 13.7104, Reconstruct Loss = 0.0011, Cls Loss = 0.0690, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0702, Reg Loss = 13.6539, Reconstruct Loss = 0.0010, Cls Loss = 0.0679, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0694, Reg Loss = 13.5690, Reconstruct Loss = 0.0009, Cls Loss = 0.0671, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0681, Reg Loss = 13.4964, Reconstruct Loss = 0.0009, Cls Loss = 0.0659, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0676, Reg Loss = 13.4750, Reconstruct Loss = 0.0009, Cls Loss = 0.0654, Learning rate = 1.0000e-03\n",
      "Epoch [39/200], Training Loss: 0.0677, Training Accuracy: 98.01, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200], Validation Loss: 40.0345, Validation Accuracy: 10.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0298, Reg Loss = 13.6053, Reconstruct Loss = 0.0000, Cls Loss = 0.0284, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0635, Reg Loss = 12.9554, Reconstruct Loss = 0.0004, Cls Loss = 0.0618, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0697, Reg Loss = 13.1375, Reconstruct Loss = 0.0007, Cls Loss = 0.0677, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0686, Reg Loss = 13.2431, Reconstruct Loss = 0.0008, Cls Loss = 0.0665, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0700, Reg Loss = 13.3239, Reconstruct Loss = 0.0009, Cls Loss = 0.0677, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0702, Reg Loss = 13.2888, Reconstruct Loss = 0.0010, Cls Loss = 0.0678, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0693, Reg Loss = 13.2292, Reconstruct Loss = 0.0010, Cls Loss = 0.0670, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0690, Reg Loss = 13.2459, Reconstruct Loss = 0.0011, Cls Loss = 0.0666, Learning rate = 1.0000e-03\n",
      "Epoch [40/200], Training Loss: 0.0690, Training Accuracy: 97.79, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/200], Validation Loss: 32.4051, Validation Accuracy: 10.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0282, Reg Loss = 13.3270, Reconstruct Loss = 0.0000, Cls Loss = 0.0268, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0662, Reg Loss = 14.1010, Reconstruct Loss = 0.0014, Cls Loss = 0.0634, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0654, Reg Loss = 13.9018, Reconstruct Loss = 0.0010, Cls Loss = 0.0630, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0659, Reg Loss = 13.8598, Reconstruct Loss = 0.0011, Cls Loss = 0.0634, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0660, Reg Loss = 13.7170, Reconstruct Loss = 0.0012, Cls Loss = 0.0635, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0661, Reg Loss = 13.6028, Reconstruct Loss = 0.0010, Cls Loss = 0.0637, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0656, Reg Loss = 13.5622, Reconstruct Loss = 0.0010, Cls Loss = 0.0632, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0652, Reg Loss = 13.5335, Reconstruct Loss = 0.0010, Cls Loss = 0.0629, Learning rate = 1.0000e-03\n",
      "Epoch [41/200], Training Loss: 0.0655, Training Accuracy: 98.08, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/200], Validation Loss: 43.8959, Validation Accuracy: 10.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0448, Reg Loss = 14.1264, Reconstruct Loss = 0.0000, Cls Loss = 0.0434, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0735, Reg Loss = 13.8867, Reconstruct Loss = 0.0020, Cls Loss = 0.0701, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0724, Reg Loss = 13.7917, Reconstruct Loss = 0.0014, Cls Loss = 0.0696, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0716, Reg Loss = 13.7590, Reconstruct Loss = 0.0015, Cls Loss = 0.0687, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0703, Reg Loss = 13.7887, Reconstruct Loss = 0.0015, Cls Loss = 0.0675, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0702, Reg Loss = 13.7737, Reconstruct Loss = 0.0014, Cls Loss = 0.0674, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0694, Reg Loss = 13.7488, Reconstruct Loss = 0.0013, Cls Loss = 0.0667, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0693, Reg Loss = 13.7343, Reconstruct Loss = 0.0013, Cls Loss = 0.0667, Learning rate = 1.0000e-03\n",
      "Epoch [42/200], Training Loss: 0.0689, Training Accuracy: 97.91, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/200], Validation Loss: 36.7587, Validation Accuracy: 11.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0820, Reg Loss = 13.6212, Reconstruct Loss = 0.0000, Cls Loss = 0.0807, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0649, Reg Loss = 13.6957, Reconstruct Loss = 0.0008, Cls Loss = 0.0627, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0672, Reg Loss = 13.4985, Reconstruct Loss = 0.0010, Cls Loss = 0.0649, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0660, Reg Loss = 13.3630, Reconstruct Loss = 0.0008, Cls Loss = 0.0639, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0662, Reg Loss = 13.3263, Reconstruct Loss = 0.0009, Cls Loss = 0.0640, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0670, Reg Loss = 13.3986, Reconstruct Loss = 0.0008, Cls Loss = 0.0648, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0654, Reg Loss = 13.5172, Reconstruct Loss = 0.0007, Cls Loss = 0.0633, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0650, Reg Loss = 13.6172, Reconstruct Loss = 0.0007, Cls Loss = 0.0630, Learning rate = 1.0000e-03\n",
      "Epoch [43/200], Training Loss: 0.0646, Training Accuracy: 98.09, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/200], Validation Loss: 45.0363, Validation Accuracy: 14.17%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0643, Reg Loss = 14.3920, Reconstruct Loss = 0.0000, Cls Loss = 0.0628, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0669, Reg Loss = 14.0697, Reconstruct Loss = 0.0008, Cls Loss = 0.0647, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0671, Reg Loss = 13.8095, Reconstruct Loss = 0.0007, Cls Loss = 0.0650, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0673, Reg Loss = 13.6361, Reconstruct Loss = 0.0006, Cls Loss = 0.0653, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0677, Reg Loss = 13.6379, Reconstruct Loss = 0.0006, Cls Loss = 0.0657, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0668, Reg Loss = 13.6304, Reconstruct Loss = 0.0008, Cls Loss = 0.0646, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0659, Reg Loss = 13.6369, Reconstruct Loss = 0.0008, Cls Loss = 0.0637, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0655, Reg Loss = 13.6457, Reconstruct Loss = 0.0007, Cls Loss = 0.0634, Learning rate = 1.0000e-03\n",
      "Epoch [44/200], Training Loss: 0.0655, Training Accuracy: 97.99, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/200], Validation Loss: 23.7647, Validation Accuracy: 18.84%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0703, Reg Loss = 13.7076, Reconstruct Loss = 0.0000, Cls Loss = 0.0690, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0653, Reg Loss = 13.6998, Reconstruct Loss = 0.0008, Cls Loss = 0.0631, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0640, Reg Loss = 13.5465, Reconstruct Loss = 0.0011, Cls Loss = 0.0616, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0660, Reg Loss = 13.3104, Reconstruct Loss = 0.0009, Cls Loss = 0.0638, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0647, Reg Loss = 13.2918, Reconstruct Loss = 0.0008, Cls Loss = 0.0626, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0636, Reg Loss = 13.2364, Reconstruct Loss = 0.0008, Cls Loss = 0.0615, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0631, Reg Loss = 13.2454, Reconstruct Loss = 0.0007, Cls Loss = 0.0611, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0637, Reg Loss = 13.2122, Reconstruct Loss = 0.0007, Cls Loss = 0.0617, Learning rate = 1.0000e-03\n",
      "Epoch [45/200], Training Loss: 0.0644, Training Accuracy: 98.10, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/200], Validation Loss: 18.5244, Validation Accuracy: 21.98%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1018, Reg Loss = 13.1296, Reconstruct Loss = 0.0000, Cls Loss = 0.1005, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0727, Reg Loss = 13.2009, Reconstruct Loss = 0.0015, Cls Loss = 0.0700, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0687, Reg Loss = 13.2175, Reconstruct Loss = 0.0012, Cls Loss = 0.0662, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0681, Reg Loss = 13.3001, Reconstruct Loss = 0.0011, Cls Loss = 0.0657, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0659, Reg Loss = 13.4352, Reconstruct Loss = 0.0009, Cls Loss = 0.0637, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0663, Reg Loss = 13.5834, Reconstruct Loss = 0.0008, Cls Loss = 0.0641, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0658, Reg Loss = 13.6948, Reconstruct Loss = 0.0009, Cls Loss = 0.0635, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0660, Reg Loss = 13.7998, Reconstruct Loss = 0.0010, Cls Loss = 0.0636, Learning rate = 1.0000e-03\n",
      "Epoch [46/200], Training Loss: 0.0656, Training Accuracy: 97.99, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/200], Validation Loss: 31.4198, Validation Accuracy: 14.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0386, Reg Loss = 13.4070, Reconstruct Loss = 0.0000, Cls Loss = 0.0373, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0697, Reg Loss = 14.3765, Reconstruct Loss = 0.0006, Cls Loss = 0.0677, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0680, Reg Loss = 14.2313, Reconstruct Loss = 0.0006, Cls Loss = 0.0660, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0668, Reg Loss = 14.0978, Reconstruct Loss = 0.0006, Cls Loss = 0.0648, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0661, Reg Loss = 14.0403, Reconstruct Loss = 0.0007, Cls Loss = 0.0640, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0656, Reg Loss = 13.9363, Reconstruct Loss = 0.0007, Cls Loss = 0.0636, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0653, Reg Loss = 13.8791, Reconstruct Loss = 0.0007, Cls Loss = 0.0633, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0655, Reg Loss = 13.8733, Reconstruct Loss = 0.0006, Cls Loss = 0.0635, Learning rate = 1.0000e-03\n",
      "Epoch [47/200], Training Loss: 0.0659, Training Accuracy: 97.97, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/200], Validation Loss: 23.8158, Validation Accuracy: 21.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0499, Reg Loss = 13.7719, Reconstruct Loss = 0.0000, Cls Loss = 0.0485, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0610, Reg Loss = 13.9135, Reconstruct Loss = 0.0012, Cls Loss = 0.0584, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0629, Reg Loss = 13.9632, Reconstruct Loss = 0.0012, Cls Loss = 0.0604, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0630, Reg Loss = 14.0423, Reconstruct Loss = 0.0009, Cls Loss = 0.0607, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0640, Reg Loss = 13.9837, Reconstruct Loss = 0.0008, Cls Loss = 0.0618, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0651, Reg Loss = 13.9941, Reconstruct Loss = 0.0009, Cls Loss = 0.0628, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0659, Reg Loss = 14.0565, Reconstruct Loss = 0.0008, Cls Loss = 0.0637, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0654, Reg Loss = 14.0847, Reconstruct Loss = 0.0008, Cls Loss = 0.0632, Learning rate = 1.0000e-03\n",
      "Epoch [48/200], Training Loss: 0.0643, Training Accuracy: 98.06, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/200], Validation Loss: 32.2692, Validation Accuracy: 13.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0577, Reg Loss = 13.8887, Reconstruct Loss = 0.0000, Cls Loss = 0.0563, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0628, Reg Loss = 13.8040, Reconstruct Loss = 0.0011, Cls Loss = 0.0604, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0615, Reg Loss = 13.8806, Reconstruct Loss = 0.0010, Cls Loss = 0.0591, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0629, Reg Loss = 13.9530, Reconstruct Loss = 0.0009, Cls Loss = 0.0605, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0629, Reg Loss = 14.0884, Reconstruct Loss = 0.0008, Cls Loss = 0.0606, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0636, Reg Loss = 14.1230, Reconstruct Loss = 0.0008, Cls Loss = 0.0613, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0640, Reg Loss = 14.1404, Reconstruct Loss = 0.0010, Cls Loss = 0.0616, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0635, Reg Loss = 14.0747, Reconstruct Loss = 0.0010, Cls Loss = 0.0611, Learning rate = 1.0000e-03\n",
      "Epoch [49/200], Training Loss: 0.0635, Training Accuracy: 98.11, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/200], Validation Loss: 30.9426, Validation Accuracy: 14.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0544, Reg Loss = 13.2213, Reconstruct Loss = 0.0000, Cls Loss = 0.0530, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0644, Reg Loss = 13.5845, Reconstruct Loss = 0.0003, Cls Loss = 0.0627, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0620, Reg Loss = 13.4350, Reconstruct Loss = 0.0007, Cls Loss = 0.0600, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0616, Reg Loss = 13.5179, Reconstruct Loss = 0.0008, Cls Loss = 0.0594, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0637, Reg Loss = 13.6166, Reconstruct Loss = 0.0007, Cls Loss = 0.0616, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0629, Reg Loss = 13.6776, Reconstruct Loss = 0.0007, Cls Loss = 0.0608, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0631, Reg Loss = 13.6724, Reconstruct Loss = 0.0007, Cls Loss = 0.0611, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0638, Reg Loss = 13.6726, Reconstruct Loss = 0.0007, Cls Loss = 0.0617, Learning rate = 1.0000e-03\n",
      "Epoch [50/200], Training Loss: 0.0640, Training Accuracy: 98.08, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Validation Loss: 29.3806, Validation Accuracy: 12.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0334, Reg Loss = 13.7114, Reconstruct Loss = 0.0000, Cls Loss = 0.0320, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0629, Reg Loss = 14.0048, Reconstruct Loss = 0.0009, Cls Loss = 0.0607, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0621, Reg Loss = 13.9895, Reconstruct Loss = 0.0008, Cls Loss = 0.0599, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0628, Reg Loss = 13.9226, Reconstruct Loss = 0.0005, Cls Loss = 0.0609, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0621, Reg Loss = 13.9911, Reconstruct Loss = 0.0007, Cls Loss = 0.0599, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0631, Reg Loss = 14.0341, Reconstruct Loss = 0.0007, Cls Loss = 0.0611, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0629, Reg Loss = 14.0040, Reconstruct Loss = 0.0006, Cls Loss = 0.0609, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0632, Reg Loss = 14.0372, Reconstruct Loss = 0.0005, Cls Loss = 0.0613, Learning rate = 1.0000e-03\n",
      "Epoch [51/200], Training Loss: 0.0639, Training Accuracy: 98.01, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/200], Validation Loss: 30.3333, Validation Accuracy: 13.60%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0171, Reg Loss = 14.3155, Reconstruct Loss = 0.0000, Cls Loss = 0.0157, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0626, Reg Loss = 14.2802, Reconstruct Loss = 0.0008, Cls Loss = 0.0604, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0619, Reg Loss = 14.1391, Reconstruct Loss = 0.0010, Cls Loss = 0.0594, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0627, Reg Loss = 14.1188, Reconstruct Loss = 0.0007, Cls Loss = 0.0605, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0617, Reg Loss = 14.1011, Reconstruct Loss = 0.0009, Cls Loss = 0.0594, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0609, Reg Loss = 14.0529, Reconstruct Loss = 0.0008, Cls Loss = 0.0587, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0611, Reg Loss = 14.0310, Reconstruct Loss = 0.0008, Cls Loss = 0.0589, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0616, Reg Loss = 14.0512, Reconstruct Loss = 0.0009, Cls Loss = 0.0593, Learning rate = 1.0000e-03\n",
      "Epoch [52/200], Training Loss: 0.0611, Training Accuracy: 98.13, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/200], Validation Loss: 33.3739, Validation Accuracy: 16.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0475, Reg Loss = 13.6191, Reconstruct Loss = 0.0000, Cls Loss = 0.0462, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0642, Reg Loss = 13.7797, Reconstruct Loss = 0.0007, Cls Loss = 0.0621, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0640, Reg Loss = 13.7501, Reconstruct Loss = 0.0009, Cls Loss = 0.0618, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0613, Reg Loss = 13.6533, Reconstruct Loss = 0.0009, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0609, Reg Loss = 13.7297, Reconstruct Loss = 0.0009, Cls Loss = 0.0586, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0607, Reg Loss = 13.8158, Reconstruct Loss = 0.0009, Cls Loss = 0.0584, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0608, Reg Loss = 13.9153, Reconstruct Loss = 0.0009, Cls Loss = 0.0585, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0612, Reg Loss = 13.9470, Reconstruct Loss = 0.0009, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Epoch [53/200], Training Loss: 0.0610, Training Accuracy: 98.16, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/200], Validation Loss: 34.5064, Validation Accuracy: 12.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0252, Reg Loss = 14.4276, Reconstruct Loss = 0.0000, Cls Loss = 0.0238, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0638, Reg Loss = 13.9231, Reconstruct Loss = 0.0005, Cls Loss = 0.0619, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0654, Reg Loss = 13.9836, Reconstruct Loss = 0.0007, Cls Loss = 0.0633, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0675, Reg Loss = 14.0407, Reconstruct Loss = 0.0007, Cls Loss = 0.0654, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0652, Reg Loss = 14.0908, Reconstruct Loss = 0.0006, Cls Loss = 0.0631, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0654, Reg Loss = 14.1241, Reconstruct Loss = 0.0007, Cls Loss = 0.0633, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0646, Reg Loss = 14.0959, Reconstruct Loss = 0.0007, Cls Loss = 0.0625, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0645, Reg Loss = 14.1323, Reconstruct Loss = 0.0007, Cls Loss = 0.0624, Learning rate = 1.0000e-03\n",
      "Epoch [54/200], Training Loss: 0.0642, Training Accuracy: 98.08, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/200], Validation Loss: 45.6940, Validation Accuracy: 13.69%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0248, Reg Loss = 14.1464, Reconstruct Loss = 0.0000, Cls Loss = 0.0233, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0642, Reg Loss = 13.9382, Reconstruct Loss = 0.0008, Cls Loss = 0.0620, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0636, Reg Loss = 14.0131, Reconstruct Loss = 0.0006, Cls Loss = 0.0616, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0634, Reg Loss = 13.9863, Reconstruct Loss = 0.0006, Cls Loss = 0.0615, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0623, Reg Loss = 13.8956, Reconstruct Loss = 0.0006, Cls Loss = 0.0603, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0621, Reg Loss = 13.8682, Reconstruct Loss = 0.0006, Cls Loss = 0.0601, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0625, Reg Loss = 13.8870, Reconstruct Loss = 0.0006, Cls Loss = 0.0605, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0621, Reg Loss = 13.8790, Reconstruct Loss = 0.0006, Cls Loss = 0.0601, Learning rate = 1.0000e-03\n",
      "Epoch [55/200], Training Loss: 0.0622, Training Accuracy: 98.17, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/200], Validation Loss: 17.7896, Validation Accuracy: 20.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0715, Reg Loss = 13.6576, Reconstruct Loss = 0.0000, Cls Loss = 0.0701, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0566, Reg Loss = 14.3038, Reconstruct Loss = 0.0009, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0611, Reg Loss = 14.3539, Reconstruct Loss = 0.0006, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0632, Reg Loss = 14.3075, Reconstruct Loss = 0.0005, Cls Loss = 0.0612, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0626, Reg Loss = 14.3566, Reconstruct Loss = 0.0005, Cls Loss = 0.0606, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0619, Reg Loss = 14.3198, Reconstruct Loss = 0.0006, Cls Loss = 0.0599, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0620, Reg Loss = 14.3188, Reconstruct Loss = 0.0007, Cls Loss = 0.0599, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0609, Reg Loss = 14.2909, Reconstruct Loss = 0.0007, Cls Loss = 0.0588, Learning rate = 1.0000e-03\n",
      "Epoch [56/200], Training Loss: 0.0614, Training Accuracy: 98.15, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/200], Validation Loss: 36.4273, Validation Accuracy: 16.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0749, Reg Loss = 13.9702, Reconstruct Loss = 0.0000, Cls Loss = 0.0735, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0616, Reg Loss = 13.8776, Reconstruct Loss = 0.0005, Cls Loss = 0.0597, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0611, Reg Loss = 13.8839, Reconstruct Loss = 0.0004, Cls Loss = 0.0593, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0629, Reg Loss = 14.0599, Reconstruct Loss = 0.0004, Cls Loss = 0.0610, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0619, Reg Loss = 14.1537, Reconstruct Loss = 0.0005, Cls Loss = 0.0599, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0609, Reg Loss = 14.1575, Reconstruct Loss = 0.0005, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0613, Reg Loss = 14.2124, Reconstruct Loss = 0.0006, Cls Loss = 0.0593, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0610, Reg Loss = 14.2519, Reconstruct Loss = 0.0006, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Epoch [57/200], Training Loss: 0.0622, Training Accuracy: 98.13, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/200], Validation Loss: 33.3310, Validation Accuracy: 14.61%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0953, Reg Loss = 14.3537, Reconstruct Loss = 0.0000, Cls Loss = 0.0938, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0702, Reg Loss = 14.9404, Reconstruct Loss = 0.0004, Cls Loss = 0.0683, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0654, Reg Loss = 14.7327, Reconstruct Loss = 0.0005, Cls Loss = 0.0634, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0622, Reg Loss = 14.5831, Reconstruct Loss = 0.0006, Cls Loss = 0.0602, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0619, Reg Loss = 14.4571, Reconstruct Loss = 0.0005, Cls Loss = 0.0599, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0617, Reg Loss = 14.3938, Reconstruct Loss = 0.0005, Cls Loss = 0.0597, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0614, Reg Loss = 14.3219, Reconstruct Loss = 0.0005, Cls Loss = 0.0595, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0614, Reg Loss = 14.3082, Reconstruct Loss = 0.0006, Cls Loss = 0.0594, Learning rate = 1.0000e-03\n",
      "Epoch [58/200], Training Loss: 0.0611, Training Accuracy: 98.19, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/200], Validation Loss: 16.0284, Validation Accuracy: 20.39%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0267, Reg Loss = 13.7205, Reconstruct Loss = 0.0000, Cls Loss = 0.0253, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0535, Reg Loss = 14.0524, Reconstruct Loss = 0.0007, Cls Loss = 0.0515, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0578, Reg Loss = 14.0342, Reconstruct Loss = 0.0006, Cls Loss = 0.0558, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0585, Reg Loss = 14.1322, Reconstruct Loss = 0.0007, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0602, Reg Loss = 14.1874, Reconstruct Loss = 0.0007, Cls Loss = 0.0580, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0606, Reg Loss = 14.2418, Reconstruct Loss = 0.0007, Cls Loss = 0.0585, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0613, Reg Loss = 14.2001, Reconstruct Loss = 0.0007, Cls Loss = 0.0591, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0621, Reg Loss = 14.2484, Reconstruct Loss = 0.0008, Cls Loss = 0.0598, Learning rate = 1.0000e-03\n",
      "Epoch [59/200], Training Loss: 0.0619, Training Accuracy: 98.12, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/200], Validation Loss: 24.0438, Validation Accuracy: 21.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0930, Reg Loss = 13.9280, Reconstruct Loss = 0.0000, Cls Loss = 0.0916, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0596, Reg Loss = 14.6017, Reconstruct Loss = 0.0011, Cls Loss = 0.0570, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0591, Reg Loss = 14.4724, Reconstruct Loss = 0.0008, Cls Loss = 0.0568, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0577, Reg Loss = 14.3481, Reconstruct Loss = 0.0007, Cls Loss = 0.0556, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0580, Reg Loss = 14.2859, Reconstruct Loss = 0.0008, Cls Loss = 0.0558, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0590, Reg Loss = 14.1893, Reconstruct Loss = 0.0007, Cls Loss = 0.0569, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0589, Reg Loss = 14.1728, Reconstruct Loss = 0.0007, Cls Loss = 0.0568, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0598, Reg Loss = 14.1273, Reconstruct Loss = 0.0007, Cls Loss = 0.0577, Learning rate = 1.0000e-03\n",
      "Epoch [60/200], Training Loss: 0.0598, Training Accuracy: 98.22, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/200], Validation Loss: 43.0004, Validation Accuracy: 12.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0316, Reg Loss = 13.6987, Reconstruct Loss = 0.0000, Cls Loss = 0.0302, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0538, Reg Loss = 14.2163, Reconstruct Loss = 0.0010, Cls Loss = 0.0514, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0573, Reg Loss = 14.1677, Reconstruct Loss = 0.0007, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0574, Reg Loss = 14.3045, Reconstruct Loss = 0.0007, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0576, Reg Loss = 14.3757, Reconstruct Loss = 0.0008, Cls Loss = 0.0554, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0581, Reg Loss = 14.4024, Reconstruct Loss = 0.0008, Cls Loss = 0.0559, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0586, Reg Loss = 14.4001, Reconstruct Loss = 0.0007, Cls Loss = 0.0565, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0592, Reg Loss = 14.4047, Reconstruct Loss = 0.0007, Cls Loss = 0.0570, Learning rate = 1.0000e-03\n",
      "Epoch [61/200], Training Loss: 0.0591, Training Accuracy: 98.22, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/200], Validation Loss: 37.7956, Validation Accuracy: 11.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0868, Reg Loss = 13.7220, Reconstruct Loss = 0.0000, Cls Loss = 0.0854, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0647, Reg Loss = 15.0398, Reconstruct Loss = 0.0007, Cls Loss = 0.0626, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0626, Reg Loss = 14.8948, Reconstruct Loss = 0.0006, Cls Loss = 0.0604, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0612, Reg Loss = 14.8474, Reconstruct Loss = 0.0007, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0602, Reg Loss = 14.7809, Reconstruct Loss = 0.0007, Cls Loss = 0.0580, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0611, Reg Loss = 14.7129, Reconstruct Loss = 0.0007, Cls Loss = 0.0590, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0607, Reg Loss = 14.7009, Reconstruct Loss = 0.0007, Cls Loss = 0.0586, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0606, Reg Loss = 14.6620, Reconstruct Loss = 0.0007, Cls Loss = 0.0585, Learning rate = 1.0000e-03\n",
      "Epoch [62/200], Training Loss: 0.0608, Training Accuracy: 98.14, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/200], Validation Loss: 37.1983, Validation Accuracy: 11.78%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0725, Reg Loss = 13.7320, Reconstruct Loss = 0.0000, Cls Loss = 0.0711, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0594, Reg Loss = 14.4086, Reconstruct Loss = 0.0011, Cls Loss = 0.0568, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0613, Reg Loss = 14.3994, Reconstruct Loss = 0.0010, Cls Loss = 0.0588, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0602, Reg Loss = 14.3386, Reconstruct Loss = 0.0010, Cls Loss = 0.0578, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0601, Reg Loss = 14.3333, Reconstruct Loss = 0.0009, Cls Loss = 0.0578, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0599, Reg Loss = 14.2835, Reconstruct Loss = 0.0008, Cls Loss = 0.0577, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0601, Reg Loss = 14.2421, Reconstruct Loss = 0.0008, Cls Loss = 0.0579, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0597, Reg Loss = 14.3209, Reconstruct Loss = 0.0008, Cls Loss = 0.0575, Learning rate = 1.0000e-03\n",
      "Epoch [63/200], Training Loss: 0.0603, Training Accuracy: 98.27, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/200], Validation Loss: 29.6850, Validation Accuracy: 16.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0373, Reg Loss = 15.6439, Reconstruct Loss = 0.0000, Cls Loss = 0.0358, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0623, Reg Loss = 14.7840, Reconstruct Loss = 0.0010, Cls Loss = 0.0598, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0608, Reg Loss = 14.7970, Reconstruct Loss = 0.0006, Cls Loss = 0.0587, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0611, Reg Loss = 14.7710, Reconstruct Loss = 0.0006, Cls Loss = 0.0591, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0604, Reg Loss = 14.7536, Reconstruct Loss = 0.0006, Cls Loss = 0.0584, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0593, Reg Loss = 14.7945, Reconstruct Loss = 0.0006, Cls Loss = 0.0573, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0587, Reg Loss = 14.8229, Reconstruct Loss = 0.0006, Cls Loss = 0.0566, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0588, Reg Loss = 14.8005, Reconstruct Loss = 0.0005, Cls Loss = 0.0568, Learning rate = 1.0000e-03\n",
      "Epoch [64/200], Training Loss: 0.0587, Training Accuracy: 98.23, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/200], Validation Loss: 36.0144, Validation Accuracy: 14.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0908, Reg Loss = 14.5396, Reconstruct Loss = 0.0000, Cls Loss = 0.0894, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0585, Reg Loss = 14.7557, Reconstruct Loss = 0.0009, Cls Loss = 0.0561, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0588, Reg Loss = 14.7238, Reconstruct Loss = 0.0008, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0589, Reg Loss = 14.6927, Reconstruct Loss = 0.0008, Cls Loss = 0.0567, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0590, Reg Loss = 14.7533, Reconstruct Loss = 0.0007, Cls Loss = 0.0569, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0592, Reg Loss = 14.7340, Reconstruct Loss = 0.0007, Cls Loss = 0.0571, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0603, Reg Loss = 14.7694, Reconstruct Loss = 0.0008, Cls Loss = 0.0580, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0597, Reg Loss = 14.7574, Reconstruct Loss = 0.0009, Cls Loss = 0.0573, Learning rate = 1.0000e-03\n",
      "Epoch [65/200], Training Loss: 0.0595, Training Accuracy: 98.17, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/200], Validation Loss: 43.7620, Validation Accuracy: 16.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0284, Reg Loss = 14.4057, Reconstruct Loss = 0.0000, Cls Loss = 0.0270, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0566, Reg Loss = 15.1667, Reconstruct Loss = 0.0008, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0597, Reg Loss = 15.1315, Reconstruct Loss = 0.0005, Cls Loss = 0.0577, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0597, Reg Loss = 15.0408, Reconstruct Loss = 0.0005, Cls Loss = 0.0577, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0600, Reg Loss = 15.0187, Reconstruct Loss = 0.0005, Cls Loss = 0.0579, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0599, Reg Loss = 15.0194, Reconstruct Loss = 0.0005, Cls Loss = 0.0579, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0600, Reg Loss = 15.0480, Reconstruct Loss = 0.0006, Cls Loss = 0.0579, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0590, Reg Loss = 15.0359, Reconstruct Loss = 0.0006, Cls Loss = 0.0569, Learning rate = 1.0000e-03\n",
      "Epoch [66/200], Training Loss: 0.0588, Training Accuracy: 98.16, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/200], Validation Loss: 27.7342, Validation Accuracy: 19.25%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0254, Reg Loss = 14.1686, Reconstruct Loss = 0.0000, Cls Loss = 0.0240, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0519, Reg Loss = 14.8955, Reconstruct Loss = 0.0001, Cls Loss = 0.0503, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0561, Reg Loss = 14.9603, Reconstruct Loss = 0.0003, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0559, Reg Loss = 15.0117, Reconstruct Loss = 0.0002, Cls Loss = 0.0542, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0560, Reg Loss = 15.0676, Reconstruct Loss = 0.0002, Cls Loss = 0.0542, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0567, Reg Loss = 15.0681, Reconstruct Loss = 0.0003, Cls Loss = 0.0549, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0570, Reg Loss = 14.9839, Reconstruct Loss = 0.0004, Cls Loss = 0.0551, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0567, Reg Loss = 14.8911, Reconstruct Loss = 0.0004, Cls Loss = 0.0548, Learning rate = 1.0000e-03\n",
      "Epoch [67/200], Training Loss: 0.0568, Training Accuracy: 98.32, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/200], Validation Loss: 32.1601, Validation Accuracy: 11.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0837, Reg Loss = 15.0228, Reconstruct Loss = 0.0000, Cls Loss = 0.0822, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0576, Reg Loss = 14.9214, Reconstruct Loss = 0.0008, Cls Loss = 0.0553, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0592, Reg Loss = 15.1295, Reconstruct Loss = 0.0006, Cls Loss = 0.0570, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0600, Reg Loss = 15.1311, Reconstruct Loss = 0.0009, Cls Loss = 0.0576, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0596, Reg Loss = 15.0959, Reconstruct Loss = 0.0009, Cls Loss = 0.0572, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0579, Reg Loss = 15.0506, Reconstruct Loss = 0.0009, Cls Loss = 0.0555, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0582, Reg Loss = 15.0593, Reconstruct Loss = 0.0008, Cls Loss = 0.0558, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0570, Reg Loss = 15.0420, Reconstruct Loss = 0.0007, Cls Loss = 0.0548, Learning rate = 1.0000e-03\n",
      "Epoch [68/200], Training Loss: 0.0571, Training Accuracy: 98.21, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/200], Validation Loss: 23.3675, Validation Accuracy: 21.19%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0482, Reg Loss = 14.9055, Reconstruct Loss = 0.0000, Cls Loss = 0.0467, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0554, Reg Loss = 14.9135, Reconstruct Loss = 0.0003, Cls Loss = 0.0536, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0572, Reg Loss = 15.0189, Reconstruct Loss = 0.0005, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0558, Reg Loss = 15.0073, Reconstruct Loss = 0.0004, Cls Loss = 0.0540, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0573, Reg Loss = 15.0260, Reconstruct Loss = 0.0005, Cls Loss = 0.0553, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0586, Reg Loss = 15.0127, Reconstruct Loss = 0.0005, Cls Loss = 0.0566, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0580, Reg Loss = 15.0336, Reconstruct Loss = 0.0007, Cls Loss = 0.0559, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0584, Reg Loss = 15.0680, Reconstruct Loss = 0.0006, Cls Loss = 0.0563, Learning rate = 1.0000e-03\n",
      "Epoch [69/200], Training Loss: 0.0583, Training Accuracy: 98.16, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/200], Validation Loss: 47.6261, Validation Accuracy: 14.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0233, Reg Loss = 15.8106, Reconstruct Loss = 0.0000, Cls Loss = 0.0218, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0565, Reg Loss = 15.9853, Reconstruct Loss = 0.0006, Cls Loss = 0.0542, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0573, Reg Loss = 15.5798, Reconstruct Loss = 0.0008, Cls Loss = 0.0550, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0577, Reg Loss = 15.3407, Reconstruct Loss = 0.0007, Cls Loss = 0.0555, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0575, Reg Loss = 15.3510, Reconstruct Loss = 0.0007, Cls Loss = 0.0553, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0587, Reg Loss = 15.2929, Reconstruct Loss = 0.0007, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0585, Reg Loss = 15.3434, Reconstruct Loss = 0.0006, Cls Loss = 0.0563, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0588, Reg Loss = 15.3699, Reconstruct Loss = 0.0007, Cls Loss = 0.0565, Learning rate = 1.0000e-03\n",
      "Epoch [70/200], Training Loss: 0.0589, Training Accuracy: 98.20, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/200], Validation Loss: 37.4345, Validation Accuracy: 12.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0997, Reg Loss = 14.6671, Reconstruct Loss = 0.0000, Cls Loss = 0.0983, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0577, Reg Loss = 14.6438, Reconstruct Loss = 0.0011, Cls Loss = 0.0551, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0589, Reg Loss = 14.8280, Reconstruct Loss = 0.0010, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0581, Reg Loss = 14.8755, Reconstruct Loss = 0.0010, Cls Loss = 0.0556, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0589, Reg Loss = 14.9597, Reconstruct Loss = 0.0010, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0574, Reg Loss = 14.9842, Reconstruct Loss = 0.0011, Cls Loss = 0.0549, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0583, Reg Loss = 15.0041, Reconstruct Loss = 0.0010, Cls Loss = 0.0559, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0576, Reg Loss = 14.9702, Reconstruct Loss = 0.0010, Cls Loss = 0.0551, Learning rate = 1.0000e-03\n",
      "Epoch [71/200], Training Loss: 0.0575, Training Accuracy: 98.26, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/200], Validation Loss: 58.0189, Validation Accuracy: 12.90%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0263, Reg Loss = 15.4320, Reconstruct Loss = 0.0000, Cls Loss = 0.0247, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0626, Reg Loss = 15.0557, Reconstruct Loss = 0.0014, Cls Loss = 0.0597, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0620, Reg Loss = 14.9069, Reconstruct Loss = 0.0009, Cls Loss = 0.0596, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0604, Reg Loss = 14.8057, Reconstruct Loss = 0.0009, Cls Loss = 0.0580, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0585, Reg Loss = 14.7981, Reconstruct Loss = 0.0008, Cls Loss = 0.0562, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0577, Reg Loss = 14.7355, Reconstruct Loss = 0.0008, Cls Loss = 0.0555, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0582, Reg Loss = 14.7303, Reconstruct Loss = 0.0008, Cls Loss = 0.0560, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0579, Reg Loss = 14.7173, Reconstruct Loss = 0.0007, Cls Loss = 0.0557, Learning rate = 1.0000e-03\n",
      "Epoch [72/200], Training Loss: 0.0585, Training Accuracy: 98.17, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/200], Validation Loss: 24.9663, Validation Accuracy: 19.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0257, Reg Loss = 14.7608, Reconstruct Loss = 0.0000, Cls Loss = 0.0243, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0563, Reg Loss = 14.7781, Reconstruct Loss = 0.0009, Cls Loss = 0.0539, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0567, Reg Loss = 14.8102, Reconstruct Loss = 0.0012, Cls Loss = 0.0540, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0564, Reg Loss = 14.7702, Reconstruct Loss = 0.0010, Cls Loss = 0.0539, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0576, Reg Loss = 14.6931, Reconstruct Loss = 0.0009, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0575, Reg Loss = 14.6533, Reconstruct Loss = 0.0009, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0571, Reg Loss = 14.6217, Reconstruct Loss = 0.0009, Cls Loss = 0.0548, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0567, Reg Loss = 14.6002, Reconstruct Loss = 0.0009, Cls Loss = 0.0544, Learning rate = 1.0000e-03\n",
      "Epoch [73/200], Training Loss: 0.0558, Training Accuracy: 98.31, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/200], Validation Loss: 35.1633, Validation Accuracy: 14.19%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0277, Reg Loss = 15.0340, Reconstruct Loss = 0.0000, Cls Loss = 0.0262, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0584, Reg Loss = 14.8245, Reconstruct Loss = 0.0004, Cls Loss = 0.0565, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0587, Reg Loss = 14.8175, Reconstruct Loss = 0.0008, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0584, Reg Loss = 14.7993, Reconstruct Loss = 0.0009, Cls Loss = 0.0561, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0577, Reg Loss = 14.7822, Reconstruct Loss = 0.0008, Cls Loss = 0.0554, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0562, Reg Loss = 14.8172, Reconstruct Loss = 0.0008, Cls Loss = 0.0539, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0571, Reg Loss = 14.8334, Reconstruct Loss = 0.0007, Cls Loss = 0.0549, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0570, Reg Loss = 14.8242, Reconstruct Loss = 0.0007, Cls Loss = 0.0548, Learning rate = 1.0000e-03\n",
      "Epoch [74/200], Training Loss: 0.0571, Training Accuracy: 98.28, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/200], Validation Loss: 34.1743, Validation Accuracy: 19.57%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0307, Reg Loss = 14.5325, Reconstruct Loss = 0.0000, Cls Loss = 0.0292, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0546, Reg Loss = 14.7359, Reconstruct Loss = 0.0008, Cls Loss = 0.0524, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0561, Reg Loss = 14.7574, Reconstruct Loss = 0.0008, Cls Loss = 0.0538, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0555, Reg Loss = 14.7466, Reconstruct Loss = 0.0007, Cls Loss = 0.0534, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0557, Reg Loss = 14.7096, Reconstruct Loss = 0.0007, Cls Loss = 0.0535, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0557, Reg Loss = 14.7110, Reconstruct Loss = 0.0008, Cls Loss = 0.0535, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0562, Reg Loss = 14.6543, Reconstruct Loss = 0.0007, Cls Loss = 0.0541, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0555, Reg Loss = 14.6464, Reconstruct Loss = 0.0007, Cls Loss = 0.0534, Learning rate = 1.0000e-03\n",
      "Epoch [75/200], Training Loss: 0.0550, Training Accuracy: 98.36, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/200], Validation Loss: 24.0958, Validation Accuracy: 19.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0221, Reg Loss = 13.7140, Reconstruct Loss = 0.0000, Cls Loss = 0.0208, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0537, Reg Loss = 14.7914, Reconstruct Loss = 0.0006, Cls Loss = 0.0516, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0580, Reg Loss = 14.8545, Reconstruct Loss = 0.0005, Cls Loss = 0.0560, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0560, Reg Loss = 14.7451, Reconstruct Loss = 0.0005, Cls Loss = 0.0540, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0554, Reg Loss = 14.7980, Reconstruct Loss = 0.0006, Cls Loss = 0.0533, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0559, Reg Loss = 14.8446, Reconstruct Loss = 0.0005, Cls Loss = 0.0539, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0553, Reg Loss = 14.8189, Reconstruct Loss = 0.0006, Cls Loss = 0.0532, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0554, Reg Loss = 14.7537, Reconstruct Loss = 0.0006, Cls Loss = 0.0533, Learning rate = 1.0000e-03\n",
      "Epoch [76/200], Training Loss: 0.0552, Training Accuracy: 98.28, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/200], Validation Loss: 25.6659, Validation Accuracy: 23.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1096, Reg Loss = 14.1892, Reconstruct Loss = 0.0000, Cls Loss = 0.1082, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0617, Reg Loss = 15.3367, Reconstruct Loss = 0.0004, Cls Loss = 0.0598, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0589, Reg Loss = 15.4187, Reconstruct Loss = 0.0007, Cls Loss = 0.0567, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0577, Reg Loss = 15.2694, Reconstruct Loss = 0.0006, Cls Loss = 0.0555, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0558, Reg Loss = 15.2785, Reconstruct Loss = 0.0007, Cls Loss = 0.0535, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0555, Reg Loss = 15.3250, Reconstruct Loss = 0.0006, Cls Loss = 0.0534, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0555, Reg Loss = 15.2972, Reconstruct Loss = 0.0006, Cls Loss = 0.0534, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0549, Reg Loss = 15.2686, Reconstruct Loss = 0.0007, Cls Loss = 0.0527, Learning rate = 1.0000e-03\n",
      "Epoch [77/200], Training Loss: 0.0554, Training Accuracy: 98.35, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/200], Validation Loss: 23.4171, Validation Accuracy: 25.53%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0940, Reg Loss = 14.9871, Reconstruct Loss = 0.0000, Cls Loss = 0.0925, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0600, Reg Loss = 15.5281, Reconstruct Loss = 0.0004, Cls Loss = 0.0580, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0567, Reg Loss = 15.4987, Reconstruct Loss = 0.0006, Cls Loss = 0.0546, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0574, Reg Loss = 15.2952, Reconstruct Loss = 0.0006, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0566, Reg Loss = 15.2241, Reconstruct Loss = 0.0006, Cls Loss = 0.0545, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0556, Reg Loss = 15.1363, Reconstruct Loss = 0.0005, Cls Loss = 0.0536, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0553, Reg Loss = 15.1032, Reconstruct Loss = 0.0005, Cls Loss = 0.0533, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0557, Reg Loss = 15.0708, Reconstruct Loss = 0.0006, Cls Loss = 0.0536, Learning rate = 1.0000e-03\n",
      "Epoch [78/200], Training Loss: 0.0557, Training Accuracy: 98.28, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/200], Validation Loss: 29.8705, Validation Accuracy: 16.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0435, Reg Loss = 15.7520, Reconstruct Loss = 0.0000, Cls Loss = 0.0419, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0536, Reg Loss = 14.9879, Reconstruct Loss = 0.0009, Cls Loss = 0.0513, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0548, Reg Loss = 14.8546, Reconstruct Loss = 0.0008, Cls Loss = 0.0525, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0539, Reg Loss = 14.8183, Reconstruct Loss = 0.0008, Cls Loss = 0.0516, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0562, Reg Loss = 14.7771, Reconstruct Loss = 0.0007, Cls Loss = 0.0540, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0570, Reg Loss = 14.8388, Reconstruct Loss = 0.0008, Cls Loss = 0.0547, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0559, Reg Loss = 14.9093, Reconstruct Loss = 0.0008, Cls Loss = 0.0536, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0559, Reg Loss = 15.0105, Reconstruct Loss = 0.0007, Cls Loss = 0.0537, Learning rate = 1.0000e-03\n",
      "Epoch [79/200], Training Loss: 0.0558, Training Accuracy: 98.27, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 36.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/200], Validation Loss: 23.7020, Validation Accuracy: 20.92%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0657, Reg Loss = 14.9842, Reconstruct Loss = 0.0000, Cls Loss = 0.0642, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0585, Reg Loss = 15.3793, Reconstruct Loss = 0.0005, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0583, Reg Loss = 15.2003, Reconstruct Loss = 0.0006, Cls Loss = 0.0561, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0559, Reg Loss = 15.1512, Reconstruct Loss = 0.0007, Cls Loss = 0.0536, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0542, Reg Loss = 15.0470, Reconstruct Loss = 0.0008, Cls Loss = 0.0520, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0542, Reg Loss = 14.9921, Reconstruct Loss = 0.0008, Cls Loss = 0.0519, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0544, Reg Loss = 14.9571, Reconstruct Loss = 0.0007, Cls Loss = 0.0522, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0549, Reg Loss = 14.9323, Reconstruct Loss = 0.0007, Cls Loss = 0.0527, Learning rate = 1.0000e-03\n",
      "Epoch [80/200], Training Loss: 0.0552, Training Accuracy: 98.38, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/200], Validation Loss: 45.4927, Validation Accuracy: 15.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0802, Reg Loss = 14.3764, Reconstruct Loss = 0.0000, Cls Loss = 0.0788, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0536, Reg Loss = 15.0102, Reconstruct Loss = 0.0009, Cls Loss = 0.0512, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0528, Reg Loss = 15.1663, Reconstruct Loss = 0.0008, Cls Loss = 0.0505, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0517, Reg Loss = 14.9975, Reconstruct Loss = 0.0007, Cls Loss = 0.0495, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0543, Reg Loss = 14.9792, Reconstruct Loss = 0.0006, Cls Loss = 0.0521, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0540, Reg Loss = 15.0483, Reconstruct Loss = 0.0007, Cls Loss = 0.0518, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0549, Reg Loss = 15.0600, Reconstruct Loss = 0.0008, Cls Loss = 0.0526, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0543, Reg Loss = 15.0679, Reconstruct Loss = 0.0008, Cls Loss = 0.0520, Learning rate = 1.0000e-03\n",
      "Epoch [81/200], Training Loss: 0.0544, Training Accuracy: 98.40, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/200], Validation Loss: 42.8763, Validation Accuracy: 18.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0435, Reg Loss = 14.4488, Reconstruct Loss = 0.0000, Cls Loss = 0.0420, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0596, Reg Loss = 14.9245, Reconstruct Loss = 0.0012, Cls Loss = 0.0569, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0581, Reg Loss = 14.7793, Reconstruct Loss = 0.0008, Cls Loss = 0.0558, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0563, Reg Loss = 14.6973, Reconstruct Loss = 0.0005, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0572, Reg Loss = 14.6803, Reconstruct Loss = 0.0006, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0562, Reg Loss = 14.6814, Reconstruct Loss = 0.0005, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0567, Reg Loss = 14.7766, Reconstruct Loss = 0.0005, Cls Loss = 0.0548, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0562, Reg Loss = 14.7642, Reconstruct Loss = 0.0006, Cls Loss = 0.0541, Learning rate = 1.0000e-03\n",
      "Epoch [82/200], Training Loss: 0.0560, Training Accuracy: 98.29, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/200], Validation Loss: 28.2779, Validation Accuracy: 20.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0329, Reg Loss = 14.7336, Reconstruct Loss = 0.0000, Cls Loss = 0.0314, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0539, Reg Loss = 14.6300, Reconstruct Loss = 0.0003, Cls Loss = 0.0521, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0539, Reg Loss = 14.7117, Reconstruct Loss = 0.0005, Cls Loss = 0.0519, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0555, Reg Loss = 14.7807, Reconstruct Loss = 0.0006, Cls Loss = 0.0535, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0567, Reg Loss = 14.8088, Reconstruct Loss = 0.0007, Cls Loss = 0.0545, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0566, Reg Loss = 14.8469, Reconstruct Loss = 0.0007, Cls Loss = 0.0545, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0565, Reg Loss = 14.8916, Reconstruct Loss = 0.0007, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0565, Reg Loss = 14.8998, Reconstruct Loss = 0.0006, Cls Loss = 0.0544, Learning rate = 1.0000e-03\n",
      "Epoch [83/200], Training Loss: 0.0560, Training Accuracy: 98.28, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/200], Validation Loss: 30.3464, Validation Accuracy: 21.27%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1602, Reg Loss = 15.2445, Reconstruct Loss = 0.0000, Cls Loss = 0.1587, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0551, Reg Loss = 15.3762, Reconstruct Loss = 0.0006, Cls Loss = 0.0529, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0549, Reg Loss = 15.3240, Reconstruct Loss = 0.0009, Cls Loss = 0.0526, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0541, Reg Loss = 15.2047, Reconstruct Loss = 0.0006, Cls Loss = 0.0519, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0524, Reg Loss = 15.1991, Reconstruct Loss = 0.0007, Cls Loss = 0.0503, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0527, Reg Loss = 15.0919, Reconstruct Loss = 0.0008, Cls Loss = 0.0504, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0530, Reg Loss = 15.0738, Reconstruct Loss = 0.0009, Cls Loss = 0.0506, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0532, Reg Loss = 15.0935, Reconstruct Loss = 0.0008, Cls Loss = 0.0508, Learning rate = 1.0000e-03\n",
      "Epoch [84/200], Training Loss: 0.0535, Training Accuracy: 98.37, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/200], Validation Loss: 24.4717, Validation Accuracy: 17.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0561, Reg Loss = 14.7459, Reconstruct Loss = 0.0000, Cls Loss = 0.0546, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0585, Reg Loss = 14.5680, Reconstruct Loss = 0.0007, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0579, Reg Loss = 14.7090, Reconstruct Loss = 0.0009, Cls Loss = 0.0555, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0553, Reg Loss = 14.7125, Reconstruct Loss = 0.0008, Cls Loss = 0.0530, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0554, Reg Loss = 14.7197, Reconstruct Loss = 0.0009, Cls Loss = 0.0531, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0552, Reg Loss = 14.7016, Reconstruct Loss = 0.0008, Cls Loss = 0.0529, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0548, Reg Loss = 14.6503, Reconstruct Loss = 0.0008, Cls Loss = 0.0525, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0556, Reg Loss = 14.5764, Reconstruct Loss = 0.0008, Cls Loss = 0.0534, Learning rate = 1.0000e-03\n",
      "Epoch [85/200], Training Loss: 0.0560, Training Accuracy: 98.28, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/200], Validation Loss: 29.4172, Validation Accuracy: 16.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0149, Reg Loss = 13.4003, Reconstruct Loss = 0.0000, Cls Loss = 0.0136, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0528, Reg Loss = 14.6101, Reconstruct Loss = 0.0009, Cls Loss = 0.0504, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0522, Reg Loss = 14.6350, Reconstruct Loss = 0.0008, Cls Loss = 0.0500, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0522, Reg Loss = 14.6965, Reconstruct Loss = 0.0008, Cls Loss = 0.0499, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0516, Reg Loss = 14.7439, Reconstruct Loss = 0.0008, Cls Loss = 0.0493, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0521, Reg Loss = 14.7312, Reconstruct Loss = 0.0007, Cls Loss = 0.0499, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0533, Reg Loss = 14.7037, Reconstruct Loss = 0.0007, Cls Loss = 0.0511, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0533, Reg Loss = 14.7467, Reconstruct Loss = 0.0007, Cls Loss = 0.0511, Learning rate = 1.0000e-03\n",
      "Epoch [86/200], Training Loss: 0.0535, Training Accuracy: 98.35, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/200], Validation Loss: 42.5651, Validation Accuracy: 18.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0173, Reg Loss = 15.1917, Reconstruct Loss = 0.0000, Cls Loss = 0.0158, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0534, Reg Loss = 15.2449, Reconstruct Loss = 0.0009, Cls Loss = 0.0510, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0568, Reg Loss = 15.2819, Reconstruct Loss = 0.0008, Cls Loss = 0.0544, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0565, Reg Loss = 15.2027, Reconstruct Loss = 0.0007, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0561, Reg Loss = 15.2277, Reconstruct Loss = 0.0006, Cls Loss = 0.0540, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0548, Reg Loss = 15.1972, Reconstruct Loss = 0.0006, Cls Loss = 0.0526, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0534, Reg Loss = 15.1214, Reconstruct Loss = 0.0006, Cls Loss = 0.0513, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0538, Reg Loss = 15.1116, Reconstruct Loss = 0.0006, Cls Loss = 0.0517, Learning rate = 1.0000e-03\n",
      "Epoch [87/200], Training Loss: 0.0536, Training Accuracy: 98.35, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/200], Validation Loss: 27.7709, Validation Accuracy: 19.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0254, Reg Loss = 13.9919, Reconstruct Loss = 0.0000, Cls Loss = 0.0240, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0633, Reg Loss = 14.3504, Reconstruct Loss = 0.0004, Cls Loss = 0.0615, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0584, Reg Loss = 14.5832, Reconstruct Loss = 0.0006, Cls Loss = 0.0564, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0566, Reg Loss = 14.6934, Reconstruct Loss = 0.0006, Cls Loss = 0.0546, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0559, Reg Loss = 14.8507, Reconstruct Loss = 0.0006, Cls Loss = 0.0538, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0559, Reg Loss = 14.9671, Reconstruct Loss = 0.0006, Cls Loss = 0.0538, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0559, Reg Loss = 14.9398, Reconstruct Loss = 0.0006, Cls Loss = 0.0538, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0567, Reg Loss = 14.9172, Reconstruct Loss = 0.0006, Cls Loss = 0.0546, Learning rate = 1.0000e-03\n",
      "Epoch [88/200], Training Loss: 0.0564, Training Accuracy: 98.27, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/200], Validation Loss: 59.8165, Validation Accuracy: 15.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0526, Reg Loss = 15.6081, Reconstruct Loss = 0.0173, Cls Loss = 0.0338, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0527, Reg Loss = 15.2176, Reconstruct Loss = 0.0012, Cls Loss = 0.0499, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0526, Reg Loss = 15.4386, Reconstruct Loss = 0.0010, Cls Loss = 0.0501, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0538, Reg Loss = 15.3501, Reconstruct Loss = 0.0009, Cls Loss = 0.0514, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0548, Reg Loss = 15.3422, Reconstruct Loss = 0.0008, Cls Loss = 0.0525, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0542, Reg Loss = 15.3272, Reconstruct Loss = 0.0009, Cls Loss = 0.0517, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0542, Reg Loss = 15.2807, Reconstruct Loss = 0.0009, Cls Loss = 0.0518, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0539, Reg Loss = 15.2300, Reconstruct Loss = 0.0009, Cls Loss = 0.0515, Learning rate = 1.0000e-03\n",
      "Epoch [89/200], Training Loss: 0.0540, Training Accuracy: 98.37, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/200], Validation Loss: 38.7223, Validation Accuracy: 19.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0423, Reg Loss = 14.8539, Reconstruct Loss = 0.0000, Cls Loss = 0.0408, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0486, Reg Loss = 14.5747, Reconstruct Loss = 0.0008, Cls Loss = 0.0464, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0513, Reg Loss = 14.6010, Reconstruct Loss = 0.0006, Cls Loss = 0.0493, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0542, Reg Loss = 14.5217, Reconstruct Loss = 0.0006, Cls Loss = 0.0522, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0545, Reg Loss = 14.5895, Reconstruct Loss = 0.0005, Cls Loss = 0.0525, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0545, Reg Loss = 14.5858, Reconstruct Loss = 0.0005, Cls Loss = 0.0526, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0542, Reg Loss = 14.5753, Reconstruct Loss = 0.0005, Cls Loss = 0.0523, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0537, Reg Loss = 14.5716, Reconstruct Loss = 0.0004, Cls Loss = 0.0518, Learning rate = 1.0000e-03\n",
      "Epoch [90/200], Training Loss: 0.0533, Training Accuracy: 98.32, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/200], Validation Loss: 31.7905, Validation Accuracy: 20.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0262, Reg Loss = 13.4195, Reconstruct Loss = 0.0000, Cls Loss = 0.0249, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0535, Reg Loss = 14.0819, Reconstruct Loss = 0.0003, Cls Loss = 0.0518, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0539, Reg Loss = 14.0913, Reconstruct Loss = 0.0009, Cls Loss = 0.0516, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0564, Reg Loss = 14.1121, Reconstruct Loss = 0.0007, Cls Loss = 0.0543, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0554, Reg Loss = 14.2575, Reconstruct Loss = 0.0007, Cls Loss = 0.0533, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0541, Reg Loss = 14.3711, Reconstruct Loss = 0.0007, Cls Loss = 0.0520, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0542, Reg Loss = 14.4732, Reconstruct Loss = 0.0006, Cls Loss = 0.0521, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0541, Reg Loss = 14.5180, Reconstruct Loss = 0.0006, Cls Loss = 0.0520, Learning rate = 1.0000e-03\n",
      "Epoch [91/200], Training Loss: 0.0546, Training Accuracy: 98.39, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200], Validation Loss: 28.6794, Validation Accuracy: 18.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0244, Reg Loss = 14.3012, Reconstruct Loss = 0.0000, Cls Loss = 0.0230, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0571, Reg Loss = 14.7517, Reconstruct Loss = 0.0005, Cls Loss = 0.0551, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0565, Reg Loss = 14.7240, Reconstruct Loss = 0.0006, Cls Loss = 0.0545, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0549, Reg Loss = 14.8573, Reconstruct Loss = 0.0005, Cls Loss = 0.0529, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0551, Reg Loss = 14.7600, Reconstruct Loss = 0.0005, Cls Loss = 0.0531, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0539, Reg Loss = 14.7131, Reconstruct Loss = 0.0006, Cls Loss = 0.0519, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0536, Reg Loss = 14.6605, Reconstruct Loss = 0.0006, Cls Loss = 0.0516, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0540, Reg Loss = 14.6932, Reconstruct Loss = 0.0006, Cls Loss = 0.0519, Learning rate = 1.0000e-03\n",
      "Epoch [92/200], Training Loss: 0.0543, Training Accuracy: 98.32, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/200], Validation Loss: 26.5551, Validation Accuracy: 18.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0347, Reg Loss = 14.2166, Reconstruct Loss = 0.0000, Cls Loss = 0.0333, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0551, Reg Loss = 14.6229, Reconstruct Loss = 0.0008, Cls Loss = 0.0529, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0586, Reg Loss = 14.5846, Reconstruct Loss = 0.0010, Cls Loss = 0.0562, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0575, Reg Loss = 14.6740, Reconstruct Loss = 0.0008, Cls Loss = 0.0552, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0570, Reg Loss = 14.6984, Reconstruct Loss = 0.0009, Cls Loss = 0.0546, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0566, Reg Loss = 14.6267, Reconstruct Loss = 0.0009, Cls Loss = 0.0542, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0564, Reg Loss = 14.6151, Reconstruct Loss = 0.0008, Cls Loss = 0.0541, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0562, Reg Loss = 14.6442, Reconstruct Loss = 0.0008, Cls Loss = 0.0539, Learning rate = 1.0000e-03\n",
      "Epoch [93/200], Training Loss: 0.0561, Training Accuracy: 98.25, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/200], Validation Loss: 30.8225, Validation Accuracy: 16.62%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0677, Reg Loss = 14.5639, Reconstruct Loss = 0.0000, Cls Loss = 0.0662, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0547, Reg Loss = 14.6584, Reconstruct Loss = 0.0010, Cls Loss = 0.0523, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0534, Reg Loss = 14.5784, Reconstruct Loss = 0.0009, Cls Loss = 0.0510, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0521, Reg Loss = 14.5675, Reconstruct Loss = 0.0009, Cls Loss = 0.0498, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0526, Reg Loss = 14.5499, Reconstruct Loss = 0.0008, Cls Loss = 0.0503, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0530, Reg Loss = 14.4895, Reconstruct Loss = 0.0008, Cls Loss = 0.0507, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0539, Reg Loss = 14.4837, Reconstruct Loss = 0.0008, Cls Loss = 0.0517, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0542, Reg Loss = 14.4771, Reconstruct Loss = 0.0008, Cls Loss = 0.0520, Learning rate = 1.0000e-03\n",
      "Epoch [94/200], Training Loss: 0.0543, Training Accuracy: 98.39, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/200], Validation Loss: 18.6336, Validation Accuracy: 23.68%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0447, Reg Loss = 14.5348, Reconstruct Loss = 0.0000, Cls Loss = 0.0433, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0525, Reg Loss = 14.7180, Reconstruct Loss = 0.0008, Cls Loss = 0.0502, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0534, Reg Loss = 14.7569, Reconstruct Loss = 0.0010, Cls Loss = 0.0509, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0519, Reg Loss = 14.7355, Reconstruct Loss = 0.0009, Cls Loss = 0.0496, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0535, Reg Loss = 14.7610, Reconstruct Loss = 0.0007, Cls Loss = 0.0513, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0539, Reg Loss = 14.8123, Reconstruct Loss = 0.0006, Cls Loss = 0.0518, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0534, Reg Loss = 14.8238, Reconstruct Loss = 0.0006, Cls Loss = 0.0513, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0538, Reg Loss = 14.7855, Reconstruct Loss = 0.0006, Cls Loss = 0.0517, Learning rate = 1.0000e-03\n",
      "Epoch [95/200], Training Loss: 0.0534, Training Accuracy: 98.38, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/200], Validation Loss: 18.3986, Validation Accuracy: 21.37%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0234, Reg Loss = 14.6058, Reconstruct Loss = 0.0000, Cls Loss = 0.0219, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0505, Reg Loss = 14.6772, Reconstruct Loss = 0.0002, Cls Loss = 0.0489, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0519, Reg Loss = 14.6666, Reconstruct Loss = 0.0007, Cls Loss = 0.0497, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0513, Reg Loss = 14.6883, Reconstruct Loss = 0.0008, Cls Loss = 0.0490, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0511, Reg Loss = 14.7854, Reconstruct Loss = 0.0007, Cls Loss = 0.0490, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0513, Reg Loss = 14.8478, Reconstruct Loss = 0.0008, Cls Loss = 0.0491, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0515, Reg Loss = 14.8465, Reconstruct Loss = 0.0007, Cls Loss = 0.0493, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0520, Reg Loss = 14.8678, Reconstruct Loss = 0.0008, Cls Loss = 0.0497, Learning rate = 1.0000e-03\n",
      "Epoch [96/200], Training Loss: 0.0526, Training Accuracy: 98.41, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/200], Validation Loss: 25.7752, Validation Accuracy: 19.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1506, Reg Loss = 14.7984, Reconstruct Loss = 0.0000, Cls Loss = 0.1491, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0479, Reg Loss = 15.1692, Reconstruct Loss = 0.0008, Cls Loss = 0.0455, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0524, Reg Loss = 15.1297, Reconstruct Loss = 0.0006, Cls Loss = 0.0503, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0514, Reg Loss = 15.0907, Reconstruct Loss = 0.0006, Cls Loss = 0.0492, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0502, Reg Loss = 15.0864, Reconstruct Loss = 0.0007, Cls Loss = 0.0480, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0519, Reg Loss = 15.0756, Reconstruct Loss = 0.0007, Cls Loss = 0.0497, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0524, Reg Loss = 15.0711, Reconstruct Loss = 0.0007, Cls Loss = 0.0502, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0534, Reg Loss = 15.0949, Reconstruct Loss = 0.0007, Cls Loss = 0.0512, Learning rate = 1.0000e-03\n",
      "Epoch [97/200], Training Loss: 0.0534, Training Accuracy: 98.37, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/200], Validation Loss: 40.4871, Validation Accuracy: 17.90%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0586, Reg Loss = 15.6443, Reconstruct Loss = 0.0000, Cls Loss = 0.0570, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0517, Reg Loss = 15.4090, Reconstruct Loss = 0.0007, Cls Loss = 0.0496, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0563, Reg Loss = 15.2888, Reconstruct Loss = 0.0006, Cls Loss = 0.0542, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0553, Reg Loss = 15.2500, Reconstruct Loss = 0.0004, Cls Loss = 0.0534, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0547, Reg Loss = 15.1968, Reconstruct Loss = 0.0004, Cls Loss = 0.0528, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0547, Reg Loss = 15.1543, Reconstruct Loss = 0.0004, Cls Loss = 0.0528, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0544, Reg Loss = 15.0871, Reconstruct Loss = 0.0006, Cls Loss = 0.0523, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0533, Reg Loss = 15.0604, Reconstruct Loss = 0.0006, Cls Loss = 0.0512, Learning rate = 1.0000e-03\n",
      "Epoch [98/200], Training Loss: 0.0534, Training Accuracy: 98.42, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/200], Validation Loss: 42.6695, Validation Accuracy: 14.57%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0357, Reg Loss = 15.7307, Reconstruct Loss = 0.0000, Cls Loss = 0.0342, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0570, Reg Loss = 15.0691, Reconstruct Loss = 0.0006, Cls Loss = 0.0548, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0549, Reg Loss = 14.7510, Reconstruct Loss = 0.0006, Cls Loss = 0.0528, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0551, Reg Loss = 14.6576, Reconstruct Loss = 0.0007, Cls Loss = 0.0530, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0548, Reg Loss = 14.5806, Reconstruct Loss = 0.0007, Cls Loss = 0.0527, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0546, Reg Loss = 14.5252, Reconstruct Loss = 0.0006, Cls Loss = 0.0525, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0539, Reg Loss = 14.5929, Reconstruct Loss = 0.0006, Cls Loss = 0.0518, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0534, Reg Loss = 14.6009, Reconstruct Loss = 0.0006, Cls Loss = 0.0513, Learning rate = 1.0000e-03\n",
      "Epoch [99/200], Training Loss: 0.0533, Training Accuracy: 98.34, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/200], Validation Loss: 21.6916, Validation Accuracy: 23.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0593, Reg Loss = 15.5237, Reconstruct Loss = 0.0000, Cls Loss = 0.0578, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.0484, Reg Loss = 15.2569, Reconstruct Loss = 0.0006, Cls Loss = 0.0463, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.0485, Reg Loss = 15.1449, Reconstruct Loss = 0.0006, Cls Loss = 0.0464, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.0513, Reg Loss = 15.0847, Reconstruct Loss = 0.0007, Cls Loss = 0.0491, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.0520, Reg Loss = 15.1236, Reconstruct Loss = 0.0008, Cls Loss = 0.0497, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.0526, Reg Loss = 15.1214, Reconstruct Loss = 0.0008, Cls Loss = 0.0503, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.0520, Reg Loss = 15.1370, Reconstruct Loss = 0.0008, Cls Loss = 0.0497, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.0519, Reg Loss = 15.1283, Reconstruct Loss = 0.0007, Cls Loss = 0.0497, Learning rate = 1.0000e-03\n",
      "Epoch [100/200], Training Loss: 0.0526, Training Accuracy: 98.44, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/200], Validation Loss: 27.9366, Validation Accuracy: 19.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0398, Reg Loss = 14.1209, Reconstruct Loss = 0.0000, Cls Loss = 0.0384, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0513, Reg Loss = 14.9759, Reconstruct Loss = 0.0004, Cls Loss = 0.0494, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0505, Reg Loss = 14.9572, Reconstruct Loss = 0.0004, Cls Loss = 0.0485, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0494, Reg Loss = 14.9341, Reconstruct Loss = 0.0005, Cls Loss = 0.0474, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0488, Reg Loss = 14.9042, Reconstruct Loss = 0.0004, Cls Loss = 0.0468, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0483, Reg Loss = 14.8615, Reconstruct Loss = 0.0004, Cls Loss = 0.0463, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0491, Reg Loss = 14.8237, Reconstruct Loss = 0.0005, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0492, Reg Loss = 14.8027, Reconstruct Loss = 0.0005, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Epoch [101/200], Training Loss: 0.0489, Training Accuracy: 98.55, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200], Validation Loss: 25.4988, Validation Accuracy: 18.83%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0391, Reg Loss = 14.5720, Reconstruct Loss = 0.0000, Cls Loss = 0.0376, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0482, Reg Loss = 14.6220, Reconstruct Loss = 0.0007, Cls Loss = 0.0460, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0537, Reg Loss = 14.6168, Reconstruct Loss = 0.0007, Cls Loss = 0.0515, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0519, Reg Loss = 14.5913, Reconstruct Loss = 0.0006, Cls Loss = 0.0499, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0505, Reg Loss = 14.6052, Reconstruct Loss = 0.0005, Cls Loss = 0.0486, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0505, Reg Loss = 14.6003, Reconstruct Loss = 0.0006, Cls Loss = 0.0484, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0507, Reg Loss = 14.5869, Reconstruct Loss = 0.0006, Cls Loss = 0.0487, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0500, Reg Loss = 14.5849, Reconstruct Loss = 0.0006, Cls Loss = 0.0480, Learning rate = 1.0000e-04\n",
      "Epoch [102/200], Training Loss: 0.0502, Training Accuracy: 98.53, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/200], Validation Loss: 21.3450, Validation Accuracy: 18.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0308, Reg Loss = 13.9502, Reconstruct Loss = 0.0000, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0447, Reg Loss = 14.3488, Reconstruct Loss = 0.0007, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0456, Reg Loss = 14.2629, Reconstruct Loss = 0.0005, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0452, Reg Loss = 14.2616, Reconstruct Loss = 0.0007, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0452, Reg Loss = 14.2387, Reconstruct Loss = 0.0007, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0457, Reg Loss = 14.2084, Reconstruct Loss = 0.0006, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0463, Reg Loss = 14.1985, Reconstruct Loss = 0.0006, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0469, Reg Loss = 14.1836, Reconstruct Loss = 0.0006, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Epoch [103/200], Training Loss: 0.0482, Training Accuracy: 98.56, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/200], Validation Loss: 25.1785, Validation Accuracy: 15.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0703, Reg Loss = 13.9617, Reconstruct Loss = 0.0000, Cls Loss = 0.0689, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0450, Reg Loss = 14.1247, Reconstruct Loss = 0.0003, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0461, Reg Loss = 14.0936, Reconstruct Loss = 0.0004, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0465, Reg Loss = 14.0812, Reconstruct Loss = 0.0003, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0476, Reg Loss = 14.0565, Reconstruct Loss = 0.0003, Cls Loss = 0.0459, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0477, Reg Loss = 14.0483, Reconstruct Loss = 0.0004, Cls Loss = 0.0459, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0482, Reg Loss = 14.0259, Reconstruct Loss = 0.0005, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0480, Reg Loss = 14.0070, Reconstruct Loss = 0.0005, Cls Loss = 0.0461, Learning rate = 1.0000e-04\n",
      "Epoch [104/200], Training Loss: 0.0483, Training Accuracy: 98.58, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/200], Validation Loss: 17.6541, Validation Accuracy: 24.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0298, Reg Loss = 14.0383, Reconstruct Loss = 0.0000, Cls Loss = 0.0284, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0473, Reg Loss = 13.9801, Reconstruct Loss = 0.0005, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0477, Reg Loss = 13.9841, Reconstruct Loss = 0.0005, Cls Loss = 0.0458, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0484, Reg Loss = 13.9277, Reconstruct Loss = 0.0004, Cls Loss = 0.0466, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0489, Reg Loss = 13.8630, Reconstruct Loss = 0.0003, Cls Loss = 0.0472, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0483, Reg Loss = 13.8358, Reconstruct Loss = 0.0004, Cls Loss = 0.0465, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0478, Reg Loss = 13.8238, Reconstruct Loss = 0.0005, Cls Loss = 0.0459, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0474, Reg Loss = 13.8080, Reconstruct Loss = 0.0005, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Epoch [105/200], Training Loss: 0.0470, Training Accuracy: 98.62, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/200], Validation Loss: 20.2797, Validation Accuracy: 18.71%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0576, Reg Loss = 13.8230, Reconstruct Loss = 0.0000, Cls Loss = 0.0562, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0517, Reg Loss = 13.6774, Reconstruct Loss = 0.0004, Cls Loss = 0.0499, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0508, Reg Loss = 13.6461, Reconstruct Loss = 0.0006, Cls Loss = 0.0488, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0493, Reg Loss = 13.6393, Reconstruct Loss = 0.0006, Cls Loss = 0.0474, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0490, Reg Loss = 13.6376, Reconstruct Loss = 0.0006, Cls Loss = 0.0471, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0486, Reg Loss = 13.6407, Reconstruct Loss = 0.0006, Cls Loss = 0.0466, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0485, Reg Loss = 13.6326, Reconstruct Loss = 0.0006, Cls Loss = 0.0466, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0484, Reg Loss = 13.6188, Reconstruct Loss = 0.0006, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Epoch [106/200], Training Loss: 0.0481, Training Accuracy: 98.55, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/200], Validation Loss: 16.8790, Validation Accuracy: 22.98%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0869, Reg Loss = 13.2253, Reconstruct Loss = 0.0000, Cls Loss = 0.0856, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0468, Reg Loss = 13.4176, Reconstruct Loss = 0.0004, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0475, Reg Loss = 13.4327, Reconstruct Loss = 0.0004, Cls Loss = 0.0457, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0471, Reg Loss = 13.4369, Reconstruct Loss = 0.0004, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0470, Reg Loss = 13.4686, Reconstruct Loss = 0.0004, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0467, Reg Loss = 13.4695, Reconstruct Loss = 0.0005, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0470, Reg Loss = 13.4598, Reconstruct Loss = 0.0006, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0472, Reg Loss = 13.4390, Reconstruct Loss = 0.0006, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Epoch [107/200], Training Loss: 0.0472, Training Accuracy: 98.58, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/200], Validation Loss: 29.8697, Validation Accuracy: 18.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1005, Reg Loss = 12.3928, Reconstruct Loss = 0.0000, Cls Loss = 0.0993, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0549, Reg Loss = 13.3087, Reconstruct Loss = 0.0006, Cls Loss = 0.0529, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0497, Reg Loss = 13.2410, Reconstruct Loss = 0.0006, Cls Loss = 0.0477, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0482, Reg Loss = 13.2668, Reconstruct Loss = 0.0006, Cls Loss = 0.0463, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0469, Reg Loss = 13.2740, Reconstruct Loss = 0.0006, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0460, Reg Loss = 13.2741, Reconstruct Loss = 0.0007, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0469, Reg Loss = 13.2526, Reconstruct Loss = 0.0007, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0477, Reg Loss = 13.2320, Reconstruct Loss = 0.0007, Cls Loss = 0.0457, Learning rate = 1.0000e-04\n",
      "Epoch [108/200], Training Loss: 0.0479, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/200], Validation Loss: 15.1806, Validation Accuracy: 31.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0395, Reg Loss = 13.2087, Reconstruct Loss = 0.0000, Cls Loss = 0.0381, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0449, Reg Loss = 13.2002, Reconstruct Loss = 0.0002, Cls Loss = 0.0435, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0440, Reg Loss = 13.2783, Reconstruct Loss = 0.0005, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0450, Reg Loss = 13.2712, Reconstruct Loss = 0.0005, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0456, Reg Loss = 13.2605, Reconstruct Loss = 0.0006, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0459, Reg Loss = 13.2484, Reconstruct Loss = 0.0005, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0462, Reg Loss = 13.2289, Reconstruct Loss = 0.0005, Cls Loss = 0.0443, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0462, Reg Loss = 13.2177, Reconstruct Loss = 0.0005, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Epoch [109/200], Training Loss: 0.0463, Training Accuracy: 98.59, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/200], Validation Loss: 19.5271, Validation Accuracy: 22.50%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0740, Reg Loss = 13.6891, Reconstruct Loss = 0.0000, Cls Loss = 0.0727, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0466, Reg Loss = 13.1750, Reconstruct Loss = 0.0004, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0465, Reg Loss = 13.1130, Reconstruct Loss = 0.0003, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0468, Reg Loss = 13.1020, Reconstruct Loss = 0.0004, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0471, Reg Loss = 13.0855, Reconstruct Loss = 0.0004, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0464, Reg Loss = 13.0570, Reconstruct Loss = 0.0004, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0469, Reg Loss = 13.0316, Reconstruct Loss = 0.0003, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0465, Reg Loss = 13.0309, Reconstruct Loss = 0.0004, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Epoch [110/200], Training Loss: 0.0468, Training Accuracy: 98.57, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/200], Validation Loss: 19.4290, Validation Accuracy: 20.04%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0656, Reg Loss = 12.8983, Reconstruct Loss = 0.0000, Cls Loss = 0.0643, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0521, Reg Loss = 12.9950, Reconstruct Loss = 0.0009, Cls Loss = 0.0499, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0486, Reg Loss = 12.9735, Reconstruct Loss = 0.0008, Cls Loss = 0.0465, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0471, Reg Loss = 12.9680, Reconstruct Loss = 0.0008, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0473, Reg Loss = 12.9210, Reconstruct Loss = 0.0007, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0468, Reg Loss = 12.8990, Reconstruct Loss = 0.0006, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0472, Reg Loss = 12.8683, Reconstruct Loss = 0.0006, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0472, Reg Loss = 12.8609, Reconstruct Loss = 0.0005, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Epoch [111/200], Training Loss: 0.0473, Training Accuracy: 98.57, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/200], Validation Loss: 21.8664, Validation Accuracy: 20.04%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0132, Reg Loss = 13.2007, Reconstruct Loss = 0.0000, Cls Loss = 0.0119, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0510, Reg Loss = 12.7900, Reconstruct Loss = 0.0007, Cls Loss = 0.0490, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0462, Reg Loss = 12.8372, Reconstruct Loss = 0.0006, Cls Loss = 0.0443, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0467, Reg Loss = 12.8453, Reconstruct Loss = 0.0007, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 12.8438, Reconstruct Loss = 0.0007, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0466, Reg Loss = 12.8595, Reconstruct Loss = 0.0007, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0468, Reg Loss = 12.8456, Reconstruct Loss = 0.0007, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0475, Reg Loss = 12.8422, Reconstruct Loss = 0.0007, Cls Loss = 0.0455, Learning rate = 1.0000e-04\n",
      "Epoch [112/200], Training Loss: 0.0476, Training Accuracy: 98.55, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/200], Validation Loss: 16.5535, Validation Accuracy: 21.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1300, Reg Loss = 12.9148, Reconstruct Loss = 0.0000, Cls Loss = 0.1287, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0423, Reg Loss = 12.7095, Reconstruct Loss = 0.0003, Cls Loss = 0.0408, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0440, Reg Loss = 12.7133, Reconstruct Loss = 0.0007, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0458, Reg Loss = 12.7193, Reconstruct Loss = 0.0006, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0462, Reg Loss = 12.7074, Reconstruct Loss = 0.0006, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0460, Reg Loss = 12.6842, Reconstruct Loss = 0.0005, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0460, Reg Loss = 12.6731, Reconstruct Loss = 0.0005, Cls Loss = 0.0443, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0460, Reg Loss = 12.6551, Reconstruct Loss = 0.0005, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Epoch [113/200], Training Loss: 0.0466, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/200], Validation Loss: 21.6523, Validation Accuracy: 19.71%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0974, Reg Loss = 12.8692, Reconstruct Loss = 0.0000, Cls Loss = 0.0961, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0470, Reg Loss = 12.5978, Reconstruct Loss = 0.0004, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0479, Reg Loss = 12.6111, Reconstruct Loss = 0.0002, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0473, Reg Loss = 12.6297, Reconstruct Loss = 0.0003, Cls Loss = 0.0458, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0466, Reg Loss = 12.6280, Reconstruct Loss = 0.0003, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0462, Reg Loss = 12.6393, Reconstruct Loss = 0.0002, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0463, Reg Loss = 12.6281, Reconstruct Loss = 0.0002, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0462, Reg Loss = 12.6325, Reconstruct Loss = 0.0002, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Epoch [114/200], Training Loss: 0.0467, Training Accuracy: 98.62, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/200], Validation Loss: 19.0565, Validation Accuracy: 20.82%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0690, Reg Loss = 12.2915, Reconstruct Loss = 0.0000, Cls Loss = 0.0677, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0437, Reg Loss = 12.4068, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0438, Reg Loss = 12.4100, Reconstruct Loss = 0.0004, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0465, Reg Loss = 12.3735, Reconstruct Loss = 0.0003, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0466, Reg Loss = 12.3626, Reconstruct Loss = 0.0003, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0466, Reg Loss = 12.3302, Reconstruct Loss = 0.0003, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0467, Reg Loss = 12.3314, Reconstruct Loss = 0.0004, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0465, Reg Loss = 12.3247, Reconstruct Loss = 0.0004, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Epoch [115/200], Training Loss: 0.0472, Training Accuracy: 98.57, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/200], Validation Loss: 17.9156, Validation Accuracy: 21.68%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0335, Reg Loss = 12.5977, Reconstruct Loss = 0.0000, Cls Loss = 0.0322, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0473, Reg Loss = 12.2770, Reconstruct Loss = 0.0005, Cls Loss = 0.0455, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0458, Reg Loss = 12.2777, Reconstruct Loss = 0.0004, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0455, Reg Loss = 12.2785, Reconstruct Loss = 0.0004, Cls Loss = 0.0438, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 12.2584, Reconstruct Loss = 0.0005, Cls Loss = 0.0450, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0464, Reg Loss = 12.2156, Reconstruct Loss = 0.0005, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0464, Reg Loss = 12.1810, Reconstruct Loss = 0.0004, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0460, Reg Loss = 12.1638, Reconstruct Loss = 0.0004, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Epoch [116/200], Training Loss: 0.0458, Training Accuracy: 98.65, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200], Validation Loss: 14.2377, Validation Accuracy: 23.51%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0388, Reg Loss = 11.6529, Reconstruct Loss = 0.0000, Cls Loss = 0.0376, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0461, Reg Loss = 12.0924, Reconstruct Loss = 0.0007, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0478, Reg Loss = 12.0672, Reconstruct Loss = 0.0006, Cls Loss = 0.0460, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0473, Reg Loss = 12.0705, Reconstruct Loss = 0.0005, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0476, Reg Loss = 12.0662, Reconstruct Loss = 0.0005, Cls Loss = 0.0459, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0474, Reg Loss = 12.0640, Reconstruct Loss = 0.0004, Cls Loss = 0.0457, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0478, Reg Loss = 12.0631, Reconstruct Loss = 0.0005, Cls Loss = 0.0460, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0471, Reg Loss = 12.0789, Reconstruct Loss = 0.0005, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Epoch [117/200], Training Loss: 0.0468, Training Accuracy: 98.58, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/200], Validation Loss: 10.7631, Validation Accuracy: 30.68%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0230, Reg Loss = 12.3643, Reconstruct Loss = 0.0000, Cls Loss = 0.0218, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0418, Reg Loss = 11.9907, Reconstruct Loss = 0.0005, Cls Loss = 0.0401, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0433, Reg Loss = 12.0117, Reconstruct Loss = 0.0005, Cls Loss = 0.0416, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0433, Reg Loss = 12.0301, Reconstruct Loss = 0.0004, Cls Loss = 0.0416, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0431, Reg Loss = 12.0207, Reconstruct Loss = 0.0004, Cls Loss = 0.0415, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0442, Reg Loss = 12.0404, Reconstruct Loss = 0.0005, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0439, Reg Loss = 12.0329, Reconstruct Loss = 0.0005, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0447, Reg Loss = 12.0264, Reconstruct Loss = 0.0006, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Epoch [118/200], Training Loss: 0.0444, Training Accuracy: 98.70, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/200], Validation Loss: 14.9162, Validation Accuracy: 22.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0408, Reg Loss = 11.9371, Reconstruct Loss = 0.0000, Cls Loss = 0.0396, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0457, Reg Loss = 11.9069, Reconstruct Loss = 0.0004, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0437, Reg Loss = 11.9332, Reconstruct Loss = 0.0003, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0448, Reg Loss = 11.9555, Reconstruct Loss = 0.0003, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0454, Reg Loss = 11.9904, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 11.9739, Reconstruct Loss = 0.0004, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0448, Reg Loss = 11.9649, Reconstruct Loss = 0.0005, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0455, Reg Loss = 11.9456, Reconstruct Loss = 0.0005, Cls Loss = 0.0438, Learning rate = 1.0000e-04\n",
      "Epoch [119/200], Training Loss: 0.0460, Training Accuracy: 98.62, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/200], Validation Loss: 11.1897, Validation Accuracy: 28.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0618, Reg Loss = 11.9700, Reconstruct Loss = 0.0000, Cls Loss = 0.0606, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0422, Reg Loss = 11.8070, Reconstruct Loss = 0.0003, Cls Loss = 0.0406, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0452, Reg Loss = 11.7809, Reconstruct Loss = 0.0004, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0455, Reg Loss = 11.7714, Reconstruct Loss = 0.0004, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0471, Reg Loss = 11.7675, Reconstruct Loss = 0.0004, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0466, Reg Loss = 11.7682, Reconstruct Loss = 0.0004, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0461, Reg Loss = 11.7621, Reconstruct Loss = 0.0004, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0455, Reg Loss = 11.7671, Reconstruct Loss = 0.0004, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Epoch [120/200], Training Loss: 0.0458, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/200], Validation Loss: 15.6963, Validation Accuracy: 22.22%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0253, Reg Loss = 12.1030, Reconstruct Loss = 0.0000, Cls Loss = 0.0241, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0476, Reg Loss = 11.7599, Reconstruct Loss = 0.0005, Cls Loss = 0.0460, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0472, Reg Loss = 11.7435, Reconstruct Loss = 0.0005, Cls Loss = 0.0455, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0478, Reg Loss = 11.7190, Reconstruct Loss = 0.0005, Cls Loss = 0.0461, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0474, Reg Loss = 11.7058, Reconstruct Loss = 0.0005, Cls Loss = 0.0457, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0473, Reg Loss = 11.6954, Reconstruct Loss = 0.0005, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0465, Reg Loss = 11.6806, Reconstruct Loss = 0.0006, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0461, Reg Loss = 11.6612, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Epoch [121/200], Training Loss: 0.0471, Training Accuracy: 98.55, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/200], Validation Loss: 12.7706, Validation Accuracy: 25.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0435, Reg Loss = 12.9504, Reconstruct Loss = 0.0118, Cls Loss = 0.0304, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0481, Reg Loss = 11.6807, Reconstruct Loss = 0.0011, Cls Loss = 0.0458, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0463, Reg Loss = 11.6619, Reconstruct Loss = 0.0009, Cls Loss = 0.0443, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0453, Reg Loss = 11.6263, Reconstruct Loss = 0.0008, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0453, Reg Loss = 11.6043, Reconstruct Loss = 0.0008, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 11.5815, Reconstruct Loss = 0.0008, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0463, Reg Loss = 11.5603, Reconstruct Loss = 0.0007, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0461, Reg Loss = 11.5517, Reconstruct Loss = 0.0007, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Epoch [122/200], Training Loss: 0.0456, Training Accuracy: 98.62, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/200], Validation Loss: 11.4159, Validation Accuracy: 29.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0180, Reg Loss = 10.8959, Reconstruct Loss = 0.0000, Cls Loss = 0.0169, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0443, Reg Loss = 11.4680, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0449, Reg Loss = 11.4570, Reconstruct Loss = 0.0004, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 11.4501, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0460, Reg Loss = 11.4079, Reconstruct Loss = 0.0005, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 11.3888, Reconstruct Loss = 0.0005, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0448, Reg Loss = 11.3752, Reconstruct Loss = 0.0005, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0449, Reg Loss = 11.3738, Reconstruct Loss = 0.0004, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Epoch [123/200], Training Loss: 0.0458, Training Accuracy: 98.70, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/200], Validation Loss: 11.5902, Validation Accuracy: 24.82%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1146, Reg Loss = 11.9188, Reconstruct Loss = 0.0000, Cls Loss = 0.1134, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0471, Reg Loss = 11.3341, Reconstruct Loss = 0.0004, Cls Loss = 0.0456, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0460, Reg Loss = 11.3075, Reconstruct Loss = 0.0002, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0467, Reg Loss = 11.3247, Reconstruct Loss = 0.0003, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0469, Reg Loss = 11.3288, Reconstruct Loss = 0.0003, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0455, Reg Loss = 11.3273, Reconstruct Loss = 0.0004, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0457, Reg Loss = 11.3158, Reconstruct Loss = 0.0004, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0455, Reg Loss = 11.3239, Reconstruct Loss = 0.0004, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Epoch [124/200], Training Loss: 0.0450, Training Accuracy: 98.70, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/200], Validation Loss: 9.7170, Validation Accuracy: 29.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0341, Reg Loss = 11.0584, Reconstruct Loss = 0.0000, Cls Loss = 0.0330, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0440, Reg Loss = 11.3871, Reconstruct Loss = 0.0007, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0441, Reg Loss = 11.3956, Reconstruct Loss = 0.0007, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 11.3443, Reconstruct Loss = 0.0006, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0435, Reg Loss = 11.3341, Reconstruct Loss = 0.0006, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 11.3117, Reconstruct Loss = 0.0006, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0447, Reg Loss = 11.3094, Reconstruct Loss = 0.0005, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0453, Reg Loss = 11.2898, Reconstruct Loss = 0.0005, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Epoch [125/200], Training Loss: 0.0452, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 31.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/200], Validation Loss: 16.2117, Validation Accuracy: 20.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0434, Reg Loss = 11.4791, Reconstruct Loss = 0.0000, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0476, Reg Loss = 11.1888, Reconstruct Loss = 0.0005, Cls Loss = 0.0460, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0461, Reg Loss = 11.2243, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0463, Reg Loss = 11.2152, Reconstruct Loss = 0.0005, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0467, Reg Loss = 11.2052, Reconstruct Loss = 0.0005, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0457, Reg Loss = 11.1881, Reconstruct Loss = 0.0005, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0458, Reg Loss = 11.1850, Reconstruct Loss = 0.0004, Cls Loss = 0.0443, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0455, Reg Loss = 11.1680, Reconstruct Loss = 0.0004, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Epoch [126/200], Training Loss: 0.0455, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/200], Validation Loss: 14.4215, Validation Accuracy: 22.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0542, Reg Loss = 10.6801, Reconstruct Loss = 0.0000, Cls Loss = 0.0531, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0481, Reg Loss = 11.0914, Reconstruct Loss = 0.0003, Cls Loss = 0.0467, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0484, Reg Loss = 11.0697, Reconstruct Loss = 0.0003, Cls Loss = 0.0470, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0482, Reg Loss = 11.1007, Reconstruct Loss = 0.0004, Cls Loss = 0.0466, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0461, Reg Loss = 11.1089, Reconstruct Loss = 0.0004, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0461, Reg Loss = 11.1190, Reconstruct Loss = 0.0004, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0466, Reg Loss = 11.1086, Reconstruct Loss = 0.0004, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0460, Reg Loss = 11.1045, Reconstruct Loss = 0.0004, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Epoch [127/200], Training Loss: 0.0452, Training Accuracy: 98.66, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/200], Validation Loss: 11.4972, Validation Accuracy: 26.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0504, Reg Loss = 10.3645, Reconstruct Loss = 0.0000, Cls Loss = 0.0494, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0428, Reg Loss = 11.0552, Reconstruct Loss = 0.0004, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0439, Reg Loss = 11.0562, Reconstruct Loss = 0.0005, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0432, Reg Loss = 11.0672, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0441, Reg Loss = 11.0683, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 11.0644, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0448, Reg Loss = 11.0584, Reconstruct Loss = 0.0005, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0437, Reg Loss = 11.0545, Reconstruct Loss = 0.0005, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Epoch [128/200], Training Loss: 0.0439, Training Accuracy: 98.71, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/200], Validation Loss: 6.6269, Validation Accuracy: 35.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0354, Reg Loss = 11.4039, Reconstruct Loss = 0.0000, Cls Loss = 0.0342, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0391, Reg Loss = 10.9458, Reconstruct Loss = 0.0005, Cls Loss = 0.0375, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0419, Reg Loss = 10.9511, Reconstruct Loss = 0.0003, Cls Loss = 0.0405, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0454, Reg Loss = 10.9724, Reconstruct Loss = 0.0004, Cls Loss = 0.0438, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0451, Reg Loss = 10.9864, Reconstruct Loss = 0.0004, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0449, Reg Loss = 10.9797, Reconstruct Loss = 0.0004, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0452, Reg Loss = 10.9864, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0455, Reg Loss = 10.9873, Reconstruct Loss = 0.0004, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Epoch [129/200], Training Loss: 0.0457, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/200], Validation Loss: 13.7365, Validation Accuracy: 25.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0164, Reg Loss = 11.2703, Reconstruct Loss = 0.0000, Cls Loss = 0.0153, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0452, Reg Loss = 10.9394, Reconstruct Loss = 0.0003, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0465, Reg Loss = 10.9958, Reconstruct Loss = 0.0005, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0453, Reg Loss = 10.9871, Reconstruct Loss = 0.0006, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0443, Reg Loss = 10.9868, Reconstruct Loss = 0.0006, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0444, Reg Loss = 10.9848, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0439, Reg Loss = 10.9701, Reconstruct Loss = 0.0004, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0442, Reg Loss = 10.9672, Reconstruct Loss = 0.0004, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Epoch [130/200], Training Loss: 0.0446, Training Accuracy: 98.68, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/200], Validation Loss: 9.3310, Validation Accuracy: 30.07%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0196, Reg Loss = 10.2514, Reconstruct Loss = 0.0000, Cls Loss = 0.0186, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0434, Reg Loss = 10.8378, Reconstruct Loss = 0.0001, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0426, Reg Loss = 10.8634, Reconstruct Loss = 0.0002, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0436, Reg Loss = 10.8569, Reconstruct Loss = 0.0004, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0445, Reg Loss = 10.8577, Reconstruct Loss = 0.0004, Cls Loss = 0.0430, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0448, Reg Loss = 10.8532, Reconstruct Loss = 0.0004, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0450, Reg Loss = 10.8585, Reconstruct Loss = 0.0005, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0444, Reg Loss = 10.8540, Reconstruct Loss = 0.0005, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Epoch [131/200], Training Loss: 0.0447, Training Accuracy: 98.69, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/200], Validation Loss: 10.7099, Validation Accuracy: 28.03%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0617, Reg Loss = 10.2596, Reconstruct Loss = 0.0000, Cls Loss = 0.0606, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0454, Reg Loss = 10.8191, Reconstruct Loss = 0.0006, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0445, Reg Loss = 10.8209, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0444, Reg Loss = 10.8519, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0447, Reg Loss = 10.8321, Reconstruct Loss = 0.0004, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 10.8194, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0451, Reg Loss = 10.8084, Reconstruct Loss = 0.0004, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0451, Reg Loss = 10.8092, Reconstruct Loss = 0.0004, Cls Loss = 0.0436, Learning rate = 1.0000e-04\n",
      "Epoch [132/200], Training Loss: 0.0453, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/200], Validation Loss: 15.4554, Validation Accuracy: 23.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0663, Reg Loss = 10.5468, Reconstruct Loss = 0.0000, Cls Loss = 0.0652, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0427, Reg Loss = 10.7603, Reconstruct Loss = 0.0005, Cls Loss = 0.0411, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0440, Reg Loss = 10.7784, Reconstruct Loss = 0.0005, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0427, Reg Loss = 10.7470, Reconstruct Loss = 0.0006, Cls Loss = 0.0410, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0447, Reg Loss = 10.7416, Reconstruct Loss = 0.0006, Cls Loss = 0.0430, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0449, Reg Loss = 10.7150, Reconstruct Loss = 0.0005, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0444, Reg Loss = 10.7279, Reconstruct Loss = 0.0007, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0445, Reg Loss = 10.7123, Reconstruct Loss = 0.0006, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Epoch [133/200], Training Loss: 0.0445, Training Accuracy: 98.68, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/200], Validation Loss: 12.0839, Validation Accuracy: 26.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0611, Reg Loss = 10.5425, Reconstruct Loss = 0.0000, Cls Loss = 0.0600, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0465, Reg Loss = 10.7050, Reconstruct Loss = 0.0002, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0433, Reg Loss = 10.6843, Reconstruct Loss = 0.0003, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0441, Reg Loss = 10.6672, Reconstruct Loss = 0.0003, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0441, Reg Loss = 10.6569, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0448, Reg Loss = 10.6375, Reconstruct Loss = 0.0004, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0445, Reg Loss = 10.6253, Reconstruct Loss = 0.0004, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0446, Reg Loss = 10.6250, Reconstruct Loss = 0.0004, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Epoch [134/200], Training Loss: 0.0444, Training Accuracy: 98.67, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/200], Validation Loss: 9.7761, Validation Accuracy: 28.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0394, Reg Loss = 10.2830, Reconstruct Loss = 0.0000, Cls Loss = 0.0384, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0420, Reg Loss = 10.6233, Reconstruct Loss = 0.0004, Cls Loss = 0.0406, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0429, Reg Loss = 10.6066, Reconstruct Loss = 0.0005, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0423, Reg Loss = 10.5674, Reconstruct Loss = 0.0006, Cls Loss = 0.0407, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0432, Reg Loss = 10.5605, Reconstruct Loss = 0.0007, Cls Loss = 0.0415, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0437, Reg Loss = 10.5251, Reconstruct Loss = 0.0006, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0445, Reg Loss = 10.5283, Reconstruct Loss = 0.0006, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0437, Reg Loss = 10.5240, Reconstruct Loss = 0.0006, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Epoch [135/200], Training Loss: 0.0441, Training Accuracy: 98.71, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/200], Validation Loss: 9.7579, Validation Accuracy: 31.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0350, Reg Loss = 10.4946, Reconstruct Loss = 0.0000, Cls Loss = 0.0340, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0466, Reg Loss = 10.5210, Reconstruct Loss = 0.0008, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0448, Reg Loss = 10.4961, Reconstruct Loss = 0.0007, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0446, Reg Loss = 10.4684, Reconstruct Loss = 0.0008, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0445, Reg Loss = 10.4203, Reconstruct Loss = 0.0007, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0441, Reg Loss = 10.4077, Reconstruct Loss = 0.0007, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0435, Reg Loss = 10.4129, Reconstruct Loss = 0.0007, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0440, Reg Loss = 10.3980, Reconstruct Loss = 0.0007, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Epoch [136/200], Training Loss: 0.0446, Training Accuracy: 98.72, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/200], Validation Loss: 9.6776, Validation Accuracy: 27.17%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0271, Reg Loss = 9.7238, Reconstruct Loss = 0.0000, Cls Loss = 0.0261, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0427, Reg Loss = 10.2820, Reconstruct Loss = 0.0003, Cls Loss = 0.0414, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0443, Reg Loss = 10.2835, Reconstruct Loss = 0.0002, Cls Loss = 0.0430, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0459, Reg Loss = 10.3054, Reconstruct Loss = 0.0004, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0459, Reg Loss = 10.3161, Reconstruct Loss = 0.0004, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0462, Reg Loss = 10.3312, Reconstruct Loss = 0.0005, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0460, Reg Loss = 10.3368, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0461, Reg Loss = 10.3312, Reconstruct Loss = 0.0004, Cls Loss = 0.0447, Learning rate = 1.0000e-04\n",
      "Epoch [137/200], Training Loss: 0.0468, Training Accuracy: 98.61, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/200], Validation Loss: 8.0130, Validation Accuracy: 34.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0189, Reg Loss = 10.0652, Reconstruct Loss = 0.0000, Cls Loss = 0.0179, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0419, Reg Loss = 10.2466, Reconstruct Loss = 0.0005, Cls Loss = 0.0404, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0422, Reg Loss = 10.2398, Reconstruct Loss = 0.0004, Cls Loss = 0.0408, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0416, Reg Loss = 10.2337, Reconstruct Loss = 0.0003, Cls Loss = 0.0403, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0428, Reg Loss = 10.2537, Reconstruct Loss = 0.0003, Cls Loss = 0.0415, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0432, Reg Loss = 10.2445, Reconstruct Loss = 0.0003, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0426, Reg Loss = 10.2529, Reconstruct Loss = 0.0003, Cls Loss = 0.0412, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0428, Reg Loss = 10.2568, Reconstruct Loss = 0.0003, Cls Loss = 0.0415, Learning rate = 1.0000e-04\n",
      "Epoch [138/200], Training Loss: 0.0432, Training Accuracy: 98.75, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/200], Validation Loss: 11.5621, Validation Accuracy: 25.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0369, Reg Loss = 10.5509, Reconstruct Loss = 0.0000, Cls Loss = 0.0358, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0489, Reg Loss = 10.2359, Reconstruct Loss = 0.0003, Cls Loss = 0.0476, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0490, Reg Loss = 10.2655, Reconstruct Loss = 0.0002, Cls Loss = 0.0478, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0487, Reg Loss = 10.2815, Reconstruct Loss = 0.0003, Cls Loss = 0.0474, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0478, Reg Loss = 10.2875, Reconstruct Loss = 0.0004, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0467, Reg Loss = 10.2736, Reconstruct Loss = 0.0003, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0456, Reg Loss = 10.2688, Reconstruct Loss = 0.0003, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0454, Reg Loss = 10.2672, Reconstruct Loss = 0.0004, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Epoch [139/200], Training Loss: 0.0449, Training Accuracy: 98.65, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/200], Validation Loss: 9.1553, Validation Accuracy: 33.00%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0659, Reg Loss = 10.2275, Reconstruct Loss = 0.0000, Cls Loss = 0.0649, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0439, Reg Loss = 10.1900, Reconstruct Loss = 0.0007, Cls Loss = 0.0422, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0446, Reg Loss = 10.1875, Reconstruct Loss = 0.0005, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0437, Reg Loss = 10.2045, Reconstruct Loss = 0.0003, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0447, Reg Loss = 10.1748, Reconstruct Loss = 0.0003, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0456, Reg Loss = 10.1510, Reconstruct Loss = 0.0004, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0458, Reg Loss = 10.1319, Reconstruct Loss = 0.0004, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0454, Reg Loss = 10.1052, Reconstruct Loss = 0.0004, Cls Loss = 0.0441, Learning rate = 1.0000e-04\n",
      "Epoch [140/200], Training Loss: 0.0451, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/200], Validation Loss: 9.9731, Validation Accuracy: 27.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0212, Reg Loss = 10.3506, Reconstruct Loss = 0.0000, Cls Loss = 0.0202, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0479, Reg Loss = 10.0564, Reconstruct Loss = 0.0005, Cls Loss = 0.0464, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0467, Reg Loss = 10.0542, Reconstruct Loss = 0.0004, Cls Loss = 0.0453, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0462, Reg Loss = 10.0566, Reconstruct Loss = 0.0006, Cls Loss = 0.0446, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0462, Reg Loss = 10.0640, Reconstruct Loss = 0.0006, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0468, Reg Loss = 10.0633, Reconstruct Loss = 0.0006, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0464, Reg Loss = 10.0590, Reconstruct Loss = 0.0006, Cls Loss = 0.0448, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0460, Reg Loss = 10.0647, Reconstruct Loss = 0.0006, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Epoch [141/200], Training Loss: 0.0456, Training Accuracy: 98.59, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/200], Validation Loss: 10.1216, Validation Accuracy: 27.61%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0428, Reg Loss = 10.5165, Reconstruct Loss = 0.0000, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0434, Reg Loss = 10.1269, Reconstruct Loss = 0.0008, Cls Loss = 0.0416, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0448, Reg Loss = 10.1134, Reconstruct Loss = 0.0005, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0466, Reg Loss = 10.0933, Reconstruct Loss = 0.0005, Cls Loss = 0.0452, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0464, Reg Loss = 10.0710, Reconstruct Loss = 0.0005, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0448, Reg Loss = 10.0651, Reconstruct Loss = 0.0005, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0445, Reg Loss = 10.0554, Reconstruct Loss = 0.0005, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0449, Reg Loss = 10.0421, Reconstruct Loss = 0.0005, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Epoch [142/200], Training Loss: 0.0448, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/200], Validation Loss: 7.8979, Validation Accuracy: 36.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0722, Reg Loss = 11.4118, Reconstruct Loss = 0.0120, Cls Loss = 0.0591, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0491, Reg Loss = 9.9907, Reconstruct Loss = 0.0008, Cls Loss = 0.0473, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0460, Reg Loss = 9.9523, Reconstruct Loss = 0.0006, Cls Loss = 0.0444, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0447, Reg Loss = 9.9586, Reconstruct Loss = 0.0005, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0435, Reg Loss = 9.9719, Reconstruct Loss = 0.0005, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0434, Reg Loss = 9.9777, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0440, Reg Loss = 9.9860, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0444, Reg Loss = 9.9920, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Epoch [143/200], Training Loss: 0.0440, Training Accuracy: 98.68, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/200], Validation Loss: 9.6875, Validation Accuracy: 29.67%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0174, Reg Loss = 9.9325, Reconstruct Loss = 0.0000, Cls Loss = 0.0164, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0423, Reg Loss = 9.9695, Reconstruct Loss = 0.0003, Cls Loss = 0.0410, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0441, Reg Loss = 9.9995, Reconstruct Loss = 0.0004, Cls Loss = 0.0427, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0445, Reg Loss = 9.9761, Reconstruct Loss = 0.0004, Cls Loss = 0.0431, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0440, Reg Loss = 9.9774, Reconstruct Loss = 0.0004, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0446, Reg Loss = 9.9556, Reconstruct Loss = 0.0004, Cls Loss = 0.0432, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0438, Reg Loss = 9.9397, Reconstruct Loss = 0.0003, Cls Loss = 0.0424, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0439, Reg Loss = 9.9314, Reconstruct Loss = 0.0003, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Epoch [144/200], Training Loss: 0.0443, Training Accuracy: 98.67, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/200], Validation Loss: 7.8410, Validation Accuracy: 30.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0708, Reg Loss = 9.8186, Reconstruct Loss = 0.0000, Cls Loss = 0.0698, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0441, Reg Loss = 9.9539, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0420, Reg Loss = 10.0009, Reconstruct Loss = 0.0005, Cls Loss = 0.0405, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0433, Reg Loss = 9.9978, Reconstruct Loss = 0.0006, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0443, Reg Loss = 9.9577, Reconstruct Loss = 0.0005, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0440, Reg Loss = 9.9675, Reconstruct Loss = 0.0006, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0444, Reg Loss = 9.9648, Reconstruct Loss = 0.0006, Cls Loss = 0.0428, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0444, Reg Loss = 9.9419, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-04\n",
      "Epoch [145/200], Training Loss: 0.0441, Training Accuracy: 98.68, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/200], Validation Loss: 5.8730, Validation Accuracy: 37.99%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0443, Reg Loss = 9.8097, Reconstruct Loss = 0.0000, Cls Loss = 0.0433, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0408, Reg Loss = 10.0298, Reconstruct Loss = 0.0010, Cls Loss = 0.0388, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0436, Reg Loss = 10.0040, Reconstruct Loss = 0.0007, Cls Loss = 0.0419, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0430, Reg Loss = 9.9874, Reconstruct Loss = 0.0008, Cls Loss = 0.0412, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0422, Reg Loss = 9.9838, Reconstruct Loss = 0.0008, Cls Loss = 0.0404, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0419, Reg Loss = 9.9684, Reconstruct Loss = 0.0007, Cls Loss = 0.0402, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0431, Reg Loss = 9.9580, Reconstruct Loss = 0.0006, Cls Loss = 0.0415, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0436, Reg Loss = 9.9530, Reconstruct Loss = 0.0006, Cls Loss = 0.0419, Learning rate = 1.0000e-04\n",
      "Epoch [146/200], Training Loss: 0.0440, Training Accuracy: 98.67, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/200], Validation Loss: 4.1258, Validation Accuracy: 46.56%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0302, Reg Loss = 9.4931, Reconstruct Loss = 0.0000, Cls Loss = 0.0293, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0426, Reg Loss = 9.8848, Reconstruct Loss = 0.0007, Cls Loss = 0.0409, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0412, Reg Loss = 9.8465, Reconstruct Loss = 0.0004, Cls Loss = 0.0398, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0434, Reg Loss = 9.8825, Reconstruct Loss = 0.0006, Cls Loss = 0.0418, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0438, Reg Loss = 9.8812, Reconstruct Loss = 0.0005, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0440, Reg Loss = 9.8904, Reconstruct Loss = 0.0005, Cls Loss = 0.0425, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0441, Reg Loss = 9.8824, Reconstruct Loss = 0.0005, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0436, Reg Loss = 9.8763, Reconstruct Loss = 0.0005, Cls Loss = 0.0421, Learning rate = 1.0000e-04\n",
      "Epoch [147/200], Training Loss: 0.0446, Training Accuracy: 98.63, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/200], Validation Loss: 7.6685, Validation Accuracy: 33.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0350, Reg Loss = 10.0786, Reconstruct Loss = 0.0000, Cls Loss = 0.0340, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0398, Reg Loss = 9.9207, Reconstruct Loss = 0.0007, Cls Loss = 0.0381, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0420, Reg Loss = 9.9403, Reconstruct Loss = 0.0007, Cls Loss = 0.0403, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0441, Reg Loss = 9.9358, Reconstruct Loss = 0.0006, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0442, Reg Loss = 9.9272, Reconstruct Loss = 0.0006, Cls Loss = 0.0426, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0450, Reg Loss = 9.9150, Reconstruct Loss = 0.0007, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0450, Reg Loss = 9.9070, Reconstruct Loss = 0.0006, Cls Loss = 0.0434, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0455, Reg Loss = 9.9019, Reconstruct Loss = 0.0006, Cls Loss = 0.0439, Learning rate = 1.0000e-04\n",
      "Epoch [148/200], Training Loss: 0.0452, Training Accuracy: 98.67, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 34.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/200], Validation Loss: 8.6723, Validation Accuracy: 28.69%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0270, Reg Loss = 10.0453, Reconstruct Loss = 0.0000, Cls Loss = 0.0260, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0433, Reg Loss = 9.8513, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0453, Reg Loss = 9.7957, Reconstruct Loss = 0.0003, Cls Loss = 0.0440, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0455, Reg Loss = 9.7830, Reconstruct Loss = 0.0003, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0458, Reg Loss = 9.7859, Reconstruct Loss = 0.0003, Cls Loss = 0.0445, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0465, Reg Loss = 9.8109, Reconstruct Loss = 0.0005, Cls Loss = 0.0451, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0464, Reg Loss = 9.8027, Reconstruct Loss = 0.0005, Cls Loss = 0.0449, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0458, Reg Loss = 9.8105, Reconstruct Loss = 0.0006, Cls Loss = 0.0442, Learning rate = 1.0000e-04\n",
      "Epoch [149/200], Training Loss: 0.0455, Training Accuracy: 98.62, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/200], Validation Loss: 8.5974, Validation Accuracy: 28.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0304, Reg Loss = 9.9815, Reconstruct Loss = 0.0000, Cls Loss = 0.0294, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.0469, Reg Loss = 9.8669, Reconstruct Loss = 0.0006, Cls Loss = 0.0454, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.0434, Reg Loss = 9.8581, Reconstruct Loss = 0.0005, Cls Loss = 0.0419, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.0424, Reg Loss = 9.8142, Reconstruct Loss = 0.0004, Cls Loss = 0.0410, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.0427, Reg Loss = 9.8349, Reconstruct Loss = 0.0005, Cls Loss = 0.0413, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.0428, Reg Loss = 9.8214, Reconstruct Loss = 0.0005, Cls Loss = 0.0414, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.0434, Reg Loss = 9.8065, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.0437, Reg Loss = 9.7861, Reconstruct Loss = 0.0004, Cls Loss = 0.0423, Learning rate = 1.0000e-04\n",
      "Epoch [150/200], Training Loss: 0.0436, Training Accuracy: 98.65, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/200], Validation Loss: 7.2007, Validation Accuracy: 33.78%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0417, Reg Loss = 9.8809, Reconstruct Loss = 0.0000, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 9.6774, Reconstruct Loss = 0.0001, Cls Loss = 0.0472, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0470, Reg Loss = 9.6723, Reconstruct Loss = 0.0004, Cls Loss = 0.0456, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0459, Reg Loss = 9.6606, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0454, Reg Loss = 9.6712, Reconstruct Loss = 0.0005, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0444, Reg Loss = 9.6623, Reconstruct Loss = 0.0004, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0434, Reg Loss = 9.6607, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0434, Reg Loss = 9.6581, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Epoch [151/200], Training Loss: 0.0438, Training Accuracy: 98.72, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/200], Validation Loss: 8.7969, Validation Accuracy: 31.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0641, Reg Loss = 9.3736, Reconstruct Loss = 0.0000, Cls Loss = 0.0632, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0438, Reg Loss = 9.7053, Reconstruct Loss = 0.0007, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0423, Reg Loss = 9.6996, Reconstruct Loss = 0.0008, Cls Loss = 0.0405, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0432, Reg Loss = 9.6937, Reconstruct Loss = 0.0007, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0423, Reg Loss = 9.6777, Reconstruct Loss = 0.0006, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0434, Reg Loss = 9.6869, Reconstruct Loss = 0.0006, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0445, Reg Loss = 9.6739, Reconstruct Loss = 0.0005, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0438, Reg Loss = 9.6756, Reconstruct Loss = 0.0005, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Epoch [152/200], Training Loss: 0.0440, Training Accuracy: 98.63, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/200], Validation Loss: 7.0337, Validation Accuracy: 35.82%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0589, Reg Loss = 9.7563, Reconstruct Loss = 0.0000, Cls Loss = 0.0579, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0468, Reg Loss = 9.6749, Reconstruct Loss = 0.0002, Cls Loss = 0.0456, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0448, Reg Loss = 9.6629, Reconstruct Loss = 0.0003, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0451, Reg Loss = 9.6527, Reconstruct Loss = 0.0003, Cls Loss = 0.0438, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0447, Reg Loss = 9.6602, Reconstruct Loss = 0.0004, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0440, Reg Loss = 9.6575, Reconstruct Loss = 0.0003, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0437, Reg Loss = 9.6525, Reconstruct Loss = 0.0004, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0432, Reg Loss = 9.6538, Reconstruct Loss = 0.0004, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Epoch [153/200], Training Loss: 0.0436, Training Accuracy: 98.69, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/200], Validation Loss: 6.8768, Validation Accuracy: 35.92%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0122, Reg Loss = 9.4198, Reconstruct Loss = 0.0000, Cls Loss = 0.0113, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0468, Reg Loss = 9.6063, Reconstruct Loss = 0.0005, Cls Loss = 0.0454, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0465, Reg Loss = 9.6331, Reconstruct Loss = 0.0005, Cls Loss = 0.0451, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0457, Reg Loss = 9.6519, Reconstruct Loss = 0.0005, Cls Loss = 0.0443, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0464, Reg Loss = 9.6560, Reconstruct Loss = 0.0005, Cls Loss = 0.0449, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0459, Reg Loss = 9.6469, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0448, Reg Loss = 9.6492, Reconstruct Loss = 0.0005, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0438, Reg Loss = 9.6469, Reconstruct Loss = 0.0005, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Epoch [154/200], Training Loss: 0.0443, Training Accuracy: 98.67, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/200], Validation Loss: 8.5551, Validation Accuracy: 29.61%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0653, Reg Loss = 9.8268, Reconstruct Loss = 0.0000, Cls Loss = 0.0643, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0468, Reg Loss = 9.6277, Reconstruct Loss = 0.0005, Cls Loss = 0.0454, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0486, Reg Loss = 9.6428, Reconstruct Loss = 0.0005, Cls Loss = 0.0472, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0475, Reg Loss = 9.6448, Reconstruct Loss = 0.0004, Cls Loss = 0.0461, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0461, Reg Loss = 9.6370, Reconstruct Loss = 0.0004, Cls Loss = 0.0448, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 9.6474, Reconstruct Loss = 0.0004, Cls Loss = 0.0438, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0443, Reg Loss = 9.6389, Reconstruct Loss = 0.0004, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0441, Reg Loss = 9.6299, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Epoch [155/200], Training Loss: 0.0447, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [155/200], Validation Loss: 7.1611, Validation Accuracy: 35.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0112, Reg Loss = 9.9947, Reconstruct Loss = 0.0000, Cls Loss = 0.0102, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0417, Reg Loss = 9.6237, Reconstruct Loss = 0.0003, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0423, Reg Loss = 9.6429, Reconstruct Loss = 0.0005, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0411, Reg Loss = 9.6554, Reconstruct Loss = 0.0005, Cls Loss = 0.0396, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0421, Reg Loss = 9.6516, Reconstruct Loss = 0.0005, Cls Loss = 0.0406, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0425, Reg Loss = 9.6396, Reconstruct Loss = 0.0004, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0432, Reg Loss = 9.6456, Reconstruct Loss = 0.0004, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0432, Reg Loss = 9.6541, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Epoch [156/200], Training Loss: 0.0431, Training Accuracy: 98.70, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [156/200], Validation Loss: 5.9768, Validation Accuracy: 39.61%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0504, Reg Loss = 9.7283, Reconstruct Loss = 0.0000, Cls Loss = 0.0494, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0422, Reg Loss = 9.7148, Reconstruct Loss = 0.0005, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0420, Reg Loss = 9.6877, Reconstruct Loss = 0.0004, Cls Loss = 0.0406, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0423, Reg Loss = 9.6838, Reconstruct Loss = 0.0003, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0441, Reg Loss = 9.6702, Reconstruct Loss = 0.0003, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0444, Reg Loss = 9.6725, Reconstruct Loss = 0.0004, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0439, Reg Loss = 9.6677, Reconstruct Loss = 0.0004, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0439, Reg Loss = 9.6601, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Epoch [157/200], Training Loss: 0.0440, Training Accuracy: 98.62, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/200], Validation Loss: 6.8696, Validation Accuracy: 37.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0620, Reg Loss = 9.2778, Reconstruct Loss = 0.0000, Cls Loss = 0.0610, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0452, Reg Loss = 9.6463, Reconstruct Loss = 0.0005, Cls Loss = 0.0438, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0424, Reg Loss = 9.6496, Reconstruct Loss = 0.0004, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0431, Reg Loss = 9.6486, Reconstruct Loss = 0.0004, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0423, Reg Loss = 9.6671, Reconstruct Loss = 0.0005, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0427, Reg Loss = 9.6622, Reconstruct Loss = 0.0005, Cls Loss = 0.0413, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0422, Reg Loss = 9.6547, Reconstruct Loss = 0.0004, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0426, Reg Loss = 9.6552, Reconstruct Loss = 0.0004, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Epoch [158/200], Training Loss: 0.0431, Training Accuracy: 98.77, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/200], Validation Loss: 10.3644, Validation Accuracy: 27.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0299, Reg Loss = 9.3688, Reconstruct Loss = 0.0000, Cls Loss = 0.0290, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0432, Reg Loss = 9.6896, Reconstruct Loss = 0.0005, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0438, Reg Loss = 9.6924, Reconstruct Loss = 0.0006, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0435, Reg Loss = 9.6968, Reconstruct Loss = 0.0007, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0437, Reg Loss = 9.7024, Reconstruct Loss = 0.0007, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 9.6937, Reconstruct Loss = 0.0007, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0440, Reg Loss = 9.6762, Reconstruct Loss = 0.0006, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0442, Reg Loss = 9.6612, Reconstruct Loss = 0.0006, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Epoch [159/200], Training Loss: 0.0442, Training Accuracy: 98.71, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/200], Validation Loss: 6.3008, Validation Accuracy: 36.56%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0108, Reg Loss = 9.7831, Reconstruct Loss = 0.0000, Cls Loss = 0.0099, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0474, Reg Loss = 9.5934, Reconstruct Loss = 0.0001, Cls Loss = 0.0463, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0463, Reg Loss = 9.6178, Reconstruct Loss = 0.0004, Cls Loss = 0.0449, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0460, Reg Loss = 9.6097, Reconstruct Loss = 0.0004, Cls Loss = 0.0446, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0453, Reg Loss = 9.6160, Reconstruct Loss = 0.0005, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 9.6149, Reconstruct Loss = 0.0004, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0441, Reg Loss = 9.6183, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0449, Reg Loss = 9.6182, Reconstruct Loss = 0.0005, Cls Loss = 0.0435, Learning rate = 1.0000e-05\n",
      "Epoch [160/200], Training Loss: 0.0446, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/200], Validation Loss: 5.7489, Validation Accuracy: 41.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0439, Reg Loss = 9.6704, Reconstruct Loss = 0.0000, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0389, Reg Loss = 9.5991, Reconstruct Loss = 0.0004, Cls Loss = 0.0375, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0415, Reg Loss = 9.5829, Reconstruct Loss = 0.0003, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0417, Reg Loss = 9.6183, Reconstruct Loss = 0.0005, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0429, Reg Loss = 9.6211, Reconstruct Loss = 0.0005, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0428, Reg Loss = 9.6274, Reconstruct Loss = 0.0005, Cls Loss = 0.0413, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0433, Reg Loss = 9.6259, Reconstruct Loss = 0.0005, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0435, Reg Loss = 9.6309, Reconstruct Loss = 0.0005, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Epoch [161/200], Training Loss: 0.0441, Training Accuracy: 98.67, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/200], Validation Loss: 7.3452, Validation Accuracy: 33.53%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0226, Reg Loss = 9.5677, Reconstruct Loss = 0.0000, Cls Loss = 0.0217, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0450, Reg Loss = 9.6477, Reconstruct Loss = 0.0008, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0446, Reg Loss = 9.6616, Reconstruct Loss = 0.0008, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0439, Reg Loss = 9.6390, Reconstruct Loss = 0.0006, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0446, Reg Loss = 9.6150, Reconstruct Loss = 0.0005, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0451, Reg Loss = 9.6210, Reconstruct Loss = 0.0006, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0451, Reg Loss = 9.6337, Reconstruct Loss = 0.0006, Cls Loss = 0.0435, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0446, Reg Loss = 9.6503, Reconstruct Loss = 0.0007, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Epoch [162/200], Training Loss: 0.0440, Training Accuracy: 98.68, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/200], Validation Loss: 10.0891, Validation Accuracy: 27.22%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0837, Reg Loss = 9.4714, Reconstruct Loss = 0.0000, Cls Loss = 0.0827, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0433, Reg Loss = 9.6240, Reconstruct Loss = 0.0007, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0432, Reg Loss = 9.6383, Reconstruct Loss = 0.0006, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0427, Reg Loss = 9.6507, Reconstruct Loss = 0.0007, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0434, Reg Loss = 9.6621, Reconstruct Loss = 0.0007, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0431, Reg Loss = 9.6580, Reconstruct Loss = 0.0007, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0430, Reg Loss = 9.6494, Reconstruct Loss = 0.0006, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0431, Reg Loss = 9.6483, Reconstruct Loss = 0.0006, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Epoch [163/200], Training Loss: 0.0435, Training Accuracy: 98.67, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/200], Validation Loss: 8.7207, Validation Accuracy: 29.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0599, Reg Loss = 9.7406, Reconstruct Loss = 0.0000, Cls Loss = 0.0590, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0421, Reg Loss = 9.6117, Reconstruct Loss = 0.0006, Cls Loss = 0.0405, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0402, Reg Loss = 9.5965, Reconstruct Loss = 0.0005, Cls Loss = 0.0388, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0419, Reg Loss = 9.6022, Reconstruct Loss = 0.0004, Cls Loss = 0.0405, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0432, Reg Loss = 9.6008, Reconstruct Loss = 0.0004, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0438, Reg Loss = 9.6120, Reconstruct Loss = 0.0004, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0437, Reg Loss = 9.6131, Reconstruct Loss = 0.0004, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0438, Reg Loss = 9.6173, Reconstruct Loss = 0.0005, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Epoch [164/200], Training Loss: 0.0433, Training Accuracy: 98.68, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/200], Validation Loss: 6.5561, Validation Accuracy: 38.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1039, Reg Loss = 9.4569, Reconstruct Loss = 0.0000, Cls Loss = 0.1030, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0432, Reg Loss = 9.5542, Reconstruct Loss = 0.0004, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0427, Reg Loss = 9.5863, Reconstruct Loss = 0.0004, Cls Loss = 0.0413, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0434, Reg Loss = 9.5906, Reconstruct Loss = 0.0005, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0436, Reg Loss = 9.5941, Reconstruct Loss = 0.0005, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0440, Reg Loss = 9.6082, Reconstruct Loss = 0.0005, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0443, Reg Loss = 9.5955, Reconstruct Loss = 0.0004, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0445, Reg Loss = 9.6012, Reconstruct Loss = 0.0004, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Epoch [165/200], Training Loss: 0.0441, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/200], Validation Loss: 8.2923, Validation Accuracy: 31.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0103, Reg Loss = 9.3104, Reconstruct Loss = 0.0000, Cls Loss = 0.0094, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0458, Reg Loss = 9.5901, Reconstruct Loss = 0.0004, Cls Loss = 0.0445, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0433, Reg Loss = 9.6047, Reconstruct Loss = 0.0005, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0425, Reg Loss = 9.6066, Reconstruct Loss = 0.0005, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0441, Reg Loss = 9.5986, Reconstruct Loss = 0.0005, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0439, Reg Loss = 9.5977, Reconstruct Loss = 0.0005, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0437, Reg Loss = 9.5995, Reconstruct Loss = 0.0005, Cls Loss = 0.0422, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0433, Reg Loss = 9.5952, Reconstruct Loss = 0.0006, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Epoch [166/200], Training Loss: 0.0440, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/200], Validation Loss: 6.9412, Validation Accuracy: 36.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0260, Reg Loss = 9.2293, Reconstruct Loss = 0.0000, Cls Loss = 0.0251, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0453, Reg Loss = 9.6243, Reconstruct Loss = 0.0007, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0447, Reg Loss = 9.6121, Reconstruct Loss = 0.0006, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 9.6005, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0447, Reg Loss = 9.5995, Reconstruct Loss = 0.0004, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0443, Reg Loss = 9.5729, Reconstruct Loss = 0.0004, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0437, Reg Loss = 9.5730, Reconstruct Loss = 0.0003, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0445, Reg Loss = 9.5822, Reconstruct Loss = 0.0004, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Epoch [167/200], Training Loss: 0.0444, Training Accuracy: 98.67, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/200], Validation Loss: 7.4215, Validation Accuracy: 33.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0662, Reg Loss = 8.8853, Reconstruct Loss = 0.0000, Cls Loss = 0.0653, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0423, Reg Loss = 9.5915, Reconstruct Loss = 0.0006, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0451, Reg Loss = 9.6328, Reconstruct Loss = 0.0008, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0450, Reg Loss = 9.6156, Reconstruct Loss = 0.0007, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0442, Reg Loss = 9.6198, Reconstruct Loss = 0.0008, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0452, Reg Loss = 9.6260, Reconstruct Loss = 0.0009, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0446, Reg Loss = 9.6076, Reconstruct Loss = 0.0008, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0443, Reg Loss = 9.6077, Reconstruct Loss = 0.0007, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Epoch [168/200], Training Loss: 0.0446, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [168/200], Validation Loss: 8.7825, Validation Accuracy: 29.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.1108, Reg Loss = 11.3346, Reconstruct Loss = 0.0104, Cls Loss = 0.0993, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0457, Reg Loss = 9.5891, Reconstruct Loss = 0.0009, Cls Loss = 0.0438, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0438, Reg Loss = 9.5672, Reconstruct Loss = 0.0006, Cls Loss = 0.0422, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0441, Reg Loss = 9.5622, Reconstruct Loss = 0.0006, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0432, Reg Loss = 9.5552, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0441, Reg Loss = 9.5607, Reconstruct Loss = 0.0005, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0444, Reg Loss = 9.5610, Reconstruct Loss = 0.0005, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0440, Reg Loss = 9.5570, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Epoch [169/200], Training Loss: 0.0437, Training Accuracy: 98.72, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/200], Validation Loss: 8.7912, Validation Accuracy: 27.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0218, Reg Loss = 9.4446, Reconstruct Loss = 0.0000, Cls Loss = 0.0209, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0449, Reg Loss = 9.6242, Reconstruct Loss = 0.0009, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0449, Reg Loss = 9.5920, Reconstruct Loss = 0.0006, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0451, Reg Loss = 9.5727, Reconstruct Loss = 0.0006, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0456, Reg Loss = 9.5759, Reconstruct Loss = 0.0006, Cls Loss = 0.0440, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0449, Reg Loss = 9.5714, Reconstruct Loss = 0.0006, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0454, Reg Loss = 9.5575, Reconstruct Loss = 0.0006, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0450, Reg Loss = 9.5517, Reconstruct Loss = 0.0005, Cls Loss = 0.0435, Learning rate = 1.0000e-05\n",
      "Epoch [170/200], Training Loss: 0.0453, Training Accuracy: 98.62, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/200], Validation Loss: 7.8986, Validation Accuracy: 32.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0180, Reg Loss = 8.9210, Reconstruct Loss = 0.0000, Cls Loss = 0.0171, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0428, Reg Loss = 9.4916, Reconstruct Loss = 0.0002, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0432, Reg Loss = 9.5403, Reconstruct Loss = 0.0004, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0438, Reg Loss = 9.5201, Reconstruct Loss = 0.0004, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0439, Reg Loss = 9.5064, Reconstruct Loss = 0.0003, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0431, Reg Loss = 9.5076, Reconstruct Loss = 0.0003, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0424, Reg Loss = 9.5067, Reconstruct Loss = 0.0004, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0432, Reg Loss = 9.5216, Reconstruct Loss = 0.0004, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Epoch [171/200], Training Loss: 0.0433, Training Accuracy: 98.67, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/200], Validation Loss: 6.7965, Validation Accuracy: 36.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0067, Reg Loss = 9.6338, Reconstruct Loss = 0.0000, Cls Loss = 0.0058, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0459, Reg Loss = 9.5695, Reconstruct Loss = 0.0005, Cls Loss = 0.0445, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0461, Reg Loss = 9.5354, Reconstruct Loss = 0.0005, Cls Loss = 0.0447, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0443, Reg Loss = 9.5230, Reconstruct Loss = 0.0005, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0428, Reg Loss = 9.5093, Reconstruct Loss = 0.0004, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0423, Reg Loss = 9.5103, Reconstruct Loss = 0.0004, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0429, Reg Loss = 9.5157, Reconstruct Loss = 0.0005, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0435, Reg Loss = 9.5133, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Epoch [172/200], Training Loss: 0.0435, Training Accuracy: 98.69, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/200], Validation Loss: 9.1247, Validation Accuracy: 28.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0347, Reg Loss = 9.6006, Reconstruct Loss = 0.0000, Cls Loss = 0.0338, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0437, Reg Loss = 9.5382, Reconstruct Loss = 0.0009, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0446, Reg Loss = 9.5646, Reconstruct Loss = 0.0009, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0433, Reg Loss = 9.5351, Reconstruct Loss = 0.0007, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0425, Reg Loss = 9.5449, Reconstruct Loss = 0.0007, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0429, Reg Loss = 9.5420, Reconstruct Loss = 0.0007, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0423, Reg Loss = 9.5359, Reconstruct Loss = 0.0007, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0418, Reg Loss = 9.5289, Reconstruct Loss = 0.0007, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Epoch [173/200], Training Loss: 0.0420, Training Accuracy: 98.76, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/200], Validation Loss: 7.4078, Validation Accuracy: 32.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0318, Reg Loss = 9.8177, Reconstruct Loss = 0.0000, Cls Loss = 0.0308, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0417, Reg Loss = 9.5398, Reconstruct Loss = 0.0008, Cls Loss = 0.0400, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0431, Reg Loss = 9.5412, Reconstruct Loss = 0.0006, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0443, Reg Loss = 9.5485, Reconstruct Loss = 0.0006, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0447, Reg Loss = 9.5542, Reconstruct Loss = 0.0006, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 9.5274, Reconstruct Loss = 0.0005, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0445, Reg Loss = 9.5206, Reconstruct Loss = 0.0005, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0452, Reg Loss = 9.5349, Reconstruct Loss = 0.0006, Cls Loss = 0.0437, Learning rate = 1.0000e-05\n",
      "Epoch [174/200], Training Loss: 0.0446, Training Accuracy: 98.64, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200], Validation Loss: 9.0535, Validation Accuracy: 28.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0118, Reg Loss = 9.2699, Reconstruct Loss = 0.0000, Cls Loss = 0.0109, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0405, Reg Loss = 9.4744, Reconstruct Loss = 0.0001, Cls Loss = 0.0394, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0406, Reg Loss = 9.4939, Reconstruct Loss = 0.0002, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0405, Reg Loss = 9.5003, Reconstruct Loss = 0.0003, Cls Loss = 0.0392, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0417, Reg Loss = 9.5134, Reconstruct Loss = 0.0004, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0428, Reg Loss = 9.5110, Reconstruct Loss = 0.0004, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0428, Reg Loss = 9.5129, Reconstruct Loss = 0.0004, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0430, Reg Loss = 9.5226, Reconstruct Loss = 0.0004, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Epoch [175/200], Training Loss: 0.0445, Training Accuracy: 98.67, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/200], Validation Loss: 6.1326, Validation Accuracy: 39.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0420, Reg Loss = 9.7754, Reconstruct Loss = 0.0000, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0416, Reg Loss = 9.5404, Reconstruct Loss = 0.0003, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0428, Reg Loss = 9.5230, Reconstruct Loss = 0.0004, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0429, Reg Loss = 9.5129, Reconstruct Loss = 0.0004, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0421, Reg Loss = 9.5203, Reconstruct Loss = 0.0004, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0422, Reg Loss = 9.5298, Reconstruct Loss = 0.0004, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0433, Reg Loss = 9.5342, Reconstruct Loss = 0.0005, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0436, Reg Loss = 9.5289, Reconstruct Loss = 0.0004, Cls Loss = 0.0422, Learning rate = 1.0000e-05\n",
      "Epoch [176/200], Training Loss: 0.0431, Training Accuracy: 98.71, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/200], Validation Loss: 6.3521, Validation Accuracy: 35.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0472, Reg Loss = 11.1595, Reconstruct Loss = 0.0103, Cls Loss = 0.0358, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0436, Reg Loss = 9.5433, Reconstruct Loss = 0.0003, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0450, Reg Loss = 9.5825, Reconstruct Loss = 0.0006, Cls Loss = 0.0435, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0447, Reg Loss = 9.5567, Reconstruct Loss = 0.0006, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0446, Reg Loss = 9.5459, Reconstruct Loss = 0.0005, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 9.5317, Reconstruct Loss = 0.0005, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0442, Reg Loss = 9.5306, Reconstruct Loss = 0.0005, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0445, Reg Loss = 9.5284, Reconstruct Loss = 0.0005, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Epoch [177/200], Training Loss: 0.0441, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/200], Validation Loss: 5.3392, Validation Accuracy: 39.55%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0660, Reg Loss = 8.9322, Reconstruct Loss = 0.0000, Cls Loss = 0.0651, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0474, Reg Loss = 9.5591, Reconstruct Loss = 0.0010, Cls Loss = 0.0455, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0449, Reg Loss = 9.5158, Reconstruct Loss = 0.0006, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0453, Reg Loss = 9.4807, Reconstruct Loss = 0.0005, Cls Loss = 0.0438, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0444, Reg Loss = 9.4747, Reconstruct Loss = 0.0004, Cls Loss = 0.0430, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0443, Reg Loss = 9.4760, Reconstruct Loss = 0.0004, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0438, Reg Loss = 9.4867, Reconstruct Loss = 0.0004, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0441, Reg Loss = 9.4900, Reconstruct Loss = 0.0004, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Epoch [178/200], Training Loss: 0.0437, Training Accuracy: 98.62, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/200], Validation Loss: 7.0384, Validation Accuracy: 33.91%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0222, Reg Loss = 9.7027, Reconstruct Loss = 0.0000, Cls Loss = 0.0212, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0483, Reg Loss = 9.5064, Reconstruct Loss = 0.0002, Cls Loss = 0.0471, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0438, Reg Loss = 9.4977, Reconstruct Loss = 0.0003, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0429, Reg Loss = 9.4992, Reconstruct Loss = 0.0004, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0428, Reg Loss = 9.4942, Reconstruct Loss = 0.0004, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0432, Reg Loss = 9.4827, Reconstruct Loss = 0.0004, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0428, Reg Loss = 9.4774, Reconstruct Loss = 0.0004, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0431, Reg Loss = 9.4639, Reconstruct Loss = 0.0003, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Epoch [179/200], Training Loss: 0.0440, Training Accuracy: 98.70, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/200], Validation Loss: 8.3131, Validation Accuracy: 30.92%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0580, Reg Loss = 9.2159, Reconstruct Loss = 0.0000, Cls Loss = 0.0571, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0422, Reg Loss = 9.4411, Reconstruct Loss = 0.0001, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0412, Reg Loss = 9.4315, Reconstruct Loss = 0.0001, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0414, Reg Loss = 9.4516, Reconstruct Loss = 0.0002, Cls Loss = 0.0403, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0415, Reg Loss = 9.4572, Reconstruct Loss = 0.0003, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0404, Reg Loss = 9.4461, Reconstruct Loss = 0.0003, Cls Loss = 0.0392, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0410, Reg Loss = 9.4584, Reconstruct Loss = 0.0003, Cls Loss = 0.0397, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0405, Reg Loss = 9.4577, Reconstruct Loss = 0.0003, Cls Loss = 0.0393, Learning rate = 1.0000e-05\n",
      "Epoch [180/200], Training Loss: 0.0406, Training Accuracy: 98.85, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/200], Validation Loss: 9.1912, Validation Accuracy: 28.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0795, Reg Loss = 9.3059, Reconstruct Loss = 0.0000, Cls Loss = 0.0786, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0416, Reg Loss = 9.4714, Reconstruct Loss = 0.0005, Cls Loss = 0.0402, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0421, Reg Loss = 9.4593, Reconstruct Loss = 0.0004, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0425, Reg Loss = 9.4600, Reconstruct Loss = 0.0004, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0428, Reg Loss = 9.4402, Reconstruct Loss = 0.0003, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0427, Reg Loss = 9.4465, Reconstruct Loss = 0.0004, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0434, Reg Loss = 9.4514, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0440, Reg Loss = 9.4557, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Epoch [181/200], Training Loss: 0.0446, Training Accuracy: 98.72, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/200], Validation Loss: 4.6027, Validation Accuracy: 47.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0448, Reg Loss = 9.5721, Reconstruct Loss = 0.0000, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0489, Reg Loss = 9.5001, Reconstruct Loss = 0.0005, Cls Loss = 0.0474, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0450, Reg Loss = 9.4956, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0444, Reg Loss = 9.4735, Reconstruct Loss = 0.0003, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0442, Reg Loss = 9.4887, Reconstruct Loss = 0.0004, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0441, Reg Loss = 9.4785, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0447, Reg Loss = 9.4709, Reconstruct Loss = 0.0003, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0449, Reg Loss = 9.4639, Reconstruct Loss = 0.0003, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Epoch [182/200], Training Loss: 0.0452, Training Accuracy: 98.62, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/200], Validation Loss: 8.2527, Validation Accuracy: 31.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0232, Reg Loss = 9.5902, Reconstruct Loss = 0.0000, Cls Loss = 0.0222, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0437, Reg Loss = 9.5007, Reconstruct Loss = 0.0008, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0439, Reg Loss = 9.5199, Reconstruct Loss = 0.0008, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0436, Reg Loss = 9.5050, Reconstruct Loss = 0.0008, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0430, Reg Loss = 9.4945, Reconstruct Loss = 0.0007, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0437, Reg Loss = 9.4898, Reconstruct Loss = 0.0007, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0439, Reg Loss = 9.4722, Reconstruct Loss = 0.0006, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0436, Reg Loss = 9.4717, Reconstruct Loss = 0.0006, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Epoch [183/200], Training Loss: 0.0442, Training Accuracy: 98.70, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 32.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/200], Validation Loss: 4.1569, Validation Accuracy: 48.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0281, Reg Loss = 9.2422, Reconstruct Loss = 0.0000, Cls Loss = 0.0272, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0458, Reg Loss = 9.4856, Reconstruct Loss = 0.0005, Cls Loss = 0.0444, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0464, Reg Loss = 9.4651, Reconstruct Loss = 0.0005, Cls Loss = 0.0450, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0460, Reg Loss = 9.4480, Reconstruct Loss = 0.0004, Cls Loss = 0.0446, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0452, Reg Loss = 9.4428, Reconstruct Loss = 0.0003, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0445, Reg Loss = 9.4325, Reconstruct Loss = 0.0003, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0443, Reg Loss = 9.4356, Reconstruct Loss = 0.0003, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0444, Reg Loss = 9.4328, Reconstruct Loss = 0.0003, Cls Loss = 0.0431, Learning rate = 1.0000e-05\n",
      "Epoch [184/200], Training Loss: 0.0444, Training Accuracy: 98.71, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/200], Validation Loss: 8.2914, Validation Accuracy: 30.67%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0877, Reg Loss = 9.6757, Reconstruct Loss = 0.0000, Cls Loss = 0.0867, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0455, Reg Loss = 9.4348, Reconstruct Loss = 0.0006, Cls Loss = 0.0440, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0425, Reg Loss = 9.4098, Reconstruct Loss = 0.0004, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0424, Reg Loss = 9.4027, Reconstruct Loss = 0.0004, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0431, Reg Loss = 9.4136, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0436, Reg Loss = 9.4385, Reconstruct Loss = 0.0006, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0430, Reg Loss = 9.4365, Reconstruct Loss = 0.0005, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0434, Reg Loss = 9.4244, Reconstruct Loss = 0.0005, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Epoch [185/200], Training Loss: 0.0443, Training Accuracy: 98.69, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/200], Validation Loss: 6.2047, Validation Accuracy: 37.76%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0623, Reg Loss = 9.6066, Reconstruct Loss = 0.0000, Cls Loss = 0.0613, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0453, Reg Loss = 9.3974, Reconstruct Loss = 0.0002, Cls Loss = 0.0441, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0433, Reg Loss = 9.4102, Reconstruct Loss = 0.0003, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0441, Reg Loss = 9.4083, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0446, Reg Loss = 9.4173, Reconstruct Loss = 0.0004, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0436, Reg Loss = 9.4260, Reconstruct Loss = 0.0004, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0434, Reg Loss = 9.4230, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0432, Reg Loss = 9.4192, Reconstruct Loss = 0.0004, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Epoch [186/200], Training Loss: 0.0430, Training Accuracy: 98.71, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/200], Validation Loss: 6.7185, Validation Accuracy: 36.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0694, Reg Loss = 9.6767, Reconstruct Loss = 0.0000, Cls Loss = 0.0684, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0465, Reg Loss = 9.4571, Reconstruct Loss = 0.0006, Cls Loss = 0.0450, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0442, Reg Loss = 9.4413, Reconstruct Loss = 0.0005, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0448, Reg Loss = 9.4217, Reconstruct Loss = 0.0004, Cls Loss = 0.0435, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0444, Reg Loss = 9.4167, Reconstruct Loss = 0.0003, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0438, Reg Loss = 9.4299, Reconstruct Loss = 0.0004, Cls Loss = 0.0424, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0441, Reg Loss = 9.4306, Reconstruct Loss = 0.0004, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0439, Reg Loss = 9.4330, Reconstruct Loss = 0.0005, Cls Loss = 0.0425, Learning rate = 1.0000e-05\n",
      "Epoch [187/200], Training Loss: 0.0447, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/200], Validation Loss: 7.9088, Validation Accuracy: 31.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0414, Reg Loss = 9.5105, Reconstruct Loss = 0.0000, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0447, Reg Loss = 9.4319, Reconstruct Loss = 0.0004, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0455, Reg Loss = 9.4811, Reconstruct Loss = 0.0009, Cls Loss = 0.0437, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0465, Reg Loss = 9.4778, Reconstruct Loss = 0.0008, Cls Loss = 0.0447, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0462, Reg Loss = 9.4708, Reconstruct Loss = 0.0008, Cls Loss = 0.0445, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0466, Reg Loss = 9.4684, Reconstruct Loss = 0.0008, Cls Loss = 0.0449, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0460, Reg Loss = 9.4575, Reconstruct Loss = 0.0007, Cls Loss = 0.0444, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0459, Reg Loss = 9.4585, Reconstruct Loss = 0.0007, Cls Loss = 0.0443, Learning rate = 1.0000e-05\n",
      "Epoch [188/200], Training Loss: 0.0454, Training Accuracy: 98.60, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/200], Validation Loss: 8.1209, Validation Accuracy: 31.07%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0757, Reg Loss = 9.2143, Reconstruct Loss = 0.0000, Cls Loss = 0.0748, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0411, Reg Loss = 9.4357, Reconstruct Loss = 0.0004, Cls Loss = 0.0397, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0409, Reg Loss = 9.4070, Reconstruct Loss = 0.0005, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0415, Reg Loss = 9.4040, Reconstruct Loss = 0.0005, Cls Loss = 0.0401, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0409, Reg Loss = 9.3919, Reconstruct Loss = 0.0004, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0420, Reg Loss = 9.4092, Reconstruct Loss = 0.0004, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0427, Reg Loss = 9.4051, Reconstruct Loss = 0.0004, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0429, Reg Loss = 9.4129, Reconstruct Loss = 0.0005, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Epoch [189/200], Training Loss: 0.0432, Training Accuracy: 98.71, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/200], Validation Loss: 8.7681, Validation Accuracy: 29.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0481, Reg Loss = 10.6198, Reconstruct Loss = 0.0124, Cls Loss = 0.0345, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0405, Reg Loss = 9.3879, Reconstruct Loss = 0.0005, Cls Loss = 0.0391, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0392, Reg Loss = 9.3958, Reconstruct Loss = 0.0004, Cls Loss = 0.0378, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0402, Reg Loss = 9.3998, Reconstruct Loss = 0.0004, Cls Loss = 0.0389, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0419, Reg Loss = 9.4164, Reconstruct Loss = 0.0005, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0425, Reg Loss = 9.4258, Reconstruct Loss = 0.0005, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0430, Reg Loss = 9.4290, Reconstruct Loss = 0.0006, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0423, Reg Loss = 9.4287, Reconstruct Loss = 0.0006, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Epoch [190/200], Training Loss: 0.0427, Training Accuracy: 98.71, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/200], Validation Loss: 6.8386, Validation Accuracy: 36.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0459, Reg Loss = 9.7079, Reconstruct Loss = 0.0000, Cls Loss = 0.0449, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0423, Reg Loss = 9.3832, Reconstruct Loss = 0.0005, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0429, Reg Loss = 9.4335, Reconstruct Loss = 0.0007, Cls Loss = 0.0413, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0442, Reg Loss = 9.4259, Reconstruct Loss = 0.0007, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0434, Reg Loss = 9.4165, Reconstruct Loss = 0.0006, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0430, Reg Loss = 9.4109, Reconstruct Loss = 0.0005, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0431, Reg Loss = 9.3974, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0433, Reg Loss = 9.3946, Reconstruct Loss = 0.0005, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Epoch [191/200], Training Loss: 0.0432, Training Accuracy: 98.76, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/200], Validation Loss: 7.2272, Validation Accuracy: 34.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0230, Reg Loss = 9.5638, Reconstruct Loss = 0.0000, Cls Loss = 0.0221, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0441, Reg Loss = 9.4687, Reconstruct Loss = 0.0008, Cls Loss = 0.0423, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0460, Reg Loss = 9.4641, Reconstruct Loss = 0.0008, Cls Loss = 0.0443, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0444, Reg Loss = 9.4514, Reconstruct Loss = 0.0007, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0436, Reg Loss = 9.4365, Reconstruct Loss = 0.0006, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0443, Reg Loss = 9.4295, Reconstruct Loss = 0.0006, Cls Loss = 0.0428, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0448, Reg Loss = 9.4219, Reconstruct Loss = 0.0006, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0447, Reg Loss = 9.4223, Reconstruct Loss = 0.0006, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Epoch [192/200], Training Loss: 0.0446, Training Accuracy: 98.66, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/200], Validation Loss: 8.1991, Validation Accuracy: 31.20%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0393, Reg Loss = 9.4591, Reconstruct Loss = 0.0000, Cls Loss = 0.0383, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0439, Reg Loss = 9.4414, Reconstruct Loss = 0.0007, Cls Loss = 0.0422, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0448, Reg Loss = 9.4218, Reconstruct Loss = 0.0005, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0454, Reg Loss = 9.4068, Reconstruct Loss = 0.0004, Cls Loss = 0.0440, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0450, Reg Loss = 9.4043, Reconstruct Loss = 0.0004, Cls Loss = 0.0436, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0450, Reg Loss = 9.4036, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0451, Reg Loss = 9.3925, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0448, Reg Loss = 9.3907, Reconstruct Loss = 0.0004, Cls Loss = 0.0434, Learning rate = 1.0000e-05\n",
      "Epoch [193/200], Training Loss: 0.0449, Training Accuracy: 98.57, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/200], Validation Loss: 8.5114, Validation Accuracy: 29.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0416, Reg Loss = 9.6243, Reconstruct Loss = 0.0000, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0452, Reg Loss = 9.3707, Reconstruct Loss = 0.0004, Cls Loss = 0.0439, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0422, Reg Loss = 9.3898, Reconstruct Loss = 0.0005, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0436, Reg Loss = 9.3899, Reconstruct Loss = 0.0005, Cls Loss = 0.0422, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0423, Reg Loss = 9.3850, Reconstruct Loss = 0.0005, Cls Loss = 0.0408, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0428, Reg Loss = 9.3893, Reconstruct Loss = 0.0005, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0427, Reg Loss = 9.3847, Reconstruct Loss = 0.0005, Cls Loss = 0.0413, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0432, Reg Loss = 9.3880, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Epoch [194/200], Training Loss: 0.0431, Training Accuracy: 98.69, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/200], Validation Loss: 6.8327, Validation Accuracy: 36.77%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0379, Reg Loss = 9.2366, Reconstruct Loss = 0.0000, Cls Loss = 0.0369, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0460, Reg Loss = 9.4606, Reconstruct Loss = 0.0009, Cls Loss = 0.0442, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0425, Reg Loss = 9.4252, Reconstruct Loss = 0.0006, Cls Loss = 0.0409, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0426, Reg Loss = 9.4209, Reconstruct Loss = 0.0006, Cls Loss = 0.0411, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0425, Reg Loss = 9.4137, Reconstruct Loss = 0.0006, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0426, Reg Loss = 9.4121, Reconstruct Loss = 0.0006, Cls Loss = 0.0410, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0423, Reg Loss = 9.4173, Reconstruct Loss = 0.0006, Cls Loss = 0.0407, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0434, Reg Loss = 9.4150, Reconstruct Loss = 0.0006, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Epoch [195/200], Training Loss: 0.0431, Training Accuracy: 98.72, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [195/200], Validation Loss: 6.8379, Validation Accuracy: 33.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0552, Reg Loss = 9.7111, Reconstruct Loss = 0.0000, Cls Loss = 0.0542, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0447, Reg Loss = 9.4124, Reconstruct Loss = 0.0006, Cls Loss = 0.0432, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0431, Reg Loss = 9.3738, Reconstruct Loss = 0.0003, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0425, Reg Loss = 9.3791, Reconstruct Loss = 0.0004, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0431, Reg Loss = 9.3749, Reconstruct Loss = 0.0003, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0439, Reg Loss = 9.3761, Reconstruct Loss = 0.0004, Cls Loss = 0.0426, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0450, Reg Loss = 9.3744, Reconstruct Loss = 0.0004, Cls Loss = 0.0437, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0447, Reg Loss = 9.3748, Reconstruct Loss = 0.0004, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Epoch [196/200], Training Loss: 0.0450, Training Accuracy: 98.64, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/200], Validation Loss: 5.9329, Validation Accuracy: 40.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0234, Reg Loss = 9.1031, Reconstruct Loss = 0.0000, Cls Loss = 0.0225, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0457, Reg Loss = 9.3199, Reconstruct Loss = 0.0001, Cls Loss = 0.0446, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0444, Reg Loss = 9.3432, Reconstruct Loss = 0.0002, Cls Loss = 0.0433, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0434, Reg Loss = 9.3559, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0432, Reg Loss = 9.3590, Reconstruct Loss = 0.0004, Cls Loss = 0.0419, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0429, Reg Loss = 9.3743, Reconstruct Loss = 0.0004, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0434, Reg Loss = 9.3782, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0429, Reg Loss = 9.3764, Reconstruct Loss = 0.0005, Cls Loss = 0.0415, Learning rate = 1.0000e-05\n",
      "Epoch [197/200], Training Loss: 0.0431, Training Accuracy: 98.73, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [197/200], Validation Loss: 5.5541, Validation Accuracy: 41.60%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0334, Reg Loss = 9.1734, Reconstruct Loss = 0.0000, Cls Loss = 0.0325, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0430, Reg Loss = 9.3354, Reconstruct Loss = 0.0005, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0418, Reg Loss = 9.3606, Reconstruct Loss = 0.0004, Cls Loss = 0.0404, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0441, Reg Loss = 9.3463, Reconstruct Loss = 0.0003, Cls Loss = 0.0429, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0439, Reg Loss = 9.3556, Reconstruct Loss = 0.0003, Cls Loss = 0.0427, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0430, Reg Loss = 9.3666, Reconstruct Loss = 0.0004, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0428, Reg Loss = 9.3759, Reconstruct Loss = 0.0005, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0428, Reg Loss = 9.3665, Reconstruct Loss = 0.0004, Cls Loss = 0.0414, Learning rate = 1.0000e-05\n",
      "Epoch [198/200], Training Loss: 0.0429, Training Accuracy: 98.73, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [198/200], Validation Loss: 5.4984, Validation Accuracy: 41.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0264, Reg Loss = 8.8859, Reconstruct Loss = 0.0000, Cls Loss = 0.0255, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0399, Reg Loss = 9.2611, Reconstruct Loss = 0.0003, Cls Loss = 0.0388, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0417, Reg Loss = 9.3052, Reconstruct Loss = 0.0002, Cls Loss = 0.0406, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0427, Reg Loss = 9.3058, Reconstruct Loss = 0.0002, Cls Loss = 0.0416, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0425, Reg Loss = 9.3222, Reconstruct Loss = 0.0004, Cls Loss = 0.0412, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0431, Reg Loss = 9.3155, Reconstruct Loss = 0.0004, Cls Loss = 0.0418, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0435, Reg Loss = 9.3230, Reconstruct Loss = 0.0004, Cls Loss = 0.0421, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0431, Reg Loss = 9.3283, Reconstruct Loss = 0.0005, Cls Loss = 0.0417, Learning rate = 1.0000e-05\n",
      "Epoch [199/200], Training Loss: 0.0440, Training Accuracy: 98.65, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/200], Validation Loss: 7.4560, Validation Accuracy: 33.03%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.0137, Reg Loss = 8.9574, Reconstruct Loss = 0.0000, Cls Loss = 0.0128, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.0372, Reg Loss = 9.2866, Reconstruct Loss = 0.0002, Cls Loss = 0.0361, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.0409, Reg Loss = 9.3213, Reconstruct Loss = 0.0005, Cls Loss = 0.0395, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.0414, Reg Loss = 9.3214, Reconstruct Loss = 0.0004, Cls Loss = 0.0401, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.0433, Reg Loss = 9.3342, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.0434, Reg Loss = 9.3337, Reconstruct Loss = 0.0004, Cls Loss = 0.0420, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.0436, Reg Loss = 9.3357, Reconstruct Loss = 0.0004, Cls Loss = 0.0422, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.0436, Reg Loss = 9.3337, Reconstruct Loss = 0.0004, Cls Loss = 0.0422, Learning rate = 1.0000e-05\n",
      "Epoch [200/200], Training Loss: 0.0436, Training Accuracy: 98.70, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/200], Validation Loss: 5.5063, Validation Accuracy: 38.86%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the epochs\n",
    "for epoch in range(start_epoch, args.experiment.num_epochs):\n",
    "    # Train the hypernetwork to generate a model with random dimension for one epoch\n",
    "    train_loss, dim_dict, gt_model_dict, train_acc = train_one_epoch(hyper_model, train_loader, optimizer, criterion, \n",
    "                                                                     dim_dict, gt_model_dict, epoch_idx=epoch, ema=ema, \n",
    "                                                                     args=args, device=device)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the training loss and learning rate\n",
    "    print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc*100:.2f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # If it's time to evaluate the model\n",
    "    if (epoch + 1) % args.experiment.eval_interval == 0:\n",
    "        # Apply EMA if it is specified\n",
    "        if ema:\n",
    "            ema.apply()  # Save the weights of original model created before training_loop\n",
    "        \n",
    "        # Sample the merged model (create model of same structure before training loop by using the hypernetwork)\n",
    "        # And then test the performance of the hypernetwork by seeing how good it is in generating the weights\n",
    "        model = sample_merge_model(hyper_model, model, args) \n",
    "        # Validate the merged model\n",
    "        val_loss, acc = validate_single(model, val_loader, val_criterion, args=args)\n",
    "\n",
    "        # If EMA is specified, restore the original weights\n",
    "        if ema:\n",
    "            ema.restore()  # Restore the original weights to the weights of the pretrained networks\n",
    "\n",
    "        # Log the validation loss and accuracy to wandb\n",
    "        wandb.log({\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": acc\n",
    "        })\n",
    "        # Print the validation loss and accuracy\n",
    "        print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Save the checkpoint if the accuracy is better than the previous best\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_checkpoint(f\"{args.training.save_model_path}/cifar10_nerf_best.pth\",hyper_model,optimizer,ema,epoch,best_acc)\n",
    "            print(f\"Checkpoint saved at epoch {epoch} with accuracy: {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31152508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>██▄▃▃▂▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Learning rate</td><td>███████████████████▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss</td><td>██▆▆▆▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>Reconstruct Loss</td><td>█▇▇▅▁▄▂▄▁▁▄▄▄▅▅▃▃▃▃▃▃▃▄▂▃▃▄▁▃▂▁▁▄▂▁▄▃▃▂▃</td></tr><tr><td>Reg Loss</td><td>▁▂▄▄▄▄▄▅▆▆▇▇▇▇▇███▇█▇███▇▆▆▆▆▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>Training accuracy</td><td>▁▃▅▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Validation Accuracy</td><td>▅▆▄▅▃▁▁▁▄▂▂▁▂▂▃▂▄▂▃▃▃▃▄▄▆▇▅▇▇█▅▆█▆██▅█▆█</td></tr><tr><td>Validation Loss</td><td>▁▄▄▄▄▄▅▆█▅▆█▇▆▃▇▆██▅▅▄█▄▅▄▃▂▃▃▂▂▂▂▂▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>0.04222</td></tr><tr><td>Learning rate</td><td>1e-05</td></tr><tr><td>Loss</td><td>0.04359</td></tr><tr><td>Reconstruct Loss</td><td>0.00044</td></tr><tr><td>Reg Loss</td><td>9.33373</td></tr><tr><td>Training accuracy</td><td>0.98704</td></tr><tr><td>Validation Accuracy</td><td>0.3886</td></tr><tr><td>Validation Loss</td><td>5.50633</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20250530111917-dense_20th_experiment</strong> at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/m32hvkdp' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial/runs/m32hvkdp</a><br> View project at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/dense-inr-trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250530_111918-m32hvkdp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e92a8",
   "metadata": {},
   "source": [
    "### 7 Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ac18d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_hypernet_path = args.training.save_model_path + '/cifar10_nerf_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1aa0d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy/experiments_densenet/dense_20th_experiment/cifar10_nerf_best.pth'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_hypernet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d59b8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "hyper_model_test = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4d3b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(saved_hypernet_path, map_location=\"cpu\")  # or \"cuda\" if using GPU\n",
    "hyper_model_test.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a834964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 12, Validation Loss: 9.7371, Validation Accuracy: 34.07%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 13, Validation Loss: 12.6486, Validation Accuracy: 28.75%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 14, Validation Loss: 14.2502, Validation Accuracy: 23.93%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 15, Validation Loss: 17.6085, Validation Accuracy: 25.04%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 16, Validation Loss: 11.4885, Validation Accuracy: 28.00%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 17, Validation Loss: 13.4291, Validation Accuracy: 25.77%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 18, Validation Loss: 2.8830, Validation Accuracy: 50.00%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 19, Validation Loss: 16.0110, Validation Accuracy: 21.07%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 20, Validation Loss: 7.8439, Validation Accuracy: 32.89%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 21, Validation Loss: 9.7168, Validation Accuracy: 29.37%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 22, Validation Loss: 11.2336, Validation Accuracy: 24.66%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 23, Validation Loss: 8.4449, Validation Accuracy: 29.59%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 24, Validation Loss: 8.7883, Validation Accuracy: 34.10%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 25, Validation Loss: 9.0409, Validation Accuracy: 31.10%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 26, Validation Loss: 9.3659, Validation Accuracy: 34.59%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 27, Validation Loss: 11.5001, Validation Accuracy: 25.73%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 45.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 28, Validation Loss: 15.1476, Validation Accuracy: 27.48%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 29, Validation Loss: 5.7368, Validation Accuracy: 35.78%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 30, Validation Loss: 11.2974, Validation Accuracy: 28.20%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 31, Validation Loss: 8.7017, Validation Accuracy: 32.37%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 32, Validation Loss: 11.7477, Validation Accuracy: 31.18%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 33, Validation Loss: 1.9817, Validation Accuracy: 62.87%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 34, Validation Loss: 5.6612, Validation Accuracy: 42.18%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 35, Validation Loss: 6.1205, Validation Accuracy: 38.51%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 36, Validation Loss: 15.3799, Validation Accuracy: 25.70%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 37, Validation Loss: 11.7321, Validation Accuracy: 24.95%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 38, Validation Loss: 12.6469, Validation Accuracy: 25.06%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 39, Validation Loss: 13.9622, Validation Accuracy: 25.63%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 40, Validation Loss: 10.6248, Validation Accuracy: 26.18%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 41, Validation Loss: 5.6883, Validation Accuracy: 36.49%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 42, Validation Loss: 6.6273, Validation Accuracy: 35.82%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 43, Validation Loss: 11.9562, Validation Accuracy: 27.02%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 44, Validation Loss: 7.5024, Validation Accuracy: 34.35%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 45, Validation Loss: 9.6257, Validation Accuracy: 29.93%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 46, Validation Loss: 2.2847, Validation Accuracy: 56.43%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 47, Validation Loss: 6.8339, Validation Accuracy: 32.36%\n",
      "\n",
      "\n",
      "Loading model from toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'DenseNet', 'pretrained_path': 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth', 'layers': 40, 'growth': 12, 'compression': 0.5, 'bottleneck': True, 'drop_rate': 0.0}: hidden_dim 48, Validation Loss: 1.1644, Validation Accuracy: 71.63%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in range(12, 49):\n",
    "    # Create a model for this given dimension\n",
    "    model_trained = create_model(args.model.type,\n",
    "                                 layers=args.model.layers,\n",
    "                                 growth=args.model.growth,\n",
    "                                 compression=args.model.compression,\n",
    "                                 bottleneck=args.model.bottleneck,\n",
    "                                 drop_rate=args.model.drop_rate,\n",
    "                                 path=args.model.pretrained_path,\n",
    "                                 hidden_dim=hidden_dim).to(device)\n",
    "    \n",
    "    # If EMA is specified, apply it\n",
    "    if ema:\n",
    "        print('Applying EMA')\n",
    "        ema.apply()\n",
    "\n",
    "    # Sample the merged model\n",
    "    accumulated_model = sample_merge_model(hyper_model_test, model_trained, args, K=100)\n",
    "\n",
    "    # Validate the merged model\n",
    "    val_loss, acc = validate_single(accumulated_model, val_loader, val_criterion, args=args)\n",
    "\n",
    "    # If EMA is specified, restore the original weights after applying EMA\n",
    "    if ema:\n",
    "        ema.restore()  # Restore the original weights after applying \n",
    "        \n",
    "    # Save the model\n",
    "    save_name = os.path.join(args.training.save_model_path, f\"cifar10_{accumulated_model.__class__.__name__}_dim{hidden_dim}_single.pth\")\n",
    "    torch.save(accumulated_model.state_dict(),save_name)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test using model {args.model}: hidden_dim {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Define the directory and filename structure\n",
    "    filename = f\"cifar10_results_{args.experiment.name}.txt\"\n",
    "    filepath = os.path.join(args.training.save_model_path, filename)\n",
    "\n",
    "    # Write the results. 'a' is used to append the results; a new file will be created if it doesn't exist.\n",
    "    with open(filepath, \"a\") as file:\n",
    "        file.write(f\"Hidden_dim: {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
