{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4faf3c9",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7f334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e39782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe9dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_model_cifar10 as create_model\n",
    "from neumeta.utils import (\n",
    "    parse_args, print_omegaconf,\n",
    "    load_checkpoint, save_checkpoint,\n",
    "    set_seed,\n",
    "    get_cifar10, \n",
    "    sample_coordinates, sample_subset, shuffle_coordinates_all,\n",
    "    get_hypernetwork, get_optimizer, \n",
    "    sample_weights,\n",
    "    weighted_regression_loss, validate_single, AverageMeter, EMA,\n",
    "    sample_single_model, sample_merge_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cea0a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad05e8",
   "metadata": {},
   "source": [
    "### 1 Find maximum dimension of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504abeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dim(model_cls):\n",
    "    \"\"\"Find maximum dimension of the model\"\"\"\n",
    "    # Get the learnable parameters of the model\n",
    "    checkpoint = model_cls.learnable_parameter \n",
    "\n",
    "    # Set the maximum value to the length of the checkpoint\n",
    "    max_value = len(checkpoint)\n",
    "\n",
    "    # Iterate over the new model's weight\n",
    "    for i, (k, tensor) in enumerate(checkpoint.items()):\n",
    "        # Handle 2D tensors (e.g., weight matrices) \n",
    "        if len(tensor.shape) == 4:\n",
    "            coords = [tensor.shape[0], tensor.shape[1]]\n",
    "            max_value = max(max_value, max(coords))\n",
    "        # Handle 1D tensors (e.g., biases)\n",
    "        elif len(tensor.shape) == 1:\n",
    "            max_value = max(max_value, tensor.shape[0])\n",
    "    \n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413443e",
   "metadata": {},
   "source": [
    "### 2 Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f49acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wandb(config):\n",
    "    import time\n",
    "    \"\"\"\n",
    "    Initializes Weights and Biases (wandb) with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        configuration (dict): Configuration parameters for the run.\n",
    "    \"\"\"\n",
    "    # Name the run using current time and configuration name\n",
    "    run_name = f\"{time.strftime('%Y%m%d%H%M%S')}-{config.experiment.name}\"\n",
    "    \n",
    "    wandb.init(project=\"ninr-trial\", name=run_name, config=dict(config), group='cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cc73b",
   "metadata": {},
   "source": [
    "### 3 Initialize model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed520bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(args, device):\n",
    "    \"\"\"\n",
    "    Initializes a dictionary of models for each dimension in the given range, along with ground truth models for the starting dimension.\n",
    "\n",
    "    Args:\n",
    "        args: An object containing the arguments for initializing the models.\n",
    "\n",
    "    Returns:\n",
    "        dim_dict: A dictionary containing the models for each dimension, along with their corresponding coordinates, keys, indices, size, and ground truth models.\n",
    "        gt_model_dict: A dictionary containing the ground truth models for the starting dimension.\n",
    "    \"\"\"\n",
    "    dim_dict = {}\n",
    "    gt_model_dict = {}\n",
    "    \n",
    "    # Create a model for each dimension in dimensions range\n",
    "    for dim in args.dimensions.range:\n",
    "        model_cls = create_model(args.model.type,\n",
    "                                 hidden_dim=dim,\n",
    "                                 path=args.model.pretrained_path,\n",
    "                                 smooth=args.model.smooth).to(device)\n",
    "        # Sample the coordinates, keys, indices, and the size for the model\n",
    "        coords_tensor, keys_list, indices_list, size_list = sample_coordinates(model_cls)\n",
    "        # Add the model, coordinates, keys, indices, size, and key mask to the dictionary\n",
    "        dim_dict[f\"{dim}\"] = (model_cls, coords_tensor, keys_list, indices_list, size_list, None)\n",
    "\n",
    "        # Print to makes line better\n",
    "        print('\\n')\n",
    "        \n",
    "        # If the dimension is the starting dimension (the dimension of pretrained_model), add the ground truth model to the dictionary\n",
    "        if dim == args.dimensions.start:\n",
    "            print(f\"Loading model for dim {dim}\")\n",
    "            model_trained = create_model(args.model.type, \n",
    "                                         hidden_dim=dim, \n",
    "                                         path=args.model.pretrained_path, \n",
    "                                         smooth=args.model.smooth).to(device)\n",
    "            model_trained.eval()\n",
    "            gt_model_dict[f'{dim}'] = model_trained\n",
    "\n",
    "    \n",
    "    return dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b8aa0",
   "metadata": {},
   "source": [
    "### 4 Training function for target model of a random dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab93eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, dim_dict, gt_model_dict, epoch_idx, ema=None, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    reconstruct_losses = AverageMeter()\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Preprocess input\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Move the data to the device\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # Choose a random hidden dimension\n",
    "        hidden_dim = random.choice(args.dimensions.range)\n",
    "        # Get the model class, coordinates, keys, indices, size, and key mask for the chosen dimension\n",
    "        model_cls, coords_tensor, keys_list, indices_list, size_list, key_mask = dim_dict[f\"{hidden_dim}\"]\n",
    "        # Sample a subset the input tensor of the coordinates, keys, indices, size, and selected keys\n",
    "        coords_tensor, keys_list, indices_list, size_list, selected_keys = sample_subset(coords_tensor,\n",
    "                                                                                         keys_list,\n",
    "                                                                                         indices_list,\n",
    "                                                                                         size_list,\n",
    "                                                                                         key_mask,\n",
    "                                                                                         ratio=args.ratio)\n",
    "        # Add noise to the coordinates if specified\n",
    "        if args.training.coordinate_noise > 0.0:\n",
    "            coords_tensor = coords_tensor + (torch.rand_like(coords_tensor) - 0.5) * args.training.coordinate_noise\n",
    "\n",
    "\n",
    "        # Main task of hypernetwork and target network\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Sample the weights for the target model using hypernetwork\n",
    "        model_cls, reconstructed_weights = sample_weights(model, model_cls,\n",
    "                                                          coords_tensor, keys_list, indices_list, size_list, key_mask, selected_keys,\n",
    "                                                          device=device, NORM=args.dimensions.norm)\n",
    "        # Forward pass\n",
    "        predict = model_cls(x)\n",
    "\n",
    "\n",
    "        # Compute losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Compute classification loss\n",
    "        cls_loss = criterion(predict, target) \n",
    "        # Compute regularization loss\n",
    "        reg_loss = sum([torch.norm(w, p=2) for w in reconstructed_weights])\n",
    "        # Compute reconstruction loss if ground truth model is available\n",
    "        if f\"{hidden_dim}\" in gt_model_dict:\n",
    "            gt_model = gt_model_dict[f\"{hidden_dim}\"]\n",
    "            gt_selected_weights = [\n",
    "                w for k, w in gt_model.learnable_parameter.items() if k in selected_keys]\n",
    "\n",
    "            reconstruct_loss = weighted_regression_loss(\n",
    "                reconstructed_weights, gt_selected_weights)\n",
    "        else:\n",
    "            reconstruct_loss = torch.tensor(0.0)\n",
    "        # Compute the total loss\n",
    "        loss = args.hyper_model.loss_weight.ce_weight * cls_loss + args.hyper_model.loss_weight.reg_weight * \\\n",
    "            reg_loss + args.hyper_model.loss_weight.recon_weight * reconstruct_loss\n",
    "\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Zero the gradients of the updated weights\n",
    "        for updated_weight in model_cls.parameters():\n",
    "            updated_weight.grad = None\n",
    "\n",
    "        # Compute the gradients of the reconstructed weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        torch.autograd.backward(reconstructed_weights, [\n",
    "                                w.grad for k, w in model_cls.named_parameters() if k in selected_keys])\n",
    "        \n",
    "        # Clip the gradients if specified\n",
    "        if args.training.get('clip_grad', 0.0) > 0:\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), args.training.clip_grad)\n",
    "            \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the EMA if specified\n",
    "        if ema:\n",
    "            ema.update()  # Update the EMA after each training step\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update the AverageMeter objects\n",
    "        losses.update(loss.item())\n",
    "        cls_losses.update(cls_loss.item())\n",
    "        reg_losses.update(reg_loss.item())\n",
    "        reconstruct_losses.update(reconstruct_loss.item())\n",
    "\n",
    "\n",
    "        # Log (or plot) losses\n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        # Log the losses and learning rate to wandb\n",
    "        if batch_idx % args.experiment.log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"Loss\": losses.avg,\n",
    "                \"Cls Loss\": cls_losses.avg,\n",
    "                \"Reg Loss\": reg_losses.avg,\n",
    "                \"Reconstruct Loss\": reconstruct_losses.avg,\n",
    "                \"Learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }, step=batch_idx + epoch_idx * len(train_loader))\n",
    "            # Print the losses and learning rate\n",
    "            print(\n",
    "                f\"Iteration {batch_idx}: Loss = {losses.avg:.4f}, Reg Loss = {reg_losses.avg:.4f}, Reconstruct Loss = {reconstruct_losses.avg:.4f}, Cls Loss = {cls_losses.avg:.4f}, Learning rate = {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "    \n",
    "    # Returns the training loss, structure of network in each dimension, and the original structure of pretrained network\n",
    "    return losses.avg, dim_dict, gt_model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d8965",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e292aae",
   "metadata": {},
   "source": [
    "### 0 Set device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670c10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd9af3",
   "metadata": {},
   "source": [
    "### 1 Parsing arguments for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21d5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = 'neumeta/config/resnet20_cifar10_32-64v3_200e-coordnoise-resmlpv2_smooth_5_256_16_smooth.yaml'\n",
    "RATIO = '1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6fd9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv_train = ['--config', CONFIG_PATH, '--ratio', RATIO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebf601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base config from toy/experiments/base_config.yaml\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                 Key                  |                                                                Value                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|           experiment.name            |                          ninr_resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16_smooth                          |\n",
      "|         experiment.recononly         |                                                                  0                                                                   |\n",
      "|        experiment.num_epochs         |                                                                 200                                                                  |\n",
      "|       experiment.log_interval        |                                                                 100                                                                  |\n",
      "|       experiment.eval_interval       |                                                                  1                                                                   |\n",
      "|           experiment.seed            |                                                                  42                                                                  |\n",
      "|              model.type              |                                                               ResNet20                                                               |\n",
      "|        model.pretrained_path         |                                           toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth                                            |\n",
      "|             model.smooth             |                                                                 True                                                                 |\n",
      "|        training.learning_rate        |                                                                0.001                                                                 |\n",
      "|         training.batch_size          |                                                                  64                                                                  |\n",
      "|      training.coordinate_noise       |                                                                 1.0                                                                  |\n",
      "|          training.lr_steps           |                                                              [100, 150]                                                              |\n",
      "|        training.weight_decay         |                                                                 0.01                                                                 |\n",
      "|          training.clip_grad          |                                                                 10.0                                                                 |\n",
      "|       training.save_model_path       |                    toy/experiments/resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16_smooth                     |\n",
      "|        hyper_model.input_dim         |                                                                  6                                                                   |\n",
      "|        hyper_model.hidden_dim        |                                                                 256                                                                  |\n",
      "|        hyper_model.num_layers        |                                                                  5                                                                   |\n",
      "|        hyper_model.num_freqs         |                                                                  16                                                                  |\n",
      "|        hyper_model.output_dim        |                                                                  9                                                                   |\n",
      "|        hyper_model.ema_decay         |                                                                0.995                                                                 |\n",
      "|  hyper_model.loss_weight.ce_weight   |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.reg_weight  |                                                                0.0001                                                                |\n",
      "| hyper_model.loss_weight.recon_weight |                                                                 1.0                                                                  |\n",
      "|  hyper_model.loss_weight.kd_weight   |                                                                 0.1                                                                  |\n",
      "|           hyper_model.type           |                                                                resmlp                                                                |\n",
      "|           dimensions.range           | [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64] |\n",
      "|           dimensions.test            |                                                                  32                                                                  |\n",
      "|           dimensions.norm            |                                                                  64                                                                  |\n",
      "|           dimensions.start           |                                                                  64                                                                  |\n",
      "|             base_config              |                                                   toy/experiments/base_config.yaml                                                   |\n",
      "|                config                |                     neumeta/config/resnet20_cifar10_32-64v3_200e-coordnoise-resmlpv2_smooth_5_256_16_smooth.yaml                     |\n",
      "|                ratio                 |                                                                 1.0                                                                  |\n",
      "|             resume_from              |                                                                 None                                                                 |\n",
      "|              load_from               |                                                                 None                                                                 |\n",
      "|           test_result_path           |                                                                 None                                                                 |\n",
      "|                 test                 |                                                                False                                                                 |\n",
      "+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(argv_train)  # Parse arguments\n",
    "print_omegaconf(args)  # Print arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84954fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed... 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.experiment.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2086b8",
   "metadata": {},
   "source": [
    "### 2 Get training and validation data (in dataloader format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633b90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_cifar10(args.training.batch_size, strong_transform=args.training.get('strong_aug', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685e32a",
   "metadata": {},
   "source": [
    "### 3 Create target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d8f75",
   "metadata": {},
   "source": [
    "#### 3.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47436d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1321.4044189453125\n",
      "Permuted TV original model: 1039.4691162109375\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args.model.type,\n",
    "                     hidden_dim=args.dimensions.start,\n",
    "                     path=args.model.pretrained_path,\n",
    "                     smooth=args.model.smooth).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb133f",
   "metadata": {},
   "source": [
    "#### 3.1 Print the structure and shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09f9614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): Identity()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock_Resize(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b86d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3.2.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv1.bias torch.Size([64])\n",
      "layer3.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, (k, tensor) in enumerate(model.learnable_parameter.items()):\n",
    "    print(k, tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f7b45",
   "metadata": {},
   "source": [
    "#### 3.2 The maximum dimension of the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad8c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum DIM: 64\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum dimension of the model\n",
    "print(f'Maximum DIM: {find_max_dim(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195929e",
   "metadata": {},
   "source": [
    "#### 3.3 Validate the accuracy of pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d75f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 55.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.2825, Validation Accuracy: 92.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(model, val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb61dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learnable parameters of the model\n",
    "checkpoint = model.learnable_parameter\n",
    "# Get the number of parameters\n",
    "number_param = len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2fe99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters keys: ['layer3.2.conv1.weight', 'layer3.2.conv1.bias', 'layer3.2.conv2.weight', 'layer3.2.conv2.bias']\n",
      "Number of parameters to be learned: 4\n"
     ]
    }
   ],
   "source": [
    "# Print the keys of the parameters and the number of parameters\n",
    "print(f\"Parameters keys: {model.keys}\")\n",
    "print(f\"Number of parameters to be learned: {number_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5fa6f",
   "metadata": {},
   "source": [
    "### 4 Create the hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa4a2f",
   "metadata": {},
   "source": [
    "#### 4.0 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82e9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Get the hypermodel\n",
    "hyper_model = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297bd73",
   "metadata": {},
   "source": [
    "#### 4.1 Print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903829b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF_ResMLP_Compose(\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (model): ModuleList(\n",
       "    (0-3): 4 x NeRF_MLP_Residual_Scaled(\n",
       "      (initial_layer): Linear(in_features=198, out_features=256, bias=True)\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (scalars): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (2): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "          (3): Parameter containing: [torch.float32 of size  (cuda:0)]\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "      (output_layer): Linear(in_features=256, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d592e",
   "metadata": {},
   "source": [
    "#### 4.2 Initialize EMA to track only a smooth version of the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a4812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA\n",
    "ema = EMA(hyper_model, decay=args.hyper_model.ema_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffae0",
   "metadata": {},
   "source": [
    "### 5 Get Loss function, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079aa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, val_criterion, optimizer, scheduler = get_optimizer(args, hyper_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7561c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Val_criterion: CrossEntropyLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x00000235D7488610>\n"
     ]
    }
   ],
   "source": [
    "print(f'Criterion: {criterion}\\nVal_criterion: {val_criterion}\\nOptimizer: {optimizer}\\nScheduler: {scheduler}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906454",
   "metadata": {},
   "source": [
    "### 6 Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d1d4f",
   "metadata": {},
   "source": [
    "#### 6.1 Initialize training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2cdca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the starting epoch and best accuracy\n",
    "start_epoch = 0\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373217",
   "metadata": {},
   "source": [
    "#### 6.2 Directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35a2746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to save the model\n",
    "os.makedirs(args.training.save_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504af23",
   "metadata": {},
   "source": [
    "#### 6.3 Resume training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "714db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume_from:\n",
    "        print(f\"Resuming from checkpoint: {args.resume_from}\")\n",
    "        checkpoint_info = load_checkpoint(args.resume_from, hyper_model, optimizer, ema)\n",
    "        start_epoch = checkpoint_info['epoch']\n",
    "        best_acc = checkpoint_info['best_acc']\n",
    "        print(f\"Resuming from epoch: {start_epoch}, best accuracy: {best_acc*100:.2f}%\")\n",
    "        # Note: If there are more elements to retrieve, do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a3248",
   "metadata": {},
   "source": [
    "#### 6.4 Initialize wandb for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9fd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mefradosuryadi\u001b[0m (\u001b[33mefradosuryadi-universitas-indonesia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Main\\Education\\Skripsi\\Codes\\1-experiment\\code-trials\\neumeta-trial\\wandb\\run-20250520_052852-61limfrt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/61limfrt' target=\"_blank\">20250520052850-ninr_resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16_smooth</a></strong> to <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/61limfrt' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/61limfrt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "initialize_wandb(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46056e65",
   "metadata": {},
   "source": [
    "#### 6.5 Initialize model dictionary for each dimension and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641149b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2145.013427734375\n",
      "Permuted TV original model: 2026.074951171875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2189.1943359375\n",
      "Permuted TV original model: 2082.717041015625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2238.868896484375\n",
      "Permuted TV original model: 2126.083251953125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2279.739501953125\n",
      "Permuted TV original model: 2160.0830078125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2322.078125\n",
      "Permuted TV original model: 2206.77490234375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2378.829345703125\n",
      "Permuted TV original model: 2258.082275390625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2426.804931640625\n",
      "Permuted TV original model: 2311.1318359375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2481.0322265625\n",
      "Permuted TV original model: 2357.761474609375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2512.455322265625\n",
      "Permuted TV original model: 2384.34326171875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2542.427734375\n",
      "Permuted TV original model: 2417.08056640625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2612.404052734375\n",
      "Permuted TV original model: 2488.0048828125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2663.52783203125\n",
      "Permuted TV original model: 2533.535400390625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2680.248291015625\n",
      "Permuted TV original model: 2560.14111328125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2759.303955078125\n",
      "Permuted TV original model: 2619.108154296875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2764.61279296875\n",
      "Permuted TV original model: 2629.851318359375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2839.306884765625\n",
      "Permuted TV original model: 2713.488037109375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2891.559814453125\n",
      "Permuted TV original model: 2753.822021484375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2915.774169921875\n",
      "Permuted TV original model: 2785.911865234375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2975.538818359375\n",
      "Permuted TV original model: 2835.06103515625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3022.835205078125\n",
      "Permuted TV original model: 2874.58203125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3071.655517578125\n",
      "Permuted TV original model: 2918.1328125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3118.525634765625\n",
      "Permuted TV original model: 2968.888916015625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3181.5654296875\n",
      "Permuted TV original model: 3020.291259765625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3198.560302734375\n",
      "Permuted TV original model: 3036.58203125\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3245.9443359375\n",
      "Permuted TV original model: 3091.692138671875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3283.04443359375\n",
      "Permuted TV original model: 3141.059326171875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3352.396728515625\n",
      "Permuted TV original model: 3193.7998046875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3379.979736328125\n",
      "Permuted TV original model: 3221.863525390625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3431.7470703125\n",
      "Permuted TV original model: 3274.9052734375\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3465.706298828125\n",
      "Permuted TV original model: 3305.91796875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3532.7451171875\n",
      "Permuted TV original model: 3375.207763671875\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3592.18359375\n",
      "Permuted TV original model: 3431.21337890625\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1321.4044189453125\n",
      "Permuted TV original model: 1036.8819580078125\n",
      "\n",
      "\n",
      "Loading model for dim 64\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1321.4044189453125\n",
      "Permuted TV original model: 1040.2781982421875\n"
     ]
    }
   ],
   "source": [
    "# Initialize model dictionary\n",
    "dim_dict, gt_model_dict = init_model_dict(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d01d9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'64': CifarResNet(\n",
       "   (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn1): Identity()\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "         (1): Identity()\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "     (2): BasicBlock_Resize(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn1): Identity()\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (bn2): Identity()\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26d9c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  None)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7476d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'32': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 32., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 32., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '33': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 33., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 33., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '34': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 34., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 34., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '35': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(35, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 35., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 35., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '36': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 36., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 36., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '37': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(37, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 37., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 37., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '38': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(38, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 38., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 38., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '39': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 39., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 39., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '40': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 40., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 40., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '41': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(41, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 41., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 41., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '42': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 42., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 42., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '43': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 43., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 43., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '44': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(44, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 44., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 44., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '45': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 45., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 45., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '46': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(46, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 46., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 46., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '47': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(47, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 47., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 47., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '48': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 48., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 48., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '49': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 49., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 49., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '50': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 50., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 50., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '51': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 51., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 51., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '52': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 52., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 52., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '53': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 53., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 53., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '54': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 54., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 54., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '55': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 55., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 55., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '56': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 56., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 56., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '57': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 57., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 57., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '58': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 58., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 58., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '59': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 59., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 59., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '60': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 60., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 60., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '61': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(61, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 61., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 61., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '62': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 62., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 62., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '63': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 63., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 63., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])}),\n",
       " '64': (CifarResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "      (2): BasicBlock_Resize(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       "  tensor([[ 0.,  0.,  0.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  1.,  4., 64., 64.],\n",
       "          [ 0.,  0.,  2.,  4., 64., 64.],\n",
       "          ...,\n",
       "          [ 3., 61.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 62.,  0.,  4., 64.,  1.],\n",
       "          [ 3., 63.,  0.,  4., 64.,  1.]]),\n",
       "  array(['layer3.2.conv1.weight', 'layer3.2.conv1.weight',\n",
       "         'layer3.2.conv1.weight', ..., 'layer3.2.conv2.bias',\n",
       "         'layer3.2.conv2.bias', 'layer3.2.conv2.bias'], dtype='<U21'),\n",
       "  tensor([[ 0,  0,  3,  3],\n",
       "          [ 0,  1,  3,  3],\n",
       "          [ 0,  2,  3,  3],\n",
       "          ...,\n",
       "          [61,  0,  0,  0],\n",
       "          [62,  0,  0,  0],\n",
       "          [63,  0,  0,  0]]),\n",
       "  tensor([4, 4, 4,  ..., 1, 1, 1]),\n",
       "  {np.str_('layer3.2.conv1.bias'): tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv1.weight'): tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       "   np.str_('layer3.2.conv2.bias'): tensor([0, 0, 0,  ..., 1, 1, 1]),\n",
       "   np.str_('layer3.2.conv2.weight'): tensor([0, 0, 0,  ..., 0, 0, 0])})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dict = shuffle_coordinates_all(dim_dict)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d6ad4",
   "metadata": {},
   "source": [
    "#### 6.6 Hypernetwork training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332580b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.experiment.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f486f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 1.8145, Reg Loss = 3.1098, Reconstruct Loss = 0.0000, Cls Loss = 1.8142, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.9051, Reg Loss = 6.5934, Reconstruct Loss = 0.0014, Cls Loss = 1.9030, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8847, Reg Loss = 5.9661, Reconstruct Loss = 0.0015, Cls Loss = 1.8825, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8749, Reg Loss = 5.5874, Reconstruct Loss = 0.0016, Cls Loss = 1.8728, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8680, Reg Loss = 5.3095, Reconstruct Loss = 0.0015, Cls Loss = 1.8660, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8645, Reg Loss = 5.0454, Reconstruct Loss = 0.0014, Cls Loss = 1.8626, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8622, Reg Loss = 4.7522, Reconstruct Loss = 0.0012, Cls Loss = 1.8605, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8600, Reg Loss = 4.4929, Reconstruct Loss = 0.0010, Cls Loss = 1.8585, Learning rate = 1.0000e-03\n",
      "Epoch [1/200], Training Loss: 1.8580, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 63.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Validation Loss: 1.8090, Validation Accuracy: 74.72%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 0 with accuracy: 74.72%\n",
      "Iteration 0: Loss = 1.8691, Reg Loss = 2.8508, Reconstruct Loss = 0.0000, Cls Loss = 1.8688, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8495, Reg Loss = 2.9095, Reconstruct Loss = 0.0014, Cls Loss = 1.8478, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8457, Reg Loss = 2.8630, Reconstruct Loss = 0.0009, Cls Loss = 1.8446, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8443, Reg Loss = 2.7727, Reconstruct Loss = 0.0008, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8446, Reg Loss = 2.6236, Reconstruct Loss = 0.0009, Cls Loss = 1.8434, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8447, Reg Loss = 2.4956, Reconstruct Loss = 0.0010, Cls Loss = 1.8434, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8446, Reg Loss = 2.3807, Reconstruct Loss = 0.0012, Cls Loss = 1.8432, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8444, Reg Loss = 2.3011, Reconstruct Loss = 0.0013, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Epoch [2/200], Training Loss: 1.8441, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 64.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Validation Loss: 1.8102, Validation Accuracy: 73.20%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8388, Reg Loss = 2.0779, Reconstruct Loss = 0.0000, Cls Loss = 1.8386, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8374, Reg Loss = 1.7746, Reconstruct Loss = 0.0011, Cls Loss = 1.8361, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8423, Reg Loss = 1.6321, Reconstruct Loss = 0.0018, Cls Loss = 1.8404, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8445, Reg Loss = 1.6184, Reconstruct Loss = 0.0015, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8432, Reg Loss = 1.5984, Reconstruct Loss = 0.0015, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8432, Reg Loss = 1.5715, Reconstruct Loss = 0.0014, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8430, Reg Loss = 1.5770, Reconstruct Loss = 0.0013, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8434, Reg Loss = 1.5931, Reconstruct Loss = 0.0012, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Epoch [3/200], Training Loss: 1.8434, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Validation Loss: 1.8077, Validation Accuracy: 75.46%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 2 with accuracy: 75.46%\n",
      "Iteration 0: Loss = 1.8470, Reg Loss = 1.3151, Reconstruct Loss = 0.0000, Cls Loss = 1.8469, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8417, Reg Loss = 1.2014, Reconstruct Loss = 0.0011, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8396, Reg Loss = 1.1849, Reconstruct Loss = 0.0011, Cls Loss = 1.8385, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8416, Reg Loss = 1.2302, Reconstruct Loss = 0.0009, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8413, Reg Loss = 1.2255, Reconstruct Loss = 0.0011, Cls Loss = 1.8401, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8416, Reg Loss = 1.2827, Reconstruct Loss = 0.0011, Cls Loss = 1.8403, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8422, Reg Loss = 1.2772, Reconstruct Loss = 0.0010, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8423, Reg Loss = 1.3247, Reconstruct Loss = 0.0009, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Epoch [4/200], Training Loss: 1.8425, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Validation Loss: 1.8080, Validation Accuracy: 75.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8321, Reg Loss = 1.4896, Reconstruct Loss = 0.0000, Cls Loss = 1.8320, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8436, Reg Loss = 1.2743, Reconstruct Loss = 0.0004, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8426, Reg Loss = 1.1815, Reconstruct Loss = 0.0011, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8409, Reg Loss = 1.1396, Reconstruct Loss = 0.0011, Cls Loss = 1.8397, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8412, Reg Loss = 1.0863, Reconstruct Loss = 0.0011, Cls Loss = 1.8399, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8420, Reg Loss = 1.0418, Reconstruct Loss = 0.0011, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8419, Reg Loss = 1.0053, Reconstruct Loss = 0.0013, Cls Loss = 1.8406, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8424, Reg Loss = 0.9883, Reconstruct Loss = 0.0014, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Epoch [5/200], Training Loss: 1.8422, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Validation Loss: 1.8094, Validation Accuracy: 74.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8055, Reg Loss = 0.8352, Reconstruct Loss = 0.0000, Cls Loss = 1.8054, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8431, Reg Loss = 0.9139, Reconstruct Loss = 0.0022, Cls Loss = 1.8408, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8437, Reg Loss = 1.1479, Reconstruct Loss = 0.0020, Cls Loss = 1.8416, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8452, Reg Loss = 1.2800, Reconstruct Loss = 0.0020, Cls Loss = 1.8431, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8439, Reg Loss = 1.2585, Reconstruct Loss = 0.0016, Cls Loss = 1.8421, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8420, Reg Loss = 1.2647, Reconstruct Loss = 0.0014, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8418, Reg Loss = 1.2623, Reconstruct Loss = 0.0012, Cls Loss = 1.8405, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8423, Reg Loss = 1.2359, Reconstruct Loss = 0.0010, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Epoch [6/200], Training Loss: 1.8422, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Validation Loss: 1.8079, Validation Accuracy: 75.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8528, Reg Loss = 0.9675, Reconstruct Loss = 0.0000, Cls Loss = 1.8527, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8416, Reg Loss = 0.9346, Reconstruct Loss = 0.0015, Cls Loss = 1.8400, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8439, Reg Loss = 1.1741, Reconstruct Loss = 0.0013, Cls Loss = 1.8425, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8434, Reg Loss = 1.1365, Reconstruct Loss = 0.0011, Cls Loss = 1.8422, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8430, Reg Loss = 1.0451, Reconstruct Loss = 0.0009, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8430, Reg Loss = 1.0614, Reconstruct Loss = 0.0010, Cls Loss = 1.8420, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8428, Reg Loss = 1.1867, Reconstruct Loss = 0.0009, Cls Loss = 1.8418, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8426, Reg Loss = 1.2772, Reconstruct Loss = 0.0009, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Epoch [7/200], Training Loss: 1.8427, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Validation Loss: 1.8071, Validation Accuracy: 76.38%\n",
      "\n",
      "\n",
      "\n",
      "Checkpoint saved at epoch 6 with accuracy: 76.38%\n",
      "Iteration 0: Loss = 1.8676, Reg Loss = 1.6405, Reconstruct Loss = 0.0000, Cls Loss = 1.8674, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8381, Reg Loss = 1.4570, Reconstruct Loss = 0.0000, Cls Loss = 1.8379, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8385, Reg Loss = 1.4436, Reconstruct Loss = 0.0002, Cls Loss = 1.8381, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8403, Reg Loss = 1.3248, Reconstruct Loss = 0.0004, Cls Loss = 1.8398, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8419, Reg Loss = 1.2199, Reconstruct Loss = 0.0004, Cls Loss = 1.8414, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8422, Reg Loss = 1.1701, Reconstruct Loss = 0.0005, Cls Loss = 1.8415, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8420, Reg Loss = 1.1369, Reconstruct Loss = 0.0006, Cls Loss = 1.8413, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8419, Reg Loss = 1.1511, Reconstruct Loss = 0.0007, Cls Loss = 1.8411, Learning rate = 1.0000e-03\n",
      "Epoch [8/200], Training Loss: 1.8416, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Validation Loss: 1.8079, Validation Accuracy: 75.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8454, Reg Loss = 1.1535, Reconstruct Loss = 0.0000, Cls Loss = 1.8453, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8382, Reg Loss = 1.0068, Reconstruct Loss = 0.0007, Cls Loss = 1.8373, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8424, Reg Loss = 1.1413, Reconstruct Loss = 0.0013, Cls Loss = 1.8410, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8435, Reg Loss = 1.3806, Reconstruct Loss = 0.0010, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8438, Reg Loss = 1.3994, Reconstruct Loss = 0.0008, Cls Loss = 1.8428, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8434, Reg Loss = 1.7303, Reconstruct Loss = 0.0008, Cls Loss = 1.8424, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8413, Reg Loss = 2.2168, Reconstruct Loss = 0.0009, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8415, Reg Loss = 2.7776, Reconstruct Loss = 0.0010, Cls Loss = 1.8402, Learning rate = 1.0000e-03\n",
      "Epoch [9/200], Training Loss: 1.8404, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Validation Loss: 1.8086, Validation Accuracy: 74.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8719, Reg Loss = 7.4532, Reconstruct Loss = 0.0000, Cls Loss = 1.8711, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8440, Reg Loss = 7.8922, Reconstruct Loss = 0.0023, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8389, Reg Loss = 7.6807, Reconstruct Loss = 0.0018, Cls Loss = 1.8364, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8391, Reg Loss = 8.0533, Reconstruct Loss = 0.0018, Cls Loss = 1.8365, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8348, Reg Loss = 8.3056, Reconstruct Loss = 0.0017, Cls Loss = 1.8323, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.8317, Reg Loss = 8.7557, Reconstruct Loss = 0.0015, Cls Loss = 1.8294, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.8272, Reg Loss = 9.1381, Reconstruct Loss = 0.0014, Cls Loss = 1.8249, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.8264, Reg Loss = 9.4381, Reconstruct Loss = 0.0017, Cls Loss = 1.8238, Learning rate = 1.0000e-03\n",
      "Epoch [10/200], Training Loss: 1.8243, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Validation Loss: 1.8026, Validation Accuracy: 75.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8561, Reg Loss = 12.5804, Reconstruct Loss = 0.0000, Cls Loss = 1.8548, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.8094, Reg Loss = 11.3132, Reconstruct Loss = 0.0014, Cls Loss = 1.8069, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.8062, Reg Loss = 11.5577, Reconstruct Loss = 0.0012, Cls Loss = 1.8039, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.8021, Reg Loss = 11.6727, Reconstruct Loss = 0.0012, Cls Loss = 1.7997, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.8003, Reg Loss = 11.6516, Reconstruct Loss = 0.0013, Cls Loss = 1.7978, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7970, Reg Loss = 11.6108, Reconstruct Loss = 0.0012, Cls Loss = 1.7946, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7963, Reg Loss = 11.6359, Reconstruct Loss = 0.0011, Cls Loss = 1.7940, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7925, Reg Loss = 11.6598, Reconstruct Loss = 0.0012, Cls Loss = 1.7902, Learning rate = 1.0000e-03\n",
      "Epoch [11/200], Training Loss: 1.7904, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Validation Loss: 1.7741, Validation Accuracy: 59.73%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8374, Reg Loss = 11.5833, Reconstruct Loss = 0.0000, Cls Loss = 1.8363, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7662, Reg Loss = 11.9293, Reconstruct Loss = 0.0020, Cls Loss = 1.7629, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7673, Reg Loss = 11.9874, Reconstruct Loss = 0.0018, Cls Loss = 1.7644, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7694, Reg Loss = 11.8509, Reconstruct Loss = 0.0017, Cls Loss = 1.7666, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7666, Reg Loss = 11.7746, Reconstruct Loss = 0.0014, Cls Loss = 1.7640, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7682, Reg Loss = 11.7583, Reconstruct Loss = 0.0012, Cls Loss = 1.7658, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7663, Reg Loss = 11.7457, Reconstruct Loss = 0.0011, Cls Loss = 1.7640, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7648, Reg Loss = 11.7650, Reconstruct Loss = 0.0011, Cls Loss = 1.7625, Learning rate = 1.0000e-03\n",
      "Epoch [12/200], Training Loss: 1.7651, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Validation Loss: 1.7467, Validation Accuracy: 57.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7863, Reg Loss = 12.6748, Reconstruct Loss = 0.0000, Cls Loss = 1.7851, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7474, Reg Loss = 12.3785, Reconstruct Loss = 0.0010, Cls Loss = 1.7452, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7493, Reg Loss = 12.3728, Reconstruct Loss = 0.0007, Cls Loss = 1.7474, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7509, Reg Loss = 12.4073, Reconstruct Loss = 0.0008, Cls Loss = 1.7489, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7509, Reg Loss = 12.4955, Reconstruct Loss = 0.0006, Cls Loss = 1.7491, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7520, Reg Loss = 12.5634, Reconstruct Loss = 0.0008, Cls Loss = 1.7500, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7503, Reg Loss = 12.6207, Reconstruct Loss = 0.0008, Cls Loss = 1.7483, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7493, Reg Loss = 12.6665, Reconstruct Loss = 0.0008, Cls Loss = 1.7472, Learning rate = 1.0000e-03\n",
      "Epoch [13/200], Training Loss: 1.7486, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Validation Loss: 1.7417, Validation Accuracy: 56.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7447, Reg Loss = 11.5631, Reconstruct Loss = 0.0000, Cls Loss = 1.7436, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7409, Reg Loss = 13.0650, Reconstruct Loss = 0.0016, Cls Loss = 1.7380, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7311, Reg Loss = 13.2334, Reconstruct Loss = 0.0011, Cls Loss = 1.7286, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7322, Reg Loss = 13.3891, Reconstruct Loss = 0.0009, Cls Loss = 1.7300, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7321, Reg Loss = 13.5051, Reconstruct Loss = 0.0012, Cls Loss = 1.7296, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7307, Reg Loss = 13.5992, Reconstruct Loss = 0.0013, Cls Loss = 1.7280, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7310, Reg Loss = 13.6406, Reconstruct Loss = 0.0013, Cls Loss = 1.7284, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7316, Reg Loss = 13.6901, Reconstruct Loss = 0.0012, Cls Loss = 1.7290, Learning rate = 1.0000e-03\n",
      "Epoch [14/200], Training Loss: 1.7327, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Validation Loss: 1.7513, Validation Accuracy: 51.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8223, Reg Loss = 14.2754, Reconstruct Loss = 0.0000, Cls Loss = 1.8208, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7354, Reg Loss = 13.7499, Reconstruct Loss = 0.0003, Cls Loss = 1.7337, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7334, Reg Loss = 13.8500, Reconstruct Loss = 0.0007, Cls Loss = 1.7314, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7344, Reg Loss = 13.9238, Reconstruct Loss = 0.0009, Cls Loss = 1.7321, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7341, Reg Loss = 13.9673, Reconstruct Loss = 0.0009, Cls Loss = 1.7319, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7338, Reg Loss = 13.9857, Reconstruct Loss = 0.0010, Cls Loss = 1.7315, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7342, Reg Loss = 14.0010, Reconstruct Loss = 0.0010, Cls Loss = 1.7318, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7325, Reg Loss = 14.0179, Reconstruct Loss = 0.0010, Cls Loss = 1.7300, Learning rate = 1.0000e-03\n",
      "Epoch [15/200], Training Loss: 1.7312, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Validation Loss: 1.7510, Validation Accuracy: 47.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6395, Reg Loss = 14.0948, Reconstruct Loss = 0.0000, Cls Loss = 1.6381, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7476, Reg Loss = 14.3072, Reconstruct Loss = 0.0017, Cls Loss = 1.7445, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7416, Reg Loss = 14.2262, Reconstruct Loss = 0.0014, Cls Loss = 1.7388, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7320, Reg Loss = 14.3302, Reconstruct Loss = 0.0012, Cls Loss = 1.7293, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7310, Reg Loss = 14.4097, Reconstruct Loss = 0.0012, Cls Loss = 1.7283, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7288, Reg Loss = 14.4881, Reconstruct Loss = 0.0011, Cls Loss = 1.7263, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7266, Reg Loss = 14.5238, Reconstruct Loss = 0.0010, Cls Loss = 1.7241, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7293, Reg Loss = 14.5700, Reconstruct Loss = 0.0009, Cls Loss = 1.7269, Learning rate = 1.0000e-03\n",
      "Epoch [16/200], Training Loss: 1.7284, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Validation Loss: 1.7665, Validation Accuracy: 37.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8855, Reg Loss = 14.2867, Reconstruct Loss = 0.0000, Cls Loss = 1.8841, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7169, Reg Loss = 14.7880, Reconstruct Loss = 0.0004, Cls Loss = 1.7151, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7207, Reg Loss = 14.8799, Reconstruct Loss = 0.0007, Cls Loss = 1.7186, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7193, Reg Loss = 14.9408, Reconstruct Loss = 0.0007, Cls Loss = 1.7171, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7188, Reg Loss = 15.0692, Reconstruct Loss = 0.0005, Cls Loss = 1.7168, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7173, Reg Loss = 15.1454, Reconstruct Loss = 0.0005, Cls Loss = 1.7153, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7164, Reg Loss = 15.1600, Reconstruct Loss = 0.0006, Cls Loss = 1.7143, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7145, Reg Loss = 15.2314, Reconstruct Loss = 0.0005, Cls Loss = 1.7124, Learning rate = 1.0000e-03\n",
      "Epoch [17/200], Training Loss: 1.7143, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200], Validation Loss: 1.7403, Validation Accuracy: 47.72%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7006, Reg Loss = 14.7259, Reconstruct Loss = 0.0000, Cls Loss = 1.6991, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7127, Reg Loss = 15.6745, Reconstruct Loss = 0.0010, Cls Loss = 1.7101, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7160, Reg Loss = 15.5938, Reconstruct Loss = 0.0013, Cls Loss = 1.7131, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7126, Reg Loss = 15.5118, Reconstruct Loss = 0.0010, Cls Loss = 1.7100, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7142, Reg Loss = 15.5952, Reconstruct Loss = 0.0010, Cls Loss = 1.7116, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7115, Reg Loss = 15.5960, Reconstruct Loss = 0.0010, Cls Loss = 1.7089, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7104, Reg Loss = 15.6726, Reconstruct Loss = 0.0011, Cls Loss = 1.7077, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7116, Reg Loss = 15.7005, Reconstruct Loss = 0.0010, Cls Loss = 1.7090, Learning rate = 1.0000e-03\n",
      "Epoch [18/200], Training Loss: 1.7126, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200], Validation Loss: 1.7526, Validation Accuracy: 47.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8059, Reg Loss = 15.2979, Reconstruct Loss = 0.0000, Cls Loss = 1.8044, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6981, Reg Loss = 16.0743, Reconstruct Loss = 0.0014, Cls Loss = 1.6952, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7075, Reg Loss = 16.0807, Reconstruct Loss = 0.0016, Cls Loss = 1.7044, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7054, Reg Loss = 16.0798, Reconstruct Loss = 0.0013, Cls Loss = 1.7025, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7038, Reg Loss = 16.1469, Reconstruct Loss = 0.0012, Cls Loss = 1.7009, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7004, Reg Loss = 16.1816, Reconstruct Loss = 0.0012, Cls Loss = 1.6976, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6995, Reg Loss = 16.2820, Reconstruct Loss = 0.0012, Cls Loss = 1.6967, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7014, Reg Loss = 16.2747, Reconstruct Loss = 0.0010, Cls Loss = 1.6988, Learning rate = 1.0000e-03\n",
      "Epoch [19/200], Training Loss: 1.7023, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Validation Loss: 1.7470, Validation Accuracy: 51.70%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5690, Reg Loss = 14.8850, Reconstruct Loss = 0.0000, Cls Loss = 1.5675, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7007, Reg Loss = 16.8374, Reconstruct Loss = 0.0003, Cls Loss = 1.6986, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7029, Reg Loss = 16.7890, Reconstruct Loss = 0.0003, Cls Loss = 1.7009, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6985, Reg Loss = 16.7938, Reconstruct Loss = 0.0007, Cls Loss = 1.6961, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.7004, Reg Loss = 16.7096, Reconstruct Loss = 0.0007, Cls Loss = 1.6979, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.7007, Reg Loss = 16.6750, Reconstruct Loss = 0.0008, Cls Loss = 1.6982, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.7022, Reg Loss = 16.6262, Reconstruct Loss = 0.0009, Cls Loss = 1.6997, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.7011, Reg Loss = 16.5905, Reconstruct Loss = 0.0009, Cls Loss = 1.6986, Learning rate = 1.0000e-03\n",
      "Epoch [20/200], Training Loss: 1.7002, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Validation Loss: 1.7551, Validation Accuracy: 48.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6169, Reg Loss = 18.7291, Reconstruct Loss = 0.0345, Cls Loss = 1.5805, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7152, Reg Loss = 16.9183, Reconstruct Loss = 0.0010, Cls Loss = 1.7125, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.7043, Reg Loss = 16.9443, Reconstruct Loss = 0.0012, Cls Loss = 1.7014, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.7017, Reg Loss = 16.9763, Reconstruct Loss = 0.0013, Cls Loss = 1.6987, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6988, Reg Loss = 16.9480, Reconstruct Loss = 0.0012, Cls Loss = 1.6959, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6992, Reg Loss = 16.9518, Reconstruct Loss = 0.0010, Cls Loss = 1.6965, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6987, Reg Loss = 16.8742, Reconstruct Loss = 0.0011, Cls Loss = 1.6960, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6956, Reg Loss = 16.8502, Reconstruct Loss = 0.0009, Cls Loss = 1.6930, Learning rate = 1.0000e-03\n",
      "Epoch [21/200], Training Loss: 1.6948, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Validation Loss: 1.7428, Validation Accuracy: 47.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6172, Reg Loss = 18.0969, Reconstruct Loss = 0.0000, Cls Loss = 1.6154, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.7005, Reg Loss = 16.7698, Reconstruct Loss = 0.0007, Cls Loss = 1.6981, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6994, Reg Loss = 16.8410, Reconstruct Loss = 0.0019, Cls Loss = 1.6958, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6975, Reg Loss = 16.7847, Reconstruct Loss = 0.0017, Cls Loss = 1.6942, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6962, Reg Loss = 16.8932, Reconstruct Loss = 0.0015, Cls Loss = 1.6931, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6966, Reg Loss = 16.9436, Reconstruct Loss = 0.0014, Cls Loss = 1.6935, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6965, Reg Loss = 16.8827, Reconstruct Loss = 0.0014, Cls Loss = 1.6934, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6936, Reg Loss = 16.9187, Reconstruct Loss = 0.0015, Cls Loss = 1.6904, Learning rate = 1.0000e-03\n",
      "Epoch [22/200], Training Loss: 1.6913, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200], Validation Loss: 1.7605, Validation Accuracy: 44.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6580, Reg Loss = 17.3605, Reconstruct Loss = 0.0000, Cls Loss = 1.6563, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6803, Reg Loss = 17.1309, Reconstruct Loss = 0.0013, Cls Loss = 1.6773, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6834, Reg Loss = 17.1705, Reconstruct Loss = 0.0012, Cls Loss = 1.6805, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6831, Reg Loss = 17.2048, Reconstruct Loss = 0.0009, Cls Loss = 1.6804, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6836, Reg Loss = 17.1438, Reconstruct Loss = 0.0009, Cls Loss = 1.6810, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6838, Reg Loss = 17.0766, Reconstruct Loss = 0.0010, Cls Loss = 1.6811, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6850, Reg Loss = 17.0152, Reconstruct Loss = 0.0009, Cls Loss = 1.6824, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6854, Reg Loss = 16.9583, Reconstruct Loss = 0.0010, Cls Loss = 1.6828, Learning rate = 1.0000e-03\n",
      "Epoch [23/200], Training Loss: 1.6849, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200], Validation Loss: 1.8100, Validation Accuracy: 40.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7188, Reg Loss = 17.0119, Reconstruct Loss = 0.0000, Cls Loss = 1.7171, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6900, Reg Loss = 16.6384, Reconstruct Loss = 0.0003, Cls Loss = 1.6880, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6960, Reg Loss = 16.5133, Reconstruct Loss = 0.0010, Cls Loss = 1.6933, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6948, Reg Loss = 16.4967, Reconstruct Loss = 0.0008, Cls Loss = 1.6924, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6910, Reg Loss = 16.6206, Reconstruct Loss = 0.0006, Cls Loss = 1.6888, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6892, Reg Loss = 16.6835, Reconstruct Loss = 0.0005, Cls Loss = 1.6870, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6898, Reg Loss = 16.7134, Reconstruct Loss = 0.0005, Cls Loss = 1.6877, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6893, Reg Loss = 16.7446, Reconstruct Loss = 0.0006, Cls Loss = 1.6870, Learning rate = 1.0000e-03\n",
      "Epoch [24/200], Training Loss: 1.6881, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Validation Loss: 1.7692, Validation Accuracy: 36.39%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6143, Reg Loss = 19.1307, Reconstruct Loss = 0.0000, Cls Loss = 1.6124, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6659, Reg Loss = 17.3111, Reconstruct Loss = 0.0013, Cls Loss = 1.6629, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6844, Reg Loss = 17.2989, Reconstruct Loss = 0.0015, Cls Loss = 1.6812, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6831, Reg Loss = 17.2497, Reconstruct Loss = 0.0015, Cls Loss = 1.6799, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6795, Reg Loss = 17.2107, Reconstruct Loss = 0.0012, Cls Loss = 1.6765, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6830, Reg Loss = 17.2612, Reconstruct Loss = 0.0010, Cls Loss = 1.6802, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6820, Reg Loss = 17.2321, Reconstruct Loss = 0.0011, Cls Loss = 1.6792, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6804, Reg Loss = 17.2254, Reconstruct Loss = 0.0011, Cls Loss = 1.6776, Learning rate = 1.0000e-03\n",
      "Epoch [25/200], Training Loss: 1.6797, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200], Validation Loss: 1.7573, Validation Accuracy: 41.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7739, Reg Loss = 16.5681, Reconstruct Loss = 0.0000, Cls Loss = 1.7723, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6760, Reg Loss = 17.3515, Reconstruct Loss = 0.0023, Cls Loss = 1.6720, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6722, Reg Loss = 17.3569, Reconstruct Loss = 0.0011, Cls Loss = 1.6693, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6786, Reg Loss = 17.2646, Reconstruct Loss = 0.0009, Cls Loss = 1.6761, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6772, Reg Loss = 17.2712, Reconstruct Loss = 0.0011, Cls Loss = 1.6744, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6793, Reg Loss = 17.2582, Reconstruct Loss = 0.0012, Cls Loss = 1.6764, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6769, Reg Loss = 17.2959, Reconstruct Loss = 0.0011, Cls Loss = 1.6741, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6763, Reg Loss = 17.2791, Reconstruct Loss = 0.0012, Cls Loss = 1.6734, Learning rate = 1.0000e-03\n",
      "Epoch [26/200], Training Loss: 1.6768, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200], Validation Loss: 1.7860, Validation Accuracy: 44.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5867, Reg Loss = 18.8740, Reconstruct Loss = 0.0000, Cls Loss = 1.5848, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6844, Reg Loss = 17.2326, Reconstruct Loss = 0.0007, Cls Loss = 1.6820, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6874, Reg Loss = 17.2691, Reconstruct Loss = 0.0010, Cls Loss = 1.6847, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6789, Reg Loss = 17.3366, Reconstruct Loss = 0.0009, Cls Loss = 1.6763, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6761, Reg Loss = 17.5342, Reconstruct Loss = 0.0007, Cls Loss = 1.6737, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6756, Reg Loss = 17.5715, Reconstruct Loss = 0.0007, Cls Loss = 1.6731, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6760, Reg Loss = 17.5821, Reconstruct Loss = 0.0007, Cls Loss = 1.6736, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6748, Reg Loss = 17.6105, Reconstruct Loss = 0.0007, Cls Loss = 1.6723, Learning rate = 1.0000e-03\n",
      "Epoch [27/200], Training Loss: 1.6747, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200], Validation Loss: 1.7963, Validation Accuracy: 36.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7866, Reg Loss = 17.3677, Reconstruct Loss = 0.0000, Cls Loss = 1.7849, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6621, Reg Loss = 18.2499, Reconstruct Loss = 0.0010, Cls Loss = 1.6593, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6598, Reg Loss = 18.1990, Reconstruct Loss = 0.0018, Cls Loss = 1.6562, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6622, Reg Loss = 18.1355, Reconstruct Loss = 0.0018, Cls Loss = 1.6586, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6664, Reg Loss = 18.0432, Reconstruct Loss = 0.0015, Cls Loss = 1.6631, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6630, Reg Loss = 18.0843, Reconstruct Loss = 0.0013, Cls Loss = 1.6599, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6649, Reg Loss = 18.0747, Reconstruct Loss = 0.0011, Cls Loss = 1.6620, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6631, Reg Loss = 18.0807, Reconstruct Loss = 0.0011, Cls Loss = 1.6602, Learning rate = 1.0000e-03\n",
      "Epoch [28/200], Training Loss: 1.6638, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200], Validation Loss: 1.7796, Validation Accuracy: 42.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7092, Reg Loss = 18.1145, Reconstruct Loss = 0.0000, Cls Loss = 1.7074, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6574, Reg Loss = 17.7516, Reconstruct Loss = 0.0003, Cls Loss = 1.6553, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6630, Reg Loss = 17.9606, Reconstruct Loss = 0.0003, Cls Loss = 1.6609, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6593, Reg Loss = 18.0053, Reconstruct Loss = 0.0004, Cls Loss = 1.6571, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6618, Reg Loss = 18.0682, Reconstruct Loss = 0.0008, Cls Loss = 1.6592, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6638, Reg Loss = 18.1325, Reconstruct Loss = 0.0009, Cls Loss = 1.6611, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6644, Reg Loss = 18.0584, Reconstruct Loss = 0.0010, Cls Loss = 1.6616, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6645, Reg Loss = 18.1115, Reconstruct Loss = 0.0012, Cls Loss = 1.6615, Learning rate = 1.0000e-03\n",
      "Epoch [29/200], Training Loss: 1.6650, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200], Validation Loss: 1.8248, Validation Accuracy: 35.57%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8659, Reg Loss = 16.6267, Reconstruct Loss = 0.0000, Cls Loss = 1.8642, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6679, Reg Loss = 18.3433, Reconstruct Loss = 0.0013, Cls Loss = 1.6648, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6720, Reg Loss = 18.1924, Reconstruct Loss = 0.0008, Cls Loss = 1.6694, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6657, Reg Loss = 18.1761, Reconstruct Loss = 0.0008, Cls Loss = 1.6631, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6636, Reg Loss = 18.1956, Reconstruct Loss = 0.0006, Cls Loss = 1.6611, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6681, Reg Loss = 18.2763, Reconstruct Loss = 0.0007, Cls Loss = 1.6656, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6677, Reg Loss = 18.2626, Reconstruct Loss = 0.0008, Cls Loss = 1.6650, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6685, Reg Loss = 18.2095, Reconstruct Loss = 0.0007, Cls Loss = 1.6659, Learning rate = 1.0000e-03\n",
      "Epoch [30/200], Training Loss: 1.6675, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Validation Loss: 1.7773, Validation Accuracy: 40.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6110, Reg Loss = 22.0718, Reconstruct Loss = 0.0000, Cls Loss = 1.6088, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6511, Reg Loss = 18.7656, Reconstruct Loss = 0.0013, Cls Loss = 1.6479, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6482, Reg Loss = 18.6282, Reconstruct Loss = 0.0010, Cls Loss = 1.6454, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6543, Reg Loss = 18.6814, Reconstruct Loss = 0.0009, Cls Loss = 1.6516, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6560, Reg Loss = 18.7075, Reconstruct Loss = 0.0008, Cls Loss = 1.6533, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6537, Reg Loss = 18.7142, Reconstruct Loss = 0.0008, Cls Loss = 1.6510, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6525, Reg Loss = 18.8120, Reconstruct Loss = 0.0007, Cls Loss = 1.6499, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6520, Reg Loss = 18.7950, Reconstruct Loss = 0.0009, Cls Loss = 1.6492, Learning rate = 1.0000e-03\n",
      "Epoch [31/200], Training Loss: 1.6534, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200], Validation Loss: 1.7477, Validation Accuracy: 43.77%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7138, Reg Loss = 21.7279, Reconstruct Loss = 0.0000, Cls Loss = 1.7116, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6608, Reg Loss = 18.6559, Reconstruct Loss = 0.0006, Cls Loss = 1.6583, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6580, Reg Loss = 18.5593, Reconstruct Loss = 0.0009, Cls Loss = 1.6552, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6555, Reg Loss = 18.7712, Reconstruct Loss = 0.0009, Cls Loss = 1.6527, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6546, Reg Loss = 18.9222, Reconstruct Loss = 0.0010, Cls Loss = 1.6518, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6555, Reg Loss = 18.9808, Reconstruct Loss = 0.0010, Cls Loss = 1.6526, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6559, Reg Loss = 19.0653, Reconstruct Loss = 0.0008, Cls Loss = 1.6532, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6559, Reg Loss = 19.1748, Reconstruct Loss = 0.0008, Cls Loss = 1.6531, Learning rate = 1.0000e-03\n",
      "Epoch [32/200], Training Loss: 1.6545, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200], Validation Loss: 1.8040, Validation Accuracy: 32.49%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7639, Reg Loss = 19.1000, Reconstruct Loss = 0.0000, Cls Loss = 1.7620, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6902, Reg Loss = 18.2899, Reconstruct Loss = 0.0006, Cls Loss = 1.6877, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6725, Reg Loss = 18.2942, Reconstruct Loss = 0.0010, Cls Loss = 1.6697, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6579, Reg Loss = 18.5984, Reconstruct Loss = 0.0009, Cls Loss = 1.6551, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6590, Reg Loss = 18.7334, Reconstruct Loss = 0.0008, Cls Loss = 1.6563, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6560, Reg Loss = 18.9109, Reconstruct Loss = 0.0008, Cls Loss = 1.6534, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6583, Reg Loss = 19.1124, Reconstruct Loss = 0.0008, Cls Loss = 1.6556, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6570, Reg Loss = 19.2606, Reconstruct Loss = 0.0009, Cls Loss = 1.6542, Learning rate = 1.0000e-03\n",
      "Epoch [33/200], Training Loss: 1.6565, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200], Validation Loss: 1.7842, Validation Accuracy: 40.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6118, Reg Loss = 17.7255, Reconstruct Loss = 0.0000, Cls Loss = 1.6100, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6475, Reg Loss = 19.4294, Reconstruct Loss = 0.0016, Cls Loss = 1.6439, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6466, Reg Loss = 19.5830, Reconstruct Loss = 0.0014, Cls Loss = 1.6432, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6436, Reg Loss = 19.8559, Reconstruct Loss = 0.0012, Cls Loss = 1.6405, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6454, Reg Loss = 19.9021, Reconstruct Loss = 0.0014, Cls Loss = 1.6420, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6465, Reg Loss = 19.9407, Reconstruct Loss = 0.0015, Cls Loss = 1.6430, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6477, Reg Loss = 19.9935, Reconstruct Loss = 0.0013, Cls Loss = 1.6443, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6494, Reg Loss = 19.9438, Reconstruct Loss = 0.0013, Cls Loss = 1.6461, Learning rate = 1.0000e-03\n",
      "Epoch [34/200], Training Loss: 1.6499, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/200], Validation Loss: 1.8330, Validation Accuracy: 36.33%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7240, Reg Loss = 20.1673, Reconstruct Loss = 0.0000, Cls Loss = 1.7220, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6569, Reg Loss = 20.2198, Reconstruct Loss = 0.0004, Cls Loss = 1.6545, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6620, Reg Loss = 20.3304, Reconstruct Loss = 0.0009, Cls Loss = 1.6591, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6512, Reg Loss = 20.2896, Reconstruct Loss = 0.0010, Cls Loss = 1.6482, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6526, Reg Loss = 20.2842, Reconstruct Loss = 0.0009, Cls Loss = 1.6496, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6470, Reg Loss = 20.3518, Reconstruct Loss = 0.0009, Cls Loss = 1.6440, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6439, Reg Loss = 20.4353, Reconstruct Loss = 0.0009, Cls Loss = 1.6410, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6452, Reg Loss = 20.4456, Reconstruct Loss = 0.0009, Cls Loss = 1.6422, Learning rate = 1.0000e-03\n",
      "Epoch [35/200], Training Loss: 1.6461, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/200], Validation Loss: 1.8024, Validation Accuracy: 37.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6501, Reg Loss = 20.8015, Reconstruct Loss = 0.0000, Cls Loss = 1.6480, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6384, Reg Loss = 20.9821, Reconstruct Loss = 0.0003, Cls Loss = 1.6360, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6288, Reg Loss = 20.9023, Reconstruct Loss = 0.0006, Cls Loss = 1.6261, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6304, Reg Loss = 21.0616, Reconstruct Loss = 0.0011, Cls Loss = 1.6273, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6366, Reg Loss = 21.0821, Reconstruct Loss = 0.0010, Cls Loss = 1.6336, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6355, Reg Loss = 21.1534, Reconstruct Loss = 0.0010, Cls Loss = 1.6323, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6354, Reg Loss = 21.1940, Reconstruct Loss = 0.0010, Cls Loss = 1.6323, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6365, Reg Loss = 21.2097, Reconstruct Loss = 0.0009, Cls Loss = 1.6335, Learning rate = 1.0000e-03\n",
      "Epoch [36/200], Training Loss: 1.6390, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200], Validation Loss: 1.8670, Validation Accuracy: 31.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6491, Reg Loss = 25.3957, Reconstruct Loss = 0.0000, Cls Loss = 1.6465, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6410, Reg Loss = 21.7201, Reconstruct Loss = 0.0007, Cls Loss = 1.6381, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6417, Reg Loss = 21.6158, Reconstruct Loss = 0.0007, Cls Loss = 1.6389, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6387, Reg Loss = 21.6310, Reconstruct Loss = 0.0008, Cls Loss = 1.6357, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6386, Reg Loss = 21.5440, Reconstruct Loss = 0.0007, Cls Loss = 1.6358, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6373, Reg Loss = 21.5883, Reconstruct Loss = 0.0007, Cls Loss = 1.6344, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6393, Reg Loss = 21.5190, Reconstruct Loss = 0.0011, Cls Loss = 1.6361, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6387, Reg Loss = 21.5210, Reconstruct Loss = 0.0010, Cls Loss = 1.6355, Learning rate = 1.0000e-03\n",
      "Epoch [37/200], Training Loss: 1.6383, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/200], Validation Loss: 1.8459, Validation Accuracy: 35.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5522, Reg Loss = 21.7442, Reconstruct Loss = 0.0000, Cls Loss = 1.5500, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6174, Reg Loss = 22.1937, Reconstruct Loss = 0.0016, Cls Loss = 1.6136, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6209, Reg Loss = 21.9681, Reconstruct Loss = 0.0012, Cls Loss = 1.6176, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6245, Reg Loss = 22.3093, Reconstruct Loss = 0.0012, Cls Loss = 1.6210, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6222, Reg Loss = 22.3577, Reconstruct Loss = 0.0012, Cls Loss = 1.6188, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6191, Reg Loss = 22.3873, Reconstruct Loss = 0.0011, Cls Loss = 1.6157, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6196, Reg Loss = 22.4289, Reconstruct Loss = 0.0010, Cls Loss = 1.6164, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6206, Reg Loss = 22.4655, Reconstruct Loss = 0.0011, Cls Loss = 1.6173, Learning rate = 1.0000e-03\n",
      "Epoch [38/200], Training Loss: 1.6219, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200], Validation Loss: 1.8796, Validation Accuracy: 34.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8431, Reg Loss = 21.7732, Reconstruct Loss = 0.0000, Cls Loss = 1.8409, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6163, Reg Loss = 22.4613, Reconstruct Loss = 0.0013, Cls Loss = 1.6127, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6164, Reg Loss = 22.7594, Reconstruct Loss = 0.0008, Cls Loss = 1.6133, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6192, Reg Loss = 22.7801, Reconstruct Loss = 0.0010, Cls Loss = 1.6159, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6211, Reg Loss = 22.8329, Reconstruct Loss = 0.0009, Cls Loss = 1.6179, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6225, Reg Loss = 22.6884, Reconstruct Loss = 0.0008, Cls Loss = 1.6194, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6209, Reg Loss = 22.6750, Reconstruct Loss = 0.0009, Cls Loss = 1.6177, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6214, Reg Loss = 22.6582, Reconstruct Loss = 0.0009, Cls Loss = 1.6182, Learning rate = 1.0000e-03\n",
      "Epoch [39/200], Training Loss: 1.6216, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200], Validation Loss: 1.9271, Validation Accuracy: 23.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6458, Reg Loss = 21.5955, Reconstruct Loss = 0.0000, Cls Loss = 1.6436, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5933, Reg Loss = 23.4961, Reconstruct Loss = 0.0013, Cls Loss = 1.5896, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6018, Reg Loss = 23.2984, Reconstruct Loss = 0.0018, Cls Loss = 1.5977, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6051, Reg Loss = 23.3671, Reconstruct Loss = 0.0013, Cls Loss = 1.6015, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.6088, Reg Loss = 23.4401, Reconstruct Loss = 0.0012, Cls Loss = 1.6052, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.6076, Reg Loss = 23.4989, Reconstruct Loss = 0.0010, Cls Loss = 1.6042, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.6037, Reg Loss = 23.5488, Reconstruct Loss = 0.0012, Cls Loss = 1.6001, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.6052, Reg Loss = 23.5347, Reconstruct Loss = 0.0012, Cls Loss = 1.6017, Learning rate = 1.0000e-03\n",
      "Epoch [40/200], Training Loss: 1.6036, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/200], Validation Loss: 1.8799, Validation Accuracy: 26.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.7208, Reg Loss = 21.9049, Reconstruct Loss = 0.0000, Cls Loss = 1.7186, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.6030, Reg Loss = 23.7757, Reconstruct Loss = 0.0000, Cls Loss = 1.6007, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.6031, Reg Loss = 24.2483, Reconstruct Loss = 0.0007, Cls Loss = 1.6000, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.6082, Reg Loss = 24.1030, Reconstruct Loss = 0.0005, Cls Loss = 1.6052, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.5986, Reg Loss = 24.0163, Reconstruct Loss = 0.0009, Cls Loss = 1.5954, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.5998, Reg Loss = 23.9053, Reconstruct Loss = 0.0008, Cls Loss = 1.5966, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.5943, Reg Loss = 23.8476, Reconstruct Loss = 0.0012, Cls Loss = 1.5908, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.5927, Reg Loss = 23.8561, Reconstruct Loss = 0.0011, Cls Loss = 1.5892, Learning rate = 1.0000e-03\n",
      "Epoch [41/200], Training Loss: 1.5933, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 69.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/200], Validation Loss: 1.9913, Validation Accuracy: 21.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6059, Reg Loss = 23.2411, Reconstruct Loss = 0.0000, Cls Loss = 1.6036, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5819, Reg Loss = 24.6969, Reconstruct Loss = 0.0014, Cls Loss = 1.5780, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.5846, Reg Loss = 24.6828, Reconstruct Loss = 0.0012, Cls Loss = 1.5809, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.5769, Reg Loss = 24.5832, Reconstruct Loss = 0.0010, Cls Loss = 1.5734, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.5783, Reg Loss = 24.7213, Reconstruct Loss = 0.0008, Cls Loss = 1.5751, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.5741, Reg Loss = 24.6350, Reconstruct Loss = 0.0008, Cls Loss = 1.5708, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.5694, Reg Loss = 24.7133, Reconstruct Loss = 0.0010, Cls Loss = 1.5659, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.5687, Reg Loss = 24.7988, Reconstruct Loss = 0.0010, Cls Loss = 1.5653, Learning rate = 1.0000e-03\n",
      "Epoch [42/200], Training Loss: 1.5658, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/200], Validation Loss: 1.9759, Validation Accuracy: 26.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.6026, Reg Loss = 29.1241, Reconstruct Loss = 0.0000, Cls Loss = 1.5997, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5477, Reg Loss = 25.0076, Reconstruct Loss = 0.0010, Cls Loss = 1.5442, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.5537, Reg Loss = 25.1636, Reconstruct Loss = 0.0009, Cls Loss = 1.5503, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.5481, Reg Loss = 25.0223, Reconstruct Loss = 0.0011, Cls Loss = 1.5445, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.5478, Reg Loss = 25.2017, Reconstruct Loss = 0.0012, Cls Loss = 1.5441, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.5529, Reg Loss = 25.2469, Reconstruct Loss = 0.0011, Cls Loss = 1.5493, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.5484, Reg Loss = 25.3235, Reconstruct Loss = 0.0012, Cls Loss = 1.5447, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.5474, Reg Loss = 25.4393, Reconstruct Loss = 0.0012, Cls Loss = 1.5437, Learning rate = 1.0000e-03\n",
      "Epoch [43/200], Training Loss: 1.5457, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/200], Validation Loss: 2.0578, Validation Accuracy: 17.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.2929, Reg Loss = 27.1342, Reconstruct Loss = 0.0000, Cls Loss = 1.2902, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5758, Reg Loss = 26.3555, Reconstruct Loss = 0.0007, Cls Loss = 1.5725, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.5414, Reg Loss = 26.5589, Reconstruct Loss = 0.0005, Cls Loss = 1.5383, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.5438, Reg Loss = 26.7785, Reconstruct Loss = 0.0009, Cls Loss = 1.5402, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.5468, Reg Loss = 26.4319, Reconstruct Loss = 0.0011, Cls Loss = 1.5431, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.5461, Reg Loss = 26.4298, Reconstruct Loss = 0.0013, Cls Loss = 1.5422, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.5425, Reg Loss = 26.5739, Reconstruct Loss = 0.0012, Cls Loss = 1.5386, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.5403, Reg Loss = 26.5935, Reconstruct Loss = 0.0011, Cls Loss = 1.5365, Learning rate = 1.0000e-03\n",
      "Epoch [44/200], Training Loss: 1.5398, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 65.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/200], Validation Loss: 1.9120, Validation Accuracy: 28.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5915, Reg Loss = 24.7276, Reconstruct Loss = 0.0000, Cls Loss = 1.5890, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5225, Reg Loss = 27.7535, Reconstruct Loss = 0.0018, Cls Loss = 1.5179, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.5279, Reg Loss = 27.8714, Reconstruct Loss = 0.0011, Cls Loss = 1.5240, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.5285, Reg Loss = 27.7086, Reconstruct Loss = 0.0012, Cls Loss = 1.5246, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.5289, Reg Loss = 27.7078, Reconstruct Loss = 0.0010, Cls Loss = 1.5251, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.5251, Reg Loss = 27.7769, Reconstruct Loss = 0.0012, Cls Loss = 1.5212, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.5253, Reg Loss = 27.7475, Reconstruct Loss = 0.0011, Cls Loss = 1.5214, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.5272, Reg Loss = 27.7973, Reconstruct Loss = 0.0010, Cls Loss = 1.5234, Learning rate = 1.0000e-03\n",
      "Epoch [45/200], Training Loss: 1.5235, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/200], Validation Loss: 2.0757, Validation Accuracy: 20.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5004, Reg Loss = 25.5693, Reconstruct Loss = 0.0000, Cls Loss = 1.4978, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5161, Reg Loss = 27.9751, Reconstruct Loss = 0.0010, Cls Loss = 1.5123, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.5106, Reg Loss = 28.2769, Reconstruct Loss = 0.0009, Cls Loss = 1.5069, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.5025, Reg Loss = 28.4853, Reconstruct Loss = 0.0009, Cls Loss = 1.4987, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.4951, Reg Loss = 28.5978, Reconstruct Loss = 0.0009, Cls Loss = 1.4913, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.5000, Reg Loss = 28.6298, Reconstruct Loss = 0.0011, Cls Loss = 1.4961, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4988, Reg Loss = 28.6134, Reconstruct Loss = 0.0011, Cls Loss = 1.4948, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4937, Reg Loss = 28.6379, Reconstruct Loss = 0.0012, Cls Loss = 1.4896, Learning rate = 1.0000e-03\n",
      "Epoch [46/200], Training Loss: 1.4931, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/200], Validation Loss: 2.0751, Validation Accuracy: 17.76%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5103, Reg Loss = 31.7744, Reconstruct Loss = 0.0000, Cls Loss = 1.5071, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5100, Reg Loss = 28.3139, Reconstruct Loss = 0.0011, Cls Loss = 1.5061, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.5123, Reg Loss = 28.4074, Reconstruct Loss = 0.0009, Cls Loss = 1.5085, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.5107, Reg Loss = 28.5558, Reconstruct Loss = 0.0011, Cls Loss = 1.5068, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.5039, Reg Loss = 28.7560, Reconstruct Loss = 0.0012, Cls Loss = 1.4998, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.4964, Reg Loss = 28.9169, Reconstruct Loss = 0.0013, Cls Loss = 1.4922, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4978, Reg Loss = 28.9630, Reconstruct Loss = 0.0012, Cls Loss = 1.4937, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4939, Reg Loss = 28.9148, Reconstruct Loss = 0.0013, Cls Loss = 1.4898, Learning rate = 1.0000e-03\n",
      "Epoch [47/200], Training Loss: 1.4947, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/200], Validation Loss: 1.9869, Validation Accuracy: 23.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.4377, Reg Loss = 28.9240, Reconstruct Loss = 0.0000, Cls Loss = 1.4348, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.5059, Reg Loss = 29.5332, Reconstruct Loss = 0.0014, Cls Loss = 1.5015, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.4997, Reg Loss = 29.4351, Reconstruct Loss = 0.0013, Cls Loss = 1.4954, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.4921, Reg Loss = 29.5605, Reconstruct Loss = 0.0013, Cls Loss = 1.4879, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.4858, Reg Loss = 29.6910, Reconstruct Loss = 0.0010, Cls Loss = 1.4818, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.4815, Reg Loss = 29.7959, Reconstruct Loss = 0.0012, Cls Loss = 1.4773, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4850, Reg Loss = 29.7084, Reconstruct Loss = 0.0014, Cls Loss = 1.4806, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4848, Reg Loss = 29.6682, Reconstruct Loss = 0.0013, Cls Loss = 1.4805, Learning rate = 1.0000e-03\n",
      "Epoch [48/200], Training Loss: 1.4799, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/200], Validation Loss: 2.0663, Validation Accuracy: 21.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5598, Reg Loss = 29.0869, Reconstruct Loss = 0.0000, Cls Loss = 1.5569, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.4880, Reg Loss = 30.0130, Reconstruct Loss = 0.0015, Cls Loss = 1.4834, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.4728, Reg Loss = 30.3049, Reconstruct Loss = 0.0015, Cls Loss = 1.4682, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.4578, Reg Loss = 30.5271, Reconstruct Loss = 0.0011, Cls Loss = 1.4536, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.4586, Reg Loss = 30.7961, Reconstruct Loss = 0.0009, Cls Loss = 1.4545, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.4610, Reg Loss = 30.8324, Reconstruct Loss = 0.0010, Cls Loss = 1.4569, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4614, Reg Loss = 30.9950, Reconstruct Loss = 0.0012, Cls Loss = 1.4571, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4592, Reg Loss = 31.0548, Reconstruct Loss = 0.0012, Cls Loss = 1.4549, Learning rate = 1.0000e-03\n",
      "Epoch [49/200], Training Loss: 1.4593, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/200], Validation Loss: 2.0332, Validation Accuracy: 23.58%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.4016, Reg Loss = 29.0502, Reconstruct Loss = 0.0000, Cls Loss = 1.3987, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.4783, Reg Loss = 32.3078, Reconstruct Loss = 0.0018, Cls Loss = 1.4733, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.4618, Reg Loss = 32.0912, Reconstruct Loss = 0.0015, Cls Loss = 1.4571, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.4554, Reg Loss = 32.2407, Reconstruct Loss = 0.0019, Cls Loss = 1.4503, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.4404, Reg Loss = 31.9570, Reconstruct Loss = 0.0015, Cls Loss = 1.4357, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.4397, Reg Loss = 32.0664, Reconstruct Loss = 0.0014, Cls Loss = 1.4351, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4363, Reg Loss = 32.0935, Reconstruct Loss = 0.0012, Cls Loss = 1.4319, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4376, Reg Loss = 32.2738, Reconstruct Loss = 0.0011, Cls Loss = 1.4333, Learning rate = 1.0000e-03\n",
      "Epoch [50/200], Training Loss: 1.4402, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Validation Loss: 1.9924, Validation Accuracy: 23.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5062, Reg Loss = 27.6027, Reconstruct Loss = 0.0000, Cls Loss = 1.5034, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.4329, Reg Loss = 32.4947, Reconstruct Loss = 0.0023, Cls Loss = 1.4274, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.4379, Reg Loss = 32.2299, Reconstruct Loss = 0.0012, Cls Loss = 1.4335, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.4406, Reg Loss = 31.9603, Reconstruct Loss = 0.0012, Cls Loss = 1.4362, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.4436, Reg Loss = 31.8141, Reconstruct Loss = 0.0009, Cls Loss = 1.4395, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.4360, Reg Loss = 31.8446, Reconstruct Loss = 0.0010, Cls Loss = 1.4319, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4335, Reg Loss = 31.9075, Reconstruct Loss = 0.0009, Cls Loss = 1.4295, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4352, Reg Loss = 31.8879, Reconstruct Loss = 0.0009, Cls Loss = 1.4312, Learning rate = 1.0000e-03\n",
      "Epoch [51/200], Training Loss: 1.4339, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/200], Validation Loss: 1.9276, Validation Accuracy: 25.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.3397, Reg Loss = 31.9637, Reconstruct Loss = 0.0000, Cls Loss = 1.3365, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.4354, Reg Loss = 32.1721, Reconstruct Loss = 0.0019, Cls Loss = 1.4303, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.4272, Reg Loss = 32.3923, Reconstruct Loss = 0.0013, Cls Loss = 1.4226, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.4266, Reg Loss = 32.5114, Reconstruct Loss = 0.0014, Cls Loss = 1.4219, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.4175, Reg Loss = 32.7458, Reconstruct Loss = 0.0012, Cls Loss = 1.4131, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.4123, Reg Loss = 33.0004, Reconstruct Loss = 0.0012, Cls Loss = 1.4077, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.4081, Reg Loss = 33.1286, Reconstruct Loss = 0.0012, Cls Loss = 1.4035, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.4074, Reg Loss = 33.1271, Reconstruct Loss = 0.0014, Cls Loss = 1.4027, Learning rate = 1.0000e-03\n",
      "Epoch [52/200], Training Loss: 1.4080, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/200], Validation Loss: 2.0342, Validation Accuracy: 22.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.4383, Reg Loss = 38.4564, Reconstruct Loss = 0.0000, Cls Loss = 1.4344, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.4252, Reg Loss = 33.5510, Reconstruct Loss = 0.0008, Cls Loss = 1.4211, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.4028, Reg Loss = 33.5664, Reconstruct Loss = 0.0006, Cls Loss = 1.3988, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.3951, Reg Loss = 33.6182, Reconstruct Loss = 0.0010, Cls Loss = 1.3907, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.3954, Reg Loss = 33.5346, Reconstruct Loss = 0.0012, Cls Loss = 1.3908, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.3949, Reg Loss = 33.6394, Reconstruct Loss = 0.0011, Cls Loss = 1.3904, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.3957, Reg Loss = 33.6956, Reconstruct Loss = 0.0009, Cls Loss = 1.3914, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.3948, Reg Loss = 33.7630, Reconstruct Loss = 0.0011, Cls Loss = 1.3903, Learning rate = 1.0000e-03\n",
      "Epoch [53/200], Training Loss: 1.3940, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/200], Validation Loss: 2.0068, Validation Accuracy: 26.51%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.8045, Reg Loss = 30.6412, Reconstruct Loss = 0.0000, Cls Loss = 1.8015, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.3823, Reg Loss = 33.4937, Reconstruct Loss = 0.0012, Cls Loss = 1.3777, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.3618, Reg Loss = 34.1001, Reconstruct Loss = 0.0012, Cls Loss = 1.3572, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.3739, Reg Loss = 34.0486, Reconstruct Loss = 0.0015, Cls Loss = 1.3690, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.3755, Reg Loss = 34.1200, Reconstruct Loss = 0.0014, Cls Loss = 1.3707, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.3766, Reg Loss = 34.1037, Reconstruct Loss = 0.0012, Cls Loss = 1.3720, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.3787, Reg Loss = 34.0871, Reconstruct Loss = 0.0012, Cls Loss = 1.3741, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.3815, Reg Loss = 34.2217, Reconstruct Loss = 0.0011, Cls Loss = 1.3770, Learning rate = 1.0000e-03\n",
      "Epoch [54/200], Training Loss: 1.3803, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/200], Validation Loss: 1.9336, Validation Accuracy: 30.42%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.2076, Reg Loss = 35.8297, Reconstruct Loss = 0.0000, Cls Loss = 1.2040, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.3548, Reg Loss = 35.8067, Reconstruct Loss = 0.0008, Cls Loss = 1.3505, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.3417, Reg Loss = 35.7955, Reconstruct Loss = 0.0014, Cls Loss = 1.3367, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.3528, Reg Loss = 35.6191, Reconstruct Loss = 0.0014, Cls Loss = 1.3478, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.3440, Reg Loss = 35.3931, Reconstruct Loss = 0.0016, Cls Loss = 1.3388, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.3405, Reg Loss = 35.4999, Reconstruct Loss = 0.0015, Cls Loss = 1.3355, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.3454, Reg Loss = 35.5500, Reconstruct Loss = 0.0013, Cls Loss = 1.3406, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.3437, Reg Loss = 35.7659, Reconstruct Loss = 0.0011, Cls Loss = 1.3391, Learning rate = 1.0000e-03\n",
      "Epoch [55/200], Training Loss: 1.3417, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/200], Validation Loss: 2.0996, Validation Accuracy: 22.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.3904, Reg Loss = 33.8317, Reconstruct Loss = 0.0000, Cls Loss = 1.3870, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.3480, Reg Loss = 35.6655, Reconstruct Loss = 0.0019, Cls Loss = 1.3425, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.3323, Reg Loss = 35.8613, Reconstruct Loss = 0.0020, Cls Loss = 1.3268, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.3305, Reg Loss = 35.8863, Reconstruct Loss = 0.0013, Cls Loss = 1.3255, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.3364, Reg Loss = 36.0824, Reconstruct Loss = 0.0013, Cls Loss = 1.3315, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.3362, Reg Loss = 36.1518, Reconstruct Loss = 0.0011, Cls Loss = 1.3314, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.3305, Reg Loss = 36.3519, Reconstruct Loss = 0.0011, Cls Loss = 1.3258, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.3313, Reg Loss = 36.4414, Reconstruct Loss = 0.0010, Cls Loss = 1.3267, Learning rate = 1.0000e-03\n",
      "Epoch [56/200], Training Loss: 1.3310, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/200], Validation Loss: 1.9566, Validation Accuracy: 26.78%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.3536, Reg Loss = 32.5819, Reconstruct Loss = 0.0000, Cls Loss = 1.3504, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.3088, Reg Loss = 36.7900, Reconstruct Loss = 0.0015, Cls Loss = 1.3036, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.3112, Reg Loss = 37.0142, Reconstruct Loss = 0.0018, Cls Loss = 1.3057, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.3151, Reg Loss = 37.3464, Reconstruct Loss = 0.0017, Cls Loss = 1.3097, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.3130, Reg Loss = 37.3678, Reconstruct Loss = 0.0014, Cls Loss = 1.3078, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.3136, Reg Loss = 37.2750, Reconstruct Loss = 0.0013, Cls Loss = 1.3085, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.3126, Reg Loss = 37.3436, Reconstruct Loss = 0.0011, Cls Loss = 1.3078, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.3127, Reg Loss = 37.3835, Reconstruct Loss = 0.0011, Cls Loss = 1.3079, Learning rate = 1.0000e-03\n",
      "Epoch [57/200], Training Loss: 1.3083, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/200], Validation Loss: 2.0385, Validation Accuracy: 25.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.5344, Reg Loss = 36.7497, Reconstruct Loss = 0.0000, Cls Loss = 1.5307, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.2655, Reg Loss = 37.7681, Reconstruct Loss = 0.0007, Cls Loss = 1.2610, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.2968, Reg Loss = 37.5485, Reconstruct Loss = 0.0005, Cls Loss = 1.2925, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.2992, Reg Loss = 37.5944, Reconstruct Loss = 0.0008, Cls Loss = 1.2946, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.2940, Reg Loss = 37.6897, Reconstruct Loss = 0.0008, Cls Loss = 1.2894, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.2895, Reg Loss = 37.8322, Reconstruct Loss = 0.0008, Cls Loss = 1.2849, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.2862, Reg Loss = 38.1751, Reconstruct Loss = 0.0009, Cls Loss = 1.2815, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.2832, Reg Loss = 38.2627, Reconstruct Loss = 0.0010, Cls Loss = 1.2785, Learning rate = 1.0000e-03\n",
      "Epoch [58/200], Training Loss: 1.2818, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 70.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/200], Validation Loss: 2.1536, Validation Accuracy: 20.97%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.4898, Reg Loss = 39.4288, Reconstruct Loss = 0.0000, Cls Loss = 1.4858, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.2439, Reg Loss = 39.9708, Reconstruct Loss = 0.0015, Cls Loss = 1.2384, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.2680, Reg Loss = 39.4358, Reconstruct Loss = 0.0009, Cls Loss = 1.2632, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.2913, Reg Loss = 38.9764, Reconstruct Loss = 0.0017, Cls Loss = 1.2858, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.2992, Reg Loss = 38.7157, Reconstruct Loss = 0.0013, Cls Loss = 1.2940, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.2953, Reg Loss = 38.5978, Reconstruct Loss = 0.0016, Cls Loss = 1.2898, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.2895, Reg Loss = 38.5105, Reconstruct Loss = 0.0017, Cls Loss = 1.2839, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.2868, Reg Loss = 38.5680, Reconstruct Loss = 0.0015, Cls Loss = 1.2814, Learning rate = 1.0000e-03\n",
      "Epoch [59/200], Training Loss: 1.2832, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/200], Validation Loss: 2.0069, Validation Accuracy: 26.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.1285, Reg Loss = 38.5271, Reconstruct Loss = 0.0000, Cls Loss = 1.1247, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.2809, Reg Loss = 39.1146, Reconstruct Loss = 0.0004, Cls Loss = 1.2766, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.2681, Reg Loss = 39.3760, Reconstruct Loss = 0.0006, Cls Loss = 1.2636, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.2658, Reg Loss = 39.6260, Reconstruct Loss = 0.0006, Cls Loss = 1.2612, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.2515, Reg Loss = 39.7661, Reconstruct Loss = 0.0007, Cls Loss = 1.2469, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.2454, Reg Loss = 39.9767, Reconstruct Loss = 0.0011, Cls Loss = 1.2403, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.2428, Reg Loss = 40.1882, Reconstruct Loss = 0.0010, Cls Loss = 1.2377, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.2448, Reg Loss = 40.1844, Reconstruct Loss = 0.0012, Cls Loss = 1.2396, Learning rate = 1.0000e-03\n",
      "Epoch [60/200], Training Loss: 1.2444, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/200], Validation Loss: 1.9703, Validation Accuracy: 28.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.2663, Reg Loss = 37.5536, Reconstruct Loss = 0.0000, Cls Loss = 1.2625, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.2695, Reg Loss = 40.8443, Reconstruct Loss = 0.0029, Cls Loss = 1.2626, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.2539, Reg Loss = 40.1061, Reconstruct Loss = 0.0019, Cls Loss = 1.2480, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.2583, Reg Loss = 40.2562, Reconstruct Loss = 0.0014, Cls Loss = 1.2529, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.2632, Reg Loss = 40.2681, Reconstruct Loss = 0.0011, Cls Loss = 1.2581, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.2590, Reg Loss = 40.3694, Reconstruct Loss = 0.0012, Cls Loss = 1.2537, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.2584, Reg Loss = 40.4359, Reconstruct Loss = 0.0012, Cls Loss = 1.2532, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.2557, Reg Loss = 40.5007, Reconstruct Loss = 0.0012, Cls Loss = 1.2504, Learning rate = 1.0000e-03\n",
      "Epoch [61/200], Training Loss: 1.2495, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/200], Validation Loss: 2.0971, Validation Accuracy: 23.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.2480, Reg Loss = 40.8979, Reconstruct Loss = 0.0000, Cls Loss = 1.2439, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.2363, Reg Loss = 42.0533, Reconstruct Loss = 0.0015, Cls Loss = 1.2305, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.2332, Reg Loss = 41.8904, Reconstruct Loss = 0.0012, Cls Loss = 1.2278, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.2360, Reg Loss = 41.8275, Reconstruct Loss = 0.0012, Cls Loss = 1.2307, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.2378, Reg Loss = 42.0036, Reconstruct Loss = 0.0010, Cls Loss = 1.2326, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.2362, Reg Loss = 42.0148, Reconstruct Loss = 0.0012, Cls Loss = 1.2308, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.2363, Reg Loss = 42.0197, Reconstruct Loss = 0.0010, Cls Loss = 1.2311, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.2369, Reg Loss = 42.0699, Reconstruct Loss = 0.0009, Cls Loss = 1.2318, Learning rate = 1.0000e-03\n",
      "Epoch [62/200], Training Loss: 1.2324, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/200], Validation Loss: 2.1892, Validation Accuracy: 23.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.1968, Reg Loss = 45.3335, Reconstruct Loss = 0.0000, Cls Loss = 1.1923, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.1841, Reg Loss = 42.7465, Reconstruct Loss = 0.0008, Cls Loss = 1.1791, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.1797, Reg Loss = 42.7895, Reconstruct Loss = 0.0012, Cls Loss = 1.1743, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.1981, Reg Loss = 42.9003, Reconstruct Loss = 0.0009, Cls Loss = 1.1928, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.1927, Reg Loss = 43.0251, Reconstruct Loss = 0.0010, Cls Loss = 1.1873, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.1880, Reg Loss = 43.0825, Reconstruct Loss = 0.0014, Cls Loss = 1.1822, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.1853, Reg Loss = 43.0472, Reconstruct Loss = 0.0014, Cls Loss = 1.1796, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.1845, Reg Loss = 43.0284, Reconstruct Loss = 0.0016, Cls Loss = 1.1786, Learning rate = 1.0000e-03\n",
      "Epoch [63/200], Training Loss: 1.1891, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/200], Validation Loss: 2.1180, Validation Accuracy: 34.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.1992, Reg Loss = 49.9265, Reconstruct Loss = 0.0000, Cls Loss = 1.1942, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.2073, Reg Loss = 43.6239, Reconstruct Loss = 0.0017, Cls Loss = 1.2012, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.2017, Reg Loss = 43.5146, Reconstruct Loss = 0.0018, Cls Loss = 1.1956, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.1832, Reg Loss = 43.3754, Reconstruct Loss = 0.0019, Cls Loss = 1.1770, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.1763, Reg Loss = 43.1799, Reconstruct Loss = 0.0017, Cls Loss = 1.1703, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.1700, Reg Loss = 43.2108, Reconstruct Loss = 0.0016, Cls Loss = 1.1642, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.1691, Reg Loss = 43.2463, Reconstruct Loss = 0.0015, Cls Loss = 1.1633, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.1716, Reg Loss = 43.2912, Reconstruct Loss = 0.0013, Cls Loss = 1.1659, Learning rate = 1.0000e-03\n",
      "Epoch [64/200], Training Loss: 1.1678, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/200], Validation Loss: 1.9559, Validation Accuracy: 28.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8450, Reg Loss = 42.7054, Reconstruct Loss = 0.0000, Cls Loss = 0.8408, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.1743, Reg Loss = 43.4115, Reconstruct Loss = 0.0016, Cls Loss = 1.1684, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.1842, Reg Loss = 43.4694, Reconstruct Loss = 0.0012, Cls Loss = 1.1787, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.1716, Reg Loss = 43.9090, Reconstruct Loss = 0.0013, Cls Loss = 1.1659, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.1674, Reg Loss = 44.0256, Reconstruct Loss = 0.0013, Cls Loss = 1.1617, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.1590, Reg Loss = 44.3199, Reconstruct Loss = 0.0013, Cls Loss = 1.1533, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.1573, Reg Loss = 44.4984, Reconstruct Loss = 0.0011, Cls Loss = 1.1517, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.1568, Reg Loss = 44.5253, Reconstruct Loss = 0.0011, Cls Loss = 1.1512, Learning rate = 1.0000e-03\n",
      "Epoch [65/200], Training Loss: 1.1544, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/200], Validation Loss: 2.0241, Validation Accuracy: 30.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.1984, Reg Loss = 41.6337, Reconstruct Loss = 0.0000, Cls Loss = 1.1942, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.1093, Reg Loss = 45.7320, Reconstruct Loss = 0.0021, Cls Loss = 1.1026, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.1169, Reg Loss = 44.9596, Reconstruct Loss = 0.0017, Cls Loss = 1.1107, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.1268, Reg Loss = 44.7779, Reconstruct Loss = 0.0018, Cls Loss = 1.1206, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.1336, Reg Loss = 44.7781, Reconstruct Loss = 0.0017, Cls Loss = 1.1274, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.1378, Reg Loss = 44.9251, Reconstruct Loss = 0.0014, Cls Loss = 1.1319, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.1363, Reg Loss = 44.8352, Reconstruct Loss = 0.0013, Cls Loss = 1.1305, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.1307, Reg Loss = 44.9026, Reconstruct Loss = 0.0013, Cls Loss = 1.1249, Learning rate = 1.0000e-03\n",
      "Epoch [66/200], Training Loss: 1.1308, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/200], Validation Loss: 1.9861, Validation Accuracy: 33.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9837, Reg Loss = 50.3611, Reconstruct Loss = 0.0000, Cls Loss = 0.9786, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.1447, Reg Loss = 44.9194, Reconstruct Loss = 0.0013, Cls Loss = 1.1389, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.1188, Reg Loss = 45.0520, Reconstruct Loss = 0.0013, Cls Loss = 1.1130, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.1122, Reg Loss = 45.0835, Reconstruct Loss = 0.0014, Cls Loss = 1.1063, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.1024, Reg Loss = 45.1517, Reconstruct Loss = 0.0015, Cls Loss = 1.0964, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.1070, Reg Loss = 45.2600, Reconstruct Loss = 0.0014, Cls Loss = 1.1010, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.1065, Reg Loss = 45.1285, Reconstruct Loss = 0.0016, Cls Loss = 1.1004, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.1103, Reg Loss = 45.3244, Reconstruct Loss = 0.0016, Cls Loss = 1.1041, Learning rate = 1.0000e-03\n",
      "Epoch [67/200], Training Loss: 1.1068, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/200], Validation Loss: 2.2412, Validation Accuracy: 29.71%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.2028, Reg Loss = 36.5097, Reconstruct Loss = 0.0000, Cls Loss = 1.1992, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.0547, Reg Loss = 46.8119, Reconstruct Loss = 0.0021, Cls Loss = 1.0479, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.0700, Reg Loss = 46.7075, Reconstruct Loss = 0.0021, Cls Loss = 1.0633, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0803, Reg Loss = 46.3626, Reconstruct Loss = 0.0018, Cls Loss = 1.0739, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0842, Reg Loss = 45.9172, Reconstruct Loss = 0.0015, Cls Loss = 1.0781, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0898, Reg Loss = 45.9401, Reconstruct Loss = 0.0013, Cls Loss = 1.0839, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0866, Reg Loss = 45.7596, Reconstruct Loss = 0.0015, Cls Loss = 1.0806, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0849, Reg Loss = 45.7934, Reconstruct Loss = 0.0015, Cls Loss = 1.0788, Learning rate = 1.0000e-03\n",
      "Epoch [68/200], Training Loss: 1.0843, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/200], Validation Loss: 2.2689, Validation Accuracy: 27.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.2214, Reg Loss = 43.8258, Reconstruct Loss = 0.0000, Cls Loss = 1.2170, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.0763, Reg Loss = 47.2149, Reconstruct Loss = 0.0012, Cls Loss = 1.0704, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.0796, Reg Loss = 47.0981, Reconstruct Loss = 0.0010, Cls Loss = 1.0739, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0803, Reg Loss = 46.9816, Reconstruct Loss = 0.0012, Cls Loss = 1.0743, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0882, Reg Loss = 47.1178, Reconstruct Loss = 0.0009, Cls Loss = 1.0825, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0845, Reg Loss = 47.1542, Reconstruct Loss = 0.0008, Cls Loss = 1.0790, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0779, Reg Loss = 47.0564, Reconstruct Loss = 0.0011, Cls Loss = 1.0720, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0785, Reg Loss = 47.0423, Reconstruct Loss = 0.0011, Cls Loss = 1.0727, Learning rate = 1.0000e-03\n",
      "Epoch [69/200], Training Loss: 1.0779, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/200], Validation Loss: 1.9865, Validation Accuracy: 32.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.0954, Reg Loss = 47.7993, Reconstruct Loss = 0.0000, Cls Loss = 1.0906, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.0420, Reg Loss = 47.9248, Reconstruct Loss = 0.0013, Cls Loss = 1.0359, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.0525, Reg Loss = 48.0067, Reconstruct Loss = 0.0013, Cls Loss = 1.0465, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0568, Reg Loss = 47.6407, Reconstruct Loss = 0.0016, Cls Loss = 1.0505, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0677, Reg Loss = 47.5907, Reconstruct Loss = 0.0016, Cls Loss = 1.0613, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0700, Reg Loss = 47.5351, Reconstruct Loss = 0.0016, Cls Loss = 1.0637, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0708, Reg Loss = 47.6406, Reconstruct Loss = 0.0015, Cls Loss = 1.0645, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0716, Reg Loss = 47.7753, Reconstruct Loss = 0.0016, Cls Loss = 1.0652, Learning rate = 1.0000e-03\n",
      "Epoch [70/200], Training Loss: 1.0699, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/200], Validation Loss: 2.0693, Validation Accuracy: 29.57%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9558, Reg Loss = 52.8862, Reconstruct Loss = 0.0000, Cls Loss = 0.9505, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.0440, Reg Loss = 46.4640, Reconstruct Loss = 0.0017, Cls Loss = 1.0377, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.0445, Reg Loss = 47.1630, Reconstruct Loss = 0.0021, Cls Loss = 1.0377, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0587, Reg Loss = 47.0892, Reconstruct Loss = 0.0017, Cls Loss = 1.0524, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0593, Reg Loss = 47.2161, Reconstruct Loss = 0.0013, Cls Loss = 1.0533, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0579, Reg Loss = 47.2084, Reconstruct Loss = 0.0011, Cls Loss = 1.0521, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0529, Reg Loss = 47.5988, Reconstruct Loss = 0.0011, Cls Loss = 1.0471, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0463, Reg Loss = 47.6526, Reconstruct Loss = 0.0012, Cls Loss = 1.0403, Learning rate = 1.0000e-03\n",
      "Epoch [71/200], Training Loss: 1.0496, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/200], Validation Loss: 2.1955, Validation Accuracy: 27.83%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8115, Reg Loss = 51.7052, Reconstruct Loss = 0.0000, Cls Loss = 0.8063, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.0013, Reg Loss = 49.0597, Reconstruct Loss = 0.0004, Cls Loss = 0.9960, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.0169, Reg Loss = 49.6520, Reconstruct Loss = 0.0013, Cls Loss = 1.0106, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0214, Reg Loss = 49.1397, Reconstruct Loss = 0.0014, Cls Loss = 1.0150, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0191, Reg Loss = 48.7793, Reconstruct Loss = 0.0016, Cls Loss = 1.0126, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0128, Reg Loss = 49.0562, Reconstruct Loss = 0.0015, Cls Loss = 1.0064, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0104, Reg Loss = 49.1945, Reconstruct Loss = 0.0014, Cls Loss = 1.0041, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0108, Reg Loss = 49.2316, Reconstruct Loss = 0.0015, Cls Loss = 1.0044, Learning rate = 1.0000e-03\n",
      "Epoch [72/200], Training Loss: 1.0140, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/200], Validation Loss: 2.1450, Validation Accuracy: 30.26%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9367, Reg Loss = 44.8116, Reconstruct Loss = 0.0000, Cls Loss = 0.9323, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9793, Reg Loss = 48.7290, Reconstruct Loss = 0.0018, Cls Loss = 0.9727, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 1.0214, Reg Loss = 48.5386, Reconstruct Loss = 0.0013, Cls Loss = 1.0153, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0278, Reg Loss = 48.3390, Reconstruct Loss = 0.0015, Cls Loss = 1.0214, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0309, Reg Loss = 48.7711, Reconstruct Loss = 0.0013, Cls Loss = 1.0247, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0296, Reg Loss = 49.2243, Reconstruct Loss = 0.0011, Cls Loss = 1.0236, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0223, Reg Loss = 49.3656, Reconstruct Loss = 0.0013, Cls Loss = 1.0162, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0249, Reg Loss = 49.5597, Reconstruct Loss = 0.0011, Cls Loss = 1.0188, Learning rate = 1.0000e-03\n",
      "Epoch [73/200], Training Loss: 1.0261, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/200], Validation Loss: 2.3909, Validation Accuracy: 26.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8275, Reg Loss = 49.1352, Reconstruct Loss = 0.0000, Cls Loss = 0.8226, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 1.0130, Reg Loss = 50.7192, Reconstruct Loss = 0.0013, Cls Loss = 1.0066, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9966, Reg Loss = 49.8630, Reconstruct Loss = 0.0015, Cls Loss = 0.9901, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 1.0339, Reg Loss = 49.3689, Reconstruct Loss = 0.0017, Cls Loss = 1.0273, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 1.0183, Reg Loss = 49.3555, Reconstruct Loss = 0.0016, Cls Loss = 1.0118, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 1.0070, Reg Loss = 49.9410, Reconstruct Loss = 0.0014, Cls Loss = 1.0006, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 1.0029, Reg Loss = 50.1645, Reconstruct Loss = 0.0016, Cls Loss = 0.9963, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 1.0014, Reg Loss = 50.2227, Reconstruct Loss = 0.0016, Cls Loss = 0.9948, Learning rate = 1.0000e-03\n",
      "Epoch [74/200], Training Loss: 1.0022, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/200], Validation Loss: 2.2625, Validation Accuracy: 26.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.0867, Reg Loss = 52.7618, Reconstruct Loss = 0.0000, Cls Loss = 1.0814, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9700, Reg Loss = 51.5685, Reconstruct Loss = 0.0009, Cls Loss = 0.9640, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9795, Reg Loss = 50.8944, Reconstruct Loss = 0.0010, Cls Loss = 0.9734, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.9783, Reg Loss = 50.4139, Reconstruct Loss = 0.0011, Cls Loss = 0.9722, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.9801, Reg Loss = 50.4516, Reconstruct Loss = 0.0011, Cls Loss = 0.9740, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.9785, Reg Loss = 50.4086, Reconstruct Loss = 0.0011, Cls Loss = 0.9724, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.9761, Reg Loss = 50.3443, Reconstruct Loss = 0.0010, Cls Loss = 0.9701, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.9691, Reg Loss = 50.4757, Reconstruct Loss = 0.0010, Cls Loss = 0.9630, Learning rate = 1.0000e-03\n",
      "Epoch [75/200], Training Loss: 0.9703, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/200], Validation Loss: 2.3207, Validation Accuracy: 28.75%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9611, Reg Loss = 48.2923, Reconstruct Loss = 0.0000, Cls Loss = 0.9563, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9747, Reg Loss = 50.6538, Reconstruct Loss = 0.0008, Cls Loss = 0.9688, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9840, Reg Loss = 50.2538, Reconstruct Loss = 0.0013, Cls Loss = 0.9777, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.9828, Reg Loss = 50.5576, Reconstruct Loss = 0.0010, Cls Loss = 0.9768, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.9773, Reg Loss = 50.9810, Reconstruct Loss = 0.0011, Cls Loss = 0.9710, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.9797, Reg Loss = 51.0810, Reconstruct Loss = 0.0012, Cls Loss = 0.9734, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.9799, Reg Loss = 51.2092, Reconstruct Loss = 0.0012, Cls Loss = 0.9736, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.9786, Reg Loss = 51.1659, Reconstruct Loss = 0.0012, Cls Loss = 0.9723, Learning rate = 1.0000e-03\n",
      "Epoch [76/200], Training Loss: 0.9783, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/200], Validation Loss: 2.3476, Validation Accuracy: 26.07%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.1805, Reg Loss = 41.4356, Reconstruct Loss = 0.0000, Cls Loss = 1.1764, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9545, Reg Loss = 49.1914, Reconstruct Loss = 0.0005, Cls Loss = 0.9491, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9428, Reg Loss = 49.7771, Reconstruct Loss = 0.0009, Cls Loss = 0.9369, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.9563, Reg Loss = 50.1819, Reconstruct Loss = 0.0006, Cls Loss = 0.9507, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.9570, Reg Loss = 50.4383, Reconstruct Loss = 0.0010, Cls Loss = 0.9510, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.9573, Reg Loss = 50.4908, Reconstruct Loss = 0.0008, Cls Loss = 0.9515, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.9523, Reg Loss = 50.7704, Reconstruct Loss = 0.0009, Cls Loss = 0.9463, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.9554, Reg Loss = 51.0598, Reconstruct Loss = 0.0010, Cls Loss = 0.9493, Learning rate = 1.0000e-03\n",
      "Epoch [77/200], Training Loss: 0.9547, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/200], Validation Loss: 2.3582, Validation Accuracy: 25.90%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.3449, Reg Loss = 46.3776, Reconstruct Loss = 0.0000, Cls Loss = 1.3403, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9725, Reg Loss = 51.3949, Reconstruct Loss = 0.0020, Cls Loss = 0.9653, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9634, Reg Loss = 50.8792, Reconstruct Loss = 0.0020, Cls Loss = 0.9563, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.9692, Reg Loss = 51.0756, Reconstruct Loss = 0.0018, Cls Loss = 0.9623, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.9617, Reg Loss = 51.3475, Reconstruct Loss = 0.0018, Cls Loss = 0.9547, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.9559, Reg Loss = 51.5901, Reconstruct Loss = 0.0017, Cls Loss = 0.9491, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.9476, Reg Loss = 51.6631, Reconstruct Loss = 0.0017, Cls Loss = 0.9407, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.9412, Reg Loss = 51.9479, Reconstruct Loss = 0.0017, Cls Loss = 0.9344, Learning rate = 1.0000e-03\n",
      "Epoch [78/200], Training Loss: 0.9387, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/200], Validation Loss: 2.2350, Validation Accuracy: 27.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9862, Reg Loss = 56.2596, Reconstruct Loss = 0.0000, Cls Loss = 0.9806, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9561, Reg Loss = 52.7741, Reconstruct Loss = 0.0029, Cls Loss = 0.9479, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9466, Reg Loss = 52.5067, Reconstruct Loss = 0.0023, Cls Loss = 0.9391, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.9383, Reg Loss = 52.2610, Reconstruct Loss = 0.0024, Cls Loss = 0.9306, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.9334, Reg Loss = 52.3350, Reconstruct Loss = 0.0022, Cls Loss = 0.9259, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.9329, Reg Loss = 52.3119, Reconstruct Loss = 0.0021, Cls Loss = 0.9255, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.9313, Reg Loss = 52.3566, Reconstruct Loss = 0.0021, Cls Loss = 0.9240, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.9318, Reg Loss = 52.3310, Reconstruct Loss = 0.0018, Cls Loss = 0.9248, Learning rate = 1.0000e-03\n",
      "Epoch [79/200], Training Loss: 0.9331, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/200], Validation Loss: 2.3127, Validation Accuracy: 29.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7802, Reg Loss = 50.6664, Reconstruct Loss = 0.0000, Cls Loss = 0.7751, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9083, Reg Loss = 53.4038, Reconstruct Loss = 0.0021, Cls Loss = 0.9008, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9076, Reg Loss = 53.2419, Reconstruct Loss = 0.0017, Cls Loss = 0.9005, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.9081, Reg Loss = 53.2369, Reconstruct Loss = 0.0013, Cls Loss = 0.9015, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.9192, Reg Loss = 53.1021, Reconstruct Loss = 0.0013, Cls Loss = 0.9126, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.9221, Reg Loss = 52.7132, Reconstruct Loss = 0.0013, Cls Loss = 0.9155, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.9170, Reg Loss = 52.6527, Reconstruct Loss = 0.0016, Cls Loss = 0.9102, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.9154, Reg Loss = 52.7094, Reconstruct Loss = 0.0016, Cls Loss = 0.9085, Learning rate = 1.0000e-03\n",
      "Epoch [80/200], Training Loss: 0.9148, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/200], Validation Loss: 2.3380, Validation Accuracy: 25.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9495, Reg Loss = 58.2183, Reconstruct Loss = 0.0000, Cls Loss = 0.9437, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9055, Reg Loss = 52.3945, Reconstruct Loss = 0.0012, Cls Loss = 0.8990, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9015, Reg Loss = 52.0577, Reconstruct Loss = 0.0016, Cls Loss = 0.8947, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8999, Reg Loss = 52.3138, Reconstruct Loss = 0.0018, Cls Loss = 0.8929, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.9045, Reg Loss = 52.0781, Reconstruct Loss = 0.0017, Cls Loss = 0.8976, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.9001, Reg Loss = 52.4097, Reconstruct Loss = 0.0016, Cls Loss = 0.8933, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8990, Reg Loss = 52.3446, Reconstruct Loss = 0.0016, Cls Loss = 0.8922, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.9044, Reg Loss = 52.5513, Reconstruct Loss = 0.0015, Cls Loss = 0.8976, Learning rate = 1.0000e-03\n",
      "Epoch [81/200], Training Loss: 0.8986, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/200], Validation Loss: 2.4116, Validation Accuracy: 26.69%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7436, Reg Loss = 57.5208, Reconstruct Loss = 0.0000, Cls Loss = 0.7379, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8862, Reg Loss = 53.4615, Reconstruct Loss = 0.0018, Cls Loss = 0.8790, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8841, Reg Loss = 53.8541, Reconstruct Loss = 0.0022, Cls Loss = 0.8765, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8918, Reg Loss = 54.2216, Reconstruct Loss = 0.0016, Cls Loss = 0.8848, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8929, Reg Loss = 54.2354, Reconstruct Loss = 0.0014, Cls Loss = 0.8860, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8938, Reg Loss = 54.0925, Reconstruct Loss = 0.0015, Cls Loss = 0.8869, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8988, Reg Loss = 53.8734, Reconstruct Loss = 0.0016, Cls Loss = 0.8918, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8956, Reg Loss = 53.6859, Reconstruct Loss = 0.0015, Cls Loss = 0.8887, Learning rate = 1.0000e-03\n",
      "Epoch [82/200], Training Loss: 0.8948, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/200], Validation Loss: 2.4657, Validation Accuracy: 27.07%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.0842, Reg Loss = 51.0158, Reconstruct Loss = 0.0000, Cls Loss = 1.0791, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.9311, Reg Loss = 53.1858, Reconstruct Loss = 0.0013, Cls Loss = 0.9245, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.9052, Reg Loss = 54.4246, Reconstruct Loss = 0.0011, Cls Loss = 0.8987, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8890, Reg Loss = 54.2593, Reconstruct Loss = 0.0009, Cls Loss = 0.8827, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8843, Reg Loss = 54.2408, Reconstruct Loss = 0.0008, Cls Loss = 0.8781, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8841, Reg Loss = 54.2561, Reconstruct Loss = 0.0009, Cls Loss = 0.8779, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8913, Reg Loss = 54.0975, Reconstruct Loss = 0.0012, Cls Loss = 0.8846, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8917, Reg Loss = 53.9577, Reconstruct Loss = 0.0012, Cls Loss = 0.8851, Learning rate = 1.0000e-03\n",
      "Epoch [83/200], Training Loss: 0.8874, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/200], Validation Loss: 2.3720, Validation Accuracy: 27.55%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9632, Reg Loss = 49.7069, Reconstruct Loss = 0.0000, Cls Loss = 0.9582, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8655, Reg Loss = 53.8627, Reconstruct Loss = 0.0000, Cls Loss = 0.8601, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8656, Reg Loss = 54.7428, Reconstruct Loss = 0.0009, Cls Loss = 0.8592, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8665, Reg Loss = 54.6597, Reconstruct Loss = 0.0009, Cls Loss = 0.8601, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8643, Reg Loss = 54.5791, Reconstruct Loss = 0.0012, Cls Loss = 0.8576, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8784, Reg Loss = 54.3077, Reconstruct Loss = 0.0010, Cls Loss = 0.8720, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8754, Reg Loss = 54.3461, Reconstruct Loss = 0.0010, Cls Loss = 0.8690, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8774, Reg Loss = 54.1424, Reconstruct Loss = 0.0011, Cls Loss = 0.8709, Learning rate = 1.0000e-03\n",
      "Epoch [84/200], Training Loss: 0.8809, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/200], Validation Loss: 2.1031, Validation Accuracy: 29.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8502, Reg Loss = 55.2392, Reconstruct Loss = 0.0000, Cls Loss = 0.8446, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8339, Reg Loss = 53.9570, Reconstruct Loss = 0.0013, Cls Loss = 0.8272, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8413, Reg Loss = 53.6208, Reconstruct Loss = 0.0009, Cls Loss = 0.8350, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8553, Reg Loss = 54.0559, Reconstruct Loss = 0.0011, Cls Loss = 0.8488, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8542, Reg Loss = 53.8605, Reconstruct Loss = 0.0011, Cls Loss = 0.8477, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8471, Reg Loss = 54.0156, Reconstruct Loss = 0.0014, Cls Loss = 0.8404, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8491, Reg Loss = 54.1393, Reconstruct Loss = 0.0016, Cls Loss = 0.8420, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8502, Reg Loss = 54.1108, Reconstruct Loss = 0.0016, Cls Loss = 0.8432, Learning rate = 1.0000e-03\n",
      "Epoch [85/200], Training Loss: 0.8495, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/200], Validation Loss: 2.6644, Validation Accuracy: 25.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 1.0754, Reg Loss = 55.4756, Reconstruct Loss = 0.0000, Cls Loss = 1.0698, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8293, Reg Loss = 54.7666, Reconstruct Loss = 0.0018, Cls Loss = 0.8221, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8278, Reg Loss = 54.7018, Reconstruct Loss = 0.0014, Cls Loss = 0.8210, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8478, Reg Loss = 54.4068, Reconstruct Loss = 0.0011, Cls Loss = 0.8414, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8395, Reg Loss = 54.2433, Reconstruct Loss = 0.0010, Cls Loss = 0.8331, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8308, Reg Loss = 54.3297, Reconstruct Loss = 0.0014, Cls Loss = 0.8240, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8337, Reg Loss = 54.6251, Reconstruct Loss = 0.0012, Cls Loss = 0.8270, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8389, Reg Loss = 54.5209, Reconstruct Loss = 0.0012, Cls Loss = 0.8322, Learning rate = 1.0000e-03\n",
      "Epoch [86/200], Training Loss: 0.8421, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/200], Validation Loss: 2.5753, Validation Accuracy: 25.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9901, Reg Loss = 56.4023, Reconstruct Loss = 0.0000, Cls Loss = 0.9844, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8314, Reg Loss = 54.3400, Reconstruct Loss = 0.0010, Cls Loss = 0.8250, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8206, Reg Loss = 54.5468, Reconstruct Loss = 0.0007, Cls Loss = 0.8145, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8297, Reg Loss = 54.8567, Reconstruct Loss = 0.0006, Cls Loss = 0.8236, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8460, Reg Loss = 54.9858, Reconstruct Loss = 0.0006, Cls Loss = 0.8399, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8477, Reg Loss = 55.0776, Reconstruct Loss = 0.0006, Cls Loss = 0.8416, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8465, Reg Loss = 55.1405, Reconstruct Loss = 0.0006, Cls Loss = 0.8403, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8435, Reg Loss = 55.2600, Reconstruct Loss = 0.0006, Cls Loss = 0.8374, Learning rate = 1.0000e-03\n",
      "Epoch [87/200], Training Loss: 0.8430, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/200], Validation Loss: 2.3359, Validation Accuracy: 28.24%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8888, Reg Loss = 47.8597, Reconstruct Loss = 0.0000, Cls Loss = 0.8840, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8422, Reg Loss = 54.3075, Reconstruct Loss = 0.0012, Cls Loss = 0.8355, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8345, Reg Loss = 54.9503, Reconstruct Loss = 0.0013, Cls Loss = 0.8277, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8334, Reg Loss = 55.2635, Reconstruct Loss = 0.0012, Cls Loss = 0.8267, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8323, Reg Loss = 55.4720, Reconstruct Loss = 0.0011, Cls Loss = 0.8257, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8275, Reg Loss = 55.3973, Reconstruct Loss = 0.0012, Cls Loss = 0.8208, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8289, Reg Loss = 55.4815, Reconstruct Loss = 0.0013, Cls Loss = 0.8220, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8279, Reg Loss = 55.6210, Reconstruct Loss = 0.0012, Cls Loss = 0.8211, Learning rate = 1.0000e-03\n",
      "Epoch [88/200], Training Loss: 0.8269, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/200], Validation Loss: 2.4292, Validation Accuracy: 28.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8008, Reg Loss = 49.3229, Reconstruct Loss = 0.0000, Cls Loss = 0.7958, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8262, Reg Loss = 55.4589, Reconstruct Loss = 0.0012, Cls Loss = 0.8194, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8235, Reg Loss = 55.3358, Reconstruct Loss = 0.0006, Cls Loss = 0.8173, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8261, Reg Loss = 55.5138, Reconstruct Loss = 0.0007, Cls Loss = 0.8198, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8332, Reg Loss = 55.6753, Reconstruct Loss = 0.0009, Cls Loss = 0.8268, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8431, Reg Loss = 55.5808, Reconstruct Loss = 0.0009, Cls Loss = 0.8367, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8421, Reg Loss = 55.6440, Reconstruct Loss = 0.0010, Cls Loss = 0.8355, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8371, Reg Loss = 55.7241, Reconstruct Loss = 0.0012, Cls Loss = 0.8304, Learning rate = 1.0000e-03\n",
      "Epoch [89/200], Training Loss: 0.8324, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/200], Validation Loss: 2.3362, Validation Accuracy: 30.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8950, Reg Loss = 49.2857, Reconstruct Loss = 0.0000, Cls Loss = 0.8901, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8152, Reg Loss = 56.8816, Reconstruct Loss = 0.0000, Cls Loss = 0.8095, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8281, Reg Loss = 55.3948, Reconstruct Loss = 0.0007, Cls Loss = 0.8219, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8244, Reg Loss = 55.2618, Reconstruct Loss = 0.0015, Cls Loss = 0.8174, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8232, Reg Loss = 55.5407, Reconstruct Loss = 0.0017, Cls Loss = 0.8159, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8308, Reg Loss = 55.4942, Reconstruct Loss = 0.0016, Cls Loss = 0.8236, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8310, Reg Loss = 55.5546, Reconstruct Loss = 0.0016, Cls Loss = 0.8239, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8290, Reg Loss = 55.6448, Reconstruct Loss = 0.0017, Cls Loss = 0.8217, Learning rate = 1.0000e-03\n",
      "Epoch [90/200], Training Loss: 0.8320, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/200], Validation Loss: 2.6403, Validation Accuracy: 25.77%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8231, Reg Loss = 58.3127, Reconstruct Loss = 0.0000, Cls Loss = 0.8173, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8828, Reg Loss = 55.2901, Reconstruct Loss = 0.0018, Cls Loss = 0.8755, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8571, Reg Loss = 55.5909, Reconstruct Loss = 0.0020, Cls Loss = 0.8495, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8451, Reg Loss = 55.3525, Reconstruct Loss = 0.0016, Cls Loss = 0.8379, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8470, Reg Loss = 55.2395, Reconstruct Loss = 0.0019, Cls Loss = 0.8396, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8456, Reg Loss = 55.3937, Reconstruct Loss = 0.0018, Cls Loss = 0.8382, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8376, Reg Loss = 55.4559, Reconstruct Loss = 0.0017, Cls Loss = 0.8303, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8287, Reg Loss = 55.5518, Reconstruct Loss = 0.0016, Cls Loss = 0.8215, Learning rate = 1.0000e-03\n",
      "Epoch [91/200], Training Loss: 0.8256, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200], Validation Loss: 2.5101, Validation Accuracy: 29.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6957, Reg Loss = 56.0319, Reconstruct Loss = 0.0000, Cls Loss = 0.6901, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.8218, Reg Loss = 56.4191, Reconstruct Loss = 0.0009, Cls Loss = 0.8153, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.8286, Reg Loss = 56.2828, Reconstruct Loss = 0.0009, Cls Loss = 0.8221, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8212, Reg Loss = 56.2490, Reconstruct Loss = 0.0009, Cls Loss = 0.8146, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.8179, Reg Loss = 56.4812, Reconstruct Loss = 0.0011, Cls Loss = 0.8111, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.8128, Reg Loss = 56.4586, Reconstruct Loss = 0.0012, Cls Loss = 0.8059, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.8114, Reg Loss = 56.3017, Reconstruct Loss = 0.0011, Cls Loss = 0.8046, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.8067, Reg Loss = 56.4189, Reconstruct Loss = 0.0010, Cls Loss = 0.8000, Learning rate = 1.0000e-03\n",
      "Epoch [92/200], Training Loss: 0.8039, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/200], Validation Loss: 2.7563, Validation Accuracy: 25.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8538, Reg Loss = 49.5635, Reconstruct Loss = 0.0000, Cls Loss = 0.8488, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7854, Reg Loss = 56.0119, Reconstruct Loss = 0.0025, Cls Loss = 0.7773, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7842, Reg Loss = 56.6908, Reconstruct Loss = 0.0019, Cls Loss = 0.7766, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.8012, Reg Loss = 56.9382, Reconstruct Loss = 0.0014, Cls Loss = 0.7941, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7966, Reg Loss = 57.0972, Reconstruct Loss = 0.0012, Cls Loss = 0.7896, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7943, Reg Loss = 57.1052, Reconstruct Loss = 0.0011, Cls Loss = 0.7874, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7911, Reg Loss = 57.3475, Reconstruct Loss = 0.0013, Cls Loss = 0.7841, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7886, Reg Loss = 57.5242, Reconstruct Loss = 0.0014, Cls Loss = 0.7815, Learning rate = 1.0000e-03\n",
      "Epoch [93/200], Training Loss: 0.7886, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/200], Validation Loss: 2.8101, Validation Accuracy: 25.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8827, Reg Loss = 58.1221, Reconstruct Loss = 0.0000, Cls Loss = 0.8769, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7813, Reg Loss = 59.1095, Reconstruct Loss = 0.0014, Cls Loss = 0.7739, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7876, Reg Loss = 58.5739, Reconstruct Loss = 0.0014, Cls Loss = 0.7804, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7853, Reg Loss = 58.2732, Reconstruct Loss = 0.0012, Cls Loss = 0.7782, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7811, Reg Loss = 57.8784, Reconstruct Loss = 0.0013, Cls Loss = 0.7741, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7818, Reg Loss = 57.9461, Reconstruct Loss = 0.0017, Cls Loss = 0.7744, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7880, Reg Loss = 57.8567, Reconstruct Loss = 0.0017, Cls Loss = 0.7805, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7842, Reg Loss = 57.7599, Reconstruct Loss = 0.0016, Cls Loss = 0.7768, Learning rate = 1.0000e-03\n",
      "Epoch [94/200], Training Loss: 0.7819, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/200], Validation Loss: 2.2148, Validation Accuracy: 30.91%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7335, Reg Loss = 61.5625, Reconstruct Loss = 0.0000, Cls Loss = 0.7274, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7738, Reg Loss = 58.1517, Reconstruct Loss = 0.0027, Cls Loss = 0.7653, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7614, Reg Loss = 57.0442, Reconstruct Loss = 0.0029, Cls Loss = 0.7528, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7582, Reg Loss = 57.0013, Reconstruct Loss = 0.0027, Cls Loss = 0.7498, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7504, Reg Loss = 57.1988, Reconstruct Loss = 0.0024, Cls Loss = 0.7423, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7578, Reg Loss = 57.4818, Reconstruct Loss = 0.0022, Cls Loss = 0.7499, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7623, Reg Loss = 57.6348, Reconstruct Loss = 0.0021, Cls Loss = 0.7544, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7644, Reg Loss = 57.6168, Reconstruct Loss = 0.0020, Cls Loss = 0.7566, Learning rate = 1.0000e-03\n",
      "Epoch [95/200], Training Loss: 0.7611, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 49.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/200], Validation Loss: 2.4554, Validation Accuracy: 27.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7904, Reg Loss = 59.5166, Reconstruct Loss = 0.0000, Cls Loss = 0.7845, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7842, Reg Loss = 56.8502, Reconstruct Loss = 0.0014, Cls Loss = 0.7772, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7905, Reg Loss = 57.0107, Reconstruct Loss = 0.0017, Cls Loss = 0.7831, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7774, Reg Loss = 57.0389, Reconstruct Loss = 0.0014, Cls Loss = 0.7703, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7691, Reg Loss = 57.3804, Reconstruct Loss = 0.0013, Cls Loss = 0.7621, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7741, Reg Loss = 57.7113, Reconstruct Loss = 0.0015, Cls Loss = 0.7668, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7715, Reg Loss = 57.8472, Reconstruct Loss = 0.0014, Cls Loss = 0.7644, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7715, Reg Loss = 57.9999, Reconstruct Loss = 0.0013, Cls Loss = 0.7643, Learning rate = 1.0000e-03\n",
      "Epoch [96/200], Training Loss: 0.7697, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 50.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/200], Validation Loss: 2.3759, Validation Accuracy: 31.53%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7844, Reg Loss = 56.0221, Reconstruct Loss = 0.0000, Cls Loss = 0.7788, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7785, Reg Loss = 57.9923, Reconstruct Loss = 0.0009, Cls Loss = 0.7718, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7673, Reg Loss = 58.4200, Reconstruct Loss = 0.0018, Cls Loss = 0.7596, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7665, Reg Loss = 58.6087, Reconstruct Loss = 0.0017, Cls Loss = 0.7590, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7649, Reg Loss = 58.2338, Reconstruct Loss = 0.0016, Cls Loss = 0.7574, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7774, Reg Loss = 58.5739, Reconstruct Loss = 0.0015, Cls Loss = 0.7701, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7711, Reg Loss = 58.5216, Reconstruct Loss = 0.0018, Cls Loss = 0.7634, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7662, Reg Loss = 58.6714, Reconstruct Loss = 0.0017, Cls Loss = 0.7587, Learning rate = 1.0000e-03\n",
      "Epoch [97/200], Training Loss: 0.7641, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/200], Validation Loss: 2.8607, Validation Accuracy: 25.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5801, Reg Loss = 61.9777, Reconstruct Loss = 0.0000, Cls Loss = 0.5739, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7462, Reg Loss = 59.4582, Reconstruct Loss = 0.0023, Cls Loss = 0.7379, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7689, Reg Loss = 58.9713, Reconstruct Loss = 0.0021, Cls Loss = 0.7609, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7607, Reg Loss = 58.9157, Reconstruct Loss = 0.0020, Cls Loss = 0.7527, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7558, Reg Loss = 59.0455, Reconstruct Loss = 0.0020, Cls Loss = 0.7480, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7568, Reg Loss = 58.9649, Reconstruct Loss = 0.0018, Cls Loss = 0.7492, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7598, Reg Loss = 58.7886, Reconstruct Loss = 0.0020, Cls Loss = 0.7519, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7612, Reg Loss = 58.7586, Reconstruct Loss = 0.0019, Cls Loss = 0.7535, Learning rate = 1.0000e-03\n",
      "Epoch [98/200], Training Loss: 0.7552, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/200], Validation Loss: 2.4343, Validation Accuracy: 30.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.9534, Reg Loss = 50.9895, Reconstruct Loss = 0.0000, Cls Loss = 0.9483, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7311, Reg Loss = 59.2223, Reconstruct Loss = 0.0004, Cls Loss = 0.7247, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7430, Reg Loss = 59.2427, Reconstruct Loss = 0.0009, Cls Loss = 0.7361, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7399, Reg Loss = 58.9067, Reconstruct Loss = 0.0017, Cls Loss = 0.7324, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7508, Reg Loss = 58.8271, Reconstruct Loss = 0.0018, Cls Loss = 0.7431, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7513, Reg Loss = 58.9137, Reconstruct Loss = 0.0022, Cls Loss = 0.7432, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7437, Reg Loss = 59.0646, Reconstruct Loss = 0.0021, Cls Loss = 0.7357, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7390, Reg Loss = 59.1573, Reconstruct Loss = 0.0020, Cls Loss = 0.7311, Learning rate = 1.0000e-03\n",
      "Epoch [99/200], Training Loss: 0.7417, Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/200], Validation Loss: 3.0942, Validation Accuracy: 26.02%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5052, Reg Loss = 58.4199, Reconstruct Loss = 0.0000, Cls Loss = 0.4994, Learning rate = 1.0000e-03\n",
      "Iteration 100: Loss = 0.7474, Reg Loss = 58.6794, Reconstruct Loss = 0.0014, Cls Loss = 0.7401, Learning rate = 1.0000e-03\n",
      "Iteration 200: Loss = 0.7468, Reg Loss = 58.4935, Reconstruct Loss = 0.0013, Cls Loss = 0.7397, Learning rate = 1.0000e-03\n",
      "Iteration 300: Loss = 0.7461, Reg Loss = 58.7121, Reconstruct Loss = 0.0013, Cls Loss = 0.7389, Learning rate = 1.0000e-03\n",
      "Iteration 400: Loss = 0.7352, Reg Loss = 58.7160, Reconstruct Loss = 0.0015, Cls Loss = 0.7278, Learning rate = 1.0000e-03\n",
      "Iteration 500: Loss = 0.7337, Reg Loss = 58.6727, Reconstruct Loss = 0.0015, Cls Loss = 0.7263, Learning rate = 1.0000e-03\n",
      "Iteration 600: Loss = 0.7321, Reg Loss = 58.9178, Reconstruct Loss = 0.0013, Cls Loss = 0.7249, Learning rate = 1.0000e-03\n",
      "Iteration 700: Loss = 0.7328, Reg Loss = 59.0070, Reconstruct Loss = 0.0015, Cls Loss = 0.7254, Learning rate = 1.0000e-03\n",
      "Epoch [100/200], Training Loss: 0.7332, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/200], Validation Loss: 2.4982, Validation Accuracy: 29.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7951, Reg Loss = 49.4119, Reconstruct Loss = 0.0000, Cls Loss = 0.7901, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.6867, Reg Loss = 58.0963, Reconstruct Loss = 0.0009, Cls Loss = 0.6800, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.6631, Reg Loss = 58.3323, Reconstruct Loss = 0.0009, Cls Loss = 0.6563, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.6460, Reg Loss = 58.9280, Reconstruct Loss = 0.0010, Cls Loss = 0.6390, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.6427, Reg Loss = 59.0923, Reconstruct Loss = 0.0011, Cls Loss = 0.6356, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.6368, Reg Loss = 59.2907, Reconstruct Loss = 0.0012, Cls Loss = 0.6297, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.6325, Reg Loss = 59.3641, Reconstruct Loss = 0.0010, Cls Loss = 0.6255, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.6301, Reg Loss = 59.5903, Reconstruct Loss = 0.0011, Cls Loss = 0.6231, Learning rate = 1.0000e-04\n",
      "Epoch [101/200], Training Loss: 0.6277, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200], Validation Loss: 2.8394, Validation Accuracy: 28.35%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6455, Reg Loss = 59.3608, Reconstruct Loss = 0.0000, Cls Loss = 0.6395, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5876, Reg Loss = 59.9457, Reconstruct Loss = 0.0009, Cls Loss = 0.5808, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5940, Reg Loss = 60.3743, Reconstruct Loss = 0.0016, Cls Loss = 0.5864, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5903, Reg Loss = 60.4333, Reconstruct Loss = 0.0011, Cls Loss = 0.5832, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5889, Reg Loss = 60.5540, Reconstruct Loss = 0.0010, Cls Loss = 0.5818, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5914, Reg Loss = 60.4888, Reconstruct Loss = 0.0012, Cls Loss = 0.5842, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5944, Reg Loss = 60.4493, Reconstruct Loss = 0.0015, Cls Loss = 0.5869, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5947, Reg Loss = 60.4550, Reconstruct Loss = 0.0013, Cls Loss = 0.5873, Learning rate = 1.0000e-04\n",
      "Epoch [102/200], Training Loss: 0.5912, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/200], Validation Loss: 2.7778, Validation Accuracy: 31.94%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5736, Reg Loss = 61.8593, Reconstruct Loss = 0.0000, Cls Loss = 0.5674, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5657, Reg Loss = 60.5431, Reconstruct Loss = 0.0000, Cls Loss = 0.5596, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5793, Reg Loss = 60.6965, Reconstruct Loss = 0.0009, Cls Loss = 0.5723, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5751, Reg Loss = 60.9400, Reconstruct Loss = 0.0006, Cls Loss = 0.5684, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5727, Reg Loss = 61.0056, Reconstruct Loss = 0.0004, Cls Loss = 0.5662, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5731, Reg Loss = 61.0427, Reconstruct Loss = 0.0010, Cls Loss = 0.5660, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5721, Reg Loss = 61.0388, Reconstruct Loss = 0.0013, Cls Loss = 0.5647, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5737, Reg Loss = 60.9923, Reconstruct Loss = 0.0012, Cls Loss = 0.5665, Learning rate = 1.0000e-04\n",
      "Epoch [103/200], Training Loss: 0.5750, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/200], Validation Loss: 2.7468, Validation Accuracy: 31.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6224, Reg Loss = 64.5395, Reconstruct Loss = 0.0000, Cls Loss = 0.6160, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5482, Reg Loss = 60.7261, Reconstruct Loss = 0.0018, Cls Loss = 0.5404, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5596, Reg Loss = 60.8139, Reconstruct Loss = 0.0025, Cls Loss = 0.5510, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5574, Reg Loss = 60.5339, Reconstruct Loss = 0.0030, Cls Loss = 0.5484, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5542, Reg Loss = 60.4639, Reconstruct Loss = 0.0024, Cls Loss = 0.5458, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5581, Reg Loss = 60.4111, Reconstruct Loss = 0.0024, Cls Loss = 0.5497, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5587, Reg Loss = 60.5268, Reconstruct Loss = 0.0022, Cls Loss = 0.5504, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5566, Reg Loss = 60.5651, Reconstruct Loss = 0.0021, Cls Loss = 0.5485, Learning rate = 1.0000e-04\n",
      "Epoch [104/200], Training Loss: 0.5590, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/200], Validation Loss: 2.6163, Validation Accuracy: 32.59%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5620, Reg Loss = 65.0813, Reconstruct Loss = 0.0000, Cls Loss = 0.5555, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5587, Reg Loss = 61.2063, Reconstruct Loss = 0.0028, Cls Loss = 0.5499, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5627, Reg Loss = 60.7803, Reconstruct Loss = 0.0016, Cls Loss = 0.5550, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5574, Reg Loss = 60.9965, Reconstruct Loss = 0.0018, Cls Loss = 0.5494, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5563, Reg Loss = 60.8776, Reconstruct Loss = 0.0016, Cls Loss = 0.5486, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5567, Reg Loss = 60.9787, Reconstruct Loss = 0.0014, Cls Loss = 0.5492, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5554, Reg Loss = 60.9569, Reconstruct Loss = 0.0014, Cls Loss = 0.5479, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5529, Reg Loss = 60.9556, Reconstruct Loss = 0.0014, Cls Loss = 0.5454, Learning rate = 1.0000e-04\n",
      "Epoch [105/200], Training Loss: 0.5554, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/200], Validation Loss: 2.9995, Validation Accuracy: 30.67%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3809, Reg Loss = 57.1931, Reconstruct Loss = 0.0000, Cls Loss = 0.3752, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5509, Reg Loss = 60.6265, Reconstruct Loss = 0.0028, Cls Loss = 0.5420, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5602, Reg Loss = 60.6428, Reconstruct Loss = 0.0023, Cls Loss = 0.5518, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5513, Reg Loss = 60.7633, Reconstruct Loss = 0.0019, Cls Loss = 0.5433, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5498, Reg Loss = 60.7368, Reconstruct Loss = 0.0018, Cls Loss = 0.5420, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5508, Reg Loss = 60.7752, Reconstruct Loss = 0.0015, Cls Loss = 0.5432, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5503, Reg Loss = 60.7510, Reconstruct Loss = 0.0014, Cls Loss = 0.5428, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5487, Reg Loss = 60.7693, Reconstruct Loss = 0.0015, Cls Loss = 0.5412, Learning rate = 1.0000e-04\n",
      "Epoch [106/200], Training Loss: 0.5506, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/200], Validation Loss: 3.1166, Validation Accuracy: 28.47%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6005, Reg Loss = 56.8108, Reconstruct Loss = 0.0000, Cls Loss = 0.5948, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5457, Reg Loss = 60.4356, Reconstruct Loss = 0.0009, Cls Loss = 0.5387, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5523, Reg Loss = 60.5927, Reconstruct Loss = 0.0009, Cls Loss = 0.5453, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5425, Reg Loss = 60.4844, Reconstruct Loss = 0.0014, Cls Loss = 0.5351, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5432, Reg Loss = 60.4433, Reconstruct Loss = 0.0012, Cls Loss = 0.5360, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5411, Reg Loss = 60.5645, Reconstruct Loss = 0.0013, Cls Loss = 0.5338, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5397, Reg Loss = 60.5170, Reconstruct Loss = 0.0015, Cls Loss = 0.5322, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5417, Reg Loss = 60.5165, Reconstruct Loss = 0.0014, Cls Loss = 0.5342, Learning rate = 1.0000e-04\n",
      "Epoch [107/200], Training Loss: 0.5414, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/200], Validation Loss: 3.1073, Validation Accuracy: 30.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5917, Reg Loss = 64.3334, Reconstruct Loss = 0.0000, Cls Loss = 0.5853, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5264, Reg Loss = 60.6298, Reconstruct Loss = 0.0019, Cls Loss = 0.5185, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5344, Reg Loss = 60.5956, Reconstruct Loss = 0.0019, Cls Loss = 0.5264, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5265, Reg Loss = 60.8433, Reconstruct Loss = 0.0019, Cls Loss = 0.5185, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5312, Reg Loss = 60.8903, Reconstruct Loss = 0.0016, Cls Loss = 0.5234, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5291, Reg Loss = 60.9483, Reconstruct Loss = 0.0016, Cls Loss = 0.5214, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5300, Reg Loss = 60.9114, Reconstruct Loss = 0.0017, Cls Loss = 0.5222, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5308, Reg Loss = 60.8910, Reconstruct Loss = 0.0017, Cls Loss = 0.5231, Learning rate = 1.0000e-04\n",
      "Epoch [108/200], Training Loss: 0.5308, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/200], Validation Loss: 2.7628, Validation Accuracy: 34.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5456, Reg Loss = 63.6251, Reconstruct Loss = 0.0000, Cls Loss = 0.5392, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5121, Reg Loss = 60.8106, Reconstruct Loss = 0.0009, Cls Loss = 0.5051, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5203, Reg Loss = 60.5264, Reconstruct Loss = 0.0017, Cls Loss = 0.5126, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5213, Reg Loss = 60.4228, Reconstruct Loss = 0.0021, Cls Loss = 0.5132, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5226, Reg Loss = 60.4107, Reconstruct Loss = 0.0022, Cls Loss = 0.5144, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5229, Reg Loss = 60.4583, Reconstruct Loss = 0.0021, Cls Loss = 0.5147, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5226, Reg Loss = 60.3658, Reconstruct Loss = 0.0024, Cls Loss = 0.5141, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5236, Reg Loss = 60.3747, Reconstruct Loss = 0.0021, Cls Loss = 0.5155, Learning rate = 1.0000e-04\n",
      "Epoch [109/200], Training Loss: 0.5250, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/200], Validation Loss: 3.3348, Validation Accuracy: 29.65%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5307, Reg Loss = 65.4148, Reconstruct Loss = 0.0000, Cls Loss = 0.5241, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5399, Reg Loss = 60.7850, Reconstruct Loss = 0.0005, Cls Loss = 0.5334, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5329, Reg Loss = 60.7366, Reconstruct Loss = 0.0012, Cls Loss = 0.5257, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5371, Reg Loss = 60.6283, Reconstruct Loss = 0.0011, Cls Loss = 0.5300, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5372, Reg Loss = 60.8120, Reconstruct Loss = 0.0012, Cls Loss = 0.5299, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5354, Reg Loss = 60.7936, Reconstruct Loss = 0.0009, Cls Loss = 0.5284, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5346, Reg Loss = 60.7737, Reconstruct Loss = 0.0009, Cls Loss = 0.5276, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5335, Reg Loss = 60.6998, Reconstruct Loss = 0.0011, Cls Loss = 0.5264, Learning rate = 1.0000e-04\n",
      "Epoch [110/200], Training Loss: 0.5306, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/200], Validation Loss: 2.8968, Validation Accuracy: 31.37%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5403, Reg Loss = 62.8709, Reconstruct Loss = 0.0000, Cls Loss = 0.5340, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5272, Reg Loss = 60.4725, Reconstruct Loss = 0.0018, Cls Loss = 0.5193, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5410, Reg Loss = 60.1392, Reconstruct Loss = 0.0019, Cls Loss = 0.5332, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5356, Reg Loss = 60.2189, Reconstruct Loss = 0.0017, Cls Loss = 0.5279, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5316, Reg Loss = 60.2592, Reconstruct Loss = 0.0014, Cls Loss = 0.5242, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5310, Reg Loss = 60.4479, Reconstruct Loss = 0.0013, Cls Loss = 0.5237, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5260, Reg Loss = 60.4305, Reconstruct Loss = 0.0013, Cls Loss = 0.5187, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5267, Reg Loss = 60.4601, Reconstruct Loss = 0.0014, Cls Loss = 0.5193, Learning rate = 1.0000e-04\n",
      "Epoch [111/200], Training Loss: 0.5235, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/200], Validation Loss: 3.4150, Validation Accuracy: 26.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3968, Reg Loss = 61.4175, Reconstruct Loss = 0.0000, Cls Loss = 0.3906, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5341, Reg Loss = 60.3998, Reconstruct Loss = 0.0014, Cls Loss = 0.5266, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5259, Reg Loss = 60.7475, Reconstruct Loss = 0.0007, Cls Loss = 0.5191, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5305, Reg Loss = 60.5582, Reconstruct Loss = 0.0014, Cls Loss = 0.5231, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5247, Reg Loss = 60.5793, Reconstruct Loss = 0.0013, Cls Loss = 0.5173, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5285, Reg Loss = 60.5452, Reconstruct Loss = 0.0013, Cls Loss = 0.5211, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5278, Reg Loss = 60.4911, Reconstruct Loss = 0.0015, Cls Loss = 0.5202, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5264, Reg Loss = 60.4603, Reconstruct Loss = 0.0016, Cls Loss = 0.5188, Learning rate = 1.0000e-04\n",
      "Epoch [112/200], Training Loss: 0.5287, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/200], Validation Loss: 2.8442, Validation Accuracy: 31.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5745, Reg Loss = 65.2545, Reconstruct Loss = 0.0000, Cls Loss = 0.5680, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5303, Reg Loss = 60.3181, Reconstruct Loss = 0.0010, Cls Loss = 0.5233, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5308, Reg Loss = 60.3968, Reconstruct Loss = 0.0019, Cls Loss = 0.5228, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5277, Reg Loss = 60.2925, Reconstruct Loss = 0.0016, Cls Loss = 0.5201, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5243, Reg Loss = 60.1305, Reconstruct Loss = 0.0016, Cls Loss = 0.5167, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5185, Reg Loss = 60.1107, Reconstruct Loss = 0.0015, Cls Loss = 0.5110, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5161, Reg Loss = 60.1046, Reconstruct Loss = 0.0017, Cls Loss = 0.5084, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5182, Reg Loss = 60.0602, Reconstruct Loss = 0.0019, Cls Loss = 0.5103, Learning rate = 1.0000e-04\n",
      "Epoch [113/200], Training Loss: 0.5217, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/200], Validation Loss: 3.1328, Validation Accuracy: 30.14%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6509, Reg Loss = 64.0844, Reconstruct Loss = 0.0000, Cls Loss = 0.6445, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5199, Reg Loss = 60.6396, Reconstruct Loss = 0.0020, Cls Loss = 0.5118, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5377, Reg Loss = 60.4560, Reconstruct Loss = 0.0010, Cls Loss = 0.5307, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5349, Reg Loss = 60.3731, Reconstruct Loss = 0.0015, Cls Loss = 0.5274, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5297, Reg Loss = 60.2448, Reconstruct Loss = 0.0013, Cls Loss = 0.5223, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5296, Reg Loss = 60.2868, Reconstruct Loss = 0.0012, Cls Loss = 0.5224, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5263, Reg Loss = 60.2414, Reconstruct Loss = 0.0011, Cls Loss = 0.5192, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5213, Reg Loss = 60.1925, Reconstruct Loss = 0.0012, Cls Loss = 0.5141, Learning rate = 1.0000e-04\n",
      "Epoch [114/200], Training Loss: 0.5219, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/200], Validation Loss: 2.7706, Validation Accuracy: 31.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4200, Reg Loss = 65.1756, Reconstruct Loss = 0.0000, Cls Loss = 0.4134, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5244, Reg Loss = 60.0792, Reconstruct Loss = 0.0014, Cls Loss = 0.5170, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5184, Reg Loss = 60.4619, Reconstruct Loss = 0.0017, Cls Loss = 0.5107, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5183, Reg Loss = 60.3457, Reconstruct Loss = 0.0018, Cls Loss = 0.5105, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5196, Reg Loss = 60.1236, Reconstruct Loss = 0.0017, Cls Loss = 0.5119, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5121, Reg Loss = 60.2498, Reconstruct Loss = 0.0018, Cls Loss = 0.5043, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5100, Reg Loss = 60.2601, Reconstruct Loss = 0.0018, Cls Loss = 0.5022, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5091, Reg Loss = 60.3339, Reconstruct Loss = 0.0017, Cls Loss = 0.5014, Learning rate = 1.0000e-04\n",
      "Epoch [115/200], Training Loss: 0.5096, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/200], Validation Loss: 2.9624, Validation Accuracy: 30.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4475, Reg Loss = 60.0998, Reconstruct Loss = 0.0000, Cls Loss = 0.4415, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5117, Reg Loss = 60.1740, Reconstruct Loss = 0.0019, Cls Loss = 0.5038, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5047, Reg Loss = 60.1268, Reconstruct Loss = 0.0017, Cls Loss = 0.4970, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5077, Reg Loss = 60.0788, Reconstruct Loss = 0.0019, Cls Loss = 0.4998, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5048, Reg Loss = 59.9549, Reconstruct Loss = 0.0017, Cls Loss = 0.4971, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5039, Reg Loss = 59.9323, Reconstruct Loss = 0.0019, Cls Loss = 0.4960, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5040, Reg Loss = 59.9798, Reconstruct Loss = 0.0020, Cls Loss = 0.4960, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5008, Reg Loss = 60.0347, Reconstruct Loss = 0.0019, Cls Loss = 0.4928, Learning rate = 1.0000e-04\n",
      "Epoch [116/200], Training Loss: 0.4997, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200], Validation Loss: 3.0654, Validation Accuracy: 31.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4117, Reg Loss = 57.6876, Reconstruct Loss = 0.0000, Cls Loss = 0.4059, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5080, Reg Loss = 60.2860, Reconstruct Loss = 0.0020, Cls Loss = 0.5000, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5165, Reg Loss = 60.0579, Reconstruct Loss = 0.0020, Cls Loss = 0.5085, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5197, Reg Loss = 60.3391, Reconstruct Loss = 0.0013, Cls Loss = 0.5124, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5137, Reg Loss = 60.3952, Reconstruct Loss = 0.0011, Cls Loss = 0.5066, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5170, Reg Loss = 60.4609, Reconstruct Loss = 0.0013, Cls Loss = 0.5097, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5144, Reg Loss = 60.4115, Reconstruct Loss = 0.0013, Cls Loss = 0.5071, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5108, Reg Loss = 60.4345, Reconstruct Loss = 0.0013, Cls Loss = 0.5034, Learning rate = 1.0000e-04\n",
      "Epoch [117/200], Training Loss: 0.5111, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/200], Validation Loss: 3.0515, Validation Accuracy: 31.46%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4987, Reg Loss = 58.2948, Reconstruct Loss = 0.0000, Cls Loss = 0.4928, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5073, Reg Loss = 60.5747, Reconstruct Loss = 0.0019, Cls Loss = 0.4993, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5077, Reg Loss = 60.4092, Reconstruct Loss = 0.0024, Cls Loss = 0.4992, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4999, Reg Loss = 60.3139, Reconstruct Loss = 0.0021, Cls Loss = 0.4917, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4976, Reg Loss = 60.3942, Reconstruct Loss = 0.0017, Cls Loss = 0.4898, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4986, Reg Loss = 60.2403, Reconstruct Loss = 0.0019, Cls Loss = 0.4907, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4970, Reg Loss = 60.3114, Reconstruct Loss = 0.0016, Cls Loss = 0.4893, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5002, Reg Loss = 60.3151, Reconstruct Loss = 0.0018, Cls Loss = 0.4924, Learning rate = 1.0000e-04\n",
      "Epoch [118/200], Training Loss: 0.5025, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/200], Validation Loss: 3.4907, Validation Accuracy: 27.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3905, Reg Loss = 61.6819, Reconstruct Loss = 0.0000, Cls Loss = 0.3843, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4947, Reg Loss = 60.2702, Reconstruct Loss = 0.0010, Cls Loss = 0.4877, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4915, Reg Loss = 60.5064, Reconstruct Loss = 0.0013, Cls Loss = 0.4842, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4938, Reg Loss = 60.4155, Reconstruct Loss = 0.0017, Cls Loss = 0.4860, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4984, Reg Loss = 60.2957, Reconstruct Loss = 0.0019, Cls Loss = 0.4905, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5023, Reg Loss = 60.2592, Reconstruct Loss = 0.0021, Cls Loss = 0.4942, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.5024, Reg Loss = 60.2949, Reconstruct Loss = 0.0018, Cls Loss = 0.4945, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.5034, Reg Loss = 60.2752, Reconstruct Loss = 0.0019, Cls Loss = 0.4955, Learning rate = 1.0000e-04\n",
      "Epoch [119/200], Training Loss: 0.5037, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/200], Validation Loss: 3.2374, Validation Accuracy: 28.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4474, Reg Loss = 61.5667, Reconstruct Loss = 0.0000, Cls Loss = 0.4413, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4861, Reg Loss = 59.5626, Reconstruct Loss = 0.0020, Cls Loss = 0.4781, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4870, Reg Loss = 59.9578, Reconstruct Loss = 0.0013, Cls Loss = 0.4797, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4920, Reg Loss = 60.0326, Reconstruct Loss = 0.0013, Cls Loss = 0.4847, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4930, Reg Loss = 60.0270, Reconstruct Loss = 0.0015, Cls Loss = 0.4855, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4937, Reg Loss = 60.1226, Reconstruct Loss = 0.0014, Cls Loss = 0.4863, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4926, Reg Loss = 60.0877, Reconstruct Loss = 0.0015, Cls Loss = 0.4851, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4933, Reg Loss = 60.1186, Reconstruct Loss = 0.0016, Cls Loss = 0.4856, Learning rate = 1.0000e-04\n",
      "Epoch [120/200], Training Loss: 0.4944, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/200], Validation Loss: 2.9683, Validation Accuracy: 30.41%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6754, Reg Loss = 61.3681, Reconstruct Loss = 0.0000, Cls Loss = 0.6693, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5012, Reg Loss = 60.2671, Reconstruct Loss = 0.0015, Cls Loss = 0.4937, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5026, Reg Loss = 60.4956, Reconstruct Loss = 0.0015, Cls Loss = 0.4950, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4950, Reg Loss = 60.4002, Reconstruct Loss = 0.0017, Cls Loss = 0.4873, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4980, Reg Loss = 60.2839, Reconstruct Loss = 0.0019, Cls Loss = 0.4900, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4932, Reg Loss = 60.2458, Reconstruct Loss = 0.0021, Cls Loss = 0.4850, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4915, Reg Loss = 60.3261, Reconstruct Loss = 0.0021, Cls Loss = 0.4834, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4901, Reg Loss = 60.3915, Reconstruct Loss = 0.0019, Cls Loss = 0.4821, Learning rate = 1.0000e-04\n",
      "Epoch [121/200], Training Loss: 0.4891, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/200], Validation Loss: 3.3916, Validation Accuracy: 28.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4024, Reg Loss = 60.4480, Reconstruct Loss = 0.0000, Cls Loss = 0.3964, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4989, Reg Loss = 60.2701, Reconstruct Loss = 0.0015, Cls Loss = 0.4914, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5026, Reg Loss = 60.2395, Reconstruct Loss = 0.0020, Cls Loss = 0.4946, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.5056, Reg Loss = 60.2257, Reconstruct Loss = 0.0015, Cls Loss = 0.4981, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.5046, Reg Loss = 60.1006, Reconstruct Loss = 0.0017, Cls Loss = 0.4969, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.5007, Reg Loss = 60.1672, Reconstruct Loss = 0.0015, Cls Loss = 0.4932, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4976, Reg Loss = 60.1194, Reconstruct Loss = 0.0014, Cls Loss = 0.4902, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4981, Reg Loss = 60.1114, Reconstruct Loss = 0.0014, Cls Loss = 0.4907, Learning rate = 1.0000e-04\n",
      "Epoch [122/200], Training Loss: 0.4966, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/200], Validation Loss: 3.3969, Validation Accuracy: 29.16%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5175, Reg Loss = 56.8379, Reconstruct Loss = 0.0000, Cls Loss = 0.5119, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4751, Reg Loss = 60.5560, Reconstruct Loss = 0.0034, Cls Loss = 0.4656, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4878, Reg Loss = 59.9682, Reconstruct Loss = 0.0022, Cls Loss = 0.4796, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4878, Reg Loss = 60.1655, Reconstruct Loss = 0.0016, Cls Loss = 0.4802, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4885, Reg Loss = 60.3063, Reconstruct Loss = 0.0015, Cls Loss = 0.4810, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4896, Reg Loss = 60.4364, Reconstruct Loss = 0.0014, Cls Loss = 0.4822, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4897, Reg Loss = 60.3046, Reconstruct Loss = 0.0017, Cls Loss = 0.4820, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4892, Reg Loss = 60.3328, Reconstruct Loss = 0.0018, Cls Loss = 0.4814, Learning rate = 1.0000e-04\n",
      "Epoch [123/200], Training Loss: 0.4915, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/200], Validation Loss: 3.2877, Validation Accuracy: 26.93%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6550, Reg Loss = 58.5495, Reconstruct Loss = 0.0000, Cls Loss = 0.6491, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4778, Reg Loss = 60.8451, Reconstruct Loss = 0.0005, Cls Loss = 0.4712, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4922, Reg Loss = 60.5869, Reconstruct Loss = 0.0005, Cls Loss = 0.4857, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4855, Reg Loss = 60.2942, Reconstruct Loss = 0.0007, Cls Loss = 0.4788, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4855, Reg Loss = 60.2919, Reconstruct Loss = 0.0009, Cls Loss = 0.4786, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4843, Reg Loss = 60.3031, Reconstruct Loss = 0.0007, Cls Loss = 0.4776, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4854, Reg Loss = 60.2959, Reconstruct Loss = 0.0007, Cls Loss = 0.4787, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4833, Reg Loss = 60.2956, Reconstruct Loss = 0.0008, Cls Loss = 0.4765, Learning rate = 1.0000e-04\n",
      "Epoch [124/200], Training Loss: 0.4852, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/200], Validation Loss: 3.3624, Validation Accuracy: 28.63%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6693, Reg Loss = 64.6158, Reconstruct Loss = 0.0000, Cls Loss = 0.6629, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4750, Reg Loss = 60.1080, Reconstruct Loss = 0.0019, Cls Loss = 0.4671, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4712, Reg Loss = 60.1887, Reconstruct Loss = 0.0010, Cls Loss = 0.4642, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4746, Reg Loss = 60.1988, Reconstruct Loss = 0.0008, Cls Loss = 0.4678, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4782, Reg Loss = 60.2247, Reconstruct Loss = 0.0009, Cls Loss = 0.4713, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4794, Reg Loss = 60.1671, Reconstruct Loss = 0.0008, Cls Loss = 0.4726, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4823, Reg Loss = 60.0944, Reconstruct Loss = 0.0011, Cls Loss = 0.4752, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4846, Reg Loss = 60.0347, Reconstruct Loss = 0.0011, Cls Loss = 0.4775, Learning rate = 1.0000e-04\n",
      "Epoch [125/200], Training Loss: 0.4865, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/200], Validation Loss: 3.7920, Validation Accuracy: 27.43%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6271, Reg Loss = 61.5710, Reconstruct Loss = 0.0000, Cls Loss = 0.6209, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.5120, Reg Loss = 59.7388, Reconstruct Loss = 0.0000, Cls Loss = 0.5061, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.5047, Reg Loss = 59.8937, Reconstruct Loss = 0.0005, Cls Loss = 0.4982, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4926, Reg Loss = 59.9842, Reconstruct Loss = 0.0008, Cls Loss = 0.4858, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4903, Reg Loss = 59.9328, Reconstruct Loss = 0.0010, Cls Loss = 0.4833, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4874, Reg Loss = 59.9800, Reconstruct Loss = 0.0011, Cls Loss = 0.4803, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4860, Reg Loss = 59.9498, Reconstruct Loss = 0.0012, Cls Loss = 0.4788, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4848, Reg Loss = 59.8468, Reconstruct Loss = 0.0013, Cls Loss = 0.4775, Learning rate = 1.0000e-04\n",
      "Epoch [126/200], Training Loss: 0.4852, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/200], Validation Loss: 2.9931, Validation Accuracy: 32.50%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5878, Reg Loss = 55.9258, Reconstruct Loss = 0.0505, Cls Loss = 0.5317, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4709, Reg Loss = 59.6841, Reconstruct Loss = 0.0020, Cls Loss = 0.4629, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4787, Reg Loss = 59.6759, Reconstruct Loss = 0.0025, Cls Loss = 0.4703, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4788, Reg Loss = 59.7489, Reconstruct Loss = 0.0023, Cls Loss = 0.4705, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4809, Reg Loss = 59.7372, Reconstruct Loss = 0.0022, Cls Loss = 0.4726, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4801, Reg Loss = 59.6535, Reconstruct Loss = 0.0023, Cls Loss = 0.4719, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4804, Reg Loss = 59.5389, Reconstruct Loss = 0.0022, Cls Loss = 0.4722, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4784, Reg Loss = 59.4753, Reconstruct Loss = 0.0022, Cls Loss = 0.4702, Learning rate = 1.0000e-04\n",
      "Epoch [127/200], Training Loss: 0.4776, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/200], Validation Loss: 3.2506, Validation Accuracy: 29.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4533, Reg Loss = 63.7654, Reconstruct Loss = 0.0000, Cls Loss = 0.4469, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4783, Reg Loss = 59.8487, Reconstruct Loss = 0.0005, Cls Loss = 0.4718, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4786, Reg Loss = 59.6684, Reconstruct Loss = 0.0010, Cls Loss = 0.4716, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4818, Reg Loss = 59.5397, Reconstruct Loss = 0.0014, Cls Loss = 0.4745, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4801, Reg Loss = 59.5813, Reconstruct Loss = 0.0015, Cls Loss = 0.4726, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4792, Reg Loss = 59.6210, Reconstruct Loss = 0.0015, Cls Loss = 0.4717, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4790, Reg Loss = 59.6971, Reconstruct Loss = 0.0014, Cls Loss = 0.4716, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4771, Reg Loss = 59.8253, Reconstruct Loss = 0.0013, Cls Loss = 0.4698, Learning rate = 1.0000e-04\n",
      "Epoch [128/200], Training Loss: 0.4737, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/200], Validation Loss: 2.7275, Validation Accuracy: 33.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3191, Reg Loss = 60.2274, Reconstruct Loss = 0.0000, Cls Loss = 0.3131, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4766, Reg Loss = 60.2579, Reconstruct Loss = 0.0020, Cls Loss = 0.4686, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4789, Reg Loss = 60.2240, Reconstruct Loss = 0.0020, Cls Loss = 0.4709, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4748, Reg Loss = 60.0180, Reconstruct Loss = 0.0015, Cls Loss = 0.4672, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4777, Reg Loss = 60.0186, Reconstruct Loss = 0.0015, Cls Loss = 0.4702, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4734, Reg Loss = 60.0524, Reconstruct Loss = 0.0018, Cls Loss = 0.4656, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4733, Reg Loss = 60.0356, Reconstruct Loss = 0.0017, Cls Loss = 0.4656, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4745, Reg Loss = 60.0132, Reconstruct Loss = 0.0017, Cls Loss = 0.4668, Learning rate = 1.0000e-04\n",
      "Epoch [129/200], Training Loss: 0.4740, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/200], Validation Loss: 3.3565, Validation Accuracy: 29.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3998, Reg Loss = 57.1760, Reconstruct Loss = 0.0000, Cls Loss = 0.3940, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4882, Reg Loss = 60.5487, Reconstruct Loss = 0.0005, Cls Loss = 0.4816, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4774, Reg Loss = 60.1906, Reconstruct Loss = 0.0010, Cls Loss = 0.4704, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4655, Reg Loss = 60.0568, Reconstruct Loss = 0.0020, Cls Loss = 0.4575, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4654, Reg Loss = 60.1060, Reconstruct Loss = 0.0018, Cls Loss = 0.4576, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4659, Reg Loss = 60.1735, Reconstruct Loss = 0.0017, Cls Loss = 0.4582, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4645, Reg Loss = 60.1987, Reconstruct Loss = 0.0019, Cls Loss = 0.4567, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4661, Reg Loss = 60.1984, Reconstruct Loss = 0.0017, Cls Loss = 0.4584, Learning rate = 1.0000e-04\n",
      "Epoch [130/200], Training Loss: 0.4656, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/200], Validation Loss: 3.3022, Validation Accuracy: 32.06%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2664, Reg Loss = 58.8124, Reconstruct Loss = 0.0000, Cls Loss = 0.2605, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4569, Reg Loss = 60.6801, Reconstruct Loss = 0.0010, Cls Loss = 0.4499, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4639, Reg Loss = 60.2955, Reconstruct Loss = 0.0010, Cls Loss = 0.4568, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4697, Reg Loss = 60.2240, Reconstruct Loss = 0.0010, Cls Loss = 0.4627, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4729, Reg Loss = 60.2265, Reconstruct Loss = 0.0009, Cls Loss = 0.4660, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4722, Reg Loss = 59.9710, Reconstruct Loss = 0.0013, Cls Loss = 0.4649, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4700, Reg Loss = 60.0021, Reconstruct Loss = 0.0014, Cls Loss = 0.4626, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4707, Reg Loss = 60.0845, Reconstruct Loss = 0.0012, Cls Loss = 0.4635, Learning rate = 1.0000e-04\n",
      "Epoch [131/200], Training Loss: 0.4708, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/200], Validation Loss: 2.9431, Validation Accuracy: 30.69%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5002, Reg Loss = 61.0488, Reconstruct Loss = 0.0000, Cls Loss = 0.4940, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4643, Reg Loss = 60.1784, Reconstruct Loss = 0.0010, Cls Loss = 0.4573, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4686, Reg Loss = 60.1506, Reconstruct Loss = 0.0010, Cls Loss = 0.4616, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4717, Reg Loss = 60.2705, Reconstruct Loss = 0.0008, Cls Loss = 0.4648, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4729, Reg Loss = 60.1298, Reconstruct Loss = 0.0011, Cls Loss = 0.4657, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4740, Reg Loss = 60.1436, Reconstruct Loss = 0.0011, Cls Loss = 0.4668, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4725, Reg Loss = 60.1355, Reconstruct Loss = 0.0012, Cls Loss = 0.4653, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4711, Reg Loss = 60.1080, Reconstruct Loss = 0.0014, Cls Loss = 0.4637, Learning rate = 1.0000e-04\n",
      "Epoch [132/200], Training Loss: 0.4709, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/200], Validation Loss: 2.9190, Validation Accuracy: 31.29%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3552, Reg Loss = 63.5761, Reconstruct Loss = 0.0000, Cls Loss = 0.3489, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4568, Reg Loss = 60.2931, Reconstruct Loss = 0.0035, Cls Loss = 0.4472, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4690, Reg Loss = 60.1011, Reconstruct Loss = 0.0025, Cls Loss = 0.4605, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4714, Reg Loss = 60.2149, Reconstruct Loss = 0.0022, Cls Loss = 0.4631, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4685, Reg Loss = 60.1543, Reconstruct Loss = 0.0021, Cls Loss = 0.4604, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4664, Reg Loss = 60.1931, Reconstruct Loss = 0.0018, Cls Loss = 0.4587, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4608, Reg Loss = 60.2967, Reconstruct Loss = 0.0015, Cls Loss = 0.4532, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4609, Reg Loss = 60.2374, Reconstruct Loss = 0.0015, Cls Loss = 0.4534, Learning rate = 1.0000e-04\n",
      "Epoch [133/200], Training Loss: 0.4642, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 68.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/200], Validation Loss: 3.4169, Validation Accuracy: 30.80%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4738, Reg Loss = 61.9180, Reconstruct Loss = 0.0000, Cls Loss = 0.4676, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4511, Reg Loss = 60.1860, Reconstruct Loss = 0.0020, Cls Loss = 0.4430, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4557, Reg Loss = 59.9721, Reconstruct Loss = 0.0018, Cls Loss = 0.4479, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4587, Reg Loss = 60.0775, Reconstruct Loss = 0.0021, Cls Loss = 0.4506, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4598, Reg Loss = 60.1354, Reconstruct Loss = 0.0018, Cls Loss = 0.4520, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4602, Reg Loss = 60.1157, Reconstruct Loss = 0.0018, Cls Loss = 0.4525, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4627, Reg Loss = 60.1559, Reconstruct Loss = 0.0019, Cls Loss = 0.4548, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4632, Reg Loss = 60.1728, Reconstruct Loss = 0.0017, Cls Loss = 0.4554, Learning rate = 1.0000e-04\n",
      "Epoch [134/200], Training Loss: 0.4626, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/200], Validation Loss: 3.3585, Validation Accuracy: 27.27%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5234, Reg Loss = 57.7273, Reconstruct Loss = 0.0000, Cls Loss = 0.5176, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4847, Reg Loss = 60.5820, Reconstruct Loss = 0.0010, Cls Loss = 0.4776, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4683, Reg Loss = 60.7807, Reconstruct Loss = 0.0010, Cls Loss = 0.4612, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4670, Reg Loss = 60.7064, Reconstruct Loss = 0.0012, Cls Loss = 0.4597, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4695, Reg Loss = 60.5582, Reconstruct Loss = 0.0014, Cls Loss = 0.4620, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4697, Reg Loss = 60.5188, Reconstruct Loss = 0.0017, Cls Loss = 0.4620, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4716, Reg Loss = 60.4668, Reconstruct Loss = 0.0016, Cls Loss = 0.4640, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4728, Reg Loss = 60.4465, Reconstruct Loss = 0.0016, Cls Loss = 0.4652, Learning rate = 1.0000e-04\n",
      "Epoch [135/200], Training Loss: 0.4706, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/200], Validation Loss: 3.6113, Validation Accuracy: 25.76%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4136, Reg Loss = 54.1780, Reconstruct Loss = 0.0000, Cls Loss = 0.4082, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4588, Reg Loss = 60.4447, Reconstruct Loss = 0.0015, Cls Loss = 0.4512, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4585, Reg Loss = 60.3201, Reconstruct Loss = 0.0010, Cls Loss = 0.4515, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4624, Reg Loss = 60.2826, Reconstruct Loss = 0.0010, Cls Loss = 0.4554, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4581, Reg Loss = 60.3849, Reconstruct Loss = 0.0009, Cls Loss = 0.4512, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4616, Reg Loss = 60.3811, Reconstruct Loss = 0.0009, Cls Loss = 0.4546, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4599, Reg Loss = 60.3887, Reconstruct Loss = 0.0011, Cls Loss = 0.4527, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4577, Reg Loss = 60.4593, Reconstruct Loss = 0.0013, Cls Loss = 0.4503, Learning rate = 1.0000e-04\n",
      "Epoch [136/200], Training Loss: 0.4588, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/200], Validation Loss: 3.5485, Validation Accuracy: 28.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2765, Reg Loss = 58.8413, Reconstruct Loss = 0.0000, Cls Loss = 0.2706, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4535, Reg Loss = 59.8142, Reconstruct Loss = 0.0021, Cls Loss = 0.4455, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4564, Reg Loss = 60.1128, Reconstruct Loss = 0.0021, Cls Loss = 0.4483, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4574, Reg Loss = 59.9548, Reconstruct Loss = 0.0019, Cls Loss = 0.4495, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4613, Reg Loss = 59.9593, Reconstruct Loss = 0.0016, Cls Loss = 0.4538, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4632, Reg Loss = 60.0223, Reconstruct Loss = 0.0014, Cls Loss = 0.4558, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4597, Reg Loss = 60.0633, Reconstruct Loss = 0.0016, Cls Loss = 0.4520, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4597, Reg Loss = 60.0792, Reconstruct Loss = 0.0016, Cls Loss = 0.4521, Learning rate = 1.0000e-04\n",
      "Epoch [137/200], Training Loss: 0.4597, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/200], Validation Loss: 3.2389, Validation Accuracy: 30.87%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5186, Reg Loss = 59.4746, Reconstruct Loss = 0.0000, Cls Loss = 0.5127, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4699, Reg Loss = 60.0962, Reconstruct Loss = 0.0005, Cls Loss = 0.4633, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4679, Reg Loss = 60.2612, Reconstruct Loss = 0.0015, Cls Loss = 0.4604, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4655, Reg Loss = 59.8286, Reconstruct Loss = 0.0014, Cls Loss = 0.4581, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4613, Reg Loss = 59.9166, Reconstruct Loss = 0.0013, Cls Loss = 0.4540, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4616, Reg Loss = 59.9337, Reconstruct Loss = 0.0011, Cls Loss = 0.4545, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4604, Reg Loss = 59.8918, Reconstruct Loss = 0.0012, Cls Loss = 0.4533, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4592, Reg Loss = 59.8367, Reconstruct Loss = 0.0016, Cls Loss = 0.4517, Learning rate = 1.0000e-04\n",
      "Epoch [138/200], Training Loss: 0.4597, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/200], Validation Loss: 3.3518, Validation Accuracy: 29.17%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3843, Reg Loss = 60.8557, Reconstruct Loss = 0.0000, Cls Loss = 0.3782, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4508, Reg Loss = 60.0824, Reconstruct Loss = 0.0037, Cls Loss = 0.4411, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4593, Reg Loss = 59.9753, Reconstruct Loss = 0.0029, Cls Loss = 0.4505, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4630, Reg Loss = 60.0025, Reconstruct Loss = 0.0023, Cls Loss = 0.4547, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4589, Reg Loss = 60.1996, Reconstruct Loss = 0.0020, Cls Loss = 0.4510, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4576, Reg Loss = 60.2244, Reconstruct Loss = 0.0020, Cls Loss = 0.4496, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4556, Reg Loss = 60.2833, Reconstruct Loss = 0.0020, Cls Loss = 0.4475, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4550, Reg Loss = 60.2906, Reconstruct Loss = 0.0020, Cls Loss = 0.4470, Learning rate = 1.0000e-04\n",
      "Epoch [139/200], Training Loss: 0.4559, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 42.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/200], Validation Loss: 3.2624, Validation Accuracy: 29.84%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4325, Reg Loss = 57.4517, Reconstruct Loss = 0.0000, Cls Loss = 0.4267, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4477, Reg Loss = 60.7251, Reconstruct Loss = 0.0021, Cls Loss = 0.4396, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4407, Reg Loss = 60.3357, Reconstruct Loss = 0.0015, Cls Loss = 0.4331, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4480, Reg Loss = 60.3826, Reconstruct Loss = 0.0014, Cls Loss = 0.4406, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4515, Reg Loss = 60.4001, Reconstruct Loss = 0.0013, Cls Loss = 0.4442, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4528, Reg Loss = 60.4237, Reconstruct Loss = 0.0012, Cls Loss = 0.4455, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4543, Reg Loss = 60.3146, Reconstruct Loss = 0.0015, Cls Loss = 0.4468, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4543, Reg Loss = 60.2596, Reconstruct Loss = 0.0014, Cls Loss = 0.4468, Learning rate = 1.0000e-04\n",
      "Epoch [140/200], Training Loss: 0.4552, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/200], Validation Loss: 3.2389, Validation Accuracy: 29.37%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6529, Reg Loss = 54.7211, Reconstruct Loss = 0.0000, Cls Loss = 0.6474, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4358, Reg Loss = 59.9898, Reconstruct Loss = 0.0021, Cls Loss = 0.4277, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4312, Reg Loss = 60.0186, Reconstruct Loss = 0.0016, Cls Loss = 0.4237, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4408, Reg Loss = 60.2235, Reconstruct Loss = 0.0012, Cls Loss = 0.4335, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4438, Reg Loss = 60.1535, Reconstruct Loss = 0.0012, Cls Loss = 0.4366, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4492, Reg Loss = 60.3188, Reconstruct Loss = 0.0015, Cls Loss = 0.4417, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4474, Reg Loss = 60.4012, Reconstruct Loss = 0.0016, Cls Loss = 0.4398, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4475, Reg Loss = 60.3829, Reconstruct Loss = 0.0014, Cls Loss = 0.4400, Learning rate = 1.0000e-04\n",
      "Epoch [141/200], Training Loss: 0.4479, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/200], Validation Loss: 3.4333, Validation Accuracy: 27.88%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.8973, Reg Loss = 53.5283, Reconstruct Loss = 0.0000, Cls Loss = 0.8920, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4529, Reg Loss = 60.1278, Reconstruct Loss = 0.0005, Cls Loss = 0.4464, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4566, Reg Loss = 60.5127, Reconstruct Loss = 0.0003, Cls Loss = 0.4503, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4507, Reg Loss = 60.4274, Reconstruct Loss = 0.0002, Cls Loss = 0.4445, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4524, Reg Loss = 60.3709, Reconstruct Loss = 0.0005, Cls Loss = 0.4458, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4524, Reg Loss = 60.3878, Reconstruct Loss = 0.0007, Cls Loss = 0.4456, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4517, Reg Loss = 60.4756, Reconstruct Loss = 0.0008, Cls Loss = 0.4449, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4516, Reg Loss = 60.4811, Reconstruct Loss = 0.0011, Cls Loss = 0.4445, Learning rate = 1.0000e-04\n",
      "Epoch [142/200], Training Loss: 0.4486, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/200], Validation Loss: 3.4735, Validation Accuracy: 28.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4647, Reg Loss = 58.7221, Reconstruct Loss = 0.0000, Cls Loss = 0.4588, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4580, Reg Loss = 60.4491, Reconstruct Loss = 0.0005, Cls Loss = 0.4514, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4426, Reg Loss = 60.6388, Reconstruct Loss = 0.0011, Cls Loss = 0.4354, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4444, Reg Loss = 60.7016, Reconstruct Loss = 0.0012, Cls Loss = 0.4371, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4465, Reg Loss = 60.6551, Reconstruct Loss = 0.0012, Cls Loss = 0.4392, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4460, Reg Loss = 60.7003, Reconstruct Loss = 0.0012, Cls Loss = 0.4388, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4497, Reg Loss = 60.7743, Reconstruct Loss = 0.0015, Cls Loss = 0.4421, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4501, Reg Loss = 60.8184, Reconstruct Loss = 0.0016, Cls Loss = 0.4424, Learning rate = 1.0000e-04\n",
      "Epoch [143/200], Training Loss: 0.4510, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/200], Validation Loss: 3.2087, Validation Accuracy: 29.01%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5806, Reg Loss = 54.5268, Reconstruct Loss = 0.0000, Cls Loss = 0.5751, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4489, Reg Loss = 60.1187, Reconstruct Loss = 0.0015, Cls Loss = 0.4414, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4525, Reg Loss = 60.3531, Reconstruct Loss = 0.0010, Cls Loss = 0.4454, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4445, Reg Loss = 60.2912, Reconstruct Loss = 0.0010, Cls Loss = 0.4374, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4450, Reg Loss = 60.3158, Reconstruct Loss = 0.0015, Cls Loss = 0.4374, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4458, Reg Loss = 60.3999, Reconstruct Loss = 0.0015, Cls Loss = 0.4382, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4456, Reg Loss = 60.4371, Reconstruct Loss = 0.0015, Cls Loss = 0.4381, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4443, Reg Loss = 60.3445, Reconstruct Loss = 0.0016, Cls Loss = 0.4367, Learning rate = 1.0000e-04\n",
      "Epoch [144/200], Training Loss: 0.4450, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/200], Validation Loss: 3.3510, Validation Accuracy: 30.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2990, Reg Loss = 62.9118, Reconstruct Loss = 0.0000, Cls Loss = 0.2927, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4465, Reg Loss = 60.4651, Reconstruct Loss = 0.0010, Cls Loss = 0.4394, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4451, Reg Loss = 60.6116, Reconstruct Loss = 0.0010, Cls Loss = 0.4380, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4353, Reg Loss = 60.4898, Reconstruct Loss = 0.0012, Cls Loss = 0.4281, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4363, Reg Loss = 60.5358, Reconstruct Loss = 0.0013, Cls Loss = 0.4290, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4372, Reg Loss = 60.4592, Reconstruct Loss = 0.0013, Cls Loss = 0.4298, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4401, Reg Loss = 60.3943, Reconstruct Loss = 0.0014, Cls Loss = 0.4326, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4399, Reg Loss = 60.4140, Reconstruct Loss = 0.0013, Cls Loss = 0.4326, Learning rate = 1.0000e-04\n",
      "Epoch [145/200], Training Loss: 0.4417, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/200], Validation Loss: 3.3307, Validation Accuracy: 30.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3663, Reg Loss = 63.2012, Reconstruct Loss = 0.0000, Cls Loss = 0.3600, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4477, Reg Loss = 60.3437, Reconstruct Loss = 0.0026, Cls Loss = 0.4391, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4422, Reg Loss = 60.4976, Reconstruct Loss = 0.0023, Cls Loss = 0.4339, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4332, Reg Loss = 60.6789, Reconstruct Loss = 0.0019, Cls Loss = 0.4252, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4424, Reg Loss = 60.6479, Reconstruct Loss = 0.0015, Cls Loss = 0.4348, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4402, Reg Loss = 60.6446, Reconstruct Loss = 0.0014, Cls Loss = 0.4327, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4414, Reg Loss = 60.6132, Reconstruct Loss = 0.0014, Cls Loss = 0.4338, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4403, Reg Loss = 60.6635, Reconstruct Loss = 0.0015, Cls Loss = 0.4328, Learning rate = 1.0000e-04\n",
      "Epoch [146/200], Training Loss: 0.4418, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 81.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/200], Validation Loss: 3.4057, Validation Accuracy: 29.45%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4810, Reg Loss = 58.4204, Reconstruct Loss = 0.0000, Cls Loss = 0.4752, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4319, Reg Loss = 60.1615, Reconstruct Loss = 0.0015, Cls Loss = 0.4244, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4510, Reg Loss = 60.5580, Reconstruct Loss = 0.0013, Cls Loss = 0.4436, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4432, Reg Loss = 60.6351, Reconstruct Loss = 0.0012, Cls Loss = 0.4359, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4456, Reg Loss = 60.6155, Reconstruct Loss = 0.0012, Cls Loss = 0.4383, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4450, Reg Loss = 60.7215, Reconstruct Loss = 0.0015, Cls Loss = 0.4375, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4406, Reg Loss = 60.6448, Reconstruct Loss = 0.0013, Cls Loss = 0.4332, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4370, Reg Loss = 60.7278, Reconstruct Loss = 0.0012, Cls Loss = 0.4297, Learning rate = 1.0000e-04\n",
      "Epoch [147/200], Training Loss: 0.4400, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/200], Validation Loss: 3.1078, Validation Accuracy: 32.08%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2298, Reg Loss = 64.2365, Reconstruct Loss = 0.0000, Cls Loss = 0.2234, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4308, Reg Loss = 60.7715, Reconstruct Loss = 0.0016, Cls Loss = 0.4232, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4239, Reg Loss = 60.9845, Reconstruct Loss = 0.0015, Cls Loss = 0.4162, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4277, Reg Loss = 60.9234, Reconstruct Loss = 0.0012, Cls Loss = 0.4205, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4306, Reg Loss = 60.7835, Reconstruct Loss = 0.0021, Cls Loss = 0.4225, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4301, Reg Loss = 60.7422, Reconstruct Loss = 0.0020, Cls Loss = 0.4220, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4326, Reg Loss = 60.7831, Reconstruct Loss = 0.0020, Cls Loss = 0.4245, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4336, Reg Loss = 60.7007, Reconstruct Loss = 0.0019, Cls Loss = 0.4256, Learning rate = 1.0000e-04\n",
      "Epoch [148/200], Training Loss: 0.4352, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/200], Validation Loss: 3.1809, Validation Accuracy: 31.15%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4701, Reg Loss = 61.9330, Reconstruct Loss = 0.0000, Cls Loss = 0.4639, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4276, Reg Loss = 59.9598, Reconstruct Loss = 0.0026, Cls Loss = 0.4190, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4453, Reg Loss = 60.0743, Reconstruct Loss = 0.0023, Cls Loss = 0.4370, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4423, Reg Loss = 59.9936, Reconstruct Loss = 0.0017, Cls Loss = 0.4346, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4402, Reg Loss = 59.9872, Reconstruct Loss = 0.0013, Cls Loss = 0.4329, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4407, Reg Loss = 59.9866, Reconstruct Loss = 0.0015, Cls Loss = 0.4332, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4386, Reg Loss = 60.0617, Reconstruct Loss = 0.0016, Cls Loss = 0.4310, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4412, Reg Loss = 60.0889, Reconstruct Loss = 0.0016, Cls Loss = 0.4336, Learning rate = 1.0000e-04\n",
      "Epoch [149/200], Training Loss: 0.4379, Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 82.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/200], Validation Loss: 3.4764, Validation Accuracy: 28.98%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4421, Reg Loss = 59.9274, Reconstruct Loss = 0.0000, Cls Loss = 0.4361, Learning rate = 1.0000e-04\n",
      "Iteration 100: Loss = 0.4214, Reg Loss = 60.2316, Reconstruct Loss = 0.0016, Cls Loss = 0.4138, Learning rate = 1.0000e-04\n",
      "Iteration 200: Loss = 0.4261, Reg Loss = 60.4728, Reconstruct Loss = 0.0013, Cls Loss = 0.4187, Learning rate = 1.0000e-04\n",
      "Iteration 300: Loss = 0.4287, Reg Loss = 60.5413, Reconstruct Loss = 0.0014, Cls Loss = 0.4213, Learning rate = 1.0000e-04\n",
      "Iteration 400: Loss = 0.4351, Reg Loss = 60.4319, Reconstruct Loss = 0.0017, Cls Loss = 0.4273, Learning rate = 1.0000e-04\n",
      "Iteration 500: Loss = 0.4361, Reg Loss = 60.3793, Reconstruct Loss = 0.0016, Cls Loss = 0.4285, Learning rate = 1.0000e-04\n",
      "Iteration 600: Loss = 0.4360, Reg Loss = 60.3677, Reconstruct Loss = 0.0018, Cls Loss = 0.4282, Learning rate = 1.0000e-04\n",
      "Iteration 700: Loss = 0.4357, Reg Loss = 60.3243, Reconstruct Loss = 0.0018, Cls Loss = 0.4278, Learning rate = 1.0000e-04\n",
      "Epoch [150/200], Training Loss: 0.4347, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/200], Validation Loss: 4.0469, Validation Accuracy: 25.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5175, Reg Loss = 54.7855, Reconstruct Loss = 0.0000, Cls Loss = 0.5120, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4322, Reg Loss = 60.9484, Reconstruct Loss = 0.0011, Cls Loss = 0.4250, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4325, Reg Loss = 60.6972, Reconstruct Loss = 0.0019, Cls Loss = 0.4245, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4335, Reg Loss = 60.5455, Reconstruct Loss = 0.0014, Cls Loss = 0.4260, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4326, Reg Loss = 60.4373, Reconstruct Loss = 0.0012, Cls Loss = 0.4254, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4283, Reg Loss = 60.4264, Reconstruct Loss = 0.0015, Cls Loss = 0.4208, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4272, Reg Loss = 60.3850, Reconstruct Loss = 0.0015, Cls Loss = 0.4197, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4293, Reg Loss = 60.3931, Reconstruct Loss = 0.0018, Cls Loss = 0.4215, Learning rate = 1.0000e-05\n",
      "Epoch [151/200], Training Loss: 0.4295, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/200], Validation Loss: 3.9114, Validation Accuracy: 26.09%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2653, Reg Loss = 61.9986, Reconstruct Loss = 0.0000, Cls Loss = 0.2591, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4521, Reg Loss = 60.5540, Reconstruct Loss = 0.0026, Cls Loss = 0.4434, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4385, Reg Loss = 60.4975, Reconstruct Loss = 0.0024, Cls Loss = 0.4301, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4315, Reg Loss = 60.5339, Reconstruct Loss = 0.0023, Cls Loss = 0.4231, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4329, Reg Loss = 60.5910, Reconstruct Loss = 0.0018, Cls Loss = 0.4250, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4337, Reg Loss = 60.5661, Reconstruct Loss = 0.0016, Cls Loss = 0.4261, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4301, Reg Loss = 60.5976, Reconstruct Loss = 0.0016, Cls Loss = 0.4225, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4295, Reg Loss = 60.5221, Reconstruct Loss = 0.0016, Cls Loss = 0.4219, Learning rate = 1.0000e-05\n",
      "Epoch [152/200], Training Loss: 0.4324, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/200], Validation Loss: 3.1437, Validation Accuracy: 31.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4550, Reg Loss = 61.8583, Reconstruct Loss = 0.0000, Cls Loss = 0.4488, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4277, Reg Loss = 60.8285, Reconstruct Loss = 0.0021, Cls Loss = 0.4195, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4344, Reg Loss = 60.6792, Reconstruct Loss = 0.0013, Cls Loss = 0.4270, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4309, Reg Loss = 60.6037, Reconstruct Loss = 0.0014, Cls Loss = 0.4234, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4279, Reg Loss = 60.6976, Reconstruct Loss = 0.0013, Cls Loss = 0.4205, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4264, Reg Loss = 60.6677, Reconstruct Loss = 0.0013, Cls Loss = 0.4191, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4265, Reg Loss = 60.6812, Reconstruct Loss = 0.0014, Cls Loss = 0.4190, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4264, Reg Loss = 60.6926, Reconstruct Loss = 0.0015, Cls Loss = 0.4189, Learning rate = 1.0000e-05\n",
      "Epoch [153/200], Training Loss: 0.4259, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/200], Validation Loss: 3.6619, Validation Accuracy: 27.54%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3481, Reg Loss = 61.1462, Reconstruct Loss = 0.0000, Cls Loss = 0.3420, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4251, Reg Loss = 60.3647, Reconstruct Loss = 0.0005, Cls Loss = 0.4185, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4303, Reg Loss = 60.2553, Reconstruct Loss = 0.0010, Cls Loss = 0.4232, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4336, Reg Loss = 60.3310, Reconstruct Loss = 0.0012, Cls Loss = 0.4264, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4315, Reg Loss = 60.5261, Reconstruct Loss = 0.0009, Cls Loss = 0.4245, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4285, Reg Loss = 60.5587, Reconstruct Loss = 0.0007, Cls Loss = 0.4217, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4254, Reg Loss = 60.5914, Reconstruct Loss = 0.0011, Cls Loss = 0.4183, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4251, Reg Loss = 60.6364, Reconstruct Loss = 0.0011, Cls Loss = 0.4179, Learning rate = 1.0000e-05\n",
      "Epoch [154/200], Training Loss: 0.4267, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 65.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/200], Validation Loss: 4.1556, Validation Accuracy: 25.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6261, Reg Loss = 59.2799, Reconstruct Loss = 0.0000, Cls Loss = 0.6201, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4215, Reg Loss = 60.3504, Reconstruct Loss = 0.0005, Cls Loss = 0.4149, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4263, Reg Loss = 60.1060, Reconstruct Loss = 0.0013, Cls Loss = 0.4190, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4227, Reg Loss = 60.2762, Reconstruct Loss = 0.0016, Cls Loss = 0.4151, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4252, Reg Loss = 60.4252, Reconstruct Loss = 0.0015, Cls Loss = 0.4176, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4265, Reg Loss = 60.3723, Reconstruct Loss = 0.0015, Cls Loss = 0.4190, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4233, Reg Loss = 60.4642, Reconstruct Loss = 0.0014, Cls Loss = 0.4158, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4238, Reg Loss = 60.5341, Reconstruct Loss = 0.0014, Cls Loss = 0.4164, Learning rate = 1.0000e-05\n",
      "Epoch [155/200], Training Loss: 0.4241, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [155/200], Validation Loss: 3.3973, Validation Accuracy: 29.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3940, Reg Loss = 62.8169, Reconstruct Loss = 0.0000, Cls Loss = 0.3878, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4217, Reg Loss = 59.9888, Reconstruct Loss = 0.0032, Cls Loss = 0.4125, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4261, Reg Loss = 60.1726, Reconstruct Loss = 0.0035, Cls Loss = 0.4166, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4349, Reg Loss = 60.1347, Reconstruct Loss = 0.0030, Cls Loss = 0.4259, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4359, Reg Loss = 60.2783, Reconstruct Loss = 0.0025, Cls Loss = 0.4274, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4286, Reg Loss = 60.3234, Reconstruct Loss = 0.0021, Cls Loss = 0.4204, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4293, Reg Loss = 60.3471, Reconstruct Loss = 0.0020, Cls Loss = 0.4213, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4275, Reg Loss = 60.4053, Reconstruct Loss = 0.0021, Cls Loss = 0.4194, Learning rate = 1.0000e-05\n",
      "Epoch [156/200], Training Loss: 0.4285, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [156/200], Validation Loss: 3.5212, Validation Accuracy: 28.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3911, Reg Loss = 57.0468, Reconstruct Loss = 0.0546, Cls Loss = 0.3308, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4255, Reg Loss = 60.6761, Reconstruct Loss = 0.0027, Cls Loss = 0.4167, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4290, Reg Loss = 60.5321, Reconstruct Loss = 0.0022, Cls Loss = 0.4208, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4225, Reg Loss = 60.6940, Reconstruct Loss = 0.0020, Cls Loss = 0.4144, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4202, Reg Loss = 60.7257, Reconstruct Loss = 0.0021, Cls Loss = 0.4120, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4218, Reg Loss = 60.6623, Reconstruct Loss = 0.0021, Cls Loss = 0.4136, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4221, Reg Loss = 60.6438, Reconstruct Loss = 0.0020, Cls Loss = 0.4141, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4225, Reg Loss = 60.6246, Reconstruct Loss = 0.0021, Cls Loss = 0.4143, Learning rate = 1.0000e-05\n",
      "Epoch [157/200], Training Loss: 0.4230, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/200], Validation Loss: 3.6431, Validation Accuracy: 26.64%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3997, Reg Loss = 63.5690, Reconstruct Loss = 0.0000, Cls Loss = 0.3934, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4132, Reg Loss = 60.6627, Reconstruct Loss = 0.0021, Cls Loss = 0.4050, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4194, Reg Loss = 60.5649, Reconstruct Loss = 0.0022, Cls Loss = 0.4112, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4166, Reg Loss = 60.7677, Reconstruct Loss = 0.0020, Cls Loss = 0.4086, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4156, Reg Loss = 60.5764, Reconstruct Loss = 0.0019, Cls Loss = 0.4076, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4165, Reg Loss = 60.6372, Reconstruct Loss = 0.0016, Cls Loss = 0.4088, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4157, Reg Loss = 60.6477, Reconstruct Loss = 0.0017, Cls Loss = 0.4079, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4208, Reg Loss = 60.5909, Reconstruct Loss = 0.0018, Cls Loss = 0.4130, Learning rate = 1.0000e-05\n",
      "Epoch [158/200], Training Loss: 0.4214, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/200], Validation Loss: 3.4056, Validation Accuracy: 28.13%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4469, Reg Loss = 58.9060, Reconstruct Loss = 0.0000, Cls Loss = 0.4410, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4197, Reg Loss = 61.0627, Reconstruct Loss = 0.0016, Cls Loss = 0.4120, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4275, Reg Loss = 61.0069, Reconstruct Loss = 0.0016, Cls Loss = 0.4198, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4238, Reg Loss = 60.8642, Reconstruct Loss = 0.0018, Cls Loss = 0.4159, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4202, Reg Loss = 60.8843, Reconstruct Loss = 0.0016, Cls Loss = 0.4125, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4183, Reg Loss = 60.9174, Reconstruct Loss = 0.0015, Cls Loss = 0.4107, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4226, Reg Loss = 60.8854, Reconstruct Loss = 0.0016, Cls Loss = 0.4149, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4210, Reg Loss = 60.8344, Reconstruct Loss = 0.0017, Cls Loss = 0.4132, Learning rate = 1.0000e-05\n",
      "Epoch [159/200], Training Loss: 0.4217, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/200], Validation Loss: 3.0808, Validation Accuracy: 30.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3387, Reg Loss = 56.5325, Reconstruct Loss = 0.0000, Cls Loss = 0.3330, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4248, Reg Loss = 60.9358, Reconstruct Loss = 0.0011, Cls Loss = 0.4176, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4186, Reg Loss = 60.8676, Reconstruct Loss = 0.0005, Cls Loss = 0.4120, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4126, Reg Loss = 60.7180, Reconstruct Loss = 0.0011, Cls Loss = 0.4055, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4141, Reg Loss = 60.8031, Reconstruct Loss = 0.0011, Cls Loss = 0.4070, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4173, Reg Loss = 60.7405, Reconstruct Loss = 0.0012, Cls Loss = 0.4100, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4179, Reg Loss = 60.7468, Reconstruct Loss = 0.0012, Cls Loss = 0.4107, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4189, Reg Loss = 60.6804, Reconstruct Loss = 0.0011, Cls Loss = 0.4117, Learning rate = 1.0000e-05\n",
      "Epoch [160/200], Training Loss: 0.4192, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/200], Validation Loss: 3.3655, Validation Accuracy: 27.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4542, Reg Loss = 62.2073, Reconstruct Loss = 0.0000, Cls Loss = 0.4479, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4437, Reg Loss = 60.6842, Reconstruct Loss = 0.0016, Cls Loss = 0.4360, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4288, Reg Loss = 60.5164, Reconstruct Loss = 0.0016, Cls Loss = 0.4211, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4268, Reg Loss = 60.6733, Reconstruct Loss = 0.0019, Cls Loss = 0.4188, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4304, Reg Loss = 60.6920, Reconstruct Loss = 0.0020, Cls Loss = 0.4224, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4256, Reg Loss = 60.6971, Reconstruct Loss = 0.0020, Cls Loss = 0.4175, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4270, Reg Loss = 60.6730, Reconstruct Loss = 0.0021, Cls Loss = 0.4188, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4241, Reg Loss = 60.7155, Reconstruct Loss = 0.0022, Cls Loss = 0.4158, Learning rate = 1.0000e-05\n",
      "Epoch [161/200], Training Loss: 0.4254, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/200], Validation Loss: 3.4983, Validation Accuracy: 28.75%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3646, Reg Loss = 63.5734, Reconstruct Loss = 0.0000, Cls Loss = 0.3583, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4300, Reg Loss = 61.1745, Reconstruct Loss = 0.0010, Cls Loss = 0.4229, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4239, Reg Loss = 60.6283, Reconstruct Loss = 0.0013, Cls Loss = 0.4165, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4174, Reg Loss = 60.7771, Reconstruct Loss = 0.0014, Cls Loss = 0.4099, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4202, Reg Loss = 60.6850, Reconstruct Loss = 0.0018, Cls Loss = 0.4123, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4213, Reg Loss = 60.5896, Reconstruct Loss = 0.0020, Cls Loss = 0.4132, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4227, Reg Loss = 60.5518, Reconstruct Loss = 0.0018, Cls Loss = 0.4148, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4208, Reg Loss = 60.6571, Reconstruct Loss = 0.0017, Cls Loss = 0.4131, Learning rate = 1.0000e-05\n",
      "Epoch [162/200], Training Loss: 0.4208, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/200], Validation Loss: 3.4231, Validation Accuracy: 28.85%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3509, Reg Loss = 60.7361, Reconstruct Loss = 0.0000, Cls Loss = 0.3449, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4086, Reg Loss = 60.8273, Reconstruct Loss = 0.0011, Cls Loss = 0.4014, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4204, Reg Loss = 60.7620, Reconstruct Loss = 0.0008, Cls Loss = 0.4135, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4207, Reg Loss = 60.6833, Reconstruct Loss = 0.0009, Cls Loss = 0.4138, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4164, Reg Loss = 60.6589, Reconstruct Loss = 0.0009, Cls Loss = 0.4094, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4166, Reg Loss = 60.7232, Reconstruct Loss = 0.0010, Cls Loss = 0.4096, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4183, Reg Loss = 60.7779, Reconstruct Loss = 0.0011, Cls Loss = 0.4111, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4172, Reg Loss = 60.7580, Reconstruct Loss = 0.0012, Cls Loss = 0.4099, Learning rate = 1.0000e-05\n",
      "Epoch [163/200], Training Loss: 0.4176, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/200], Validation Loss: 3.4573, Validation Accuracy: 27.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3824, Reg Loss = 62.2170, Reconstruct Loss = 0.0000, Cls Loss = 0.3762, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4359, Reg Loss = 61.0109, Reconstruct Loss = 0.0005, Cls Loss = 0.4293, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4173, Reg Loss = 60.9369, Reconstruct Loss = 0.0016, Cls Loss = 0.4096, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4147, Reg Loss = 60.8948, Reconstruct Loss = 0.0016, Cls Loss = 0.4070, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4136, Reg Loss = 60.9125, Reconstruct Loss = 0.0016, Cls Loss = 0.4059, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4154, Reg Loss = 60.8138, Reconstruct Loss = 0.0014, Cls Loss = 0.4079, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4180, Reg Loss = 60.7928, Reconstruct Loss = 0.0015, Cls Loss = 0.4104, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4174, Reg Loss = 60.7931, Reconstruct Loss = 0.0014, Cls Loss = 0.4099, Learning rate = 1.0000e-05\n",
      "Epoch [164/200], Training Loss: 0.4175, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/200], Validation Loss: 3.4727, Validation Accuracy: 29.44%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5215, Reg Loss = 52.7014, Reconstruct Loss = 0.0000, Cls Loss = 0.5162, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4287, Reg Loss = 60.4828, Reconstruct Loss = 0.0016, Cls Loss = 0.4211, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4204, Reg Loss = 60.4158, Reconstruct Loss = 0.0011, Cls Loss = 0.4133, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4146, Reg Loss = 60.6437, Reconstruct Loss = 0.0009, Cls Loss = 0.4076, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4103, Reg Loss = 60.7726, Reconstruct Loss = 0.0012, Cls Loss = 0.4030, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4138, Reg Loss = 60.7492, Reconstruct Loss = 0.0010, Cls Loss = 0.4067, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4115, Reg Loss = 60.7388, Reconstruct Loss = 0.0009, Cls Loss = 0.4045, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4137, Reg Loss = 60.7784, Reconstruct Loss = 0.0010, Cls Loss = 0.4067, Learning rate = 1.0000e-05\n",
      "Epoch [165/200], Training Loss: 0.4146, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 66.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/200], Validation Loss: 3.2536, Validation Accuracy: 31.21%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3042, Reg Loss = 62.1446, Reconstruct Loss = 0.0000, Cls Loss = 0.2979, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4310, Reg Loss = 60.8007, Reconstruct Loss = 0.0005, Cls Loss = 0.4244, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4123, Reg Loss = 61.1167, Reconstruct Loss = 0.0011, Cls Loss = 0.4051, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4102, Reg Loss = 60.9962, Reconstruct Loss = 0.0009, Cls Loss = 0.4032, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4128, Reg Loss = 60.8805, Reconstruct Loss = 0.0011, Cls Loss = 0.4056, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4131, Reg Loss = 60.7773, Reconstruct Loss = 0.0011, Cls Loss = 0.4059, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4159, Reg Loss = 60.7462, Reconstruct Loss = 0.0013, Cls Loss = 0.4085, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4136, Reg Loss = 60.7560, Reconstruct Loss = 0.0013, Cls Loss = 0.4062, Learning rate = 1.0000e-05\n",
      "Epoch [166/200], Training Loss: 0.4154, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/200], Validation Loss: 3.2896, Validation Accuracy: 29.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3793, Reg Loss = 59.6013, Reconstruct Loss = 0.0000, Cls Loss = 0.3733, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4136, Reg Loss = 60.2536, Reconstruct Loss = 0.0005, Cls Loss = 0.4070, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4120, Reg Loss = 60.4695, Reconstruct Loss = 0.0011, Cls Loss = 0.4048, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4184, Reg Loss = 60.4148, Reconstruct Loss = 0.0015, Cls Loss = 0.4109, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4152, Reg Loss = 60.6629, Reconstruct Loss = 0.0019, Cls Loss = 0.4072, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4148, Reg Loss = 60.6673, Reconstruct Loss = 0.0021, Cls Loss = 0.4066, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4155, Reg Loss = 60.6234, Reconstruct Loss = 0.0022, Cls Loss = 0.4072, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4157, Reg Loss = 60.6755, Reconstruct Loss = 0.0020, Cls Loss = 0.4076, Learning rate = 1.0000e-05\n",
      "Epoch [167/200], Training Loss: 0.4169, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 66.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/200], Validation Loss: 3.7706, Validation Accuracy: 28.51%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2775, Reg Loss = 63.5884, Reconstruct Loss = 0.0000, Cls Loss = 0.2711, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4262, Reg Loss = 61.1243, Reconstruct Loss = 0.0016, Cls Loss = 0.4185, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4232, Reg Loss = 61.0938, Reconstruct Loss = 0.0019, Cls Loss = 0.4152, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4207, Reg Loss = 60.9863, Reconstruct Loss = 0.0016, Cls Loss = 0.4130, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4219, Reg Loss = 60.8942, Reconstruct Loss = 0.0016, Cls Loss = 0.4142, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4221, Reg Loss = 60.8050, Reconstruct Loss = 0.0017, Cls Loss = 0.4143, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4196, Reg Loss = 60.7371, Reconstruct Loss = 0.0017, Cls Loss = 0.4118, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4210, Reg Loss = 60.7383, Reconstruct Loss = 0.0017, Cls Loss = 0.4132, Learning rate = 1.0000e-05\n",
      "Epoch [168/200], Training Loss: 0.4186, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [168/200], Validation Loss: 3.4124, Validation Accuracy: 29.56%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3623, Reg Loss = 57.7390, Reconstruct Loss = 0.0000, Cls Loss = 0.3565, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4043, Reg Loss = 61.2557, Reconstruct Loss = 0.0011, Cls Loss = 0.3971, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4125, Reg Loss = 61.1120, Reconstruct Loss = 0.0011, Cls Loss = 0.4053, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4149, Reg Loss = 61.0976, Reconstruct Loss = 0.0011, Cls Loss = 0.4077, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4152, Reg Loss = 60.9431, Reconstruct Loss = 0.0016, Cls Loss = 0.4074, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4160, Reg Loss = 60.8738, Reconstruct Loss = 0.0015, Cls Loss = 0.4084, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4177, Reg Loss = 60.8128, Reconstruct Loss = 0.0018, Cls Loss = 0.4098, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4181, Reg Loss = 60.7471, Reconstruct Loss = 0.0017, Cls Loss = 0.4103, Learning rate = 1.0000e-05\n",
      "Epoch [169/200], Training Loss: 0.4180, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/200], Validation Loss: 3.4442, Validation Accuracy: 29.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5696, Reg Loss = 64.2696, Reconstruct Loss = 0.0000, Cls Loss = 0.5631, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4230, Reg Loss = 60.9819, Reconstruct Loss = 0.0011, Cls Loss = 0.4159, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4162, Reg Loss = 60.8206, Reconstruct Loss = 0.0024, Cls Loss = 0.4077, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4136, Reg Loss = 60.6704, Reconstruct Loss = 0.0023, Cls Loss = 0.4052, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4149, Reg Loss = 60.6249, Reconstruct Loss = 0.0019, Cls Loss = 0.4069, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4135, Reg Loss = 60.6513, Reconstruct Loss = 0.0020, Cls Loss = 0.4054, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4178, Reg Loss = 60.5976, Reconstruct Loss = 0.0020, Cls Loss = 0.4098, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4178, Reg Loss = 60.6293, Reconstruct Loss = 0.0020, Cls Loss = 0.4097, Learning rate = 1.0000e-05\n",
      "Epoch [170/200], Training Loss: 0.4167, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/200], Validation Loss: 3.3675, Validation Accuracy: 29.52%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5164, Reg Loss = 54.1671, Reconstruct Loss = 0.0000, Cls Loss = 0.5110, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4341, Reg Loss = 60.5670, Reconstruct Loss = 0.0010, Cls Loss = 0.4270, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4220, Reg Loss = 60.7454, Reconstruct Loss = 0.0021, Cls Loss = 0.4138, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4262, Reg Loss = 60.8120, Reconstruct Loss = 0.0021, Cls Loss = 0.4180, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4182, Reg Loss = 60.8086, Reconstruct Loss = 0.0020, Cls Loss = 0.4101, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4153, Reg Loss = 60.7608, Reconstruct Loss = 0.0019, Cls Loss = 0.4072, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4142, Reg Loss = 60.7024, Reconstruct Loss = 0.0018, Cls Loss = 0.4064, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4160, Reg Loss = 60.6786, Reconstruct Loss = 0.0016, Cls Loss = 0.4084, Learning rate = 1.0000e-05\n",
      "Epoch [171/200], Training Loss: 0.4184, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/200], Validation Loss: 3.1390, Validation Accuracy: 31.48%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2790, Reg Loss = 60.8678, Reconstruct Loss = 0.0000, Cls Loss = 0.2729, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4130, Reg Loss = 60.2303, Reconstruct Loss = 0.0016, Cls Loss = 0.4054, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4176, Reg Loss = 59.9418, Reconstruct Loss = 0.0021, Cls Loss = 0.4095, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4217, Reg Loss = 60.0278, Reconstruct Loss = 0.0021, Cls Loss = 0.4136, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4177, Reg Loss = 60.0573, Reconstruct Loss = 0.0019, Cls Loss = 0.4098, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4194, Reg Loss = 60.3036, Reconstruct Loss = 0.0020, Cls Loss = 0.4113, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4203, Reg Loss = 60.3456, Reconstruct Loss = 0.0021, Cls Loss = 0.4122, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4214, Reg Loss = 60.3497, Reconstruct Loss = 0.0019, Cls Loss = 0.4134, Learning rate = 1.0000e-05\n",
      "Epoch [172/200], Training Loss: 0.4209, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/200], Validation Loss: 3.5049, Validation Accuracy: 28.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2976, Reg Loss = 55.3543, Reconstruct Loss = 0.0000, Cls Loss = 0.2921, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4340, Reg Loss = 60.9682, Reconstruct Loss = 0.0016, Cls Loss = 0.4263, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4095, Reg Loss = 60.9259, Reconstruct Loss = 0.0013, Cls Loss = 0.4021, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4060, Reg Loss = 60.9574, Reconstruct Loss = 0.0011, Cls Loss = 0.3988, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4050, Reg Loss = 60.8063, Reconstruct Loss = 0.0012, Cls Loss = 0.3977, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4075, Reg Loss = 60.7055, Reconstruct Loss = 0.0011, Cls Loss = 0.4004, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4079, Reg Loss = 60.7074, Reconstruct Loss = 0.0010, Cls Loss = 0.4009, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4093, Reg Loss = 60.6614, Reconstruct Loss = 0.0014, Cls Loss = 0.4018, Learning rate = 1.0000e-05\n",
      "Epoch [173/200], Training Loss: 0.4088, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/200], Validation Loss: 3.4607, Validation Accuracy: 29.19%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4891, Reg Loss = 60.0270, Reconstruct Loss = 0.0000, Cls Loss = 0.4831, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4292, Reg Loss = 60.7548, Reconstruct Loss = 0.0011, Cls Loss = 0.4221, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4181, Reg Loss = 60.7941, Reconstruct Loss = 0.0005, Cls Loss = 0.4115, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4227, Reg Loss = 60.5831, Reconstruct Loss = 0.0011, Cls Loss = 0.4156, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4177, Reg Loss = 60.6186, Reconstruct Loss = 0.0009, Cls Loss = 0.4107, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4213, Reg Loss = 60.5755, Reconstruct Loss = 0.0009, Cls Loss = 0.4144, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4228, Reg Loss = 60.5603, Reconstruct Loss = 0.0014, Cls Loss = 0.4153, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4199, Reg Loss = 60.5238, Reconstruct Loss = 0.0015, Cls Loss = 0.4124, Learning rate = 1.0000e-05\n",
      "Epoch [174/200], Training Loss: 0.4197, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200], Validation Loss: 3.6032, Validation Accuracy: 28.66%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6534, Reg Loss = 60.3068, Reconstruct Loss = 0.0000, Cls Loss = 0.6474, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4229, Reg Loss = 60.5637, Reconstruct Loss = 0.0016, Cls Loss = 0.4152, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4301, Reg Loss = 60.6005, Reconstruct Loss = 0.0021, Cls Loss = 0.4219, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4301, Reg Loss = 60.5246, Reconstruct Loss = 0.0025, Cls Loss = 0.4215, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4247, Reg Loss = 60.5074, Reconstruct Loss = 0.0020, Cls Loss = 0.4167, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4224, Reg Loss = 60.5839, Reconstruct Loss = 0.0016, Cls Loss = 0.4147, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4212, Reg Loss = 60.4928, Reconstruct Loss = 0.0017, Cls Loss = 0.4134, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4223, Reg Loss = 60.4298, Reconstruct Loss = 0.0017, Cls Loss = 0.4146, Learning rate = 1.0000e-05\n",
      "Epoch [175/200], Training Loss: 0.4202, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/200], Validation Loss: 3.2178, Validation Accuracy: 30.40%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2621, Reg Loss = 59.9118, Reconstruct Loss = 0.0000, Cls Loss = 0.2561, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4294, Reg Loss = 60.6895, Reconstruct Loss = 0.0016, Cls Loss = 0.4217, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4256, Reg Loss = 60.1423, Reconstruct Loss = 0.0021, Cls Loss = 0.4174, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4175, Reg Loss = 60.2352, Reconstruct Loss = 0.0021, Cls Loss = 0.4093, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4146, Reg Loss = 60.2075, Reconstruct Loss = 0.0019, Cls Loss = 0.4067, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4164, Reg Loss = 60.2520, Reconstruct Loss = 0.0015, Cls Loss = 0.4089, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4179, Reg Loss = 60.2352, Reconstruct Loss = 0.0016, Cls Loss = 0.4102, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4177, Reg Loss = 60.3080, Reconstruct Loss = 0.0016, Cls Loss = 0.4100, Learning rate = 1.0000e-05\n",
      "Epoch [176/200], Training Loss: 0.4146, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/200], Validation Loss: 3.2666, Validation Accuracy: 31.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2807, Reg Loss = 60.2830, Reconstruct Loss = 0.0000, Cls Loss = 0.2747, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4187, Reg Loss = 60.5389, Reconstruct Loss = 0.0016, Cls Loss = 0.4110, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4251, Reg Loss = 60.7055, Reconstruct Loss = 0.0016, Cls Loss = 0.4174, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4141, Reg Loss = 60.6686, Reconstruct Loss = 0.0014, Cls Loss = 0.4067, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4171, Reg Loss = 60.5723, Reconstruct Loss = 0.0013, Cls Loss = 0.4097, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4204, Reg Loss = 60.6500, Reconstruct Loss = 0.0014, Cls Loss = 0.4129, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4196, Reg Loss = 60.5927, Reconstruct Loss = 0.0014, Cls Loss = 0.4121, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4188, Reg Loss = 60.5810, Reconstruct Loss = 0.0014, Cls Loss = 0.4114, Learning rate = 1.0000e-05\n",
      "Epoch [177/200], Training Loss: 0.4197, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/200], Validation Loss: 3.8762, Validation Accuracy: 26.42%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4087, Reg Loss = 62.0784, Reconstruct Loss = 0.0000, Cls Loss = 0.4025, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4228, Reg Loss = 60.1040, Reconstruct Loss = 0.0010, Cls Loss = 0.4158, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4223, Reg Loss = 60.4055, Reconstruct Loss = 0.0013, Cls Loss = 0.4149, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4167, Reg Loss = 60.5363, Reconstruct Loss = 0.0011, Cls Loss = 0.4096, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4189, Reg Loss = 60.5096, Reconstruct Loss = 0.0008, Cls Loss = 0.4121, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4117, Reg Loss = 60.5662, Reconstruct Loss = 0.0010, Cls Loss = 0.4047, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4120, Reg Loss = 60.6116, Reconstruct Loss = 0.0011, Cls Loss = 0.4048, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4160, Reg Loss = 60.4889, Reconstruct Loss = 0.0011, Cls Loss = 0.4088, Learning rate = 1.0000e-05\n",
      "Epoch [178/200], Training Loss: 0.4163, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/200], Validation Loss: 3.4265, Validation Accuracy: 29.36%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6604, Reg Loss = 58.9658, Reconstruct Loss = 0.0000, Cls Loss = 0.6545, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4116, Reg Loss = 60.7234, Reconstruct Loss = 0.0005, Cls Loss = 0.4050, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4127, Reg Loss = 60.6236, Reconstruct Loss = 0.0011, Cls Loss = 0.4056, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4096, Reg Loss = 60.5262, Reconstruct Loss = 0.0016, Cls Loss = 0.4019, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4120, Reg Loss = 60.4553, Reconstruct Loss = 0.0019, Cls Loss = 0.4041, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4122, Reg Loss = 60.5014, Reconstruct Loss = 0.0017, Cls Loss = 0.4044, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4136, Reg Loss = 60.5311, Reconstruct Loss = 0.0016, Cls Loss = 0.4059, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4115, Reg Loss = 60.5402, Reconstruct Loss = 0.0015, Cls Loss = 0.4039, Learning rate = 1.0000e-05\n",
      "Epoch [179/200], Training Loss: 0.4117, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/200], Validation Loss: 3.3783, Validation Accuracy: 29.79%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3278, Reg Loss = 55.0312, Reconstruct Loss = 0.0000, Cls Loss = 0.3223, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4130, Reg Loss = 60.3852, Reconstruct Loss = 0.0021, Cls Loss = 0.4048, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4141, Reg Loss = 60.4898, Reconstruct Loss = 0.0021, Cls Loss = 0.4059, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4142, Reg Loss = 60.3718, Reconstruct Loss = 0.0020, Cls Loss = 0.4062, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4145, Reg Loss = 60.3000, Reconstruct Loss = 0.0020, Cls Loss = 0.4064, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4161, Reg Loss = 60.2342, Reconstruct Loss = 0.0024, Cls Loss = 0.4077, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4198, Reg Loss = 60.1534, Reconstruct Loss = 0.0023, Cls Loss = 0.4115, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4189, Reg Loss = 60.1182, Reconstruct Loss = 0.0022, Cls Loss = 0.4107, Learning rate = 1.0000e-05\n",
      "Epoch [180/200], Training Loss: 0.4175, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/200], Validation Loss: 3.6057, Validation Accuracy: 26.71%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7556, Reg Loss = 59.5685, Reconstruct Loss = 0.0000, Cls Loss = 0.7496, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4085, Reg Loss = 60.7046, Reconstruct Loss = 0.0016, Cls Loss = 0.4009, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4122, Reg Loss = 60.4022, Reconstruct Loss = 0.0013, Cls Loss = 0.4048, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4122, Reg Loss = 60.6071, Reconstruct Loss = 0.0014, Cls Loss = 0.4047, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4131, Reg Loss = 60.5314, Reconstruct Loss = 0.0018, Cls Loss = 0.4053, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4157, Reg Loss = 60.5218, Reconstruct Loss = 0.0017, Cls Loss = 0.4079, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4125, Reg Loss = 60.5033, Reconstruct Loss = 0.0016, Cls Loss = 0.4048, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4156, Reg Loss = 60.4641, Reconstruct Loss = 0.0018, Cls Loss = 0.4078, Learning rate = 1.0000e-05\n",
      "Epoch [181/200], Training Loss: 0.4153, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/200], Validation Loss: 3.6332, Validation Accuracy: 28.81%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4682, Reg Loss = 61.4414, Reconstruct Loss = 0.0000, Cls Loss = 0.4621, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4430, Reg Loss = 60.6418, Reconstruct Loss = 0.0005, Cls Loss = 0.4364, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4302, Reg Loss = 60.5524, Reconstruct Loss = 0.0008, Cls Loss = 0.4233, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4238, Reg Loss = 60.4951, Reconstruct Loss = 0.0009, Cls Loss = 0.4169, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4234, Reg Loss = 60.5286, Reconstruct Loss = 0.0009, Cls Loss = 0.4164, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4242, Reg Loss = 60.4465, Reconstruct Loss = 0.0012, Cls Loss = 0.4170, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4234, Reg Loss = 60.5282, Reconstruct Loss = 0.0013, Cls Loss = 0.4160, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4222, Reg Loss = 60.5259, Reconstruct Loss = 0.0013, Cls Loss = 0.4149, Learning rate = 1.0000e-05\n",
      "Epoch [182/200], Training Loss: 0.4212, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/200], Validation Loss: 3.9279, Validation Accuracy: 25.82%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3255, Reg Loss = 61.2301, Reconstruct Loss = 0.0000, Cls Loss = 0.3194, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4290, Reg Loss = 60.7875, Reconstruct Loss = 0.0011, Cls Loss = 0.4218, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4211, Reg Loss = 60.8851, Reconstruct Loss = 0.0013, Cls Loss = 0.4137, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4195, Reg Loss = 60.5960, Reconstruct Loss = 0.0016, Cls Loss = 0.4118, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4226, Reg Loss = 60.6741, Reconstruct Loss = 0.0015, Cls Loss = 0.4151, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4196, Reg Loss = 60.7122, Reconstruct Loss = 0.0014, Cls Loss = 0.4122, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4186, Reg Loss = 60.6421, Reconstruct Loss = 0.0014, Cls Loss = 0.4111, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4176, Reg Loss = 60.6067, Reconstruct Loss = 0.0015, Cls Loss = 0.4100, Learning rate = 1.0000e-05\n",
      "Epoch [183/200], Training Loss: 0.4174, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/200], Validation Loss: 3.1774, Validation Accuracy: 31.61%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5836, Reg Loss = 64.1956, Reconstruct Loss = 0.0000, Cls Loss = 0.5771, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4025, Reg Loss = 60.2863, Reconstruct Loss = 0.0005, Cls Loss = 0.3959, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4144, Reg Loss = 60.3444, Reconstruct Loss = 0.0011, Cls Loss = 0.4073, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4131, Reg Loss = 60.5018, Reconstruct Loss = 0.0012, Cls Loss = 0.4058, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4160, Reg Loss = 60.4661, Reconstruct Loss = 0.0015, Cls Loss = 0.4085, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4148, Reg Loss = 60.3769, Reconstruct Loss = 0.0016, Cls Loss = 0.4071, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4156, Reg Loss = 60.4105, Reconstruct Loss = 0.0016, Cls Loss = 0.4080, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4129, Reg Loss = 60.4709, Reconstruct Loss = 0.0015, Cls Loss = 0.4054, Learning rate = 1.0000e-05\n",
      "Epoch [184/200], Training Loss: 0.4140, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/200], Validation Loss: 3.5877, Validation Accuracy: 28.89%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3234, Reg Loss = 57.7108, Reconstruct Loss = 0.0000, Cls Loss = 0.3176, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4272, Reg Loss = 60.3597, Reconstruct Loss = 0.0016, Cls Loss = 0.4196, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4155, Reg Loss = 60.3524, Reconstruct Loss = 0.0013, Cls Loss = 0.4082, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4158, Reg Loss = 60.3830, Reconstruct Loss = 0.0011, Cls Loss = 0.4087, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4141, Reg Loss = 60.5411, Reconstruct Loss = 0.0011, Cls Loss = 0.4070, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4110, Reg Loss = 60.4833, Reconstruct Loss = 0.0012, Cls Loss = 0.4038, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4121, Reg Loss = 60.4057, Reconstruct Loss = 0.0012, Cls Loss = 0.4049, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4123, Reg Loss = 60.3382, Reconstruct Loss = 0.0012, Cls Loss = 0.4051, Learning rate = 1.0000e-05\n",
      "Epoch [185/200], Training Loss: 0.4115, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/200], Validation Loss: 3.5772, Validation Accuracy: 28.10%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4359, Reg Loss = 57.4972, Reconstruct Loss = 0.0000, Cls Loss = 0.4302, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4206, Reg Loss = 60.0478, Reconstruct Loss = 0.0011, Cls Loss = 0.4135, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4145, Reg Loss = 60.2184, Reconstruct Loss = 0.0013, Cls Loss = 0.4071, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4155, Reg Loss = 60.1843, Reconstruct Loss = 0.0018, Cls Loss = 0.4077, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4183, Reg Loss = 60.2237, Reconstruct Loss = 0.0016, Cls Loss = 0.4106, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4133, Reg Loss = 60.1645, Reconstruct Loss = 0.0020, Cls Loss = 0.4053, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4134, Reg Loss = 60.2931, Reconstruct Loss = 0.0019, Cls Loss = 0.4055, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4112, Reg Loss = 60.2632, Reconstruct Loss = 0.0019, Cls Loss = 0.4032, Learning rate = 1.0000e-05\n",
      "Epoch [186/200], Training Loss: 0.4146, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/200], Validation Loss: 3.5140, Validation Accuracy: 27.23%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3315, Reg Loss = 59.7209, Reconstruct Loss = 0.0000, Cls Loss = 0.3255, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4103, Reg Loss = 60.8241, Reconstruct Loss = 0.0032, Cls Loss = 0.4010, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4085, Reg Loss = 60.3546, Reconstruct Loss = 0.0030, Cls Loss = 0.3995, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4180, Reg Loss = 60.4790, Reconstruct Loss = 0.0020, Cls Loss = 0.4100, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4154, Reg Loss = 60.3809, Reconstruct Loss = 0.0020, Cls Loss = 0.4074, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4149, Reg Loss = 60.3828, Reconstruct Loss = 0.0019, Cls Loss = 0.4070, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4117, Reg Loss = 60.3995, Reconstruct Loss = 0.0016, Cls Loss = 0.4041, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4169, Reg Loss = 60.3888, Reconstruct Loss = 0.0017, Cls Loss = 0.4092, Learning rate = 1.0000e-05\n",
      "Epoch [187/200], Training Loss: 0.4176, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/200], Validation Loss: 3.5535, Validation Accuracy: 28.30%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5441, Reg Loss = 59.2205, Reconstruct Loss = 0.0000, Cls Loss = 0.5381, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.3830, Reg Loss = 60.2719, Reconstruct Loss = 0.0016, Cls Loss = 0.3754, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4032, Reg Loss = 60.2489, Reconstruct Loss = 0.0016, Cls Loss = 0.3956, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4030, Reg Loss = 60.4020, Reconstruct Loss = 0.0013, Cls Loss = 0.3957, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4019, Reg Loss = 60.3309, Reconstruct Loss = 0.0016, Cls Loss = 0.3942, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4075, Reg Loss = 60.2894, Reconstruct Loss = 0.0019, Cls Loss = 0.3996, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4091, Reg Loss = 60.3435, Reconstruct Loss = 0.0016, Cls Loss = 0.4014, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4103, Reg Loss = 60.4293, Reconstruct Loss = 0.0017, Cls Loss = 0.4025, Learning rate = 1.0000e-05\n",
      "Epoch [188/200], Training Loss: 0.4098, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/200], Validation Loss: 3.0819, Validation Accuracy: 32.12%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3054, Reg Loss = 60.3378, Reconstruct Loss = 0.0000, Cls Loss = 0.2994, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4093, Reg Loss = 60.4658, Reconstruct Loss = 0.0022, Cls Loss = 0.4011, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4179, Reg Loss = 60.3639, Reconstruct Loss = 0.0024, Cls Loss = 0.4094, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4140, Reg Loss = 60.4059, Reconstruct Loss = 0.0022, Cls Loss = 0.4058, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4137, Reg Loss = 60.3759, Reconstruct Loss = 0.0022, Cls Loss = 0.4055, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4151, Reg Loss = 60.4010, Reconstruct Loss = 0.0022, Cls Loss = 0.4069, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4151, Reg Loss = 60.3794, Reconstruct Loss = 0.0020, Cls Loss = 0.4071, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4161, Reg Loss = 60.3788, Reconstruct Loss = 0.0019, Cls Loss = 0.4082, Learning rate = 1.0000e-05\n",
      "Epoch [189/200], Training Loss: 0.4155, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/200], Validation Loss: 3.1153, Validation Accuracy: 31.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3384, Reg Loss = 58.8327, Reconstruct Loss = 0.0000, Cls Loss = 0.3325, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4304, Reg Loss = 60.0855, Reconstruct Loss = 0.0000, Cls Loss = 0.4244, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4214, Reg Loss = 60.5426, Reconstruct Loss = 0.0008, Cls Loss = 0.4146, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4164, Reg Loss = 60.5563, Reconstruct Loss = 0.0007, Cls Loss = 0.4097, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4186, Reg Loss = 60.6561, Reconstruct Loss = 0.0010, Cls Loss = 0.4115, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4201, Reg Loss = 60.5339, Reconstruct Loss = 0.0011, Cls Loss = 0.4130, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4185, Reg Loss = 60.4358, Reconstruct Loss = 0.0014, Cls Loss = 0.4111, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4214, Reg Loss = 60.3762, Reconstruct Loss = 0.0014, Cls Loss = 0.4140, Learning rate = 1.0000e-05\n",
      "Epoch [190/200], Training Loss: 0.4209, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/200], Validation Loss: 3.4067, Validation Accuracy: 28.74%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.7516, Reg Loss = 61.2631, Reconstruct Loss = 0.0000, Cls Loss = 0.7455, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4224, Reg Loss = 60.2594, Reconstruct Loss = 0.0027, Cls Loss = 0.4136, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4214, Reg Loss = 60.3668, Reconstruct Loss = 0.0022, Cls Loss = 0.4132, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4185, Reg Loss = 60.3377, Reconstruct Loss = 0.0016, Cls Loss = 0.4108, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4146, Reg Loss = 60.3207, Reconstruct Loss = 0.0016, Cls Loss = 0.4069, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4129, Reg Loss = 60.2762, Reconstruct Loss = 0.0017, Cls Loss = 0.4052, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4166, Reg Loss = 60.2574, Reconstruct Loss = 0.0016, Cls Loss = 0.4089, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4171, Reg Loss = 60.3422, Reconstruct Loss = 0.0016, Cls Loss = 0.4094, Learning rate = 1.0000e-05\n",
      "Epoch [191/200], Training Loss: 0.4175, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/200], Validation Loss: 3.5338, Validation Accuracy: 27.96%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3697, Reg Loss = 60.8977, Reconstruct Loss = 0.0000, Cls Loss = 0.3636, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4069, Reg Loss = 60.3008, Reconstruct Loss = 0.0011, Cls Loss = 0.3998, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4124, Reg Loss = 60.4512, Reconstruct Loss = 0.0013, Cls Loss = 0.4050, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4166, Reg Loss = 60.3548, Reconstruct Loss = 0.0014, Cls Loss = 0.4092, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4194, Reg Loss = 60.3279, Reconstruct Loss = 0.0015, Cls Loss = 0.4119, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4145, Reg Loss = 60.4390, Reconstruct Loss = 0.0015, Cls Loss = 0.4070, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4120, Reg Loss = 60.4862, Reconstruct Loss = 0.0013, Cls Loss = 0.4046, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4119, Reg Loss = 60.4183, Reconstruct Loss = 0.0015, Cls Loss = 0.4043, Learning rate = 1.0000e-05\n",
      "Epoch [192/200], Training Loss: 0.4130, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/200], Validation Loss: 3.8017, Validation Accuracy: 27.95%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.2401, Reg Loss = 64.7748, Reconstruct Loss = 0.0000, Cls Loss = 0.2336, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4306, Reg Loss = 60.3332, Reconstruct Loss = 0.0016, Cls Loss = 0.4229, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4226, Reg Loss = 60.4512, Reconstruct Loss = 0.0008, Cls Loss = 0.4157, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4207, Reg Loss = 60.6463, Reconstruct Loss = 0.0007, Cls Loss = 0.4139, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4137, Reg Loss = 60.6420, Reconstruct Loss = 0.0012, Cls Loss = 0.4064, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4158, Reg Loss = 60.6251, Reconstruct Loss = 0.0014, Cls Loss = 0.4083, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4148, Reg Loss = 60.6030, Reconstruct Loss = 0.0017, Cls Loss = 0.4070, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4148, Reg Loss = 60.5329, Reconstruct Loss = 0.0022, Cls Loss = 0.4066, Learning rate = 1.0000e-05\n",
      "Epoch [193/200], Training Loss: 0.4150, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/200], Validation Loss: 3.2410, Validation Accuracy: 30.38%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6243, Reg Loss = 60.3302, Reconstruct Loss = 0.0000, Cls Loss = 0.6183, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4334, Reg Loss = 60.5611, Reconstruct Loss = 0.0016, Cls Loss = 0.4257, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4184, Reg Loss = 60.6840, Reconstruct Loss = 0.0014, Cls Loss = 0.4109, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4170, Reg Loss = 60.6872, Reconstruct Loss = 0.0009, Cls Loss = 0.4100, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4152, Reg Loss = 60.6586, Reconstruct Loss = 0.0011, Cls Loss = 0.4080, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4133, Reg Loss = 60.6332, Reconstruct Loss = 0.0013, Cls Loss = 0.4059, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4147, Reg Loss = 60.6253, Reconstruct Loss = 0.0013, Cls Loss = 0.4073, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4158, Reg Loss = 60.6190, Reconstruct Loss = 0.0012, Cls Loss = 0.4085, Learning rate = 1.0000e-05\n",
      "Epoch [194/200], Training Loss: 0.4143, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/200], Validation Loss: 3.3847, Validation Accuracy: 28.57%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.6668, Reg Loss = 64.0724, Reconstruct Loss = 0.0000, Cls Loss = 0.6604, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4201, Reg Loss = 60.1595, Reconstruct Loss = 0.0016, Cls Loss = 0.4125, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4158, Reg Loss = 60.1381, Reconstruct Loss = 0.0019, Cls Loss = 0.4079, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4144, Reg Loss = 60.4459, Reconstruct Loss = 0.0014, Cls Loss = 0.4069, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4182, Reg Loss = 60.5137, Reconstruct Loss = 0.0013, Cls Loss = 0.4108, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4161, Reg Loss = 60.5469, Reconstruct Loss = 0.0013, Cls Loss = 0.4087, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4121, Reg Loss = 60.5325, Reconstruct Loss = 0.0016, Cls Loss = 0.4044, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4102, Reg Loss = 60.5338, Reconstruct Loss = 0.0016, Cls Loss = 0.4025, Learning rate = 1.0000e-05\n",
      "Epoch [195/200], Training Loss: 0.4111, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [195/200], Validation Loss: 3.0403, Validation Accuracy: 33.05%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.4409, Reg Loss = 59.2506, Reconstruct Loss = 0.0000, Cls Loss = 0.4350, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4177, Reg Loss = 60.3478, Reconstruct Loss = 0.0011, Cls Loss = 0.4106, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4245, Reg Loss = 60.5927, Reconstruct Loss = 0.0011, Cls Loss = 0.4174, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4213, Reg Loss = 60.4382, Reconstruct Loss = 0.0020, Cls Loss = 0.4132, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4164, Reg Loss = 60.4337, Reconstruct Loss = 0.0018, Cls Loss = 0.4086, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4134, Reg Loss = 60.4632, Reconstruct Loss = 0.0021, Cls Loss = 0.4053, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4145, Reg Loss = 60.4637, Reconstruct Loss = 0.0017, Cls Loss = 0.4067, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4142, Reg Loss = 60.4351, Reconstruct Loss = 0.0019, Cls Loss = 0.4062, Learning rate = 1.0000e-05\n",
      "Epoch [196/200], Training Loss: 0.4160, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/200], Validation Loss: 3.5952, Validation Accuracy: 28.34%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3631, Reg Loss = 55.0016, Reconstruct Loss = 0.0000, Cls Loss = 0.3576, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.3929, Reg Loss = 60.3733, Reconstruct Loss = 0.0016, Cls Loss = 0.3853, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.3999, Reg Loss = 60.2843, Reconstruct Loss = 0.0016, Cls Loss = 0.3923, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4043, Reg Loss = 60.2853, Reconstruct Loss = 0.0016, Cls Loss = 0.3967, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4119, Reg Loss = 60.2865, Reconstruct Loss = 0.0016, Cls Loss = 0.4043, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4121, Reg Loss = 60.3339, Reconstruct Loss = 0.0016, Cls Loss = 0.4044, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4151, Reg Loss = 60.3323, Reconstruct Loss = 0.0019, Cls Loss = 0.4072, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4132, Reg Loss = 60.4017, Reconstruct Loss = 0.0018, Cls Loss = 0.4054, Learning rate = 1.0000e-05\n",
      "Epoch [197/200], Training Loss: 0.4148, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [197/200], Validation Loss: 3.7610, Validation Accuracy: 27.32%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3917, Reg Loss = 60.3873, Reconstruct Loss = 0.0000, Cls Loss = 0.3856, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4233, Reg Loss = 60.0659, Reconstruct Loss = 0.0016, Cls Loss = 0.4157, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4176, Reg Loss = 60.2784, Reconstruct Loss = 0.0013, Cls Loss = 0.4102, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4210, Reg Loss = 60.2549, Reconstruct Loss = 0.0011, Cls Loss = 0.4139, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4189, Reg Loss = 60.3336, Reconstruct Loss = 0.0008, Cls Loss = 0.4120, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4180, Reg Loss = 60.3429, Reconstruct Loss = 0.0008, Cls Loss = 0.4112, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4151, Reg Loss = 60.2675, Reconstruct Loss = 0.0010, Cls Loss = 0.4081, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4170, Reg Loss = 60.2927, Reconstruct Loss = 0.0010, Cls Loss = 0.4100, Learning rate = 1.0000e-05\n",
      "Epoch [198/200], Training Loss: 0.4161, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [198/200], Validation Loss: 4.0758, Validation Accuracy: 25.28%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.3108, Reg Loss = 56.5172, Reconstruct Loss = 0.0544, Cls Loss = 0.2507, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.4030, Reg Loss = 60.3551, Reconstruct Loss = 0.0011, Cls Loss = 0.3959, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4023, Reg Loss = 60.1735, Reconstruct Loss = 0.0019, Cls Loss = 0.3944, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4033, Reg Loss = 60.3132, Reconstruct Loss = 0.0022, Cls Loss = 0.3951, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4028, Reg Loss = 60.3950, Reconstruct Loss = 0.0020, Cls Loss = 0.3947, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4044, Reg Loss = 60.2730, Reconstruct Loss = 0.0019, Cls Loss = 0.3964, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4069, Reg Loss = 60.3561, Reconstruct Loss = 0.0017, Cls Loss = 0.3992, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4093, Reg Loss = 60.3879, Reconstruct Loss = 0.0017, Cls Loss = 0.4015, Learning rate = 1.0000e-05\n",
      "Epoch [199/200], Training Loss: 0.4102, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/200], Validation Loss: 3.4494, Validation Accuracy: 29.18%\n",
      "\n",
      "\n",
      "\n",
      "Iteration 0: Loss = 0.5710, Reg Loss = 63.4012, Reconstruct Loss = 0.0000, Cls Loss = 0.5647, Learning rate = 1.0000e-05\n",
      "Iteration 100: Loss = 0.3953, Reg Loss = 60.2958, Reconstruct Loss = 0.0011, Cls Loss = 0.3881, Learning rate = 1.0000e-05\n",
      "Iteration 200: Loss = 0.4034, Reg Loss = 60.4034, Reconstruct Loss = 0.0021, Cls Loss = 0.3953, Learning rate = 1.0000e-05\n",
      "Iteration 300: Loss = 0.4048, Reg Loss = 60.4192, Reconstruct Loss = 0.0016, Cls Loss = 0.3971, Learning rate = 1.0000e-05\n",
      "Iteration 400: Loss = 0.4075, Reg Loss = 60.4145, Reconstruct Loss = 0.0013, Cls Loss = 0.4001, Learning rate = 1.0000e-05\n",
      "Iteration 500: Loss = 0.4104, Reg Loss = 60.4223, Reconstruct Loss = 0.0013, Cls Loss = 0.4030, Learning rate = 1.0000e-05\n",
      "Iteration 600: Loss = 0.4116, Reg Loss = 60.4518, Reconstruct Loss = 0.0013, Cls Loss = 0.4042, Learning rate = 1.0000e-05\n",
      "Iteration 700: Loss = 0.4119, Reg Loss = 60.4898, Reconstruct Loss = 0.0013, Cls Loss = 0.4046, Learning rate = 1.0000e-05\n",
      "Epoch [200/200], Training Loss: 0.4114, Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 66.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/200], Validation Loss: 3.4856, Validation Accuracy: 29.75%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the epochs\n",
    "for epoch in range(start_epoch, args.experiment.num_epochs):\n",
    "    # Train the hypernetwork to generate a model with random dimension for one epoch\n",
    "    train_loss, dim_dict, gt_model_dict = train_one_epoch(hyper_model, train_loader, optimizer, criterion, \n",
    "                                                          dim_dict, gt_model_dict, epoch_idx=epoch, ema=ema, \n",
    "                                                          args=args, device=device)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the training loss and learning rate\n",
    "    print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Training Loss: {train_loss:.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    # If it's time to evaluate the model\n",
    "    if (epoch + 1) % args.experiment.eval_interval == 0:\n",
    "        # Apply EMA if it is specified\n",
    "        if ema:\n",
    "            ema.apply()  # Save the weights of original model created before training_loop\n",
    "        \n",
    "        # Sample the merged model (create model of same structure before training loop by using the hypernetwork)\n",
    "        # And then test the performance of the hypernetwork by seeing how good it is in generating the weights\n",
    "        model = sample_merge_model(hyper_model, model, args) \n",
    "        # Validate the merged model\n",
    "        val_loss, acc = validate_single(model, val_loader, val_criterion, args=args)\n",
    "\n",
    "        # If EMA is specified, restore the original weights\n",
    "        if ema:\n",
    "            ema.restore()  # Restore the original weights to the weights of the pretrained networks\n",
    "\n",
    "        # Log the validation loss and accuracy to wandb\n",
    "        wandb.log({\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": acc\n",
    "        })\n",
    "        # Print the validation loss and accuracy\n",
    "        print(f\"Epoch [{epoch+1}/{args.experiment.num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # Save the checkpoint if the accuracy is better than the previous best\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            save_checkpoint(f\"{args.training.save_model_path}/cifar10_nerf_best.pth\",hyper_model,optimizer,ema,epoch,best_acc)\n",
    "            print(f\"Checkpoint saved at epoch {epoch} with accuracy: {best_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ee9bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.5552, Validation Accuracy: 81.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(dim_dict['32'][0], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b21c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.5372, Validation Accuracy: 83.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(dim_dict['64'][0], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17b7b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Permutated model Validation Loss: 0.2825, Validation Accuracy: 92.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for the starting dimension (its pretrained form)\n",
    "val_loss, acc = validate_single(gt_model_dict['64'], val_loader, nn.CrossEntropyLoss(), args=args)\n",
    "print(f'Initial Permutated model Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15464fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>████▇▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>Learning rate</td><td>████████████████████████▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Loss</td><td>███▇▇▇▇▇▇▆▅▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁</td></tr><tr><td>Reconstruct Loss</td><td>▆▅▆▄▂▃▄▅▄▄▆▄▃▄▅█▅▆▆▅▄▆▅▃▁▅▅▅▄▁▆▁▆▅▆▆▄▁▆▅</td></tr><tr><td>Reg Loss</td><td>▁▁▁▁▂▂▂▂▂▂▃▄▄▄▅▆▇██▇████████████████████</td></tr><tr><td>Validation Accuracy</td><td>█▃▅▅▄▃▃▂▁▂▃▃▂▂▂▂▃▃▂▂▂▂▂▂▃▃▂▃▂▃▂▂▂▂▂▃▂▂▂▃</td></tr><tr><td>Validation Loss</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▂▃▃▃▃▄▅▆▇▆▆▆▅▇▇▆▇▆▇▆▆▇▇▆█▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cls Loss</td><td>0.4046</td></tr><tr><td>Learning rate</td><td>1e-05</td></tr><tr><td>Loss</td><td>0.41195</td></tr><tr><td>Reconstruct Loss</td><td>0.0013</td></tr><tr><td>Reg Loss</td><td>60.48984</td></tr><tr><td>Validation Accuracy</td><td>0.2975</td></tr><tr><td>Validation Loss</td><td>3.48558</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20250520052850-ninr_resnet20_cifar10_32-64-4layer-200e-noisecoord-resmlpv2_smooth_5_256_16_smooth</strong> at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/61limfrt' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial/runs/61limfrt</a><br> View project at: <a href='https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial' target=\"_blank\">https://wandb.ai/efradosuryadi-universitas-indonesia/ninr-trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_052852-61limfrt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# End the wandb tracking\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6054a4",
   "metadata": {},
   "source": [
    "### 7 Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43945b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_hypernet_path = args.training.save_model_path + '/cifar10_nerf_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f139172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper model type: resmlp\n",
      "Using scalar 0.1\n",
      "num_freqs:  16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "hyper_model_test = get_hypernetwork(args, number_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4431caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(saved_hypernet_path, map_location=\"cpu\")  # or \"cuda\" if using GPU\n",
    "hyper_model_test.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eaa63eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 16\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1395.43017578125\n",
      "Permuted TV original model: 1317.2218017578125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 71.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 16, Validation Loss: 1.8079, Validation Accuracy: 75.60%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 17\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1437.119140625\n",
      "Permuted TV original model: 1354.6817626953125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 17, Validation Loss: 1.8079, Validation Accuracy: 75.51%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 18\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1495.8773193359375\n",
      "Permuted TV original model: 1412.2720947265625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 18, Validation Loss: 1.8078, Validation Accuracy: 75.84%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 19\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1536.5960693359375\n",
      "Permuted TV original model: 1446.2403564453125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 19, Validation Loss: 1.8079, Validation Accuracy: 75.41%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 20\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1586.2530517578125\n",
      "Permuted TV original model: 1504.114013671875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 20, Validation Loss: 1.8080, Validation Accuracy: 75.06%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 21\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1628.83642578125\n",
      "Permuted TV original model: 1536.47802734375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 21, Validation Loss: 1.8077, Validation Accuracy: 75.61%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 22\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1680.5040283203125\n",
      "Permuted TV original model: 1583.69482421875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 22, Validation Loss: 1.8077, Validation Accuracy: 75.68%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 23\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1722.16748046875\n",
      "Permuted TV original model: 1628.936279296875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 23, Validation Loss: 1.8080, Validation Accuracy: 75.32%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 24\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1776.1859130859375\n",
      "Permuted TV original model: 1674.2579345703125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 84.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 24, Validation Loss: 1.8070, Validation Accuracy: 76.30%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 25\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1810.09228515625\n",
      "Permuted TV original model: 1723.6397705078125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 83.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 25, Validation Loss: 1.8078, Validation Accuracy: 75.62%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 26\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1851.6483154296875\n",
      "Permuted TV original model: 1755.5106201171875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 26, Validation Loss: 1.8084, Validation Accuracy: 75.06%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 27\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1910.43408203125\n",
      "Permuted TV original model: 1812.1151123046875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 63.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 27, Validation Loss: 1.8078, Validation Accuracy: 75.65%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 28\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1959.797607421875\n",
      "Permuted TV original model: 1860.4151611328125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 28, Validation Loss: 1.8073, Validation Accuracy: 75.96%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 29\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2008.47998046875\n",
      "Permuted TV original model: 1901.997314453125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 29, Validation Loss: 1.8083, Validation Accuracy: 75.11%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 30\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2054.9580078125\n",
      "Permuted TV original model: 1950.2403564453125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 30, Validation Loss: 1.8072, Validation Accuracy: 76.20%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 31\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2098.635498046875\n",
      "Permuted TV original model: 1984.899658203125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 31, Validation Loss: 1.8081, Validation Accuracy: 74.91%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 32\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2138.606689453125\n",
      "Permuted TV original model: 2031.5277099609375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 32, Validation Loss: 1.8083, Validation Accuracy: 75.35%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 33\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2192.2001953125\n",
      "Permuted TV original model: 2080.08349609375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 33, Validation Loss: 1.8081, Validation Accuracy: 75.43%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 34\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2234.962646484375\n",
      "Permuted TV original model: 2129.647705078125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 34, Validation Loss: 1.8078, Validation Accuracy: 75.60%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 35\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2274.59033203125\n",
      "Permuted TV original model: 2157.695556640625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 35, Validation Loss: 1.8073, Validation Accuracy: 76.05%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 36\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2321.7158203125\n",
      "Permuted TV original model: 2211.810791015625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 36, Validation Loss: 1.8083, Validation Accuracy: 75.13%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 37\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2368.03857421875\n",
      "Permuted TV original model: 2254.5234375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 37, Validation Loss: 1.8079, Validation Accuracy: 75.41%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 38\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2406.206787109375\n",
      "Permuted TV original model: 2291.994873046875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 78.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 38, Validation Loss: 1.8082, Validation Accuracy: 75.17%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 39\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2461.343505859375\n",
      "Permuted TV original model: 2343.48388671875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 39, Validation Loss: 1.8077, Validation Accuracy: 75.61%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 40\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2500.077880859375\n",
      "Permuted TV original model: 2379.1357421875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 79.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 40, Validation Loss: 1.8078, Validation Accuracy: 75.37%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 41\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2560.488525390625\n",
      "Permuted TV original model: 2440.911376953125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 74.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 41, Validation Loss: 1.8078, Validation Accuracy: 75.66%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 42\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2590.226806640625\n",
      "Permuted TV original model: 2475.040771484375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 42, Validation Loss: 1.8078, Validation Accuracy: 75.62%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 43\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2659.673828125\n",
      "Permuted TV original model: 2522.8994140625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 43, Validation Loss: 1.8071, Validation Accuracy: 76.39%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 44\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2677.5615234375\n",
      "Permuted TV original model: 2562.8798828125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 44, Validation Loss: 1.8073, Validation Accuracy: 76.00%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 45\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2734.6728515625\n",
      "Permuted TV original model: 2607.2275390625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 45, Validation Loss: 1.8082, Validation Accuracy: 75.27%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 46\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2791.98828125\n",
      "Permuted TV original model: 2650.594482421875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 46, Validation Loss: 1.8082, Validation Accuracy: 75.08%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 47\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2828.686767578125\n",
      "Permuted TV original model: 2695.44970703125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 47, Validation Loss: 1.8074, Validation Accuracy: 75.84%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 48\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2872.621337890625\n",
      "Permuted TV original model: 2742.288818359375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 48, Validation Loss: 1.8080, Validation Accuracy: 75.47%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 49\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2919.615966796875\n",
      "Permuted TV original model: 2780.222900390625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 76.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 49, Validation Loss: 1.8083, Validation Accuracy: 74.92%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 50\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 2960.925048828125\n",
      "Permuted TV original model: 2828.312744140625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 50, Validation Loss: 1.8088, Validation Accuracy: 74.82%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 51\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3007.867919921875\n",
      "Permuted TV original model: 2867.823486328125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 51, Validation Loss: 1.8086, Validation Accuracy: 75.17%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 52\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3068.173583984375\n",
      "Permuted TV original model: 2921.28271484375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 52, Validation Loss: 1.8077, Validation Accuracy: 75.49%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 53\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3107.63525390625\n",
      "Permuted TV original model: 2962.232177734375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 53, Validation Loss: 1.8074, Validation Accuracy: 75.83%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 54\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3179.9267578125\n",
      "Permuted TV original model: 3022.8017578125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 78.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 54, Validation Loss: 1.8080, Validation Accuracy: 75.18%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 55\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3212.3740234375\n",
      "Permuted TV original model: 3054.6171875\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 77.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 55, Validation Loss: 1.8076, Validation Accuracy: 75.66%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 56\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3257.77978515625\n",
      "Permuted TV original model: 3102.453125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 72.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 56, Validation Loss: 1.8072, Validation Accuracy: 75.83%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 57\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3311.8720703125\n",
      "Permuted TV original model: 3148.69287109375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 57, Validation Loss: 1.8090, Validation Accuracy: 74.60%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 58\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3310.046630859375\n",
      "Permuted TV original model: 3168.138427734375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 75.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 58, Validation Loss: 1.8078, Validation Accuracy: 75.63%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 59\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3377.140625\n",
      "Permuted TV original model: 3219.27587890625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 73.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 59, Validation Loss: 1.8077, Validation Accuracy: 75.87%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 60\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3438.029052734375\n",
      "Permuted TV original model: 3277.72021484375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 63.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 60, Validation Loss: 1.8076, Validation Accuracy: 75.66%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 61\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3467.827880859375\n",
      "Permuted TV original model: 3307.69775390625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 61, Validation Loss: 1.8084, Validation Accuracy: 75.10%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 62\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3520.3671875\n",
      "Permuted TV original model: 3353.304443359375\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 62, Validation Loss: 1.8082, Validation Accuracy: 75.43%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 63\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 3568.601806640625\n",
      "Permuted TV original model: 3399.37353515625\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 63, Validation Loss: 1.8082, Validation Accuracy: 75.10%\n",
      "\n",
      "\n",
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n",
      "Smooth the parameters of the model\n",
      "Old TV original model: 1321.4044189453125\n",
      "Permuted TV original model: 1039.372314453125\n",
      "Applying EMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using model {'type': 'ResNet20', 'pretrained_path': 'toy/checkpoint/cifar10_ResNet20_smooth_Ours.pth', 'smooth': True}: hidden_dim 64, Validation Loss: 1.8076, Validation Accuracy: 75.73%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in range(16, 65):\n",
    "    # Create a model for this given dimension\n",
    "    model = create_model(args.model.type,\n",
    "                         hidden_dim=hidden_dim,\n",
    "                         path=args.model.pretrained_path,\n",
    "                         smooth=args.model.smooth).to(device)\n",
    "    \n",
    "    # If EMA is specified, apply it\n",
    "    if ema:\n",
    "        print('Applying EMA')\n",
    "        ema.apply()\n",
    "\n",
    "    # Sample the merged model\n",
    "    accumulated_model = sample_merge_model(hyper_model_test, model, args, K=100)\n",
    "\n",
    "    # Validate the merged model\n",
    "    val_loss, acc = validate_single(accumulated_model, val_loader, val_criterion, args=args)\n",
    "\n",
    "    # If EMA is specified, restore the original weights after applying EMA\n",
    "    if ema:\n",
    "        ema.restore()  # Restore the original weights after applying \n",
    "        \n",
    "    # Save the model\n",
    "    save_name = os.path.join(args.training.save_model_path, f\"cifar10_{accumulated_model.__class__.__name__}_dim{hidden_dim}_single.pth\")\n",
    "    torch.save(accumulated_model.state_dict(),save_name)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Test using model {args.model}: hidden_dim {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Define the directory and filename structure\n",
    "    filename = f\"cifar10_results_{args.experiment.name}.txt\"\n",
    "    filepath = os.path.join(args.training.save_model_path, filename)\n",
    "\n",
    "    # Write the results. 'a' is used to append the results; a new file will be created if it doesn't exist.\n",
    "    with open(filepath, \"a\") as file:\n",
    "        file.write(f\"Hidden_dim: {hidden_dim}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc*100:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
