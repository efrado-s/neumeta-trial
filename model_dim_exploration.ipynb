{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0b342f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ddfdad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c45bd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neumeta.models import create_model_cifar10, create_densenet_model, create_mnist_model, fuse_module\n",
    "from neumeta.utils import AverageMeter\n",
    "\n",
    "from smooth.permute import PermutationManager, compute_tv_loss_for_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cb79a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ca8561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, args=None, device='cpu'):\n",
    "    # Set the model to training mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize AverageMeter objects to track the losses\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over the training data\n",
    "        for x, target in tqdm(val_loader):\n",
    "            # Preprocess input\n",
    "            x, target = x.to(device), target.to(device)\n",
    "            predict = model(x)\n",
    "            \n",
    "            loss = criterion(predict, target) \n",
    "            \n",
    "            # Measure accuracy and record loss\n",
    "            prec1 = accuracy(predict.data, target, topk=(1,))[0].item()\n",
    "            losses.update(loss.item(), x.size(0))\n",
    "            top1.update(prec1, x.size(0))\n",
    "\n",
    "    return losses.avg, top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95bcd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43a2fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[x/255.0 for x in [125.3, 123.0, 113.9]], \n",
    "    std=[x/255.0 for x in [63.0, 62.1, 66.7]]\n",
    "    )\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d06a3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transforms_train, download=True)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7908318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2de7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49900c75",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2217347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace the last 2 block of layer3 with new block with hidden dim 64\n",
      "Loading pretrained weights for resnet20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): Identity()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "    (2): BasicBlock_Resize(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet20 = create_model_cifar10('ResNet20', 64)\n",
    "resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2a0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([16, 3, 3, 3])\n",
      "conv1.bias torch.Size([16])\n",
      "layer1.0.conv1.weight torch.Size([16, 16, 3, 3])\n",
      "layer1.0.conv1.bias torch.Size([16])\n",
      "layer1.0.conv2.weight torch.Size([16, 16, 3, 3])\n",
      "layer1.0.conv2.bias torch.Size([16])\n",
      "layer1.1.conv1.weight torch.Size([16, 16, 3, 3])\n",
      "layer1.1.conv1.bias torch.Size([16])\n",
      "layer1.1.conv2.weight torch.Size([16, 16, 3, 3])\n",
      "layer1.1.conv2.bias torch.Size([16])\n",
      "layer1.2.conv1.weight torch.Size([16, 16, 3, 3])\n",
      "layer1.2.conv1.bias torch.Size([16])\n",
      "layer1.2.conv2.weight torch.Size([16, 16, 3, 3])\n",
      "layer1.2.conv2.bias torch.Size([16])\n",
      "layer2.0.conv1.weight torch.Size([32, 16, 3, 3])\n",
      "layer2.0.conv1.bias torch.Size([32])\n",
      "layer2.0.conv2.weight torch.Size([32, 32, 3, 3])\n",
      "layer2.0.conv2.bias torch.Size([32])\n",
      "layer2.0.downsample.0.weight torch.Size([32, 16, 1, 1])\n",
      "layer2.0.downsample.0.bias torch.Size([32])\n",
      "layer2.1.conv1.weight torch.Size([32, 32, 3, 3])\n",
      "layer2.1.conv1.bias torch.Size([32])\n",
      "layer2.1.conv2.weight torch.Size([32, 32, 3, 3])\n",
      "layer2.1.conv2.bias torch.Size([32])\n",
      "layer2.2.conv1.weight torch.Size([32, 32, 3, 3])\n",
      "layer2.2.conv1.bias torch.Size([32])\n",
      "layer2.2.conv2.weight torch.Size([32, 32, 3, 3])\n",
      "layer2.2.conv2.bias torch.Size([32])\n",
      "layer3.0.conv1.weight torch.Size([64, 32, 3, 3])\n",
      "layer3.0.conv1.bias torch.Size([64])\n",
      "layer3.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.0.conv2.bias torch.Size([64])\n",
      "layer3.0.downsample.0.weight torch.Size([64, 32, 1, 1])\n",
      "layer3.0.downsample.0.bias torch.Size([64])\n",
      "layer3.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.1.conv1.bias torch.Size([64])\n",
      "layer3.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.1.conv2.bias torch.Size([64])\n",
      "layer3.2.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv1.bias torch.Size([64])\n",
      "layer3.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv2.bias torch.Size([64])\n",
      "fc.weight torch.Size([10, 64])\n",
      "fc.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k, w in resnet20.named_parameters():\n",
    "    print(k, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94758358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3.2.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv1.bias torch.Size([64])\n",
      "layer3.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer3.2.conv2.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for k in resnet20.learnable_parameter:\n",
    "    print(k, resnet20.learnable_parameter[k].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd3ccba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271690"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in resnet20.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0bde3",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9274874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistNet(\n",
       "  (conv_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
       "  (conv_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=replicate)\n",
       "  (conv_3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=replicate)\n",
       "  (f_1): ReLU()\n",
       "  (f_2): ReLU()\n",
       "  (f_3): ReLU()\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (linear): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet = create_mnist_model('LeNet', 32)\n",
    "LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70261a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1.weight torch.Size([32, 1, 3, 3])\n",
      "conv_1.bias torch.Size([32])\n",
      "conv_2.weight torch.Size([64, 32, 5, 5])\n",
      "conv_2.bias torch.Size([64])\n",
      "conv_3.weight torch.Size([128, 64, 5, 5])\n",
      "conv_3.bias torch.Size([128])\n",
      "linear.weight torch.Size([10, 128])\n",
      "linear.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k, w in LeNet.named_parameters():\n",
    "    print(k, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bca71c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1.weight torch.Size([32, 1, 3, 3])\n",
      "conv_1.bias torch.Size([32])\n",
      "conv_2.weight torch.Size([64, 32, 5, 5])\n",
      "conv_2.bias torch.Size([64])\n",
      "conv_3.weight torch.Size([128, 64, 5, 5])\n",
      "conv_3.bias torch.Size([128])\n",
      "linear.weight torch.Size([10, 128])\n",
      "linear.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k in LeNet.learnable_parameter:\n",
    "    print(k, LeNet.learnable_parameter[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa3a9d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1.weight tensor([[[[-0.0735, -0.0388, -0.1106],\n",
      "          [ 0.3012,  0.1019, -0.3244],\n",
      "          [ 0.1546, -0.0032, -0.1900]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2336, -0.0763, -0.0320],\n",
      "          [-0.3323, -0.1091,  0.2338],\n",
      "          [-0.3218,  0.2272, -0.2021]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319, -0.1555,  0.3279],\n",
      "          [ 0.2069, -0.1175, -0.1551],\n",
      "          [ 0.2684, -0.2731,  0.0276]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2689,  0.2858, -0.0018],\n",
      "          [ 0.1553,  0.0697,  0.1824],\n",
      "          [-0.3107, -0.1283, -0.2914]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2154,  0.2647, -0.1805],\n",
      "          [ 0.0115, -0.1471, -0.0709],\n",
      "          [-0.1938, -0.0823, -0.2273]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0874,  0.2806, -0.2308],\n",
      "          [-0.0901,  0.2634,  0.0506],\n",
      "          [ 0.1742, -0.1050, -0.2218]]],\n",
      "\n",
      "\n",
      "        [[[-0.0009, -0.1704, -0.2909],\n",
      "          [ 0.1640,  0.1381,  0.0827],\n",
      "          [-0.2975, -0.1517, -0.1731]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0685,  0.3230, -0.1109],\n",
      "          [-0.2757, -0.3110, -0.0805],\n",
      "          [ 0.0835,  0.2018, -0.1628]]],\n",
      "\n",
      "\n",
      "        [[[-0.2939,  0.0991,  0.0311],\n",
      "          [ 0.2170,  0.2707,  0.2661],\n",
      "          [-0.1418, -0.3086,  0.2086]]],\n",
      "\n",
      "\n",
      "        [[[-0.2924,  0.0854,  0.0381],\n",
      "          [ 0.2736,  0.1678, -0.3249],\n",
      "          [ 0.2503, -0.2405,  0.0881]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3113, -0.2113,  0.2951],\n",
      "          [ 0.2973, -0.3290,  0.1516],\n",
      "          [ 0.0698,  0.2557,  0.0820]]],\n",
      "\n",
      "\n",
      "        [[[-0.2465, -0.2281, -0.0950],\n",
      "          [ 0.0365, -0.2927,  0.0496],\n",
      "          [-0.1094,  0.1656, -0.1343]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1333,  0.1580,  0.0673],\n",
      "          [-0.2828,  0.1895,  0.3035],\n",
      "          [-0.3125,  0.1397,  0.2174]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1208, -0.1010,  0.1505],\n",
      "          [-0.2526,  0.0184, -0.2970],\n",
      "          [ 0.1026, -0.0937,  0.3008]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1604, -0.2055,  0.1525],\n",
      "          [-0.1622,  0.1265, -0.0903],\n",
      "          [ 0.2427,  0.2814, -0.1646]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2366,  0.0017,  0.2226],\n",
      "          [-0.1448,  0.1940,  0.2612],\n",
      "          [-0.3151,  0.0696, -0.0015]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0731,  0.3190,  0.2116],\n",
      "          [-0.2770,  0.2707,  0.2574],\n",
      "          [ 0.2449,  0.0903, -0.0699]]],\n",
      "\n",
      "\n",
      "        [[[-0.1448,  0.1735,  0.1266],\n",
      "          [-0.0797,  0.0967,  0.2772],\n",
      "          [ 0.2132, -0.0404, -0.3245]]],\n",
      "\n",
      "\n",
      "        [[[-0.2404, -0.2006,  0.2105],\n",
      "          [ 0.1882,  0.1584, -0.0160],\n",
      "          [-0.1655,  0.1908,  0.0078]]],\n",
      "\n",
      "\n",
      "        [[[-0.2150, -0.2809, -0.0654],\n",
      "          [ 0.0923, -0.1508,  0.0512],\n",
      "          [ 0.1798, -0.0629,  0.0098]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1060,  0.2869, -0.1496],\n",
      "          [-0.0843, -0.1214, -0.2008],\n",
      "          [-0.1493,  0.0323, -0.1604]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1235,  0.1945, -0.0540],\n",
      "          [ 0.1494, -0.2288,  0.2668],\n",
      "          [ 0.2820,  0.1314,  0.1295]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2331, -0.0477, -0.1876],\n",
      "          [-0.2628,  0.3295,  0.2130],\n",
      "          [ 0.3291, -0.0447, -0.2914]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2717, -0.0122,  0.1673],\n",
      "          [-0.0599,  0.1758,  0.0722],\n",
      "          [ 0.2058, -0.0069,  0.3312]]],\n",
      "\n",
      "\n",
      "        [[[-0.1673, -0.1129, -0.0317],\n",
      "          [ 0.2378,  0.2608,  0.2835],\n",
      "          [-0.2194,  0.1383, -0.0932]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2464, -0.1948,  0.1815],\n",
      "          [-0.2796,  0.0333, -0.0741],\n",
      "          [-0.3241,  0.2596, -0.0389]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3271,  0.2774,  0.1645],\n",
      "          [ 0.1420, -0.1178, -0.0329],\n",
      "          [ 0.0818,  0.3299, -0.2527]]],\n",
      "\n",
      "\n",
      "        [[[-0.1529, -0.1711, -0.2262],\n",
      "          [-0.0617, -0.3106, -0.1327],\n",
      "          [ 0.1281, -0.3317, -0.2960]]],\n",
      "\n",
      "\n",
      "        [[[-0.1109,  0.0132,  0.3329],\n",
      "          [-0.1968,  0.1831,  0.1321],\n",
      "          [-0.1674, -0.0092, -0.1478]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2953,  0.0436, -0.3274],\n",
      "          [ 0.2027, -0.0792, -0.2784],\n",
      "          [ 0.2516, -0.2822,  0.0221]]],\n",
      "\n",
      "\n",
      "        [[[-0.0234, -0.0631,  0.1767],\n",
      "          [-0.0166, -0.3143, -0.3239],\n",
      "          [-0.1402, -0.1622, -0.0218]]],\n",
      "\n",
      "\n",
      "        [[[-0.1198,  0.2909, -0.1689],\n",
      "          [ 0.0046, -0.0908,  0.1700],\n",
      "          [-0.0061, -0.2509, -0.0668]]]])\n",
      "conv_1.bias tensor([ 0.0547,  0.0900, -0.3164,  0.1244, -0.2676, -0.1135,  0.2648, -0.2546,\n",
      "         0.2744,  0.0540, -0.1699, -0.0649, -0.2462, -0.0713, -0.1481,  0.1876,\n",
      "        -0.1025, -0.2101,  0.0299, -0.1253, -0.0051, -0.3228, -0.2730,  0.2575,\n",
      "         0.0775, -0.2379,  0.0097,  0.1505,  0.0727,  0.0746, -0.3066, -0.3168])\n",
      "conv_2.weight tensor([[[[-9.0873e-03,  1.0742e-02,  4.1444e-03, -2.9515e-02,  2.4185e-02],\n",
      "          [-2.5668e-02, -6.4145e-04, -1.2523e-02, -2.0390e-02, -7.2943e-03],\n",
      "          [ 1.0739e-02, -6.2204e-03, -1.7846e-02, -3.3073e-03,  1.9494e-02],\n",
      "          [-2.0129e-02, -1.8351e-02, -2.4279e-02, -1.8367e-03, -1.0050e-02],\n",
      "          [-3.1452e-02,  1.5935e-02, -2.2757e-02, -2.9586e-02,  1.8978e-02]],\n",
      "\n",
      "         [[-1.3132e-02,  7.8536e-03, -1.3404e-02,  1.7420e-02, -2.0751e-02],\n",
      "          [ 9.5728e-03,  2.3020e-03, -2.9967e-02, -2.5724e-02, -2.7006e-02],\n",
      "          [ 5.3485e-04, -3.4657e-02, -6.0760e-03,  5.7659e-04, -2.1515e-02],\n",
      "          [ 2.5108e-02, -1.1943e-02,  9.4843e-03,  1.8638e-02, -3.1969e-02],\n",
      "          [ 2.0212e-02,  2.7801e-02, -2.7470e-02,  1.9531e-02, -2.8128e-02]],\n",
      "\n",
      "         [[ 5.1202e-03, -5.2328e-03,  1.6521e-02,  3.3899e-02,  2.2400e-02],\n",
      "          [-1.1444e-02, -3.4717e-02,  3.1973e-03, -3.1782e-02,  2.0686e-02],\n",
      "          [-1.7020e-03, -2.9585e-02,  3.3670e-03,  7.9636e-03, -9.1406e-03],\n",
      "          [ 3.3733e-02, -1.5070e-02,  1.4618e-02, -7.8866e-03, -2.5352e-02],\n",
      "          [-1.2560e-02, -3.5198e-02,  1.0428e-02, -1.0931e-02, -2.4983e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1200e-02,  6.7785e-03, -8.3518e-03,  8.6251e-03, -2.1633e-02],\n",
      "          [-1.7322e-02,  1.0658e-02, -2.0871e-02,  2.1993e-02,  3.3160e-03],\n",
      "          [ 9.7522e-03, -1.9846e-02,  4.6816e-03, -2.2437e-02,  2.1650e-02],\n",
      "          [-2.9825e-02, -3.7792e-03, -2.0124e-02,  2.2179e-02, -1.2303e-02],\n",
      "          [-3.4981e-03,  4.3356e-03,  5.7825e-03, -1.5316e-02, -1.5334e-02]],\n",
      "\n",
      "         [[ 1.7427e-02,  1.3172e-02,  2.3869e-02, -6.3550e-03,  1.6938e-02],\n",
      "          [-1.0839e-02, -1.5621e-02,  7.3463e-05, -2.6227e-02, -3.4771e-02],\n",
      "          [ 1.1414e-02, -2.9293e-03, -1.9530e-02,  9.6581e-03,  1.1218e-02],\n",
      "          [ 7.0193e-03, -2.0783e-02,  2.3901e-02,  1.7052e-02,  5.8055e-03],\n",
      "          [-1.2717e-02,  3.2136e-02, -7.2275e-03, -2.3934e-02, -4.3698e-06]],\n",
      "\n",
      "         [[ 2.6363e-02,  2.4248e-03, -8.7705e-03, -3.1640e-02, -3.0170e-02],\n",
      "          [ 9.7522e-03,  2.5264e-02, -3.3805e-02, -1.5952e-02,  2.0930e-02],\n",
      "          [ 2.3561e-02,  1.1802e-02,  1.8528e-03,  3.4991e-02, -3.3731e-02],\n",
      "          [-2.0165e-02, -3.4282e-02, -1.1857e-02,  3.0323e-02, -2.7977e-02],\n",
      "          [ 3.3431e-02, -7.3236e-03, -1.4509e-02,  1.1335e-02,  1.0139e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7404e-03,  1.0598e-02,  2.8773e-03,  1.8168e-02, -3.0806e-02],\n",
      "          [ 2.7616e-02, -1.4541e-02,  2.3792e-02,  2.1189e-02,  1.6447e-02],\n",
      "          [ 1.7754e-03, -5.2779e-03,  1.1108e-02,  2.7717e-02,  2.1425e-02],\n",
      "          [ 1.4335e-02,  2.0417e-02,  7.5776e-03,  7.2105e-03, -2.5870e-02],\n",
      "          [-1.3676e-02, -3.2222e-02, -2.3194e-02,  3.5298e-02,  2.6411e-02]],\n",
      "\n",
      "         [[ 8.6615e-04,  1.6485e-03,  1.9711e-02, -8.8083e-03, -3.5293e-02],\n",
      "          [ 2.2396e-03, -2.7799e-02,  6.7601e-03,  1.8081e-02,  2.1319e-02],\n",
      "          [-2.5943e-02,  7.5294e-03, -2.9003e-02, -1.7942e-03, -4.4643e-03],\n",
      "          [-3.1951e-02, -2.3090e-02,  1.2328e-02,  7.3076e-03,  1.0680e-02],\n",
      "          [ 2.5631e-02, -3.4316e-02,  2.4541e-02,  2.9340e-02, -3.2293e-02]],\n",
      "\n",
      "         [[-1.6783e-02,  2.6515e-02, -1.8225e-02, -3.2029e-02, -2.9396e-02],\n",
      "          [ 1.2193e-02,  2.2964e-02,  1.7159e-02, -1.5827e-02,  1.9466e-02],\n",
      "          [-9.1341e-03, -1.2113e-02, -7.4463e-03,  1.9963e-02,  3.5022e-02],\n",
      "          [-1.1182e-02, -1.8116e-02, -3.2789e-03,  1.9421e-02,  9.5156e-03],\n",
      "          [-8.1740e-03,  2.7332e-02, -2.1620e-03,  3.3394e-02,  2.8962e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7524e-03,  1.7312e-02,  1.7151e-02, -2.0236e-02, -1.1296e-02],\n",
      "          [-1.7809e-02, -3.3481e-02, -1.8188e-02,  2.4220e-02, -3.2231e-03],\n",
      "          [ 5.0553e-03, -1.5304e-02, -1.3457e-02,  2.6898e-02, -4.4821e-03],\n",
      "          [ 7.6381e-03,  2.1650e-02,  2.5119e-02,  6.1798e-03, -3.0949e-02],\n",
      "          [-2.8051e-02, -1.4019e-02, -2.9598e-02, -3.8462e-03,  3.3147e-02]],\n",
      "\n",
      "         [[ 3.0664e-02,  1.8946e-02, -2.9328e-02, -1.5162e-02,  2.6516e-02],\n",
      "          [ 6.0420e-04,  3.0401e-02, -3.4724e-02, -1.5824e-03, -3.3808e-02],\n",
      "          [ 1.3700e-02, -1.5961e-02, -2.8559e-03,  2.2679e-02, -1.5438e-02],\n",
      "          [ 8.4879e-03,  2.1278e-02,  2.7527e-02, -2.6013e-03,  8.3862e-03],\n",
      "          [ 2.4199e-02, -8.5219e-03, -3.6947e-04,  1.1494e-02,  1.3900e-02]],\n",
      "\n",
      "         [[ 3.5090e-02, -1.8785e-02,  1.5012e-02,  1.0059e-02, -1.1775e-02],\n",
      "          [ 2.3786e-02, -2.6110e-02,  9.2561e-03,  2.4373e-02,  3.2756e-02],\n",
      "          [-1.7792e-02,  1.8095e-02,  4.2884e-03,  2.6021e-02,  5.0009e-04],\n",
      "          [ 2.2365e-02, -1.6864e-02, -3.4412e-02,  3.3574e-02,  3.3396e-02],\n",
      "          [-3.0211e-04, -2.5390e-02,  2.1176e-02,  2.2922e-02, -2.0452e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0746e-03, -3.3894e-02, -1.2465e-02,  5.4600e-03, -1.9671e-02],\n",
      "          [-1.6484e-02, -5.5594e-03, -2.0224e-02,  3.3301e-02,  4.1426e-04],\n",
      "          [-3.1202e-02,  1.8499e-02, -5.7822e-03, -6.2108e-03,  5.3428e-03],\n",
      "          [-2.2078e-02,  1.4352e-02, -1.2211e-02, -9.8983e-03,  2.0324e-02],\n",
      "          [ 6.4744e-03,  3.4508e-02, -1.8446e-03,  6.0531e-03, -1.0621e-02]],\n",
      "\n",
      "         [[ 1.8901e-02, -2.2228e-02,  2.9646e-02,  8.9264e-03,  2.8574e-02],\n",
      "          [-3.2773e-02, -1.4514e-02, -7.9609e-03,  2.6702e-02, -7.0330e-03],\n",
      "          [-6.7350e-03, -1.0715e-02,  1.8395e-02, -1.0807e-02,  2.0106e-02],\n",
      "          [ 7.3340e-03, -2.8948e-02,  3.0249e-02, -2.4589e-03, -3.0800e-02],\n",
      "          [ 5.1729e-03, -3.2365e-02, -1.1409e-02,  4.3466e-03, -2.6698e-02]],\n",
      "\n",
      "         [[-8.9006e-03,  2.6114e-02, -3.3497e-02, -5.3844e-04,  3.4248e-02],\n",
      "          [-1.2521e-02,  1.5164e-02,  3.1675e-03, -3.8899e-03, -4.6120e-03],\n",
      "          [ 1.5835e-02,  4.5486e-05, -5.9966e-03,  4.9380e-03, -5.5872e-03],\n",
      "          [ 2.2515e-02, -2.2232e-02, -1.3344e-02, -2.3442e-02,  3.1624e-02],\n",
      "          [ 9.0688e-03, -6.3913e-03,  1.1091e-02,  3.5214e-03, -1.0929e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0610e-03,  1.2906e-02, -2.9211e-03, -2.2365e-02,  1.6361e-02],\n",
      "          [-2.7261e-02,  4.2448e-03,  3.3443e-02, -1.6120e-02, -1.3866e-02],\n",
      "          [-7.0141e-03,  2.1126e-02,  3.0079e-02, -2.5080e-02,  9.0496e-04],\n",
      "          [ 3.4773e-02,  2.1745e-02, -2.3511e-02, -6.8417e-03,  1.7510e-02],\n",
      "          [-2.2095e-02, -2.8035e-02, -1.1235e-02,  1.5759e-02, -9.6978e-03]],\n",
      "\n",
      "         [[ 1.8299e-02, -1.1393e-02, -4.2839e-03, -1.2066e-02,  3.2864e-02],\n",
      "          [ 3.4658e-02,  3.2055e-02,  1.9011e-02, -2.2375e-02,  1.8590e-02],\n",
      "          [ 2.5121e-02,  1.5411e-02, -1.6780e-02,  3.4975e-02, -2.4917e-02],\n",
      "          [-1.1430e-02, -1.5897e-02, -1.4706e-02, -5.5668e-03,  1.2677e-02],\n",
      "          [ 3.2681e-02,  3.4208e-02, -2.1348e-02,  6.2303e-03, -3.0364e-02]],\n",
      "\n",
      "         [[-2.0282e-02,  1.0489e-03, -3.8961e-03, -2.2220e-03,  2.8814e-03],\n",
      "          [ 6.8309e-04,  2.9020e-02, -3.3992e-02,  2.7583e-02,  1.2623e-03],\n",
      "          [ 3.0638e-02,  2.1505e-02, -2.0675e-03, -9.2430e-03,  3.0728e-03],\n",
      "          [-4.2809e-03, -1.1758e-02,  1.8454e-02,  2.2368e-02, -2.2491e-02],\n",
      "          [ 1.3122e-03, -1.1961e-02,  9.6511e-03, -3.2134e-02,  2.6238e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.2596e-02,  1.5621e-02,  1.2100e-02,  1.8504e-02,  4.1598e-03],\n",
      "          [ 5.2270e-03, -3.4879e-02,  6.1198e-03,  2.1184e-02,  6.4773e-03],\n",
      "          [ 8.3122e-03,  1.4153e-02,  2.4719e-02,  3.1679e-02, -1.2060e-02],\n",
      "          [ 2.2824e-02, -7.9516e-03, -2.7316e-02, -5.1973e-03,  6.7030e-04],\n",
      "          [ 1.8943e-02,  2.7235e-02,  1.7380e-02,  2.8390e-02,  3.4712e-02]],\n",
      "\n",
      "         [[ 1.9316e-02,  8.1890e-04, -1.8973e-02,  1.5745e-02, -2.7375e-02],\n",
      "          [ 1.5197e-02, -3.1145e-02,  5.5585e-03,  3.0459e-02, -3.4040e-02],\n",
      "          [ 5.9120e-04, -2.9996e-02, -3.0526e-03, -1.2227e-02, -2.7963e-02],\n",
      "          [ 2.1265e-02, -2.2508e-02,  3.3039e-02, -3.4109e-02,  1.2406e-02],\n",
      "          [ 2.4240e-02,  2.5621e-02,  5.1715e-03, -2.2536e-02,  2.9689e-04]],\n",
      "\n",
      "         [[ 2.8901e-02,  1.4368e-02, -5.3520e-03, -1.2280e-02, -1.9326e-02],\n",
      "          [ 3.4082e-02,  2.1446e-02,  1.6069e-02, -2.8384e-02, -9.7642e-03],\n",
      "          [-1.9834e-02, -1.4825e-02,  1.5504e-02, -1.0907e-03,  2.1832e-02],\n",
      "          [ 2.8955e-02,  1.7792e-02,  7.7905e-04,  2.6855e-02, -8.8137e-03],\n",
      "          [-2.6620e-02, -3.2590e-02, -2.6078e-02, -5.6010e-03, -8.2557e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-02, -8.2196e-03, -1.9083e-02, -1.2364e-02,  1.4559e-02],\n",
      "          [ 7.9262e-03, -2.8264e-02,  2.7225e-02, -2.9674e-02, -2.4741e-02],\n",
      "          [ 2.2587e-02, -8.8997e-03, -2.0692e-02,  4.1986e-03,  5.0582e-03],\n",
      "          [ 2.5502e-02,  1.1272e-03,  1.4627e-02, -1.7818e-02, -1.0483e-02],\n",
      "          [ 2.7696e-02, -2.7285e-02,  1.9068e-02,  3.0459e-02,  1.3001e-02]],\n",
      "\n",
      "         [[ 3.4716e-03, -2.6877e-02,  3.2790e-03,  2.2540e-02, -2.7916e-02],\n",
      "          [-3.3651e-02,  3.0344e-02,  3.3834e-02,  3.1139e-02, -1.9609e-02],\n",
      "          [-3.4866e-02,  2.3640e-02,  1.6120e-02, -1.6429e-02,  5.5629e-03],\n",
      "          [ 1.1583e-02, -3.0059e-03, -2.0254e-03,  5.2899e-03,  1.0113e-02],\n",
      "          [-1.1235e-02, -2.7617e-02,  1.4559e-02, -1.6778e-02, -3.3915e-02]],\n",
      "\n",
      "         [[ 1.3468e-02,  1.6263e-02, -3.3904e-02, -7.4599e-05,  8.1430e-03],\n",
      "          [-1.2779e-02,  2.4170e-02, -2.7390e-02,  1.8784e-02, -1.3067e-02],\n",
      "          [-2.8724e-02, -1.1671e-02, -1.0006e-02, -3.6981e-04, -1.4113e-02],\n",
      "          [ 2.4274e-02,  3.3958e-02,  3.3670e-02,  3.4316e-02, -2.9779e-02],\n",
      "          [ 1.3327e-02,  3.3265e-02, -2.9737e-03,  1.0598e-02, -7.2275e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.3979e-02,  1.9157e-02,  1.2279e-02, -3.3222e-02,  1.1075e-02],\n",
      "          [ 2.8569e-02,  1.2837e-02,  8.1651e-03,  1.3311e-02, -2.0654e-02],\n",
      "          [ 1.7282e-02,  6.4352e-03, -1.9615e-02,  1.2893e-02, -1.8166e-02],\n",
      "          [ 2.3192e-02, -2.0394e-02, -2.4892e-02, -1.0543e-03, -1.9168e-03],\n",
      "          [ 1.6454e-02,  3.3458e-02, -1.0975e-03,  2.0866e-02, -3.1933e-02]],\n",
      "\n",
      "         [[ 2.4336e-02,  6.2589e-03, -2.8612e-02, -3.4153e-02, -2.9073e-02],\n",
      "          [ 2.7734e-02, -1.5614e-02,  2.4507e-02,  1.4088e-02, -1.3966e-02],\n",
      "          [ 4.7609e-03,  1.9032e-02,  1.2799e-02,  1.1226e-02,  1.7379e-02],\n",
      "          [-3.5189e-02, -7.9941e-03,  3.2376e-02, -2.6618e-02,  9.1187e-03],\n",
      "          [ 1.1807e-02, -1.1270e-02, -3.2424e-03, -1.4358e-02,  6.1967e-03]],\n",
      "\n",
      "         [[ 6.6508e-03,  2.4845e-02, -2.8422e-02,  2.1965e-02, -1.8542e-02],\n",
      "          [ 3.3054e-02, -1.5202e-02, -6.1546e-03, -1.1576e-03, -3.3257e-02],\n",
      "          [ 3.6123e-03,  2.4845e-02,  6.0623e-03,  1.0245e-02,  4.6544e-03],\n",
      "          [-3.6792e-03,  2.9776e-02,  3.4527e-02, -2.9715e-02,  2.8508e-02],\n",
      "          [ 5.8811e-05, -3.2354e-02, -3.3888e-02,  9.0355e-03, -8.1144e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9800e-02,  2.0804e-02,  1.8087e-02, -2.7786e-02,  1.1855e-02],\n",
      "          [ 2.9161e-02, -1.3458e-02, -1.0235e-02,  2.4149e-02, -3.4048e-02],\n",
      "          [ 1.3495e-02,  3.0293e-02,  2.4638e-02,  2.4363e-02,  1.4271e-02],\n",
      "          [-4.5754e-03, -3.2337e-02,  3.2594e-04,  1.9106e-02, -3.1028e-02],\n",
      "          [ 2.1134e-03,  1.5819e-02,  2.4778e-03, -7.4727e-03, -2.8161e-02]],\n",
      "\n",
      "         [[ 6.5026e-03, -1.6032e-02, -1.5946e-02,  5.6625e-03, -1.7138e-02],\n",
      "          [ 2.5186e-02, -2.5819e-02,  1.2467e-03, -1.6444e-02,  1.6974e-02],\n",
      "          [ 2.7187e-02,  2.6526e-02,  3.3663e-02, -1.2290e-02,  6.4063e-03],\n",
      "          [-2.9175e-02,  7.4989e-03, -6.3351e-03,  1.0800e-02,  1.0065e-02],\n",
      "          [-1.3499e-02,  2.7954e-03, -3.2531e-02, -1.1363e-02,  1.8377e-02]],\n",
      "\n",
      "         [[ 1.4163e-02, -2.7805e-02,  2.5025e-02, -1.8249e-02,  1.1618e-02],\n",
      "          [ 2.5864e-02,  2.0983e-02,  1.6586e-02, -2.3538e-02, -7.5989e-03],\n",
      "          [ 1.8395e-02, -6.5092e-03,  3.3620e-02, -2.5111e-02, -1.3478e-02],\n",
      "          [ 2.4352e-03,  1.7109e-03, -2.2525e-03, -3.1236e-03, -3.0548e-02],\n",
      "          [ 2.8170e-02, -1.8644e-02,  2.2470e-02,  7.2914e-03,  1.1357e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8831e-03, -2.5301e-02,  2.2234e-02,  2.6222e-02,  3.4846e-02],\n",
      "          [ 2.8971e-02,  4.5716e-03,  6.7150e-03,  3.2711e-02,  1.9802e-02],\n",
      "          [ 3.4908e-02, -2.2781e-02, -1.7293e-02,  2.7291e-02, -2.9614e-02],\n",
      "          [ 3.1646e-02, -2.3506e-02,  2.6919e-02,  3.0040e-02, -1.2698e-03],\n",
      "          [-7.3507e-03,  1.7873e-02,  3.0080e-02,  1.9704e-02,  2.5554e-02]],\n",
      "\n",
      "         [[-1.0333e-02, -8.4418e-03, -1.4093e-02,  2.4948e-02,  5.6407e-04],\n",
      "          [-1.1262e-02, -2.1295e-02,  8.5547e-03,  3.0243e-02, -2.7015e-02],\n",
      "          [ 2.4149e-02, -3.4177e-02,  8.6927e-04, -2.4144e-02, -2.4342e-02],\n",
      "          [-3.2243e-02, -6.3983e-03, -4.1109e-03, -3.1102e-02,  8.0813e-03],\n",
      "          [ 2.5253e-03, -2.6684e-02, -2.4370e-02, -2.1477e-02,  1.6224e-02]],\n",
      "\n",
      "         [[-2.7591e-03, -3.5348e-02, -2.5060e-02, -1.1750e-02,  2.9282e-04],\n",
      "          [-1.9300e-02,  2.5683e-02, -2.9007e-03, -2.7906e-02,  9.1432e-03],\n",
      "          [ 3.1251e-02,  1.5153e-02, -2.8037e-03, -5.4777e-04, -3.1068e-02],\n",
      "          [ 4.6058e-03,  3.3977e-02, -2.8983e-02,  3.1661e-02, -9.1366e-03],\n",
      "          [ 1.4870e-02,  1.0647e-02, -1.5805e-02,  2.0857e-02, -2.6766e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1740e-02, -2.4403e-03,  1.7748e-02, -1.6704e-02, -1.4626e-02],\n",
      "          [-1.6029e-02, -1.4737e-02, -3.1257e-02, -2.5167e-02, -6.4641e-03],\n",
      "          [-7.8702e-03,  1.9361e-02, -5.7249e-03,  2.2604e-02,  7.0781e-03],\n",
      "          [-2.2443e-02, -1.1964e-02,  3.1087e-03,  1.2316e-03,  2.3708e-02],\n",
      "          [ 1.0161e-03,  3.3630e-02,  1.8853e-02,  2.5333e-04, -1.7477e-03]],\n",
      "\n",
      "         [[-2.9304e-03, -1.9375e-02, -3.7084e-03,  2.6400e-02, -2.1813e-02],\n",
      "          [ 2.5266e-02, -1.5304e-02, -3.0953e-02, -1.7973e-02,  2.9623e-02],\n",
      "          [-1.8877e-02, -1.9706e-02,  1.7717e-02,  2.7227e-02,  1.2133e-03],\n",
      "          [ 2.2912e-02, -2.4734e-02,  2.6775e-02,  1.8936e-02,  3.0545e-02],\n",
      "          [ 2.0572e-02, -2.3829e-02,  3.3992e-02, -1.9554e-02, -1.1977e-02]],\n",
      "\n",
      "         [[ 2.3044e-02,  4.1161e-03, -2.2146e-02,  1.8994e-02, -3.4934e-04],\n",
      "          [ 2.4842e-02, -6.7056e-03, -2.4794e-02, -1.5000e-02,  3.2946e-02],\n",
      "          [-2.6995e-02,  1.1770e-03,  2.3187e-02,  3.0647e-02, -1.1743e-02],\n",
      "          [ 2.4095e-02, -1.6741e-02,  3.1244e-02,  1.3191e-02, -6.7474e-03],\n",
      "          [ 1.0920e-02,  3.4541e-02, -2.5125e-02,  1.7750e-02,  1.0296e-02]]]])\n",
      "conv_2.bias tensor([ 0.0323,  0.0217,  0.0118,  0.0061,  0.0150, -0.0259,  0.0304,  0.0282,\n",
      "         0.0271,  0.0128,  0.0038, -0.0041,  0.0213, -0.0142, -0.0038,  0.0052,\n",
      "         0.0344,  0.0339, -0.0299, -0.0235, -0.0225,  0.0321, -0.0149,  0.0325,\n",
      "         0.0320, -0.0313,  0.0169,  0.0092,  0.0045, -0.0176, -0.0323, -0.0108,\n",
      "         0.0343, -0.0040, -0.0293, -0.0136,  0.0264, -0.0295, -0.0050, -0.0277,\n",
      "        -0.0034,  0.0087, -0.0263,  0.0019, -0.0240,  0.0276, -0.0343, -0.0276,\n",
      "         0.0037, -0.0057, -0.0100, -0.0297, -0.0200,  0.0296,  0.0096,  0.0085,\n",
      "         0.0178,  0.0057,  0.0153,  0.0152, -0.0195,  0.0113, -0.0256,  0.0217])\n",
      "conv_3.weight tensor([[[[-1.2383e-02, -9.7146e-03,  1.7585e-02, -2.1254e-02, -1.9729e-02],\n",
      "          [ 7.9811e-03,  6.3658e-05,  3.6957e-03, -3.5004e-03, -1.8870e-02],\n",
      "          [-1.1459e-02,  1.7584e-02,  2.0932e-02,  1.6092e-02, -2.4910e-02],\n",
      "          [-2.2988e-02,  1.3491e-02, -8.9891e-03, -1.7034e-02,  1.4874e-02],\n",
      "          [ 1.3338e-02,  5.2881e-03,  5.8235e-03, -7.9574e-03, -1.1327e-02]],\n",
      "\n",
      "         [[ 2.2331e-02, -1.7379e-02, -4.9888e-04,  7.0269e-03,  1.1848e-03],\n",
      "          [ 3.6215e-05,  2.3910e-02,  1.4036e-02,  4.3810e-03, -6.0937e-03],\n",
      "          [ 1.4373e-02,  1.8543e-02, -4.4884e-03, -2.3376e-02,  5.1092e-03],\n",
      "          [-3.8451e-03,  4.1198e-03, -7.2267e-05,  2.9000e-03, -2.0012e-03],\n",
      "          [-1.3664e-02, -2.4215e-02, -1.5527e-02,  1.5502e-02, -1.1552e-02]],\n",
      "\n",
      "         [[-4.9247e-03, -1.2119e-02, -9.5786e-03, -1.4539e-03,  2.4013e-02],\n",
      "          [-1.0605e-02, -1.5873e-02,  2.3016e-02,  1.4319e-02,  2.1500e-02],\n",
      "          [-3.1863e-03, -1.6794e-02,  2.0161e-02,  4.3062e-03, -9.0848e-03],\n",
      "          [ 1.3783e-02,  1.3625e-02, -9.5729e-03, -1.0411e-02,  2.2608e-02],\n",
      "          [-5.8872e-03,  1.2845e-02,  1.6050e-02, -3.4946e-03,  1.3105e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9391e-02, -1.2970e-02,  2.1325e-02,  2.0957e-03, -1.8877e-02],\n",
      "          [-2.1740e-02, -8.9881e-03, -1.8881e-02, -2.6198e-03,  1.1681e-02],\n",
      "          [-7.7737e-03, -2.1496e-02,  6.8085e-03, -1.4955e-02,  6.1528e-03],\n",
      "          [-1.5342e-02, -1.5493e-02, -2.4049e-02, -2.7980e-03, -1.0381e-02],\n",
      "          [-2.4270e-02,  1.0989e-02, -4.6307e-03, -1.7301e-02, -1.8011e-02]],\n",
      "\n",
      "         [[ 2.0640e-03, -1.7038e-02,  9.6889e-03,  2.4086e-02, -7.8998e-03],\n",
      "          [-7.0075e-03, -2.3191e-02, -2.3443e-02, -1.2007e-02,  2.3273e-02],\n",
      "          [ 3.8119e-03, -1.5896e-03,  3.0536e-03, -9.5730e-03, -1.5842e-02],\n",
      "          [ 4.5934e-03, -2.2281e-02, -1.8796e-02, -1.3632e-02,  4.1255e-03],\n",
      "          [ 6.6370e-03, -1.4828e-03,  1.3763e-02,  1.8916e-02, -2.2818e-02]],\n",
      "\n",
      "         [[-2.4771e-02,  1.1985e-02,  1.1091e-02, -5.8611e-03, -3.3233e-03],\n",
      "          [ 2.3652e-02,  2.4936e-03,  1.9255e-02,  7.8623e-03, -3.7347e-03],\n",
      "          [-1.9743e-02,  1.9734e-02,  1.2163e-02, -7.1051e-03, -7.2458e-03],\n",
      "          [-1.2624e-02, -1.1486e-03, -9.2241e-03,  1.5521e-02, -8.1535e-03],\n",
      "          [-1.0471e-02,  9.1920e-03,  5.9194e-03,  2.1546e-03,  9.4024e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.4723e-03, -1.6545e-02, -2.3791e-02,  2.0879e-02, -6.0135e-04],\n",
      "          [ 2.1118e-02, -5.8790e-03, -1.6062e-02, -1.5291e-02,  1.0582e-02],\n",
      "          [ 1.6207e-02, -2.1166e-03, -1.6086e-02,  4.5341e-03,  2.6197e-03],\n",
      "          [-1.8794e-02, -1.9051e-02,  1.4714e-02,  5.8995e-04, -1.1573e-02],\n",
      "          [-1.6816e-02,  2.4829e-02, -3.3651e-03, -2.4241e-02,  1.2910e-02]],\n",
      "\n",
      "         [[-2.2863e-02,  1.9855e-02, -2.4996e-02, -2.4659e-02,  1.1739e-02],\n",
      "          [-1.1570e-02,  2.4913e-02, -1.6691e-02,  7.8437e-03,  1.9472e-02],\n",
      "          [-1.0105e-02, -1.9567e-02,  4.7599e-03, -1.2115e-02,  1.9622e-03],\n",
      "          [-1.8778e-02, -1.2852e-02,  1.1944e-02,  1.5398e-02, -5.2098e-03],\n",
      "          [-8.3112e-03, -1.1670e-02,  6.5922e-03, -1.9854e-03,  9.2081e-03]],\n",
      "\n",
      "         [[ 1.5739e-02, -8.4915e-03,  2.1060e-02, -2.4535e-02,  9.7884e-03],\n",
      "          [ 1.9185e-02,  1.7552e-02, -5.2832e-03, -8.8893e-03,  2.1367e-02],\n",
      "          [ 1.4818e-02, -1.2460e-02, -2.3894e-02,  3.0820e-03, -9.0949e-03],\n",
      "          [ 1.6615e-02,  2.6909e-03, -1.2361e-02, -2.4634e-02,  2.4575e-02],\n",
      "          [ 1.9086e-02,  2.7945e-04, -1.4132e-02,  3.6376e-03,  1.2953e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2011e-02, -9.0717e-03,  1.2025e-02,  4.3307e-03,  7.8360e-03],\n",
      "          [-1.8373e-02,  1.8437e-02,  1.1901e-02,  8.6968e-03,  2.3685e-02],\n",
      "          [ 1.9903e-02, -8.9058e-03,  8.5469e-03, -2.2525e-03,  5.0791e-03],\n",
      "          [ 1.8156e-02, -1.4451e-02, -2.2569e-02, -6.5278e-03, -2.2570e-02],\n",
      "          [-1.5193e-03, -1.4292e-02, -1.5387e-02, -3.0215e-04,  9.8552e-03]],\n",
      "\n",
      "         [[ 1.6412e-02, -1.4216e-02,  3.2528e-03, -6.6629e-03,  1.8566e-02],\n",
      "          [ 7.2060e-03,  1.7311e-02,  2.4787e-02, -1.5025e-02,  6.9581e-03],\n",
      "          [ 2.3934e-02,  2.3159e-02,  1.4532e-02, -2.2962e-02,  5.3753e-03],\n",
      "          [ 2.1669e-02, -1.4845e-02,  2.3145e-02,  9.5230e-03, -7.9460e-03],\n",
      "          [ 3.9097e-03, -1.7817e-02, -1.5925e-02, -1.0125e-02,  8.7023e-03]],\n",
      "\n",
      "         [[-2.3372e-02, -1.6386e-03,  5.5887e-04,  9.6712e-03,  1.2422e-03],\n",
      "          [ 5.9452e-03,  2.0507e-03,  2.1907e-02,  2.0134e-03, -2.3404e-02],\n",
      "          [-1.7704e-02, -2.3253e-02, -1.0064e-02,  1.5241e-02,  1.4988e-02],\n",
      "          [ 1.2228e-02, -1.3733e-02,  8.9988e-03,  3.8819e-03, -9.5477e-03],\n",
      "          [ 6.8014e-03,  9.8998e-03, -2.4351e-02, -3.7968e-03, -5.3033e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4897e-02,  4.0549e-03,  1.5519e-02, -5.9242e-03,  9.4114e-04],\n",
      "          [-1.2511e-02, -1.0892e-02, -1.0969e-02,  2.0278e-02,  4.0244e-04],\n",
      "          [-1.8587e-03, -1.5385e-02, -7.0443e-03, -3.2147e-03, -1.3611e-02],\n",
      "          [-2.4788e-02, -8.9924e-03,  1.1628e-02,  1.1024e-02, -7.3888e-03],\n",
      "          [-4.7986e-03, -2.0825e-02,  1.4776e-02,  2.0797e-02,  1.8982e-02]],\n",
      "\n",
      "         [[-2.2603e-02,  6.9538e-03, -1.0368e-02, -2.4417e-02,  2.4648e-02],\n",
      "          [-2.2839e-02, -1.1587e-02, -9.5260e-04, -2.3238e-03, -8.8709e-03],\n",
      "          [-6.7515e-03, -1.9247e-02, -2.1166e-02, -4.0419e-03,  2.1975e-02],\n",
      "          [ 7.6190e-03, -1.1671e-02,  1.0645e-02,  1.3723e-02, -1.4802e-02],\n",
      "          [-2.3303e-02, -6.9443e-03, -1.5093e-02,  1.5234e-02,  5.0679e-03]],\n",
      "\n",
      "         [[-1.8136e-02,  2.0578e-02, -8.4094e-03,  2.0304e-02, -1.1608e-02],\n",
      "          [-3.6153e-03, -2.5491e-03,  8.0228e-03, -2.1459e-02, -2.1033e-02],\n",
      "          [ 1.3989e-02, -2.2799e-02, -2.2045e-02, -2.0549e-02, -1.9594e-02],\n",
      "          [ 1.4901e-02, -1.5433e-02, -1.6303e-02,  2.0011e-02,  6.8040e-03],\n",
      "          [ 3.6622e-03,  1.0807e-02,  2.4270e-02,  2.1053e-02, -2.2800e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4317e-02, -1.6254e-02, -1.2022e-02, -1.1684e-03, -5.1159e-03],\n",
      "          [ 2.1611e-02, -3.1277e-03,  2.1516e-02,  9.6149e-03,  1.7595e-02],\n",
      "          [-1.7559e-02,  1.6274e-02, -2.3873e-02, -2.2110e-02,  1.2431e-02],\n",
      "          [-5.8971e-03, -6.3174e-04,  1.3696e-02, -7.0865e-03,  2.4179e-03],\n",
      "          [-6.4915e-05, -2.2190e-02, -1.7177e-02, -1.2487e-02,  2.0457e-02]],\n",
      "\n",
      "         [[ 1.6861e-02, -2.2690e-02, -1.3309e-02,  1.5712e-02, -2.2709e-02],\n",
      "          [ 7.0406e-04,  9.1208e-03, -1.5855e-02, -1.3365e-02,  2.7120e-04],\n",
      "          [ 5.1871e-03,  9.7172e-03,  1.9986e-02, -9.1408e-03,  9.1688e-03],\n",
      "          [-1.3045e-02,  1.5634e-02, -3.7224e-03, -1.1318e-03, -2.0594e-02],\n",
      "          [ 1.3402e-02,  2.3791e-02, -1.1548e-02,  1.6958e-02, -2.3481e-02]],\n",
      "\n",
      "         [[-1.6407e-02, -8.9707e-03, -9.4380e-03, -4.0628e-03,  2.0789e-02],\n",
      "          [-1.2797e-02, -1.6945e-02,  3.5851e-03, -3.1787e-03,  2.0669e-02],\n",
      "          [ 8.3587e-04, -5.5232e-03,  2.0291e-02, -1.8468e-02,  2.9300e-03],\n",
      "          [-2.1988e-02,  4.3323e-03,  1.7540e-02, -1.7944e-02, -2.0903e-03],\n",
      "          [-9.5677e-03, -2.2737e-02,  2.2005e-02, -9.9083e-03,  1.6050e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-9.5253e-04, -1.7184e-02, -9.0526e-03, -1.8494e-02, -3.7239e-03],\n",
      "          [ 1.3347e-02,  1.8299e-02,  3.1131e-03,  1.2021e-02,  2.3237e-02],\n",
      "          [ 2.9445e-03,  3.2460e-04, -1.6147e-02,  8.0303e-03,  1.6057e-03],\n",
      "          [-1.6528e-02, -1.6507e-02, -2.0097e-02,  1.8403e-02, -3.1317e-03],\n",
      "          [ 6.2650e-04, -2.4983e-02, -2.1162e-02, -2.2252e-02, -4.9952e-03]],\n",
      "\n",
      "         [[-1.4173e-02,  1.6629e-02,  2.2385e-02,  1.6104e-03,  1.8862e-03],\n",
      "          [-2.2675e-02, -2.3712e-02,  6.6593e-04, -1.7657e-02, -1.9945e-02],\n",
      "          [-1.0659e-02, -1.6965e-02,  8.1904e-03, -2.1382e-02, -1.5504e-02],\n",
      "          [ 1.7517e-02, -2.0035e-02,  1.8529e-02, -1.4636e-02, -1.2565e-02],\n",
      "          [ 1.5236e-02, -2.9125e-03, -1.0946e-02,  2.1002e-02,  1.4319e-02]],\n",
      "\n",
      "         [[-1.4411e-02, -1.6953e-02,  5.7943e-03,  1.5881e-04, -1.4709e-02],\n",
      "          [-9.8784e-03,  1.6640e-02,  2.4447e-02, -4.8690e-03, -1.3988e-02],\n",
      "          [-7.6616e-03, -6.0965e-03,  1.1082e-02, -1.1776e-02, -4.1833e-03],\n",
      "          [ 1.2146e-02, -4.7096e-03, -2.4785e-02, -3.3194e-03, -9.1999e-03],\n",
      "          [ 2.7950e-03,  4.2957e-03,  1.3650e-02, -2.0658e-02,  8.4541e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0532e-02, -1.9046e-02, -1.2812e-02, -1.1928e-02,  2.2353e-02],\n",
      "          [ 2.4478e-02,  1.9943e-02,  7.7111e-03,  2.1974e-02,  2.2971e-02],\n",
      "          [-2.4548e-02, -5.5217e-03, -2.3716e-02,  2.3550e-04, -2.1669e-02],\n",
      "          [-2.1411e-02, -2.1383e-02, -1.0349e-02,  1.6643e-04,  1.1756e-02],\n",
      "          [ 2.3812e-02,  1.0225e-02, -2.3720e-02, -2.0318e-02,  1.5044e-02]],\n",
      "\n",
      "         [[ 1.1015e-02,  1.4812e-03, -1.1001e-02, -1.1400e-02, -5.9946e-03],\n",
      "          [ 2.4396e-02, -6.1276e-03, -1.6664e-02, -1.6033e-02, -1.8137e-02],\n",
      "          [-1.3856e-02,  8.8574e-03,  1.1773e-02, -1.3810e-03, -8.5089e-03],\n",
      "          [ 1.9474e-02,  1.2357e-02,  6.6452e-03, -1.7492e-02, -1.6250e-02],\n",
      "          [ 9.4025e-03, -1.6231e-02, -6.0568e-03, -5.7119e-03, -3.6087e-03]],\n",
      "\n",
      "         [[-2.0209e-02,  1.5932e-02, -1.9482e-02, -1.9925e-02,  3.4139e-03],\n",
      "          [ 4.2650e-03,  1.1035e-02, -7.3550e-03,  2.3222e-02,  2.1634e-02],\n",
      "          [-1.1448e-02,  7.9809e-03, -1.9075e-02,  1.0675e-02,  2.0131e-02],\n",
      "          [-6.2055e-03, -8.7644e-03, -8.0055e-03,  1.1571e-02, -1.1744e-02],\n",
      "          [ 6.9904e-03, -7.6576e-03,  1.8555e-02,  1.6165e-02,  2.1422e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1041e-02, -1.7023e-02, -1.0079e-02, -2.0053e-02, -1.7688e-02],\n",
      "          [-1.9447e-02,  2.1925e-02,  1.3842e-02, -1.5800e-02,  1.5368e-02],\n",
      "          [-1.0267e-02,  7.2304e-03,  1.2873e-04, -1.9805e-02, -1.8612e-02],\n",
      "          [-1.3842e-02, -1.4902e-02, -2.4453e-02,  2.4267e-02,  8.8176e-03],\n",
      "          [-1.8210e-02,  5.6438e-06,  2.3200e-02,  1.6877e-02, -3.1974e-03]],\n",
      "\n",
      "         [[ 5.6565e-03,  1.4252e-02,  1.4308e-02, -2.1544e-02,  1.6519e-02],\n",
      "          [ 9.1204e-03,  8.2610e-03, -2.3577e-02, -1.1016e-03, -2.0614e-03],\n",
      "          [-1.8547e-02, -3.0358e-04, -1.8418e-02, -1.6833e-02,  5.7921e-03],\n",
      "          [-1.3354e-02,  2.2164e-05,  1.7488e-02,  4.2279e-03, -2.2912e-02],\n",
      "          [-2.2117e-02,  1.9640e-03, -1.7943e-02, -3.9839e-03, -1.3049e-02]],\n",
      "\n",
      "         [[ 2.8186e-03, -1.0359e-03, -9.6767e-03, -1.5453e-02, -4.4607e-03],\n",
      "          [ 1.6343e-02,  7.3527e-03,  1.7558e-02, -6.1418e-03,  6.2957e-03],\n",
      "          [-7.8503e-03, -2.0668e-02,  1.1488e-02,  1.7473e-02, -1.4821e-02],\n",
      "          [ 5.9012e-03,  1.0083e-03, -2.9011e-03, -1.2400e-02,  2.2599e-02],\n",
      "          [-1.0967e-02,  7.3466e-03, -1.9431e-02,  1.9831e-02, -1.4970e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4919e-02,  8.6972e-03,  1.8333e-02,  1.4762e-02, -1.6453e-02],\n",
      "          [ 1.4609e-02, -1.6281e-02,  2.1528e-03,  1.6567e-02, -2.1079e-02],\n",
      "          [ 2.3386e-02,  1.1881e-02, -4.3133e-03, -1.5197e-02, -2.2392e-02],\n",
      "          [ 1.7533e-02,  1.0338e-02,  8.3606e-03,  5.8889e-03, -1.0936e-03],\n",
      "          [ 1.8927e-02,  1.9379e-02, -1.1215e-02,  3.0368e-03, -4.0200e-03]],\n",
      "\n",
      "         [[ 2.3076e-02, -4.4001e-03, -6.0984e-03,  1.2762e-02,  8.5319e-03],\n",
      "          [-7.2943e-03,  2.4113e-02,  1.1991e-02,  8.5800e-03, -1.3421e-02],\n",
      "          [ 4.9382e-03, -2.3848e-03,  1.5378e-02,  1.9750e-02,  3.8058e-03],\n",
      "          [-2.7063e-03, -3.0907e-03,  2.4284e-02,  6.9159e-03,  2.3737e-02],\n",
      "          [ 2.4113e-02,  9.6756e-03, -1.3461e-02, -1.9781e-02,  3.0529e-03]],\n",
      "\n",
      "         [[ 5.8131e-03,  1.7354e-02, -7.1066e-04,  2.2766e-02,  1.1333e-02],\n",
      "          [-2.8726e-04,  9.1684e-03,  1.0843e-02, -2.3407e-02, -1.1076e-02],\n",
      "          [ 1.5112e-02,  1.8528e-02, -1.5327e-02, -1.0890e-02,  1.9925e-03],\n",
      "          [ 1.1739e-02,  1.4831e-02, -2.0627e-02, -6.0683e-03, -1.1262e-02],\n",
      "          [ 1.7420e-02, -9.3298e-03,  7.0355e-04, -2.1126e-02, -1.8818e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.5981e-04,  2.2844e-02, -5.2918e-03,  1.7281e-02,  1.1156e-02],\n",
      "          [-1.7360e-02, -1.9601e-02,  2.1197e-02,  1.7800e-03,  2.2353e-02],\n",
      "          [-1.8755e-02,  4.2851e-03,  2.2748e-02,  3.9168e-03, -2.3177e-02],\n",
      "          [ 1.0759e-02, -2.4047e-02, -1.5575e-02, -2.4576e-03, -2.3657e-02],\n",
      "          [-8.3055e-03,  2.3693e-02, -5.1651e-03,  1.1793e-02, -3.7128e-03]],\n",
      "\n",
      "         [[ 2.2131e-02, -1.6155e-02, -1.2243e-02, -6.3936e-03,  1.9485e-02],\n",
      "          [-1.9629e-03, -1.9139e-02, -4.5871e-04, -1.8319e-02, -6.7197e-03],\n",
      "          [ 2.1125e-02,  1.8357e-02, -1.5882e-02, -9.5211e-03,  6.2137e-03],\n",
      "          [-1.1225e-02, -1.4421e-03, -2.1027e-02,  2.4778e-02, -3.5721e-03],\n",
      "          [ 2.1153e-02, -1.3095e-02,  1.2639e-02, -9.8881e-03, -1.3895e-02]],\n",
      "\n",
      "         [[-2.4861e-02, -1.8683e-02,  2.1192e-02,  1.4062e-02, -1.4344e-02],\n",
      "          [ 7.5593e-03,  4.2588e-03,  2.1984e-02, -1.7557e-02,  2.7395e-04],\n",
      "          [-1.1945e-02,  1.1506e-02, -1.0706e-02,  2.4414e-02, -9.4726e-03],\n",
      "          [ 1.3760e-02, -6.8209e-03,  1.4393e-02, -9.4808e-04, -2.0954e-02],\n",
      "          [-2.0660e-02, -1.2766e-02, -5.2187e-03,  4.2173e-03,  1.8513e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8650e-03,  8.2056e-03, -1.8578e-02,  8.8880e-03,  7.5796e-03],\n",
      "          [ 1.2672e-02,  1.4825e-02, -1.0504e-02, -6.4895e-03, -2.9285e-04],\n",
      "          [-2.4098e-02,  8.9437e-03, -8.5093e-03, -3.8796e-03, -8.2587e-03],\n",
      "          [-2.0581e-02,  1.5655e-02,  3.8387e-03, -1.2184e-02,  1.3163e-03],\n",
      "          [-1.5467e-02,  2.0702e-03, -3.2082e-03,  2.1269e-02,  1.3466e-02]],\n",
      "\n",
      "         [[-1.7035e-02,  1.8304e-02, -2.8921e-04,  2.3226e-02, -2.3540e-02],\n",
      "          [ 1.6679e-02, -1.9342e-02,  2.2752e-03, -9.6402e-04,  1.6131e-03],\n",
      "          [ 1.4635e-02, -2.3968e-02, -2.4273e-02, -3.5855e-03, -2.0434e-02],\n",
      "          [ 1.2367e-02, -7.1438e-03, -1.7048e-02, -2.3232e-02,  1.4412e-02],\n",
      "          [ 9.0347e-03,  6.8104e-03, -2.1935e-02, -7.9166e-03, -2.4697e-03]],\n",
      "\n",
      "         [[ 1.5785e-03,  1.7775e-02,  5.4630e-03, -1.7517e-02, -2.1193e-02],\n",
      "          [ 2.7082e-04, -1.3659e-02, -2.9756e-03, -1.2708e-03,  1.5863e-02],\n",
      "          [ 2.4473e-02, -2.4069e-02,  1.6090e-02, -2.2606e-02,  2.3961e-02],\n",
      "          [ 9.4908e-03, -1.1054e-02,  5.4705e-03,  5.5959e-03,  8.8580e-03],\n",
      "          [ 2.2012e-02,  2.4067e-02, -1.5969e-02, -2.7356e-03,  1.6726e-02]]]])\n",
      "conv_3.bias tensor([-0.0104, -0.0156, -0.0155,  0.0163,  0.0028,  0.0081, -0.0112,  0.0236,\n",
      "        -0.0116, -0.0100,  0.0084, -0.0005,  0.0070, -0.0216,  0.0184, -0.0224,\n",
      "        -0.0028, -0.0059,  0.0213,  0.0103, -0.0089, -0.0192,  0.0025, -0.0105,\n",
      "         0.0006, -0.0020,  0.0217,  0.0049,  0.0249, -0.0034,  0.0233, -0.0171,\n",
      "        -0.0143,  0.0032, -0.0154, -0.0016,  0.0081,  0.0200,  0.0191,  0.0032,\n",
      "         0.0032, -0.0240, -0.0234,  0.0204,  0.0111,  0.0176, -0.0082, -0.0008,\n",
      "         0.0130, -0.0204, -0.0174,  0.0123,  0.0022, -0.0241, -0.0204, -0.0098,\n",
      "         0.0157, -0.0067,  0.0014, -0.0193, -0.0144, -0.0001, -0.0038, -0.0124,\n",
      "        -0.0073,  0.0235, -0.0148, -0.0195,  0.0064,  0.0123,  0.0115, -0.0007,\n",
      "        -0.0107, -0.0197, -0.0159, -0.0233,  0.0228,  0.0039, -0.0103,  0.0166,\n",
      "         0.0061, -0.0233, -0.0202, -0.0221,  0.0018,  0.0178,  0.0236, -0.0081,\n",
      "         0.0168,  0.0196,  0.0248, -0.0145,  0.0236, -0.0073, -0.0230,  0.0196,\n",
      "         0.0198,  0.0088, -0.0010,  0.0074, -0.0007, -0.0004,  0.0142, -0.0051,\n",
      "        -0.0121, -0.0024, -0.0213, -0.0041, -0.0102,  0.0059, -0.0108,  0.0091,\n",
      "        -0.0081, -0.0199,  0.0112, -0.0053,  0.0084, -0.0012, -0.0002,  0.0199,\n",
      "        -0.0101,  0.0126, -0.0074,  0.0141,  0.0100, -0.0021, -0.0194,  0.0168])\n",
      "linear.weight tensor([[ 0.0872,  0.0229, -0.0353,  ...,  0.0867,  0.0306,  0.0438],\n",
      "        [-0.0173, -0.0832,  0.0866,  ...,  0.0780,  0.0295,  0.0621],\n",
      "        [ 0.0358, -0.0549, -0.0240,  ..., -0.0715, -0.0390, -0.0046],\n",
      "        ...,\n",
      "        [-0.0692,  0.0569,  0.0314,  ...,  0.0635,  0.0401,  0.0674],\n",
      "        [ 0.0379,  0.0376,  0.0486,  ...,  0.0583,  0.0419,  0.0411],\n",
      "        [ 0.0291,  0.0882, -0.0151,  ...,  0.0684,  0.0411,  0.0375]])\n",
      "linear.bias tensor([-0.0466,  0.0408, -0.0507, -0.0386,  0.0752,  0.0204,  0.0634,  0.0435,\n",
      "         0.0252, -0.0155])\n"
     ]
    }
   ],
   "source": [
    "for k in LeNet.learnable_parameter:\n",
    "    print(k, LeNet.learnable_parameter[k].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4dd62a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257802"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in LeNet.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb107d",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "faec08f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet3(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block2): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block3): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_bc_40_12 = create_densenet_model('DenseNet', 40, 12, 0.5, True, 0.0).to(device)\n",
    "densenet_bc_40_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "482eceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([24, 3, 3, 3])\n",
      "block1.layer.0.bn1.weight torch.Size([24])\n",
      "block1.layer.0.bn1.bias torch.Size([24])\n",
      "block1.layer.0.conv1.weight torch.Size([48, 24, 1, 1])\n",
      "block1.layer.0.bn2.weight torch.Size([48])\n",
      "block1.layer.0.bn2.bias torch.Size([48])\n",
      "block1.layer.0.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.1.bn1.weight torch.Size([36])\n",
      "block1.layer.1.bn1.bias torch.Size([36])\n",
      "block1.layer.1.conv1.weight torch.Size([48, 36, 1, 1])\n",
      "block1.layer.1.bn2.weight torch.Size([48])\n",
      "block1.layer.1.bn2.bias torch.Size([48])\n",
      "block1.layer.1.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.2.bn1.weight torch.Size([48])\n",
      "block1.layer.2.bn1.bias torch.Size([48])\n",
      "block1.layer.2.conv1.weight torch.Size([48, 48, 1, 1])\n",
      "block1.layer.2.bn2.weight torch.Size([48])\n",
      "block1.layer.2.bn2.bias torch.Size([48])\n",
      "block1.layer.2.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.3.bn1.weight torch.Size([60])\n",
      "block1.layer.3.bn1.bias torch.Size([60])\n",
      "block1.layer.3.conv1.weight torch.Size([48, 60, 1, 1])\n",
      "block1.layer.3.bn2.weight torch.Size([48])\n",
      "block1.layer.3.bn2.bias torch.Size([48])\n",
      "block1.layer.3.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.4.bn1.weight torch.Size([72])\n",
      "block1.layer.4.bn1.bias torch.Size([72])\n",
      "block1.layer.4.conv1.weight torch.Size([48, 72, 1, 1])\n",
      "block1.layer.4.bn2.weight torch.Size([48])\n",
      "block1.layer.4.bn2.bias torch.Size([48])\n",
      "block1.layer.4.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.5.bn1.weight torch.Size([84])\n",
      "block1.layer.5.bn1.bias torch.Size([84])\n",
      "block1.layer.5.conv1.weight torch.Size([48, 84, 1, 1])\n",
      "block1.layer.5.bn2.weight torch.Size([48])\n",
      "block1.layer.5.bn2.bias torch.Size([48])\n",
      "block1.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "trans1.bn1.weight torch.Size([96])\n",
      "trans1.bn1.bias torch.Size([96])\n",
      "trans1.conv1.weight torch.Size([48, 96, 1, 1])\n",
      "block2.layer.0.bn1.weight torch.Size([48])\n",
      "block2.layer.0.bn1.bias torch.Size([48])\n",
      "block2.layer.0.conv1.weight torch.Size([48, 48, 1, 1])\n",
      "block2.layer.0.bn2.weight torch.Size([48])\n",
      "block2.layer.0.bn2.bias torch.Size([48])\n",
      "block2.layer.0.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.1.bn1.weight torch.Size([60])\n",
      "block2.layer.1.bn1.bias torch.Size([60])\n",
      "block2.layer.1.conv1.weight torch.Size([48, 60, 1, 1])\n",
      "block2.layer.1.bn2.weight torch.Size([48])\n",
      "block2.layer.1.bn2.bias torch.Size([48])\n",
      "block2.layer.1.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.2.bn1.weight torch.Size([72])\n",
      "block2.layer.2.bn1.bias torch.Size([72])\n",
      "block2.layer.2.conv1.weight torch.Size([48, 72, 1, 1])\n",
      "block2.layer.2.bn2.weight torch.Size([48])\n",
      "block2.layer.2.bn2.bias torch.Size([48])\n",
      "block2.layer.2.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.3.bn1.weight torch.Size([84])\n",
      "block2.layer.3.bn1.bias torch.Size([84])\n",
      "block2.layer.3.conv1.weight torch.Size([48, 84, 1, 1])\n",
      "block2.layer.3.bn2.weight torch.Size([48])\n",
      "block2.layer.3.bn2.bias torch.Size([48])\n",
      "block2.layer.3.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.4.bn1.weight torch.Size([96])\n",
      "block2.layer.4.bn1.bias torch.Size([96])\n",
      "block2.layer.4.conv1.weight torch.Size([48, 96, 1, 1])\n",
      "block2.layer.4.bn2.weight torch.Size([48])\n",
      "block2.layer.4.bn2.bias torch.Size([48])\n",
      "block2.layer.4.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.5.bn1.weight torch.Size([108])\n",
      "block2.layer.5.bn1.bias torch.Size([108])\n",
      "block2.layer.5.conv1.weight torch.Size([48, 108, 1, 1])\n",
      "block2.layer.5.bn2.weight torch.Size([48])\n",
      "block2.layer.5.bn2.bias torch.Size([48])\n",
      "block2.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "trans2.bn1.weight torch.Size([120])\n",
      "trans2.bn1.bias torch.Size([120])\n",
      "trans2.conv1.weight torch.Size([60, 120, 1, 1])\n",
      "block3.layer.0.bn1.weight torch.Size([60])\n",
      "block3.layer.0.bn1.bias torch.Size([60])\n",
      "block3.layer.0.conv1.weight torch.Size([48, 60, 1, 1])\n",
      "block3.layer.0.bn2.weight torch.Size([48])\n",
      "block3.layer.0.bn2.bias torch.Size([48])\n",
      "block3.layer.0.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.1.bn1.weight torch.Size([72])\n",
      "block3.layer.1.bn1.bias torch.Size([72])\n",
      "block3.layer.1.conv1.weight torch.Size([48, 72, 1, 1])\n",
      "block3.layer.1.bn2.weight torch.Size([48])\n",
      "block3.layer.1.bn2.bias torch.Size([48])\n",
      "block3.layer.1.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.2.bn1.weight torch.Size([84])\n",
      "block3.layer.2.bn1.bias torch.Size([84])\n",
      "block3.layer.2.conv1.weight torch.Size([48, 84, 1, 1])\n",
      "block3.layer.2.bn2.weight torch.Size([48])\n",
      "block3.layer.2.bn2.bias torch.Size([48])\n",
      "block3.layer.2.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.3.bn1.weight torch.Size([96])\n",
      "block3.layer.3.bn1.bias torch.Size([96])\n",
      "block3.layer.3.conv1.weight torch.Size([48, 96, 1, 1])\n",
      "block3.layer.3.bn2.weight torch.Size([48])\n",
      "block3.layer.3.bn2.bias torch.Size([48])\n",
      "block3.layer.3.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.4.bn1.weight torch.Size([108])\n",
      "block3.layer.4.bn1.bias torch.Size([108])\n",
      "block3.layer.4.conv1.weight torch.Size([48, 108, 1, 1])\n",
      "block3.layer.4.bn2.weight torch.Size([48])\n",
      "block3.layer.4.bn2.bias torch.Size([48])\n",
      "block3.layer.4.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.5.bn1.weight torch.Size([120])\n",
      "block3.layer.5.bn1.bias torch.Size([120])\n",
      "block3.layer.5.conv1.weight torch.Size([48, 120, 1, 1])\n",
      "block3.layer.5.bn2.weight torch.Size([48])\n",
      "block3.layer.5.bn2.bias torch.Size([48])\n",
      "block3.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "bn1.weight torch.Size([132])\n",
      "bn1.bias torch.Size([132])\n",
      "fc.weight torch.Size([10, 132])\n",
      "fc.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k, w in densenet_bc_40_12.named_parameters():\n",
    "    print(k, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_checkpoint = 'toy/experiments/densenet_bc_40_12_baseline/densenet_bc_40_12_cifar10_baseline_best.pth'\n",
    "densenet_checkpoint = torch.load(densenet_checkpoint, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95481ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_bc_40_12.load_state_dict(densenet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbecce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 157/157 [00:04<00:00, 38.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on DenseNet-BC-40-12, Validation Loss: 0.2863, Validation Accuracy: 93.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = validate(densenet_bc_40_12, val_loader, criterion, device=device)\n",
    "print(f\"Test on DenseNet-BC-40-12, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c26eadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_bc_40_12_test = copy.deepcopy(densenet_bc_40_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4a57c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 157/157 [00:03<00:00, 40.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on DenseNet-BC-40-12, Validation Loss: 0.2863, Validation Accuracy: 93.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = validate(densenet_bc_40_12_test, val_loader, criterion, device=device)\n",
    "print(f\"Test on DenseNet-BC-40-12, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9460bc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176122"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in densenet_bc_40_12.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34b0450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_module(densenet_bc_40_12_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "340159f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 157/157 [00:03<00:00, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on DenseNet-BC-40-12, Validation Loss: 0.2863, Validation Accuracy: 93.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = validate(densenet_bc_40_12_test, val_loader, criterion, device=device)\n",
    "print(f\"Test on DenseNet-BC-40-12, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd95012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet3(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block2): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block3): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_bc_40_12_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3263beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([24, 3, 3, 3])\n",
      "block1.layer.0.bn1.weight torch.Size([24])\n",
      "block1.layer.0.bn1.bias torch.Size([24])\n",
      "block1.layer.0.conv1.weight torch.Size([48, 24, 1, 1])\n",
      "block1.layer.0.conv1.bias torch.Size([48])\n",
      "block1.layer.0.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.1.bn1.weight torch.Size([36])\n",
      "block1.layer.1.bn1.bias torch.Size([36])\n",
      "block1.layer.1.conv1.weight torch.Size([48, 36, 1, 1])\n",
      "block1.layer.1.conv1.bias torch.Size([48])\n",
      "block1.layer.1.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.2.bn1.weight torch.Size([48])\n",
      "block1.layer.2.bn1.bias torch.Size([48])\n",
      "block1.layer.2.conv1.weight torch.Size([48, 48, 1, 1])\n",
      "block1.layer.2.conv1.bias torch.Size([48])\n",
      "block1.layer.2.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.3.bn1.weight torch.Size([60])\n",
      "block1.layer.3.bn1.bias torch.Size([60])\n",
      "block1.layer.3.conv1.weight torch.Size([48, 60, 1, 1])\n",
      "block1.layer.3.conv1.bias torch.Size([48])\n",
      "block1.layer.3.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.4.bn1.weight torch.Size([72])\n",
      "block1.layer.4.bn1.bias torch.Size([72])\n",
      "block1.layer.4.conv1.weight torch.Size([48, 72, 1, 1])\n",
      "block1.layer.4.conv1.bias torch.Size([48])\n",
      "block1.layer.4.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block1.layer.5.bn1.weight torch.Size([84])\n",
      "block1.layer.5.bn1.bias torch.Size([84])\n",
      "block1.layer.5.conv1.weight torch.Size([48, 84, 1, 1])\n",
      "block1.layer.5.conv1.bias torch.Size([48])\n",
      "block1.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "trans1.bn1.weight torch.Size([96])\n",
      "trans1.bn1.bias torch.Size([96])\n",
      "trans1.conv1.weight torch.Size([48, 96, 1, 1])\n",
      "block2.layer.0.bn1.weight torch.Size([48])\n",
      "block2.layer.0.bn1.bias torch.Size([48])\n",
      "block2.layer.0.conv1.weight torch.Size([48, 48, 1, 1])\n",
      "block2.layer.0.conv1.bias torch.Size([48])\n",
      "block2.layer.0.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.1.bn1.weight torch.Size([60])\n",
      "block2.layer.1.bn1.bias torch.Size([60])\n",
      "block2.layer.1.conv1.weight torch.Size([48, 60, 1, 1])\n",
      "block2.layer.1.conv1.bias torch.Size([48])\n",
      "block2.layer.1.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.2.bn1.weight torch.Size([72])\n",
      "block2.layer.2.bn1.bias torch.Size([72])\n",
      "block2.layer.2.conv1.weight torch.Size([48, 72, 1, 1])\n",
      "block2.layer.2.conv1.bias torch.Size([48])\n",
      "block2.layer.2.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.3.bn1.weight torch.Size([84])\n",
      "block2.layer.3.bn1.bias torch.Size([84])\n",
      "block2.layer.3.conv1.weight torch.Size([48, 84, 1, 1])\n",
      "block2.layer.3.conv1.bias torch.Size([48])\n",
      "block2.layer.3.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.4.bn1.weight torch.Size([96])\n",
      "block2.layer.4.bn1.bias torch.Size([96])\n",
      "block2.layer.4.conv1.weight torch.Size([48, 96, 1, 1])\n",
      "block2.layer.4.conv1.bias torch.Size([48])\n",
      "block2.layer.4.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block2.layer.5.bn1.weight torch.Size([108])\n",
      "block2.layer.5.bn1.bias torch.Size([108])\n",
      "block2.layer.5.conv1.weight torch.Size([48, 108, 1, 1])\n",
      "block2.layer.5.conv1.bias torch.Size([48])\n",
      "block2.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "trans2.bn1.weight torch.Size([120])\n",
      "trans2.bn1.bias torch.Size([120])\n",
      "trans2.conv1.weight torch.Size([60, 120, 1, 1])\n",
      "block3.layer.0.bn1.weight torch.Size([60])\n",
      "block3.layer.0.bn1.bias torch.Size([60])\n",
      "block3.layer.0.conv1.weight torch.Size([48, 60, 1, 1])\n",
      "block3.layer.0.conv1.bias torch.Size([48])\n",
      "block3.layer.0.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.1.bn1.weight torch.Size([72])\n",
      "block3.layer.1.bn1.bias torch.Size([72])\n",
      "block3.layer.1.conv1.weight torch.Size([48, 72, 1, 1])\n",
      "block3.layer.1.conv1.bias torch.Size([48])\n",
      "block3.layer.1.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.2.bn1.weight torch.Size([84])\n",
      "block3.layer.2.bn1.bias torch.Size([84])\n",
      "block3.layer.2.conv1.weight torch.Size([48, 84, 1, 1])\n",
      "block3.layer.2.conv1.bias torch.Size([48])\n",
      "block3.layer.2.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.3.bn1.weight torch.Size([96])\n",
      "block3.layer.3.bn1.bias torch.Size([96])\n",
      "block3.layer.3.conv1.weight torch.Size([48, 96, 1, 1])\n",
      "block3.layer.3.conv1.bias torch.Size([48])\n",
      "block3.layer.3.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.4.bn1.weight torch.Size([108])\n",
      "block3.layer.4.bn1.bias torch.Size([108])\n",
      "block3.layer.4.conv1.weight torch.Size([48, 108, 1, 1])\n",
      "block3.layer.4.conv1.bias torch.Size([48])\n",
      "block3.layer.4.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "block3.layer.5.bn1.weight torch.Size([120])\n",
      "block3.layer.5.bn1.bias torch.Size([120])\n",
      "block3.layer.5.conv1.weight torch.Size([48, 120, 1, 1])\n",
      "block3.layer.5.conv1.bias torch.Size([48])\n",
      "block3.layer.5.conv2.weight torch.Size([12, 48, 3, 3])\n",
      "bn1.weight torch.Size([132])\n",
      "bn1.bias torch.Size([132])\n",
      "fc.weight torch.Size([10, 132])\n",
      "fc.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k, w in densenet_bc_40_12_test.named_parameters():\n",
    "    print (k, w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb947a08",
   "metadata": {},
   "source": [
    "> Above shows that DenseNet still works even after it has been fuse_model, and fuse_model also worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "392b5d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175258"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in densenet_bc_40_12_test.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c88b6f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet3(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block2): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionBlock(\n",
       "    (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Conv2d(120, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (block3): DenseBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): BottleneckBlock(\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=132, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_bc_40_12_test_smooth = copy.deepcopy(densenet_bc_40_12_test)\n",
    "densenet_bc_40_12_test_smooth.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17901ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 157/157 [00:03<00:00, 41.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on DenseNet-BC-40-12, Validation Loss: 0.2863, Validation Accuracy: 93.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = validate(densenet_bc_40_12_test_smooth, val_loader, criterion, device=device)\n",
    "print(f\"Test on DenseNet-BC-40-12, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4cd01453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old TV original model: 428.705078125\n"
     ]
    }
   ],
   "source": [
    "print(f'Old TV original model: {compute_tv_loss_for_network(densenet_bc_40_12_test_smooth, lambda_tv=1.0).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8689283",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 3, 32, 32).to(device)\n",
    "permute_func = PermutationManager(densenet_bc_40_12_test_smooth, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3e63719",
   "metadata": {},
   "outputs": [],
   "source": [
    "permute_dict = permute_func.compute_permute_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95332304",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_bc_40_12_smooth = permute_func.apply_permutations(permute_dict, ignored_keys=[\n",
    "    ('conv1.weight', 'in_channels'),\n",
    "    ('fc.weight', 'out_channels'),\n",
    "    ('fc.bias', 'out_channels')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b018c6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old TV original model: 394.69140625\n"
     ]
    }
   ],
   "source": [
    "print(f'Old TV original model: {compute_tv_loss_for_network(densenet_bc_40_12_smooth, lambda_tv=1.0).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e71abf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 157/157 [00:03<00:00, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on DenseNet-BC-40-12, Validation Loss: 0.2863, Validation Accuracy: 93.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = validate(densenet_bc_40_12_smooth, val_loader, criterion, device=device)\n",
    "print(f\"Test on DenseNet-BC-40-12, Validation Loss: {val_loss:.4f}, Validation Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10222635",
   "metadata": {},
   "source": [
    "> Prove that the model can still worked well even after it has been smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "532db259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175258"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in densenet_bc_40_12_smooth.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
